{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "As other nltk versions exist some bugs in calculating bleu, the the experiment should be ran in nltk 3.6.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-26T05:27:40.269389Z",
     "start_time": "2021-04-26T05:27:36.076141Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install nltk==3.6.1\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The result of different combinations on $TLC_{Dedup}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## utils function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:02:11.886727Z",
     "start_time": "2021-08-28T12:02:05.036370Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../metrics\")\n",
    "from metrics.evaluate import read_to_list\n",
    "from metrics.evaluate import read_to_list\n",
    "from bleu.codenn_bleu import codenn_smooth_bleu\n",
    "from bleu.codenn_bleu import codenn_smooth_bleu\n",
    "from bleu.google_bleu import compute_bleu\n",
    "from bleu.rencos_bleu import Bleu as recos_bleu\n",
    "import prettytable as pt\n",
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:02:11.909850Z",
     "start_time": "2021-08-28T12:02:11.889664Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_mean_std(arr):\n",
    "    arr_mean = np.mean(arr)\n",
    "    arr_std = np.std(arr, ddof=1)\n",
    "    return arr_mean ,  arr_std\n",
    "def show_dict(all_bleu):\n",
    "        tb = pt.PrettyTable()\n",
    "        tb.field_names = all_bleu.keys()\n",
    "        tb.add_row(all_bleu.values())\n",
    "        print(tb)\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction        \n",
    "def get_codenn_score(refs, preds):\n",
    "    r_str_list = []\n",
    "    p_str_list = []\n",
    "    for r, p in zip(refs, preds):\n",
    "        if len(r[0]) == 0 or len(p) == 0:\n",
    "            continue\n",
    "        r_str_list.append([\" \".join([str(token_id) for token_id in r[0]])])\n",
    "        p_str_list.append(\" \".join([str(token_id) for token_id in p]))\n",
    "    try:\n",
    "        bleu_list = codenn_smooth_bleu(r_str_list, p_str_list)\n",
    "    except:\n",
    "        bleu_list = [0, 0, 0, 0]\n",
    "    codenn_bleu = bleu_list[0]\n",
    "    codenn_bleu = round(codenn_bleu,4)\n",
    "    return codenn_bleu\n",
    "def get_bleu_dm(refs,preds):\n",
    "    sentence_bleu0 = [sentence_bleu(ref, pred) for ref, pred in zip(refs, preds)]\n",
    "    sentence_bleu0 = np.mean(sentence_bleu0)\n",
    "    sentence_bleu0 = round(sentence_bleu0 * 100, 4)\n",
    "    return sentence_bleu0 \n",
    "def get_bleu_fc(refs,preds):\n",
    "    c_bleu4 = corpus_bleu(refs, preds, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    c_bleu4 = round(c_bleu4 * 100, 4)\n",
    "    return   c_bleu4\n",
    "def get_bleu_dc(refs,preds):\n",
    "    all_score = 0.0\n",
    "    count = 0\n",
    "    for r, p in zip(refs, preds):\n",
    "        # nltk bug: https://github.com/nltk/nltk/issues/2204\n",
    "        if len(p) == 1:\n",
    "            continue\n",
    "        score = nltk.translate.bleu(r, p, smoothing_function=SmoothingFunction().method4)\n",
    "        all_score += score\n",
    "        count += 1\n",
    "    emse_bleu = round(all_score / count * 100, 4)\n",
    "    return emse_bleu\n",
    "def get_bleu_cn(refs,preds):\n",
    "    r_str_list = []\n",
    "    p_str_list = []\n",
    "    for r, p in zip(refs, preds):\n",
    "        if len(r[0]) == 0 or len(p) == 0:\n",
    "            continue\n",
    "        r_str_list.append([\" \".join([str(token_id) for token_id in r[0]])])\n",
    "        p_str_list.append(\" \".join([str(token_id) for token_id in p]))\n",
    "    try:\n",
    "        bleu_list = codenn_smooth_bleu(r_str_list, p_str_list)\n",
    "    except:\n",
    "        bleu_list = [0, 0, 0, 0]\n",
    "    codenn_bleu = bleu_list[0]\n",
    "    codenn_bleu = round(codenn_bleu,4)\n",
    "    return codenn_bleu\n",
    "def get_bleu_ncs(refs,preds):\n",
    "    google_bleu4 = [compute_bleu([ref], [pred], smooth=True)[0] for ref, pred in zip(refs, preds)]\n",
    "    google_bleu4 = np.mean(google_bleu4)\n",
    "    google_bleu4 = round(google_bleu4 * 100, 4)\n",
    "    return google_bleu4\n",
    "def get_bleu_rc(refs,preds):\n",
    "    res = {k: [\" \".join(v)] for k, v in enumerate(preds)}\n",
    "    gts = {k: [\" \".join(v[0])] for k, v in enumerate(refs)}\n",
    "    _, scores_Bleu = recos_bleu(4).compute_score(gts, res)\n",
    "    rencos_bleu4 =round(np.mean(scores_Bleu[3])*100, 4)\n",
    "    return rencos_bleu4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:02:11.918050Z",
     "start_time": "2021-08-28T12:02:11.912531Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_diff_combination_scores(approaches,data_dir,refs_filename,get_bleu_score):\n",
    "    for approach in approaches:\n",
    "        combination_result_dict = {}\n",
    "        latex_diff_combination_result = {}\n",
    "        for combination in all_data_processing_combinations:\n",
    "#             refs_filename = os.path.join(data_dir, approach, combination,\"test.gold\")\n",
    "            preds_filename = os.path.join(data_dir, approach,combination, \"test.pred\")\n",
    "            preds = read_to_list(preds_filename)\n",
    "            refs = read_to_list(refs_filename)\n",
    "            refs = [[t] for t in refs[:len( preds)]]\n",
    "            codenn_bleu = get_bleu_score(refs, preds)\n",
    "            combination_result_dict[combination] = codenn_bleu\n",
    "#             latex_diff_combination_result[combination] = \"&%.2f \"%codenn_bleu\n",
    "        all_bleu = {key:round(value, 2) for key, value in combination_result_dict.items()}\n",
    "        tb = pt.PrettyTable()\n",
    "        tb.field_names = all_bleu.keys()\n",
    "        tb.add_row(all_bleu.values())\n",
    "        print(30*\"*\")\n",
    "        print(approach)\n",
    "#         print(\" \".join(list(latex_diff_combination_result.values())))\n",
    "        print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:02:11.923003Z",
     "start_time": "2021-08-28T12:02:11.920282Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = \"data_processing_result\"\n",
    "refs_filename = os.path.join(data_dir,\"test.gold\")\n",
    "approaches = [\"codenn\", \"astattgru\", \"rencos\", \"ncs\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:02:11.928107Z",
     "start_time": "2021-08-28T12:02:11.924939Z"
    }
   },
   "outputs": [],
   "source": [
    "all_data_processing_combinations = ['P0000', 'P0001', 'P0010', 'P0011', 'P0100', 'P0101', 'P0110', 'P0111', 'P1000', 'P1001', 'P1010', 'P1011', 'P1100', 'P1101', 'P1110', 'P1111']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:03:15.061936Z",
     "start_time": "2021-08-28T12:02:11.929821Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "codenn\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| P0000 | P0001 | P0010 | P0011 | P0100 | P0101 | P0110 | P0111 | P1000 | P1001 | P1010 | P1011 | P1100 | P1101 | P1110 | P1111 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  7.06 |  7.1  |  6.98 |  7.25 |  7.54 |  7.01 |  7.43 |  7.06 |  7.22 |  7.19 |  7.24 |  7.4  |  7.06 |  7.34 |  7.02 |  7.05 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "******************************\n",
      "astattgru\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| P0000 | P0001 | P0010 | P0011 | P0100 | P0101 | P0110 | P0111 | P1000 | P1001 | P1010 | P1011 | P1100 | P1101 | P1110 | P1111 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  5.67 |  5.65 |  5.44 |  5.48 |  6.17 |  6.67 |  6.28 |  6.41 |  5.84 |  5.83 |  5.3  |  5.81 |  5.79 |  6.62 |  6.03 |  6.09 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "******************************\n",
      "rencos\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| P0000 | P0001 | P0010 | P0011 | P0100 | P0101 | P0110 | P0111 | P1000 | P1001 | P1010 | P1011 | P1100 | P1101 | P1110 | P1111 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| 20.21 | 20.35 | 21.28 | 21.01 | 21.52 | 23.37 | 22.25 | 22.45 | 20.91 | 20.96 |  21.2 | 21.33 | 21.42 | 24.21 | 22.62 | 22.15 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "******************************\n",
      "ncs\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| P0000 | P0001 | P0010 | P0011 | P0100 | P0101 | P0110 | P0111 | P1000 | P1001 | P1010 | P1011 | P1100 | P1101 | P1110 | P1111 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| 11.22 | 11.95 | 11.12 | 12.07 | 12.06 |  13.3 | 12.12 | 12.82 | 11.87 | 11.51 | 11.78 | 11.64 | 12.34 | 13.67 | 12.09 | 12.67 |\n",
      "+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "get_diff_combination_scores(approaches ,data_dir,refs_filename,get_bleu_dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## significant test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:03:15.076021Z",
     "start_time": "2021-08-28T12:03:15.063592Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "def get_four_operations(data):\n",
    "    r0 = data[8:]\n",
    "    r1 = data[:8]\n",
    "    s0 = data[:4] + data[8:12]\n",
    "    s1 = data[4:8] + data[12:]\n",
    "    f0 = [data[i] for i in [2, 3, 6, 7, 10, 11, 14, 15]]\n",
    "    f1 = [data[i] for i in [0, 1, 4, 5, 8, 9, 12, 13]]\n",
    "    l0 = [data[2 * i] for i in range(8)]\n",
    "    l1 = [data[2 * i + 1] for i in range(8)]\n",
    "    return r0, r1, s0, s1, f0, f1, l0, l1\n",
    "\n",
    "\n",
    "def get_t_test_and_MWW_test(approach_data):\n",
    "    r0, r1, s0, s1, f0, f1, l0, l1 = [], [], [], [], [], [], [], []\n",
    "    x1_new, r1_new, s0_new, s1_new, f0_new, f1_new, l0_new, l1_new = get_four_operations(approach_data)\n",
    "    r0.extend(x1_new) \n",
    "    r1.extend(r1_new)\n",
    "    s0.extend(s0_new)\n",
    "    s1.extend(s1_new)\n",
    "    f0.extend(f0_new)\n",
    "    f1.extend(f1_new)\n",
    "    l0.extend(l0_new)\n",
    "    l1.extend(l1_new)\n",
    "    p_val_t_dict = {} \n",
    "    p_mwu_val_dict = {} \n",
    "    avg = {\"R0\":np.mean(r0), \"R1\":np.mean(r1),\"S0\":np.mean(s0),\"S1\":np.mean(s1),\n",
    "           \"F0\":np.mean(f0),\"F1\":np.mean(f1),\"L0\":np.mean(l0),\"L1\":np.mean(l1),}\n",
    "    avg = {key:str(round(item,2))  for key,item in avg.items()}\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.field_names = avg.keys()\n",
    "    tb.add_row(avg.values())\n",
    "    print(tb)\n",
    "#     print(\"& \".join(list(avg.values())))\n",
    "    # R \n",
    "    _, p_val_t_test = stats.ttest_ind(r0, r1, equal_var=False)\n",
    "    _, p_val_wwu_test = stats.mannwhitneyu(r0, r1, alternative='two-sided') \n",
    "    p_val_t_dict[\"R\"] = \"%.4f\" % p_val_t_test \n",
    "    p_mwu_val_dict[\"R\"] = \"%.4f\" % p_val_wwu_test\n",
    "    # S\n",
    "    _, p_val_t_test = stats.ttest_ind(s0, s1, equal_var=False)\n",
    "    _, p_val_wwu_test = stats.mannwhitneyu(s0, s1, alternative='two-sided')\n",
    "    p_val_t_dict[\"S\"]= \"%.4f\" % p_val_t_test\n",
    "    p_mwu_val_dict[\"S\"] =\"%.4f\" % p_val_wwu_test\n",
    "    # F\n",
    "    _, p_val_t_test = stats.ttest_ind(f0, f1, equal_var=False)\n",
    "    _, p_val_wwu_test = stats.mannwhitneyu(f0, f1, alternative='two-sided')\n",
    "    p_val_t_dict[\"F\"] =\"%.4f\" % p_val_t_test\n",
    "    p_mwu_val_dict[\"F\"] = \"%.4f\" % p_val_wwu_test\n",
    "    # L\n",
    "    _, p_val_t_test = stats.ttest_ind(l0, l1, equal_var=False)\n",
    "    _, p_val_wwu_test = stats.mannwhitneyu(l0, l1, alternative='two-sided')\n",
    "    p_val_t_dict[\"L\"] = \"%.4f\" % p_val_t_test\n",
    "    p_mwu_val_dict[\"L\"] = \"%.4f\" % p_val_wwu_test\n",
    "    \n",
    "    print(\"t-test\")\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.field_names = p_val_t_dict.keys()\n",
    "    tb.add_row(p_val_t_dict.values())\n",
    "    print(tb)\n",
    "#     print(\"& \".join(list(p_val_t_dict.values())))\n",
    "    \n",
    "    print(\"WMW-test \")\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.field_names = p_mwu_val_dict.keys()\n",
    "    tb.add_row(p_mwu_val_dict.values())\n",
    "    print(tb)    \n",
    "#     print(\"& \" + \"& \".join(list(p_mwu_val_dict.values())))\n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:03:15.082703Z",
     "start_time": "2021-08-28T12:03:15.078448Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_diff_combination_scores_and_significant_test(approaches ,data_dir, refs_filename,get_bleu_score):\n",
    "    all_approaches_result = {}\n",
    "    for approach in approaches:\n",
    "        combination_result_dict = {}\n",
    "        latex_diff_combination_result = []\n",
    "        for combination in all_data_processing_combinations:\n",
    "#             refs_filename = os.path.join(data_dir, approach, combination,\"test.gold\")\n",
    "            preds_filename = os.path.join(data_dir, approach,combination, \"test.pred\")\n",
    "            preds = read_to_list(preds_filename)\n",
    "            refs = read_to_list(refs_filename)\n",
    "            refs = [[t] for t in refs[:len( preds)]]\n",
    "            codenn_bleu = get_bleu_score(refs, preds)\n",
    "            combination_result_dict[combination] = codenn_bleu\n",
    "            latex_diff_combination_result.append(round(codenn_bleu,2))\n",
    "        all_bleu = {key:round(value, 4) for key, value in combination_result_dict.items()}\n",
    "        print(30*\"*\")\n",
    "        print(approach)\n",
    "        get_t_test_and_MWW_test(list(all_bleu.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:04:07.186312Z",
     "start_time": "2021-08-28T12:03:15.084242Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "codenn\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  R0  |  R1  |  S0  |  S1  |  F0  |  F1  |  L0  |  L1  |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 7.19 | 7.18 | 7.18 | 7.19 | 7.18 | 7.19 | 7.19 | 7.18 |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "t-test\n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.9272 | 0.8950 | 0.9098 | 0.8370 |\n",
      "+--------+--------+--------+--------+\n",
      "WMW-test \n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.9581 | 0.7929 | 0.9581 | 0.9581 |\n",
      "+--------+--------+--------+--------+\n",
      "******************************\n",
      "astattgru\n",
      "+------+------+------+------+------+------+------+------+\n",
      "|  R0  |  R1  |  S0  |  S1  |  F0  |  F1  |  L0  |  L1  |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "| 5.91 | 5.97 | 5.63 | 6.26 | 5.85 | 6.03 | 5.81 | 6.07 |\n",
      "+------+------+------+------+------+------+------+------+\n",
      "t-test\n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.7846 | 0.0003 | 0.4086 | 0.2233 |\n",
      "+--------+--------+--------+--------+\n",
      "WMW-test \n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.9581 | 0.0028 | 0.4948 | 0.3184 |\n",
      "+--------+--------+--------+--------+\n",
      "******************************\n",
      "rencos\n",
      "+-------+-------+-------+------+-------+-------+-------+-------+\n",
      "|   R0  |   R1  |   S0  |  S1  |   F0  |   F1  |   L0  |   L1  |\n",
      "+-------+-------+-------+------+-------+-------+-------+-------+\n",
      "| 21.85 | 21.55 | 20.91 | 22.5 | 21.79 | 21.62 | 21.43 | 21.98 |\n",
      "+-------+-------+-------+------+-------+-------+-------+-------+\n",
      "t-test\n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.6010 | 0.0014 | 0.7698 | 0.3267 |\n",
      "+--------+--------+--------+--------+\n",
      "WMW-test \n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.7929 | 0.0009 | 0.4309 | 0.5635 |\n",
      "+--------+--------+--------+--------+\n",
      "******************************\n",
      "ncs\n",
      "+------+-------+-------+-------+-------+-------+-------+-------+\n",
      "|  R0  |   R1  |   S0  |   S1  |   F0  |   F1  |   L0  |   L1  |\n",
      "+------+-------+-------+-------+-------+-------+-------+-------+\n",
      "| 12.2 | 12.08 | 11.65 | 12.63 | 12.04 | 12.24 | 11.82 | 12.45 |\n",
      "+------+-------+-------+-------+-------+-------+-------+-------+\n",
      "t-test\n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.7581 | 0.0019 | 0.5814 | 0.0731 |\n",
      "+--------+--------+--------+--------+\n",
      "WMW-test \n",
      "+--------+--------+--------+--------+\n",
      "|   R    |   S    |   F    |   L    |\n",
      "+--------+--------+--------+--------+\n",
      "| 0.9581 | 0.0014 | 0.9581 | 0.1893 |\n",
      "+--------+--------+--------+--------+\n"
     ]
    }
   ],
   "source": [
    "get_diff_combination_scores_and_significant_test(approaches ,data_dir,refs_filename,get_bleu_dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Average of five model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:04:07.198707Z",
     "start_time": "2021-08-28T12:04:07.187918Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_four_operations(data):\n",
    "    r0 = data[8:]\n",
    "    r1 = data[:8]\n",
    "    s0 = data[:4] + data[8:12]\n",
    "    s1 = data[4:8] + data[12:]\n",
    "    f0 = [data[i] for i in [2, 3, 6, 7, 10, 11, 14, 15]]\n",
    "    f1 = [data[i] for i in [0, 1, 4, 5, 8, 9, 12, 13]]\n",
    "    l0 = [data[2 * i] for i in range(8)]\n",
    "    l1 = [data[2 * i + 1] for i in range(8)]\n",
    "    return r0, r1, s0, s1, f0, f1, l0, l1\n",
    "\n",
    "\n",
    "def get_four_opetarot_avg_score(approach_data):\n",
    "    r0, r1, s0, s1, f0, f1, l0, l1 = [], [], [], [], [], [], [], []\n",
    "    x1_new, r1_new, s0_new, s1_new, f0_new, f1_new, l0_new, l1_new = get_four_operations(approach_data)\n",
    "    r0.extend(x1_new) \n",
    "    r1.extend(r1_new)\n",
    "    s0.extend(s0_new)\n",
    "    s1.extend(s1_new)\n",
    "    f0.extend(f0_new)\n",
    "    f1.extend(f1_new)\n",
    "    l0.extend(l0_new)\n",
    "    l1.extend(l1_new)\n",
    "    p_val_t_dict = {} \n",
    "    p_mwu_val_dict = {} \n",
    "    avg = {\"R0\":np.mean(r0), \"R1\":np.mean(r1),\"S0\":np.mean(s0),\"S1\":np.mean(s1),\n",
    "           \"F0\":np.mean(f0),\"F1\":np.mean(f1),\"L0\":np.mean(l0),\"L1\":np.mean(l1),}\n",
    "    avg = {key:round(item,2)  for key,item in avg.items()}\n",
    "    return avg\n",
    "\n",
    "def get_diff_avg_combination_scores(approaches ,data_dir,refs_filename,get_bleu_score):\n",
    "    all_approaches_result = {}\n",
    "    for approach in approaches:\n",
    "        combination_result_dict = {}\n",
    "#         latex_diff_combination_result = []\n",
    "        for combination in all_data_processing_combinations:\n",
    "#             refs_filename = os.path.join(data_dir, approach, combination,\"test.gold\")\n",
    "            preds_filename = os.path.join(data_dir, approach,combination, \"test.pred\")\n",
    "            preds = read_to_list(preds_filename)\n",
    "            refs = read_to_list(refs_filename)\n",
    "            refs = [[t] for t in refs[:len( preds)]]\n",
    "            codenn_bleu = get_bleu_score(refs, preds)\n",
    "            combination_result_dict[combination] = codenn_bleu\n",
    "#             latex_diff_combination_result.append(round(codenn_bleu,2))\n",
    "#         all_bleu = {key:round(value, 2) for key, value in combination_result_dict.items()}\n",
    "#         print(30*\"*\")\n",
    "#         print(approach)\n",
    "        approach_result = get_four_opetarot_avg_score(list(combination_result_dict.values()))\n",
    "        all_approaches_result[approach] =approach_result\n",
    "    avg_dict = {}\n",
    "    for key in all_approaches_result[approach]:\n",
    "        avg = np.mean([value[key] for value in all_approaches_result.values()])\n",
    "        avg_dict[key] = round(avg,2)\n",
    "    print(\"The average the all model\")\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.field_names = avg_dict.keys()\n",
    "    tb.add_row(avg_dict.values())\n",
    "    print(tb) \n",
    "#     print(\"& \" + \"& \".join(list(avg_dict.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:05:05.584913Z",
     "start_time": "2021-08-28T12:04:07.200101Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average the all model\n",
      "+-------+------+-------+-------+-------+-------+-------+-------+\n",
      "|   R0  |  R1  |   S0  |   S1  |   F0  |   F1  |   L0  |   L1  |\n",
      "+-------+------+-------+-------+-------+-------+-------+-------+\n",
      "| 11.79 | 11.7 | 11.34 | 12.15 | 11.72 | 11.77 | 11.56 | 11.92 |\n",
      "+-------+------+-------+-------+-------+-------+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "get_diff_avg_combination_scores(approaches ,data_dir,refs_filename,get_bleu_dc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:06:50.142494Z",
     "start_time": "2021-08-28T12:06:50.134749Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ensemble_scores(approaches,data_dir,refs_filename,get_bleu_score):\n",
    "    result_dict = {}\n",
    "    for approach in approaches:\n",
    "        preds_filename = os.path.join(data_dir, approach,\"ensemble\", \"test.pred\")\n",
    "        preds = read_to_list(preds_filename)\n",
    "        refs = read_to_list(refs_filename)\n",
    "        refs = [[t] for t in refs[:len( preds)]]\n",
    "        codenn_bleu = get_bleu_score(refs, preds)\n",
    "        result_dict[ approach] = codenn_bleu\n",
    "#             latex_diff_combination_result[combination] = \"&%.2f \"%codenn_bleu\n",
    "    all_bleu = {key:round(value, 2) for key, value in result_dict.items()}\n",
    "    tb = pt.PrettyTable()\n",
    "    tb.field_names = all_bleu.keys()\n",
    "    tb.add_row(all_bleu.values())\n",
    "    print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-28T12:06:54.133804Z",
     "start_time": "2021-08-28T12:06:50.337800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------+------+\n",
      "| codenn | astattgru | rencos | ncs  |\n",
      "+--------+-----------+--------+------+\n",
      "| 10.64  |   11.28   | 24.21  | 19.9 |\n",
      "+--------+-----------+--------+------+\n"
     ]
    }
   ],
   "source": [
    "get_ensemble_scores(approaches ,data_dir,refs_filename,get_bleu_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "304.469px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
