makes sure the fast - path emits in order .
mirrors the one observablesource in an iterable of several observablesources that first either emits an item or sends a termination notification . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / amb . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code amb } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
mirrors the one observablesource in an array of several observablesources that first either emits an item or sends a termination notification . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / amb . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code ambarray } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
concatenates elements of each observablesource provided via an iterable sequence into a single sequence of elements without interleaving them . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concat . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns an observable that emits the items emitted by each of the observablesources emitted by the source observablesource one after the other without interleaving them . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concat . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
concatenates a variable number of observablesource sources . <p > note : named this way because of overload conflict with concat ( observablesource&lt ; observablesource&gt ; ) <p > <img width = 640 height = 290 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatarray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
concatenates a variable number of observablesource sources and delays errors from any of them till all terminate . <p > <img width = 640 height = 290 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatarray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
concatenates an array of observablesources eagerly into a single stream of values . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatarrayeager . png alt = > <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source observablesources . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
concatenates an array of observablesources eagerly into a single stream of values . <p > <img width = 640 height = 495 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatarrayeager . nn . png alt = > <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source observablesources . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
concatenates an array of {
concatenates the observablesource sequence of observablesources into a single sequence by subscribing to each inner observablesource one after the other one at a time and delays any errors till the all inner and the outer observablesources terminate . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatdelayerror . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
concatenates the observablesource sequence of observablesources into a single sequence by subscribing to each inner observablesource one after the other one at a time and delays any errors till the all inner and the outer observablesources terminate . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatdelayerror . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
concatenates an observablesource sequence of observablesources eagerly into a single stream of values . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the emitted source observablesources as they are observed . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concateager . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
concatenates a sequence of observablesources eagerly into a single stream of values . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source observablesources . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concateager . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
returns an observable that emits no items to the { @link observer } and immediately invokes its { @link observer#oncomplete oncomplete } method . <p > <img width = 640 height = 190 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / empty . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code empty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that invokes an { @link observer } s { @link observer#onerror onerror } method when the observer subscribes to it . <p > <img width = 640 height = 220 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / error . supplier . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code error } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts an array into an observablesource that emits the items in the array . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / from . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromarray } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts an { @link iterable } sequence into an observablesource that emits the items in the sequence . <p > <img width = 640 height = 186 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / fromiterable . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromiterable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts an arbitrary reactive - streams publisher into an observable . <p > <img width = 640 height = 344 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / frompublisher . o . png alt = > <p > the {
returns a cold synchronous and stateless generator of values . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / generate . 2 . png alt = > <p > note that the { @link emitter#onnext } { @link emitter#onerror } and { @link emitter#oncomplete } methods provided to the function via the { @link emitter } instance should be called synchronously never concurrently and only while the function body is executing . calling them from multiple threads or outside the function call is not supported and leads to an undefined behavior . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code generate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a cold synchronous and stateful generator of values . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / generate . 2 . png alt = > <p > note that the { @link emitter#onnext } { @link emitter#onerror } and { @link emitter#oncomplete } methods provided to the function via the { @link emitter } instance should be called synchronously never concurrently and only while the function body is executing . calling them from multiple threads or outside the function call is not supported and leads to an undefined behavior . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code generate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits a { @code 0l } after the { @code initialdelay } and ever increasing numbers after each { @code period } of time thereafter on a specified { @link scheduler } . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timer . ps . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits a sequential number every specified interval of time . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / interval . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code interval } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits a sequential number every specified interval of time on a specified scheduler . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / interval . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
signals a range of long values the first after some initial delay and the rest periodically after . <p > the sequence completes immediately after the last value ( start + count - 1 ) has been reached . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / intervalrange . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
signals a range of long values the first after some initial delay and the rest periodically after . <p > the sequence completes immediately after the last value ( start + count - 1 ) has been reached . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / intervalrange . s . png alt = > * <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you provide the {
returns an observable that signals the given ( constant reference ) item and then completes . <p > <img width = 640 height = 290 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / just . item . png alt = > <p > note that the item is taken and re - emitted as is and not computed by any means by { @code just } . use { @link #fromcallable ( callable ) } to generate a single item on demand ( when { @code observer } s subscribe to it ) . <p > see the multi - parameter overloads of { @code just } to emit more than one ( constant reference ) items one after the other . use { @link #fromarray ( object ... ) } to emit an arbitrary number of items that are known upfront . <p > to emit the items of an { @link iterable } sequence ( such as a { @link java . util . list } ) use { @link #fromiterable ( iterable ) } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code just } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
flattens an iterable of observablesources into one observablesource without any transformation while limiting the number of concurrent subscriptions to these observablesources . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > you can combine the items emitted by multiple observablesources so that they appear as a single observablesource by using the { @code merge } method . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code merge } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if any of the source { @code observablesource } s signal a { @code throwable } via { @code onerror } the resulting { @code observable } terminates with that { @code throwable } and all other source { @code observablesource } s are disposed . if more than one { @code observablesource } signals an error the resulting { @code observable } may terminate with the first one s error or depending on the concurrency of the sources may terminate with a { @code compositeexception } containing two or more of the various error signals . { @code throwable } s that didn t make into the composite will be sent ( individually ) to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } method as { @code undeliverableexception } errors . similarly { @code throwable } s signaled by source ( s ) after the returned { @code observable } has been disposed or terminated with a ( composite ) error will be sent to the same global error handler . use { @link #mergedelayerror ( iterable int int ) } to merge sources and terminate only when all source { @code observablesource } s have completed or failed with an error . < / dd > < / dl >
flattens an iterable of observablesources into one observablesource without any transformation while limiting the number of concurrent subscriptions to these observablesources . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > you can combine the items emitted by multiple observablesources so that they appear as a single observablesource by using the { @code merge } method . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergearray } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if any of the source { @code observablesource } s signal a { @code throwable } via { @code onerror } the resulting { @code observable } terminates with that { @code throwable } and all other source { @code observablesource } s are disposed . if more than one { @code observablesource } signals an error the resulting { @code observable } may terminate with the first one s error or depending on the concurrency of the sources may terminate with a { @code compositeexception } containing two or more of the various error signals . { @code throwable } s that didn t make into the composite will be sent ( individually ) to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } method as { @code undeliverableexception } errors . similarly { @code throwable } s signaled by source ( s ) after the returned { @code observable } has been disposed or terminated with a ( composite ) error will be sent to the same global error handler . use { @link #mergearraydelayerror ( int int observablesource ... ) } to merge sources and terminate only when all source { @code observablesource } s have completed or failed with an error . < / dd > < / dl >
flattens an observablesource that emits observablesources into a single observablesource that emits the items emitted by those observablesources without any transformation . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . oo . png alt = > <p > you can combine the items emitted by multiple observablesources so that they appear as a single observablesource by using the { @code merge } method . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code merge } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if any of the source { @code observablesource } s signal a { @code throwable } via { @code onerror } the resulting { @code observable } terminates with that { @code throwable } and all other source { @code observablesource } s are disposed . if more than one { @code observablesource } signals an error the resulting { @code observable } may terminate with the first one s error or depending on the concurrency of the sources may terminate with a { @code compositeexception } containing two or more of the various error signals . { @code throwable } s that didn t make into the composite will be sent ( individually ) to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } method as { @code undeliverableexception } errors . similarly { @code throwable } s signaled by source ( s ) after the returned { @code observable } has been disposed or terminated with a ( composite ) error will be sent to the same global error handler . use { @link #mergedelayerror ( observablesource ) } to merge sources and terminate only when all source { @code observablesource } s have completed or failed with an error . < / dd > < / dl >
flattens an array of observablesources into one observablesource without any transformation . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . io . png alt = > <p > you can combine items emitted by multiple observablesources so that they appear as a single observablesource by using the { @code merge } method . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergearray } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if any of the source { @code observablesource } s signal a { @code throwable } via { @code onerror } the resulting { @code observable } terminates with that { @code throwable } and all other source { @code observablesource } s are disposed . if more than one { @code observablesource } signals an error the resulting { @code observable } may terminate with the first one s error or depending on the concurrency of the sources may terminate with a { @code compositeexception } containing two or more of the various error signals . { @code throwable } s that didn t make into the composite will be sent ( individually ) to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } method as { @code undeliverableexception } errors . similarly { @code throwable } s signaled by source ( s ) after the returned { @code observable } has been disposed or terminated with a ( composite ) error will be sent to the same global error handler . use { @link #mergearraydelayerror ( observablesource ... ) } to merge sources and terminate only when all source { @code observablesource } s have completed or failed with an error . < / dd > < / dl >
flattens three observablesources into one observablesource in a way that allows an observer to receive all successfully emitted items from all of the source observablesources without being interrupted by an error notification from one of them . <p > this behaves like { @link #merge ( observablesource observablesource observablesource ) } except that if any of the merged observablesources notify of an error via { @link observer#onerror onerror } { @code mergedelayerror } will refrain from propagating that error notification until all of the merged observablesources have finished emitting items . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergedelayerror . png alt = > <p > even if multiple merged observablesources send { @code onerror } notifications { @code mergedelayerror } will only invoke the { @code onerror } method of its observers once . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergedelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that never sends any items or notifications to an { @link observer } . <p > <img width = 640 height = 185 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / never . png alt = > <p > this observablesource is useful primarily for testing purposes . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code never } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits a sequence of integers within a specified range . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / range . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code range } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits a sequence of longs within a specified range . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / rangelong . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code rangelong } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two observablesource sequences are the same by comparing the items emitted by each observablesource pairwise based on the results of a specified equality function . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two observablesource sequences are the same by comparing the items emitted by each observablesource pairwise based on the results of a specified equality function . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two observablesource sequences are the same by comparing the items emitted by each observablesource pairwise . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts an observablesource that emits observablesources into an observablesource that emits the items emitted by the most recently emitted of those observablesources . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchdo . png alt = > <p > { @code switchonnext } subscribes to an observablesource that emits observablesources . each time it observes one of these emitted observablesources the observablesource returned by { @code switchonnext } begins emitting the items emitted by that observablesource . when a new observablesource is emitted { @code switchonnext } stops emitting items from the earlier - emitted observablesource and begins emitting items from the new one . <p > the resulting observablesource completes if both the outer observablesource and the last inner observablesource if any complete . if the outer observablesource signals an onerror the inner observablesource is disposed and the error delivered in - sequence . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchonnext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts an observablesource that emits observablesources into an observablesource that emits the items emitted by the most recently emitted of those observablesources and delays any exception until all observablesources terminate . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchonnextdelayerror . png alt = > <p > { @code switchonnext } subscribes to an observablesource that emits observablesources . each time it observes one of these emitted observablesources the observablesource returned by { @code switchonnext } begins emitting the items emitted by that observablesource . when a new observablesource is emitted { @code switchonnext } stops emitting items from the earlier - emitted observablesource and begins emitting items from the new one . <p > the resulting observablesource completes if both the main observablesource and the last inner observablesource if any complete . if the main observablesource signals an onerror the termination of the last inner observablesource will emit that error as is or wrapped into a compositeexception along with the other possible errors the former inner observablesources signalled . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchonnextdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
create an observable by wrapping an observablesource <em > which has to be implemented according to the reactive - streams - based observable specification by handling disposal correctly ; no safeguards are provided by the observable itself< / em > . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
constructs an observablesource that creates a dependent resource object which is disposed of when the downstream calls dispose () . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / using . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code using } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
constructs an observablesource that creates a dependent resource object which is disposed of just before termination if you have set { @code disposeeagerly } to { @code true } and a dispose () call does not occur before termination . otherwise resource disposal will occur on a dispose () call . eager disposal is particularly appropriate for a synchronous observablesource that reuses resources . { @code disposeaction } will only be called once per subscription . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / using . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code using } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
wraps an observablesource into an observable if not already an observable .
returns an observable that emits the results of a specified combiner function applied to combinations of items emitted in sequence by an iterable of other observablesources . <p > { @code zip } applies this function in strict sequence so the first item emitted by the new observablesource will be the result of the function applied to the first item emitted by each of the source observablesources ; the second item emitted by the new observablesource will be the result of the function applied to the second item emitted by each of those observablesources ; and so forth . <p > the resulting { @code observablesource<r > } returned from { @code zip } will invoke { @code onnext } as many times as the number of { @code onnext } invocations of the source observablesource that emits the fewest items . <p > the operator subscribes to its sources in order they are specified and completes eagerly if one of the sources is shorter than the rest while disposing the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will dispose b immediately . for example : <pre > <code > zip ( arrays . aslist ( range ( 1 5 ) . dooncomplete ( action1 ) range ( 6 5 ) . dooncomplete ( action2 )) ( a ) - &gt ; a ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #doondispose ( action ) } as well or use { @code using () } to do cleanup in case of completion or a dispose () call . <p > note on method signature : since java doesn t allow creating a generic array with { @code new t [] } the implementation of this operator has to create an { @code object [] } instead . unfortunately a { @code function<integer [] r > } passed to the method would trigger a { @code classcastexception } .
returns an observable that emits the results of a specified combiner function applied to combinations of <i > n< / i > items emitted in sequence by the <i > n< / i > observablesources emitted by a specified observablesource . <p > { @code zip } applies this function in strict sequence so the first item emitted by the new observablesource will be the result of the function applied to the first item emitted by each of the observablesources emitted by the source observablesource ; the second item emitted by the new observablesource will be the result of the function applied to the second item emitted by each of those observablesources ; and so forth . <p > the resulting { @code observablesource<r > } returned from { @code zip } will invoke { @code onnext } as many times as the number of { @code onnext } invocations of the source observablesource that emits the fewest items . <p > the operator subscribes to its sources in order they are specified and completes eagerly if one of the sources is shorter than the rest while disposing the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will dispose b immediately . for example : <pre > <code > zip ( just ( range ( 1 5 ) . dooncomplete ( action1 ) range ( 6 5 ) . dooncomplete ( action2 )) ( a ) - &gt ; a ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #doondispose ( action ) } as well or use { @code using () } to do cleanup in case of completion or a dispose () call . <p > note on method signature : since java doesn t allow creating a generic array with { @code new t [] } the implementation of this operator has to create an { @code object [] } instead . unfortunately a { @code function<integer [] r > } passed to the method would trigger a { @code classcastexception } .
returns an observable that emits the results of a specified combiner function applied to combinations of items emitted in sequence by an array of other observablesources . <p > { @code zip } applies this function in strict sequence so the first item emitted by the new observablesource will be the result of the function applied to the first item emitted by each of the source observablesources ; the second item emitted by the new observablesource will be the result of the function applied to the second item emitted by each of those observablesources ; and so forth . <p > the resulting { @code observablesource<r > } returned from { @code zip } will invoke { @code onnext } as many times as the number of { @code onnext } invocations of the source observablesource that emits the fewest items . <p > the operator subscribes to its sources in order they are specified and completes eagerly if one of the sources is shorter than the rest while disposing the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will dispose b immediately . for example : <pre > <code > zip ( new observablesource [] { range ( 1 5 ) . dooncomplete ( action1 ) range ( 6 5 ) . dooncomplete ( action2 ) } ( a ) - &gt ; a ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #doondispose ( action ) } as well or use { @code using () } to do cleanup in case of completion or a dispose () call . <p > note on method signature : since java doesn t allow creating a generic array with { @code new t [] } the implementation of this operator has to create an { @code object [] } instead . unfortunately a { @code function<integer [] r > } passed to the method would trigger a { @code classcastexception } .
returns a single that emits a boolean that indicates whether all of the items emitted by the source observablesource satisfy a condition . <p > <img width = 640 height = 264 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / all . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code all } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
mirrors the observablesource ( current or provided ) that first either emits an item or sends a termination notification . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / ambwith . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code ambwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits { @code true } if any item emitted by the source observablesource satisfies a specified condition otherwise { @code false } . <em > note : < / em > this always emits { @code false } if the source observablesource is empty . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / any . 2 . png alt = > <p > in rx . net this is the { @code any } observer but we renamed it in rxjava to better match java naming idioms . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code any } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns the first item emitted by this { @code observable } or throws { @code nosuchelementexception } if it emits no items . <p > <img width = 640 height = 412 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockingfirst . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingfirst } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
consumes the upstream { @code observable } in a blocking fashion and invokes the given { @code consumer } with each upstream item on the <em > current thread< / em > until the upstream terminates . <p > <img width = 640 height = 330 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockingforeach . o . png alt = > <p > <em > note : < / em > the method will only return if the upstream terminates or the current thread is interrupted . <p > this method executes the { @code consumer } on the current thread while { @link #subscribe ( consumer ) } executes the consumer on the original caller thread of the sequence . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingforeach } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
converts this { @code observable } into an { @link iterable } . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockingiterable . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingiterable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns the last item emitted by this { @code observable } or throws { @code nosuchelementexception } if this { @code observable } emits no items . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockinglast . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockinglast } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
returns an { @link iterable } that always returns the item most recently emitted by this { @code observable } . <p > <img width = 640 height = 426 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockingmostrecent . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingmostrecent } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
if this { @code observable } completes after emitting a single item return that item otherwise throw a { @code nosuchelementexception } . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockingsingle . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingsingle } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
if this { @code observable } completes after emitting a single item return that item ; if it emits more than one item throw an { @code illegalargumentexception } ; if it emits no items return a default value . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / blockingsingledefault . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingsingle } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
returns a { @link future } representing the only value emitted by this { @code observable } . <p > <img width = 640 height = 312 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / tofuture . o . png alt = > <p > if the { @link observable } emits more than one item { @link java . util . concurrent . future } will receive an { @link java . lang . indexoutofboundsexception } . if the { @link observable } is empty { @link java . util . concurrent . future } will receive an { @link java . util . nosuchelementexception } . the { @code observable } source has to terminate in order for the returned { @code future } to terminate as well . <p > if the { @code observable } may emit more than one item use { @code observable . tolist () . tofuture () } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tofuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to the source and calls the given callbacks <strong > on the current thread< / strong > . <p > <img width = 640 height = 393 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / blockingsubscribe . o . 1 . png alt = > <p > if the {
subscribes to the source and calls the given callbacks <strong > on the current thread< / strong > . <p > <img width = 640 height = 396 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / blockingsubscribe . o . 2 . png alt = > <p > note that calling this method will block the caller thread until the upstream terminates normally or with an error . therefore calling this method from special threads such as the android main thread or the swing event dispatch thread is not recommended . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
subscribes to the source and calls the given callbacks <strong > on the current thread< / strong > . <p > <img width = 640 height = 394 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / blockingsubscribe . o . png alt = > <p > note that calling this method will block the caller thread until the upstream terminates normally or with an error . therefore calling this method from special threads such as the android main thread or the swing event dispatch thread is not recommended . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
subscribes to the source and calls the {
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping buffers each containing { @code count } items . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer3 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits buffers every { @code skip } items each containing { @code count } items . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer4 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits buffers every { @code skip } items each containing { @code count } items . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer4 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping buffers each containing { @code count } items . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer3 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource starts a new buffer periodically as determined by the { @code timeskip } argument . it emits each buffer after a fixed timespan specified by the { @code timespan } argument . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer7 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource starts a new buffer periodically as determined by the { @code timeskip } argument and on the specified { @code scheduler } . it emits each buffer after a fixed timespan specified by the { @code timespan } argument . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer7 . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping buffers each of a fixed duration specified by the { @code timespan } argument or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer6 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping buffers each of a fixed duration specified by the { @code timespan } argument as measured on the specified { @code scheduler } or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer6 . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping buffers each of a fixed duration specified by the { @code timespan } argument as measured on the specified { @code scheduler } or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source observablesource completes the resulting observablesource emits the current buffer and propagates the notification from the source observablesource . note that if the source observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer6 . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits buffers that it creates when the specified { @code openingindicator } observablesource emits an item and closes when the observablesource returned from { @code closingindicator } emits an item . if any of the source observablesource { @code openingindicator } or { @code closingindicator } issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 470 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits buffers that it creates when the specified { @code openingindicator } observablesource emits an item and closes when the observablesource returned from { @code closingindicator } emits an item . if any of the source observablesource { @code openingindicator } or { @code closingindicator } issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 470 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits non - overlapping buffered items from the source observablesource each time the specified boundary observablesource emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer8 . png alt = > <p > completion of either the source or the boundary observablesource causes the returned observablesource to emit the latest buffer and complete . if either the source observablesource or the boundary observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits non - overlapping buffered items from the source observablesource each time the specified boundary observablesource emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer8 . png alt = > <p > completion of either the source or the boundary observablesource causes the returned observablesource to emit the latest buffer and complete . if either the source observablesource or the boundary observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits non - overlapping buffered items from the source observablesource each time the specified boundary observablesource emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer8 . png alt = > <p > completion of either the source or the boundary observablesource causes the returned observablesource to emit the latest buffer and complete . if either the source observablesource or the boundary observablesource issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits buffers of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping buffers . it emits the current buffer and replaces it with a new buffer whenever the observablesource produced by the specified { @code boundarysupplier } emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer1 . png alt = > <p > if either the source { @code observablesource } or the boundary { @code observablesource } issues an { @code onerror } notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that subscribes to this observablesource lazily caches all of its events and replays them in the same order as received to all the downstream subscribers . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / cachewithinitialcapacity . o . png alt = > <p > this is useful when you want an observablesource to cache responses and you can t control the subscribe / dispose behavior of all the { @link observer } s . <p > the operator subscribes only when the first downstream subscriber subscribes and maintains a single subscription towards this observablesource . in contrast the operator family of { @link #replay () } that return a { @link connectableobservable } require an explicit call to { @link connectableobservable#connect () } . <p > <em > note : < / em > you sacrifice the ability to dispose the origin when you use the { @code cache } observer so be careful not to use this observer on observablesources that emit an infinite or very large number of items that will use up memory . a possible workaround is to apply takeuntil with a predicate or another source before ( and perhaps after ) the application of cache () . <pre > <code > atomicboolean shouldstop = new atomicboolean () ;
collects items emitted by the finite source observablesource into a single mutable data structure and returns a single that emits this structure . <p > <img width = 640 height = 330 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / collect . 2 . png alt = > <p > this is a simplified version of { @code reduce } that does not need to return the state on each pass . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code collect } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
collects items emitted by the finite source observablesource into a single mutable data structure and returns a single that emits this structure . <p > <img width = 640 height = 330 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / collectinto . o . png alt = > <p > this is a simplified version of { @code reduce } that does not need to return the state on each pass . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code collectinto } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
transform an observablesource by applying a particular transformer function to it . <p > this method operates on the observablesource itself whereas { @link #lift } operates on the observablesource s observers . <p > if the operator you are creating is designed to act on the individual items emitted by a source observablesource use { @link #lift } . if your operator is designed to transform the source observablesource as a whole ( for instance by applying a particular set of existing rxjava operators to it ) use { @code compose } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code compose } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a new observable that emits items resulting from applying a function that you supply to each item emitted by the source observablesource where that function returns an observablesource and then emitting the items that result from concatenating those resulting observablesources . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a new observable that emits items resulting from applying a function that you supply to each item emitted by the source observablesource where that function returns an observablesource and then emitting the items that result from concatenating those resulting observablesources . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps each of the items into an observablesource subscribes to them one after the other one at a time and emits their values in order while delaying any error from either this or any of the inner observablesources till all of them terminate . <p > <img width = 640 height = 347 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapdelayerror . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatmapdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps a sequence of values into observablesources and concatenates these observablesources eagerly into a single observablesource . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source observablesources . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapeager . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
maps a sequence of values into observablesources and concatenates these observablesources eagerly into a single observablesource . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source observablesources . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapeager . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
maps a sequence of values into observablesources and concatenates these observablesources eagerly into a single observablesource . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source observablesources . the operator buffers the values emitted by these observablesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 390 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapeagerdelayerror . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
maps each element of the upstream observable into completablesources subscribes to them one at a time in order and waits until the upstream and all completablesources complete . <p > <img width = 640 height = 505 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapcompletable . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream observable into completablesources subscribes to them one at a time in order and waits until the upstream and all completablesources complete . <p > <img width = 640 height = 505 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapcompletable . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatmapcompletable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl > <p > history : 2 . 1 . 6 - experimental @param mapper a function that when applied to an item emitted by the source observablesource returns a completablesource
maps the upstream items into {
maps the upstream items into {
returns an observable that concatenate each item emitted by the source observablesource with the values in an iterable corresponding to that item that is generated by a selector . <p > <img width = 640 height = 275 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapiterable . o . png alt = >
returns an observable that concatenate each item emitted by the source observablesource with the values in an iterable corresponding to that item that is generated by a selector . <p > <img width = 640 height = 275 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concatmapiterable . o . png alt = >
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
returns an observable that emits the items emitted from the current observablesource then the next one after the other without interleaving them . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concat . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an {
returns an {
returns an {
returns a single that emits a boolean that indicates whether the source observablesource emitted a specified item . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / contains . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code contains } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource except that it drops items emitted by the source observablesource that are followed by another item within a computed debounce duration . <p > <img width = 640 height = 425 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / debounce . f . png alt = > <p > the delivery of the item happens on the thread of the first { @code onnext } or { @code oncomplete } signal of the generated { @code observablesource } sequence which if takes too long a newer item may arrive from the upstream causing the generated sequence to get disposed which may also interrupt any downstream blocking operation ( yielding an { @code interruptedexception } ) . it is recommended processing items that may take long time to be moved to another thread via { @link #observeon } applied after { @code debounce } itself . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code debounce } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource except that it drops items emitted by the source observablesource that are followed by newer items before a timeout value expires . the timer resets on each emission . <p > <em > note : < / em > if items keep being emitted by the source observablesource faster than the timeout then no items will be emitted by the resulting observablesource . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / debounce . png alt = > <p > delivery of the item after the grace period happens on the { @code computation } { @code scheduler } s { @code worker } which if takes too long a newer item may arrive from the upstream causing the { @code worker } s task to get disposed which may also interrupt any downstream blocking operation ( yielding an { @code interruptedexception } ) . it is recommended processing items that may take long time to be moved to another thread via { @link #observeon } applied after { @code debounce } itself . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code debounce } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource except that it drops items emitted by the source observablesource that are followed by newer items before a timeout value expires on a specified scheduler . the timer resets on each emission . <p > <em > note : < / em > if items keep being emitted by the source observablesource faster than the timeout then no items will be emitted by the resulting observablesource . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / debounce . s . png alt = > <p > delivery of the item after the grace period happens on the given { @code scheduler } s { @code worker } which if takes too long a newer item may arrive from the upstream causing the { @code worker } s task to get disposed which may also interrupt any downstream blocking operation ( yielding an { @code interruptedexception } ) . it is recommended processing items that may take long time to be moved to another thread via { @link #observeon } applied after { @code debounce } itself . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits the items emitted by the source observablesource or a specified default item if the source observablesource is empty . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / defaultifempty . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code defaultifempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that delays the emissions of the source observablesource via another observablesource on a per - item basis . <p > <img width = 640 height = 450 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . o . png alt = > <p > <em > note : < / em > the resulting observablesource will immediately propagate any { @code onerror } notification from the source observablesource . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code delay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the items emitted by the source observablesource shifted forward in time by a specified delay . error notifications from the source observablesource are not delayed . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits the items emitted by the source observablesource shifted forward in time by a specified delay . if { @code delayerror } is true error notifications will also be delayed . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that delays the subscription to and emissions from the source observablesource via another observablesource on a per - item basis . <p > <img width = 640 height = 450 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . oo . png alt = > <p > <em > note : < / em > the resulting observablesource will immediately propagate any { @code onerror } notification from the source observablesource . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code delay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that delays the subscription to this observable until the other observable emits an element or completes normally . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delaysubscription . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that delays the subscription to the source observablesource by a given amount of time both waiting and subscribing on a given scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delaysubscription . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that reverses the effect of { @link #materialize materialize } by transforming the { @link notification } objects emitted by the source observablesource into the items or notifications they represent . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dematerialize . png alt = > <p > when the upstream signals an { @link notification#createonerror ( throwable ) onerror } or { @link notification#createoncomplete () oncomplete } item the returned observable disposes of the flow and terminates with that type of terminal event : <pre > <code > observable . just ( createonnext ( 1 ) createoncomplete () createonnext ( 2 )) . doondispose (( ) - &gt ; system . out . println ( disposed! )) ; . dematerialize () . test () . assertresult ( 1 ) ; < / code > < / pre > if the upstream signals { @code onerror } or { @code oncomplete } directly the flow is terminated with the same event . <pre > <code > observable . just ( createonnext ( 1 ) createonnext ( 2 )) . dematerialize () . test () . assertresult ( 1 2 ) ; < / code > < / pre > if this behavior is not desired the completion can be suppressed by applying { @link #concatwith ( observablesource ) } with a { @link #never () } source . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dematerialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that reverses the effect of { @link #materialize materialize } by transforming the { @link notification } objects extracted from the source items via a selector function into their respective { @code observer } signal types . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dematerialize . png alt = > <p > the intended use of the { @code selector } function is to perform a type - safe identity mapping ( see example ) on a source that is already of type { @code notification<t > } . the java language doesn t allow limiting instance methods to a certain generic argument shape therefore a function is used to ensure the conversion remains type safe . <p > when the upstream signals an { @link notification#createonerror ( throwable ) onerror } or { @link notification#createoncomplete () oncomplete } item the returned observable disposes of the flow and terminates with that type of terminal event : <pre > <code > observable . just ( createonnext ( 1 ) createoncomplete () createonnext ( 2 )) . doondispose (( ) - &gt ; system . out . println ( disposed! )) ; . dematerialize ( notification - &gt ; notification ) . test () . assertresult ( 1 ) ; < / code > < / pre > if the upstream signals { @code onerror } or { @code oncomplete } directly the flow is terminated with the same event . <pre > <code > observable . just ( createonnext ( 1 ) createonnext ( 2 )) . dematerialize ( notification - &gt ; notification ) . test () . assertresult ( 1 2 ) ; < / code > < / pre > if this behavior is not desired the completion can be suppressed by applying { @link #concatwith ( observablesource ) } with a { @link #never () } source . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dematerialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits all items emitted by the source observablesource that are distinct based on { @link object#equals ( object ) } comparison . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinct . png alt = > <p > it is recommended the elements class { @code t } in the flow overrides the default { @code object . equals () } and { @link object#hashcode () } to provide meaningful comparison between items as the default java implementation only considers reference equivalence . <p > by default { @code distinct () } uses an internal { @link java . util . hashset } per observer to remember previously seen items and uses { @link java . util . set#add ( object ) } returning { @code false } as the indicator for duplicates . <p > note that this internal { @code hashset } may grow unbounded as items won t be removed from it by the operator . therefore using very long or infinite upstream ( with very distinct elements ) may lead to { @code outofmemoryerror } . <p > customizing the retention policy can happen only by providing a custom { @link java . util . collection } implementation to the { @link #distinct ( function callable ) } overload . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinct } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits all items emitted by the source observablesource that are distinct according to a key selector function and based on { @link object#equals ( object ) } comparison of the objects returned by the key selector function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinct . key . png alt = > <p > it is recommended the keys class { @code k } overrides the default { @code object . equals () } and { @link object#hashcode () } to provide meaningful comparison between the key objects as the default java implementation only considers reference equivalence . <p > by default { @code distinct () } uses an internal { @link java . util . hashset } per observer to remember previously seen keys and uses { @link java . util . set#add ( object ) } returning { @code false } as the indicator for duplicates . <p > note that this internal { @code hashset } may grow unbounded as keys won t be removed from it by the operator . therefore using very long or infinite upstream ( with very distinct keys ) may lead to { @code outofmemoryerror } . <p > customizing the retention policy can happen only by providing a custom { @link java . util . collection } implementation to the { @link #distinct ( function callable ) } overload . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinct } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits all items emitted by the source observablesource that are distinct according to a key selector function and based on { @link object#equals ( object ) } comparison of the objects returned by the key selector function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinct . key . png alt = > <p > it is recommended the keys class { @code k } overrides the default { @code object . equals () } and { @link object#hashcode () } to provide meaningful comparison between the key objects as the default java implementation only considers reference equivalence . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinct } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits all items emitted by the source observablesource that are distinct from their immediate predecessors based on { @link object#equals ( object ) } comparison . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinctuntilchanged . png alt = > <p > it is recommended the elements class { @code t } in the flow overrides the default { @code object . equals () } to provide meaningful comparison between items as the default java implementation only considers reference equivalence . alternatively use the { @link #distinctuntilchanged ( bipredicate ) } overload and provide a comparison function in case the class { @code t } can t be overridden with custom { @code equals () } or the comparison itself should happen on different terms or properties of the class { @code t } . <p > note that the operator always retains the latest item from upstream regardless of the comparison result and uses it in the next comparison with the next upstream item . <p > note that if element type { @code t } in the flow is mutable the comparison of the previous and current item may yield unexpected results if the items are mutated externally . common cases are mutable { @code charsequence } s or { @code list } s where the objects will actually have the same references when they are modified and { @code distinctuntilchanged } will evaluate subsequent items as same . to avoid such situation it is recommended that mutable data is converted to an immutable one for example using { @code map ( charsequence :: tostring ) } or { @code map ( list - > collections . unmodifiablelist ( new arraylist< > ( list ))) } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinctuntilchanged } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits all items emitted by the source observablesource that are distinct from their immediate predecessors according to a key selector function and based on { @link object#equals ( object ) } comparison of those objects returned by the key selector function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinctuntilchanged . key . png alt = > <p > it is recommended the keys class { @code k } overrides the default { @code object . equals () } to provide meaningful comparison between the key objects as the default java implementation only considers reference equivalence . alternatively use the { @link #distinctuntilchanged ( bipredicate ) } overload and provide a comparison function in case the class { @code k } can t be overridden with custom { @code equals () } or the comparison itself should happen on different terms or properties of the item class { @code t } ( for which the keys can be derived via a similar selector ) . <p > note that the operator always retains the latest key from upstream regardless of the comparison result and uses it in the next comparison with the next key derived from the next upstream item . <p > note that if element type { @code t } in the flow is mutable the comparison of the previous and current item may yield unexpected results if the items are mutated externally . common cases are mutable { @code charsequence } s or { @code list } s where the objects will actually have the same references when they are modified and { @code distinctuntilchanged } will evaluate subsequent items as same . to avoid such situation it is recommended that mutable data is converted to an immutable one for example using { @code map ( charsequence :: tostring ) } or { @code map ( list - > collections . unmodifiablelist ( new arraylist< > ( list ))) } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinctuntilchanged } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits all items emitted by the source observablesource that are distinct from their immediate predecessors when compared with each other via the provided comparator function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinctuntilchanged . png alt = > <p > note that the operator always retains the latest item from upstream regardless of the comparison result and uses it in the next comparison with the next upstream item . <p > note that if element type { @code t } in the flow is mutable the comparison of the previous and current item may yield unexpected results if the items are mutated externally . common cases are mutable { @code charsequence } s or { @code list } s where the objects will actually have the same references when they are modified and { @code distinctuntilchanged } will evaluate subsequent items as same . to avoid such situation it is recommended that mutable data is converted to an immutable one for example using { @code map ( charsequence :: tostring ) } or { @code map ( list - > collections . unmodifiablelist ( new arraylist< > ( list ))) } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinctuntilchanged } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the specified consumer with the current item after this item has been emitted to the downstream . <p > note that the {
registers an { @link action } to be called when this observablesource invokes either { @link observer#oncomplete oncomplete } or { @link observer#onerror onerror } . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doafterterminate . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doafterterminate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the specified action after this observable signals onerror or oncompleted or gets disposed by the downstream . <p > in case of a race between a terminal event and a dispose call the provided {
calls the dispose { @code action } if the downstream disposes the sequence . <p > the action is shared between subscriptions and thus may be called concurrently from multiple threads ; the action must be thread safe . <p > if the action throws a runtime exception that exception is rethrown by the { @code dispose () } call sometimes as a { @code compositeexception } if there were multiple exceptions along the way . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doondispose . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doondispose } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source observablesource so that it invokes an action when it calls { @code oncomplete } . <p > <img width = 640 height = 358 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooncomplete . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooncomplete } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the appropriate onxxx consumer ( shared between all subscribers ) whenever a signal with the same type passes through before forwarding them to downstream . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooneach . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooneach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source observablesource so that it invokes an action for each item it emits . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooneach . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooneach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source observablesource so that it notifies an observer for each item and terminal event it emits . <p > in case the { @code onerror } of the supplied observer throws the downstream will receive a composite exception containing the original exception and the exception thrown by { @code onerror } . if either the { @code onnext } or the { @code oncomplete } method of the supplied observer throws the downstream will be terminated and will receive this thrown exception . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooneach . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooneach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source observablesource so that it invokes an action if it calls { @code onerror } . <p > in case the { @code onerror } action throws the downstream will receive a composite exception containing the original exception and the exception thrown by { @code onerror } . <p > <img width = 640 height = 355 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonerror . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the appropriate onxxx method ( shared between all observer ) for the lifecycle events of the sequence ( subscription disposal ) . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonlifecycle . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonlifecycle } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source observablesource so that it invokes an action when it calls { @code onnext } . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonnext . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonnext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source { @code observablesource } so that it invokes the given action when it is subscribed from its subscribers . each subscription will result in an invocation of the given action except when the source { @code observablesource } is reference counted in which case the source { @code observablesource } will invoke the given action for the first subscription . <p > <img width = 640 height = 390 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonsubscribe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonsubscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source observablesource so that it invokes an action when it calls { @code oncomplete } or { @code onerror } . <p > <img width = 640 height = 327 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonterminate . o . png alt = > <p > this differs from { @code doafterterminate } in that this happens <em > before< / em > the { @code oncomplete } or { @code onerror } notification . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonterminate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits the single item at a specified index in a sequence of emissions from this observable or completes if this observable signals fewer elements than index . <p > <img width = 640 height = 363 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / elementat . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code elementat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the item found at a specified index in a sequence of emissions from this observable or a default item if that index is out of range . <p > <img width = 640 height = 353 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / elementatdefault . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code elementat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the item found at a specified index in a sequence of emissions from this observable or signals a { @link nosuchelementexception } if this observable signals fewer elements than index . <p > <img width = 640 height = 362 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / elementatorerror . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code elementatorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
filters items emitted by an observablesource by only emitting those that satisfy a specified predicate . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / filter . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code filter } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits only the very first item emitted by the source observablesource or a default item if the source observablesource completes without emitting any items . <p > <img width = 640 height = 286 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / first . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code first } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items based on applying a function that you supply to each item emitted by the source observablesource where that function returns an observablesource and then merging those resulting observablesources and emitting the results of this merger . <p > <img width = 640 height = 356 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapdelayerror . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items based on applying a function that you supply to each item emitted by the source observablesource where that function returns an observablesource and then merging those resulting observablesources and emitting the results of this merger while limiting the maximum number of concurrent subscriptions to these observablesources . <p > <img width = 640 height = 441 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapmaxconcurrency . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that applies a function to each item emitted or notification raised by the source observablesource and then flattens the observablesources returned from these functions and emits the resulting items . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergemap . nce . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the results of a specified function to the pair of values emitted by the source observablesource and a specified collection observablesource . <p > <img width = 640 height = 390 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergemap . r . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps each element of the upstream observable into completablesources subscribes to them and waits until the upstream and all completablesources complete . <p > <img width = 640 height = 424 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapcompletable . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns an observable that emits the results of applying a function to the pair of values from the source observablesource and an iterable corresponding to that item that is generated by a selector . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapiterable . o . r . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmapiterable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps each element of the upstream observable into maybesources subscribes to all of them and merges their onsuccess values in no particular order into a single observable sequence . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapmaybe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream observable into maybesources subscribes to them and merges their onsuccess values in no particular order into a single observable sequence optionally delaying all errors . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapmaybe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream observable into singlesources subscribes to all of them and merges their onsuccess values in no particular order into a single observable sequence . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapsingle . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream observable into singlesources subscribes to them and merges their onsuccess values in no particular order into a single observable sequence optionally delaying all errors . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmapsingle . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
subscribes to the { @link observablesource } and receives notifications for each element and the terminal events until the onnext predicate returns false . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code foreachwhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
groups the items emitted by an { @code observablesource } according to a specified criterion and emits these grouped items as { @link groupedobservable } s . the emitted { @code groupedobservablesource } allows only a single { @link observer } during its lifetime and if this { @code observer } calls dispose () before the source terminates the next emission by the source having the same key will trigger a new { @code groupedobservablesource } emission . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / groupby . png alt = > <p > <em > note : < / em > a { @link groupedobservable } will cache the items it is to emit until such time as it is subscribed to . for this reason in order to avoid memory leaks you should not simply ignore those { @code groupedobservablesource } s that do not concern you . instead you can signal to them that they may discard their buffers by applying an operator like { @link #ignoreelements } to them . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code groupby } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
groups the items emitted by an { @code observablesource } according to a specified criterion and emits these grouped items as { @link groupedobservable } s . the emitted { @code groupedobservablesource } allows only a single { @link observer } during its lifetime and if this { @code observer } calls dispose () before the source terminates the next emission by the source having the same key will trigger a new { @code groupedobservablesource } emission . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / groupby . png alt = > <p > <em > note : < / em > a { @link groupedobservable } will cache the items it is to emit until such time as it is subscribed to . for this reason in order to avoid memory leaks you should not simply ignore those { @code groupedobservablesource } s that do not concern you . instead you can signal to them that they may discard their buffers by applying an operator like { @link #ignoreelements } to them . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code groupby } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
groups the items emitted by an { @code observablesource } according to a specified criterion and emits these grouped items as { @link groupedobservable } s . the emitted { @code groupedobservablesource } allows only a single { @link observer } during its lifetime and if this { @code observer } calls dispose () before the source terminates the next emission by the source having the same key will trigger a new { @code groupedobservablesource } emission . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / groupby . png alt = > <p > <em > note : < / em > a { @link groupedobservable } will cache the items it is to emit until such time as it is subscribed to . for this reason in order to avoid memory leaks you should not simply ignore those { @code groupedobservablesource } s that do not concern you . instead you can signal to them that they may discard their buffers by applying an operator like { @link #ignoreelements } to them . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code groupby } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
hides the identity of this observable and its disposable . <p > allows hiding extra features such as { @link io . reactivex . subjects . subject } s { @link observer } methods or preventing certain identity - based optimizations ( fusion ) . <p > <img width = 640 height = 283 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / hide . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code hide } does not operate by default on a particular { @link scheduler } . < / dd > < / dl > @return the new observable instance
ignores all items emitted by the source observablesource and only calls { @code oncomplete } or { @code onerror } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / ignoreelements . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code ignoreelements } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits { @code true } if the source observablesource is empty otherwise { @code false } . <p > in rx . net this is negated as the { @code any } observer but we renamed this in rxjava to better match java naming idioms . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / isempty . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code isempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
correlates the items emitted by two observablesources based on overlapping durations . <p > there are no guarantees in what order the items get combined when multiple items from one or both source observablesources overlap . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / join_ . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code join } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits the last item emitted by this observable or completes if this observable is empty . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / lastelement . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code lastelement } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits only the last item emitted by this observable or a default item if this observable completes without emitting any items . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / last . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code last } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits only the last item emitted by this observable or signals a { @link nosuchelementexception } if this observable is empty . <p > <img width = 640 height = 236 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / lastorerror . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code lastorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that applies a specified function to each item emitted by the source observablesource and emits the results of these function applications . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / map . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code map } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that represents all of the emissions <em > and< / em > notifications from the source observablesource into emissions marked with their original types within { @link notification } objects . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / materialize . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code materialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
flattens this and another observablesource into a single observablesource without any transformation . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > you can combine items emitted by multiple observablesources so that they appear as a single observablesource by using the { @code mergewith } method . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergewith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
merges the sequence of items of this observable with the success value of the other singlesource . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > the success value of the other {
merges the sequence of items of this observable with the success value of the other maybesource or waits both to complete normally if the maybesource is empty . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > the success value of the other {
relays the items of this observable and completes only when the other completablesource completes as well . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
modifies an observablesource to perform its emissions and notifications on a specified { @link scheduler } asynchronously with an unbounded buffer with { @link flowable#buffersize () } island size .
modifies an observablesource to perform its emissions and notifications on a specified { @link scheduler } asynchronously with an unbounded buffer of configurable island size and optionally delays onerror notifications . <p > <img width = 640 height = 308 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / observeon . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl > <p > island size indicates how large chunks the unbounded buffer allocates to store the excess elements waiting to be consumed on the other side of the asynchronous boundary . values below 16 are not recommended in performance sensitive scenarios .
instructs an observablesource to pass control to another observablesource rather than invoking { @link observer#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorresumenext . png alt = > <p > by default when an observablesource encounters an error that prevents it from emitting the expected item to its { @link observer } the observablesource invokes its observer s { @code onerror } method and then quits without invoking any more of its observer s methods . the { @code onerrorresumenext } method changes this behavior . if you pass a function that returns an observablesource ( { @code resumefunction } ) to { @code onerrorresumenext } if the original observablesource encounters an error instead of invoking its observer s { @code onerror } method it will instead relinquish control to the observablesource returned from { @code resumefunction } which will invoke the observer s { @link observer#onnext onnext } method if it is able to do so . in such a case because no observablesource necessarily invokes { @code onerror } the observer may never know that an error happened . <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorresumenext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs an observablesource to pass control to another observablesource rather than invoking { @link observer#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorresumenext . png alt = > <p > by default when an observablesource encounters an error that prevents it from emitting the expected item to its { @link observer } the observablesource invokes its observer s { @code onerror } method and then quits without invoking any more of its observer s methods . the { @code onerrorresumenext } method changes this behavior . if you pass another observablesource ( { @code resumesequence } ) to an observablesource s { @code onerrorresumenext } method if the original observablesource encounters an error instead of invoking its observer s { @code onerror } method it will instead relinquish control to { @code resumesequence } which will invoke the observer s { @link observer#onnext onnext } method if it is able to do so . in such a case because no observablesource necessarily invokes { @code onerror } the observer may never know that an error happened . <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorresumenext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs an observablesource to emit an item ( returned by a specified function ) rather than invoking { @link observer#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorreturn . o . png alt = > <p > by default when an observablesource encounters an error that prevents it from emitting the expected item to its { @link observer } the observablesource invokes its observer s { @code onerror } method and then quits without invoking any more of its observer s methods . the { @code onerrorreturn } method changes this behavior . if you pass a function ( { @code resumefunction } ) to an observablesource s { @code onerrorreturn } method if the original observablesource encounters an error instead of invoking its observer s { @code onerror } method it will instead emit the return value of { @code resumefunction } . <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorreturn } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs an observablesource to pass control to another observablesource rather than invoking { @link observer#onerror onerror } if it encounters an { @link java . lang . exception } . <p > this differs from { @link #onerrorresumenext } in that this one does not handle { @link java . lang . throwable } or { @link java . lang . error } but lets those continue through . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onexceptionresumenextviaobservablesource . png alt = > <p > by default when an observablesource encounters an exception that prevents it from emitting the expected item to its { @link observer } the observablesource invokes its observer s { @code onerror } method and then quits without invoking any more of its observer s methods . the { @code onexceptionresumenext } method changes this behavior . if you pass another observablesource ( { @code resumesequence } ) to an observablesource s { @code onexceptionresumenext } method if the original observablesource encounters an exception instead of invoking its observer s { @code onerror } method it will instead relinquish control to { @code resumesequence } which will invoke the observer s { @link observer#onnext onnext } method if it is able to do so . in such a case because no observablesource necessarily invokes { @code onerror } the observer may never know that an exception happened . <p > you can use this to prevent exceptions from propagating or to supply fallback data should exceptions be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onexceptionresumenext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
nulls out references to the upstream producer and downstream observer if the sequence is terminated or downstream calls dispose () . <p > <img width = 640 height = 246 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onterminatedetach . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns an observable that emits the results of invoking a specified selector on items emitted by a { @link connectableobservable } that shares a single subscription to the underlying sequence . <p > <img width = 640 height = 647 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / publishfunction . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code publish } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that applies a specified accumulator function to the first item emitted by a source observablesource then feeds the result of that function along with the second item emitted by the source observablesource into the same function and so on until all items have been emitted by the finite source observablesource and emits the final result from the final call to your function as its sole item . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / reduce . 2 . png alt = > <p > this technique which is called reduce here is sometimes called aggregate fold accumulate compress or inject in other programming contexts . groovy for instance has an { @code inject } method that does a similar operation on lists . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code reduce } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that applies a specified accumulator function to the first item emitted by a source observablesource and a specified seed value then feeds the result of that function along with the second item emitted by an observablesource into the same function and so on until all items have been emitted by the finite source observablesource emitting the final result from the final call to your function as its sole item . <p > <img width = 640 height = 325 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / reduceseed . o . png alt = > <p > this technique which is called reduce here is sometimes called aggregate fold accumulate compress or inject in other programming contexts . groovy for instance has an { @code inject } method that does a similar operation on lists . <p > note that the { @code seed } is shared among all subscribers to the resulting observablesource and may cause problems if it is mutable . to make sure each subscriber gets its own value defer the application of this operator via { @link #defer ( callable ) } : <pre > <code > observablesource&lt ; t&gt ; source = ... single . defer (( ) - &gt ; source . reduce ( new arraylist&lt ; &gt ; () ( list item ) - &gt ; list . add ( item ))) ;
returns a single that applies a specified accumulator function to the first item emitted by a source observablesource and a seed value derived from calling a specified seedsupplier then feeds the result of that function along with the second item emitted by an observablesource into the same function and so on until all items have been emitted by the finite source observablesource emitting the final result from the final call to your function as its sole item . <p > <img width = 640 height = 325 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / reducewith . o . png alt = > <p > this technique which is called reduce here is sometimes called aggregate fold accumulate compress or inject in other programming contexts . groovy for instance has an { @code inject } method that does a similar operation on lists . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code reducewith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that repeats the sequence of items emitted by the source observablesource indefinitely . <p > <img width = 640 height = 287 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeatinf . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that repeats the sequence of items emitted by the source observablesource at most { @code count } times . <p > <img width = 640 height = 336 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeatcount . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that repeats the sequence of items emitted by the source observablesource until the provided stop function returns true . <p > <img width = 640 height = 262 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeatuntil . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeatuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the same values as the source observablesource with the exception of an { @code oncomplete } . an { @code oncomplete } notification from the source will result in the emission of a { @code void } item to the observablesource provided as an argument to the { @code notificationhandler } function . if that observablesource calls { @code oncomplete } or { @code onerror } then { @code repeatwhen } will call { @code oncomplete } or { @code onerror } on the child subscription . otherwise this observablesource will resubscribe to the source observablesource . <p > <img width = 640 height = 430 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeatwhen . f . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeatwhen } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items that are the results of invoking a specified selector on the items emitted by a { @link connectableobservable } that shares a single subscription to the source observablesource . <p > <img width = 640 height = 449 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . f . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items that are the results of invoking a specified selector on items emitted by a { @link connectableobservable } that shares a single subscription to the source observablesource replaying no more than { @code buffersize } items that were emitted within a specified time window . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 350 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . fnt . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits items that are the results of invoking a specified selector on items emitted by a { @link connectableobservable } that shares a single subscription to the source observablesource . <p > <img width = 640 height = 406 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . fs . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a { @link connectableobservable } that shares a single subscription to the source observablesource that replays at most { @code buffersize } items emitted by that observablesource . a connectable observablesource resembles an ordinary observablesource except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . n . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a { @link connectableobservable } that shares a single subscription to the source observablesource and replays at most { @code buffersize } items that were emitted during a specified time window . a connectable observablesource resembles an ordinary observablesource except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . nt . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a { @link connectableobservable } that shares a single subscription to the source observablesource and that replays a maximum of { @code buffersize } items that are emitted within a specified time window . a connectable observablesource resembles an ordinary observablesource except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . nts . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a { @link connectableobservable } that shares a single subscription to the source observablesource and replays at most { @code buffersize } items emitted by that observablesource . a connectable observablesource resembles an ordinary observablesource except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . ns . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a { @link connectableobservable } that shares a single subscription to the source observablesource that will replay all of its items and notifications to any future { @link observer } on the given { @link scheduler } . a connectable observablesource resembles an ordinary observablesource except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . o . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that mirrors the source observablesource resubscribing to it if it calls { @code onerror } ( infinite retry count ) . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . png alt = > <p > if the source observablesource calls { @link observer#onerror } this method will resubscribe to the source observablesource rather than propagating the { @code onerror } call . <p > any and all items emitted by the source observablesource will be emitted by the resulting observablesource even those emitted during failed subscriptions . for example if an observablesource fails at first but emits { @code [ 1 2 ] } then succeeds the second time and emits { @code [ 1 2 3 4 5 ] } then the complete sequence of emissions and notifications would be { @code [ 1 2 1 2 3 4 5 oncomplete ] } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource resubscribing to it if it calls { @code onerror } and the predicate returns true for that specific exception and retry count . <p > <img width = 640 height = 235 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . o . ne . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource resubscribing to it if it calls { @code onerror } up to a specified number of retries . <p > <img width = 640 height = 325 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . o . n . png alt = > <p > if the source observablesource calls { @link observer#onerror } this method will resubscribe to the source observablesource for a maximum of { @code count } resubscriptions rather than propagating the { @code onerror } call . <p > any and all items emitted by the source observablesource will be emitted by the resulting observablesource even those emitted during failed subscriptions . for example if an observablesource fails at first but emits { @code [ 1 2 ] } then succeeds the second time and emits { @code [ 1 2 3 4 5 ] } then the complete sequence of emissions and notifications would be { @code [ 1 2 1 2 3 4 5 oncomplete ] } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
retries at most times or until the predicate returns false whichever happens first . <p > <img width = 640 height = 269 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . o . nfe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
retries the current observable if the predicate returns true . <p > <img width = 640 height = 248 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . o . e . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the same values as the source observablesource with the exception of an { @code onerror } . an { @code onerror } notification from the source will result in the emission of a { @link throwable } item to the observablesource provided as an argument to the { @code notificationhandler } function . if that observablesource calls { @code oncomplete } or { @code onerror } then { @code retry } will call { @code oncomplete } or { @code onerror } on the child subscription . otherwise this observablesource will resubscribe to the source observablesource . <p > <img width = 640 height = 430 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retrywhen . f . png alt = > <p > example :
returns an observable that emits the most recently emitted item ( if any ) emitted by the source observablesource within periodic time intervals . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sample . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sample } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits the most recently emitted item ( if any ) emitted by the source observablesource within periodic time intervals where the intervals are defined on a particular scheduler . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sample . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that when the specified { @code sampler } observablesource emits an item or completes emits the most recently emitted item ( if any ) emitted by the source observablesource since the previous emission from the { @code sampler } observablesource . <p > <img width = 640 height = 289 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sample . o . nolast . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code sample } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that applies a specified accumulator function to the first item emitted by a source observablesource then feeds the result of that function along with the second item emitted by the source observablesource into the same function and so on until all items have been emitted by the source observablesource emitting the result of each of these iterations . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / scan . png alt = > <p > this sort of function is sometimes called an accumulator . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code scan } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that applies a specified accumulator function to the first item emitted by a source observablesource and a seed value then feeds the result of that function along with the second item emitted by the source observablesource into the same function and so on until all items have been emitted by the source observablesource emitting the result of each of these iterations . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / scanseed . png alt = > <p > this sort of function is sometimes called an accumulator . <p > note that the observablesource that results from this method will emit { @code initialvalue } as its first emitted item . <p > note that the { @code initialvalue } is shared among all subscribers to the resulting observablesource and may cause problems if it is mutable . to make sure each subscriber gets its own value defer the application of this operator via { @link #defer ( callable ) } : <pre > <code > observablesource&lt ; t&gt ; source = ... observable . defer (( ) - &gt ; source . scan ( new arraylist&lt ; &gt ; () ( list item ) - &gt ; list . add ( item ))) ;
returns an observable that applies a specified accumulator function to the first item emitted by a source observablesource and a seed value then feeds the result of that function along with the second item emitted by the source observablesource into the same function and so on until all items have been emitted by the source observablesource emitting the result of each of these iterations . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / scanseed . png alt = > <p > this sort of function is sometimes called an accumulator . <p > note that the observablesource that results from this method will emit the value returned by the { @code seedsupplier } as its first item . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code scanwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
forces an observablesource s emissions and notifications to be serialized and for it to obey <a href = http : // reactivex . io / documentation / contract . html > the observablesource contract< / a > in other ways . <p > it is possible for an observablesource to invoke its observers methods asynchronously perhaps from different threads . this could make such an observablesource poorly - behaved in that it might try to invoke { @code oncomplete } or { @code onerror } before one of its { @code onnext } invocations or it might call { @code onnext } from two different threads concurrently . you can force such an observablesource to be well - behaved and sequential by applying the { @code serialize } method to it . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / synchronize . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code serialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that completes if this observable is empty or emits the single item emitted by this observable or signals an { @code illegalargumentexception } if this observable emits more than one item . <p > <img width = 640 height = 217 src = https : // raw . githubusercontent . com / wiki / reactivex / rxjava / images / rx - operators / singleelement . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code singleelement } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the single item emitted by this observable if this observable emits only a single item or a default item if the source observablesource emits no items . if the source observablesource emits more than one item an { @code illegalargumentexception } is signalled instead . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code single } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the single item emitted by this observable if this observable emits only a single item otherwise if this observable completes without emitting any items or emits more than one item a { @link nosuchelementexception } or { @code illegalargumentexception } will be signalled respectively . <p > <img width = 640 height = 228 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / singleorerror . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code singleorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that skips the first { @code count } items emitted by the source observablesource and emits the remainder . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skip . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code skip } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that skips values emitted by the source observablesource before a specified time window elapses . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skip . t . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skip } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that skips values emitted by the source observablesource before a specified time window on a specified { @link scheduler } elapses . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skip . ts . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use for the timed skipping< / dd > < / dl >
returns an observable that drops a specified number of items from the end of the sequence emitted by the source observablesource . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . png alt = > <p > this observer accumulates a queue long enough to store the first { @code count } items . as more items are received items are taken from the front of the queue and emitted by the returned observablesource . this causes such items to be delayed . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code skiplast } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that drops items emitted by the source observablesource during a specified time window before the source completes . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . t . png alt = > <p > note : this action will cache the latest items arriving in the specified time window . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skiplast } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that drops items emitted by the source observablesource during a specified time window ( defined on a specified scheduler ) before the source completes . <p > <img width = 640 height = 340 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . ts . png alt = > <p > note : this action will cache the latest items arriving in the specified time window . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use for tracking the current time< / dd > < / dl >
returns an observable that drops items emitted by the source observablesource during a specified time window ( defined on a specified scheduler ) before the source completes . <p > <img width = 640 height = 340 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . ts . png alt = > <p > note : this action will cache the latest items arriving in the specified time window . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that skips items emitted by the source observablesource until a second observablesource emits an item . <p > <img width = 640 height = 375 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skipuntil . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skipuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that skips all items emitted by the source observablesource as long as a specified condition holds true but emits all further source items as soon as the condition becomes false . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skipwhile . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skipwhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the events emitted by source observablesource in a sorted order . each item emitted by the observablesource must implement { @link comparable } with respect to all other items in the sequence . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sorted . png alt = > <p > if any item emitted by this observable does not implement { @link comparable } with respect to all other items emitted by this observable no items will be emitted and the sequence is terminated with a { @link classcastexception } .
returns an observable that emits the events emitted by source observablesource in a sorted order based on a specified comparison function .
returns an observable that emits the items in a specified { @link iterable } before it begins to emit items emitted by the source observablesource . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / startwith . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code startwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the items in a specified { @link observablesource } before it begins to emit items emitted by the source observablesource . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / startwith . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code startwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits a specified item before it begins to emit items emitted by the source observablesource . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / startwith . item . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code startwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits the specified items before it begins to emit items emitted by the source observablesource . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / startwitharray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code startwitharray } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to an observablesource and provides a callback to handle the items it emits . <p > if the observable emits an error it is wrapped into an { @link io . reactivex . exceptions . onerrornotimplementedexception onerrornotimplementedexception } and routed to the rxjavaplugins . onerror handler . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to an observablesource and provides callbacks to handle the items it emits and any error notification it issues . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to an observablesource and provides callbacks to handle the items it emits and any error or completion notification it issues . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
asynchronously subscribes observers to this observablesource on the specified { @link scheduler } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / subscribeon . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits the items emitted by the source observablesource or the items of an alternate observablesource if the source observablesource is empty . <p > <img width = 640 height = 255 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchifempty . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchifempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a new observablesource by applying a function that you supply to each item emitted by the source observablesource that returns an observablesource and then emitting the items emitted by the most recently emitted of these observablesources . <p > the resulting observablesource completes if both the upstream observablesource and the last inner observablesource if any complete . if the upstream observablesource signals an onerror the inner observablesource is disposed and the error delivered in - sequence . <p > <img width = 640 height = 350 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchmap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps the upstream values into {
maps the upstream values into {
maps the upstream items into {
maps the upstream items into {
returns a new observablesource by applying a function that you supply to each item emitted by the source observablesource that returns a singlesource and then emitting the item emitted by the most recently emitted of these singlesources . <p > the resulting observablesource completes if both the upstream observablesource and the last inner singlesource if any complete . if the upstream observablesource signals an onerror the inner singlesource is disposed and the error delivered in - sequence . <p > <img width = 640 height = 531 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchmapsingle . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a new observablesource by applying a function that you supply to each item emitted by the source observablesource that returns a singlesource and then emitting the item emitted by the most recently emitted of these singlesources and delays any error until all singlesources terminate . <p > the resulting observablesource completes if both the upstream observablesource and the last inner singlesource if any complete . if the upstream observablesource signals an onerror the termination of the last inner singlesource will emit that error as is or wrapped into a compositeexception along with the other possible errors the former inner singlesources signalled . <p > <img width = 640 height = 467 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchmapsingledelayerror . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a new observablesource by applying a function that you supply to each item emitted by the source observablesource that returns an observablesource and then emitting the items emitted by the most recently emitted of these observablesources and delays any error until all observablesources terminate . <p > the resulting observablesource completes if both the upstream observablesource and the last inner observablesource if any complete . if the upstream observablesource signals an onerror the termination of the last inner observablesource will emit that error as is or wrapped into a compositeexception along with the other possible errors the former inner observablesources signalled . <p > <img width = 640 height = 350 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchmap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchmapdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits only the first { @code count } items emitted by the source observablesource . if the source emits fewer than { @code count } items then all of its items are emitted . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / take . png alt = > <p > this method returns an observablesource that will invoke a subscribing { @link observer } s { @link observer#onnext onnext } function a maximum of { @code count } times before invoking { @link observer#oncomplete oncomplete } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code take } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits those items emitted by source observablesource before a specified time runs out . <p > if time runs out before the { @code observable } completes normally the { @code oncomplete } event will be signaled on the default { @code computation } { @link scheduler } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / take . t . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code take } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits those items emitted by source observablesource before a specified time ( on a specified scheduler ) runs out . <p > if time runs out before the { @code observable } completes normally the { @code oncomplete } event will be signaled on the provided { @link scheduler } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / take . ts . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits at most the last { @code count } items emitted by the source observablesource . if the source emits fewer than { @code count } items then all of its items are emitted . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takelast . n . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code takelast } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits at most a specified number of items from the source observablesource that were emitted in a specified window of time before the observablesource completed where the timing information is provided by a given scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takelast . tns . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use for tracking the current time< / dd > < / dl >
returns an observable that emits the items emitted by the source observable until a second observablesource emits an item . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takeuntil . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takeuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items emitted by the source observablesource so long as each item satisfied a specified condition and then completes as soon as this condition is not satisfied . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takewhile . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takewhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits only the first item emitted by the source observablesource during sequential time windows of a specified duration . <p > this differs from { @link #throttlelast } in that this only tracks passage of time whereas { @link #throttlelast } ticks at scheduled intervals . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlefirst . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code throttlefirst } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits only the first item emitted by the source observablesource during sequential time windows of a specified duration where the windows are managed by a specified scheduler . <p > this differs from { @link #throttlelast } in that this only tracks passage of time whereas { @link #throttlelast } ticks at scheduled intervals . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlefirst . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits only the last item emitted by the source observablesource during sequential time windows of a specified duration . <p > this differs from { @link #throttlefirst } in that this ticks along at a scheduled interval whereas { @link #throttlefirst } does not tick it just tracks passage of time . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlelast . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code throttlelast } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits only the last item emitted by the source observablesource during sequential time windows of a specified duration where the duration is governed by a specified scheduler . <p > this differs from { @link #throttlefirst } in that this ticks along at a scheduled interval whereas { @link #throttlefirst } does not tick it just tracks passage of time . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlelast . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that mirrors the source observablesource except that it drops items emitted by the source observablesource that are followed by newer items before a timeout value expires . the timer resets on each emission ( alias to { @link #debounce ( long timeunit scheduler ) } ) . <p > <em > note : < / em > if items keep being emitted by the source observablesource faster than the timeout then no items will be emitted by the resulting observablesource . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlewithtimeout . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code throttlewithtimeout } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource except that it drops items emitted by the source observablesource that are followed by newer items before a timeout value expires on a specified scheduler . the timer resets on each emission ( alias to { @link #debounce ( long timeunit scheduler ) } ) . <p > <em > note : < / em > if items keep being emitted by the source observablesource faster than the timeout then no items will be emitted by the resulting observablesource . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlewithtimeout . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits records of the time interval between consecutive items emitted by the source observablesource . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeinterval . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code timeinterval } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits records of the time interval between consecutive items emitted by the source observablesource where this interval is computed on a specified scheduler . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeinterval . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > the operator does not operate on any particular scheduler but uses the current time from the specified { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource but notifies observers of a { @code timeoutexception } if an item emitted by the source observablesource doesn t arrive within a window of time after the emission of the previous item where that period of time is measured by an observablesource that is a function of the previous item . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout3 . png alt = > <p > note : the arrival of the first source item is never timed out . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code immediate } { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource but that switches to a fallback observablesource if an item emitted by the source observablesource doesn t arrive within a window of time after the emission of the previous item where that period of time is measured by an observablesource that is a function of the previous item . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout4 . png alt = > <p > note : the arrival of the first source item is never timed out . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code immediate } { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource but applies a timeout policy for each emitted item . if the next item isn t emitted within the specified timeout duration starting from its predecessor the resulting observablesource terminates and notifies observers of a { @code timeoutexception } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 1 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource but applies a timeout policy for each emitted item . if the next item isn t emitted within the specified timeout duration starting from its predecessor the source observablesource is disposed and resulting observablesource begins instead to mirror a fallback observablesource . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that mirrors the source observablesource but applies a timeout policy for each emitted item using a specified scheduler . if the next item isn t emitted within the specified timeout duration starting from its predecessor the source observablesource is disposed and resulting observablesource begins instead to mirror a fallback observablesource . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 2s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that mirrors the source observablesource but applies a timeout policy for each emitted item where this policy is governed on a specified scheduler . if the next item isn t emitted within the specified timeout duration starting from its predecessor the resulting observablesource terminates and notifies observers of a { @code timeoutexception } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 1s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits each item emitted by the source observablesource wrapped in a { @link timed } object whose timestamps are provided by a specified scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timestamp . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this operator does not operate on any particular scheduler but uses the current time from the specified { @link scheduler } . < / dd > < / dl >
returns an observable that emits each item emitted by the source observablesource wrapped in a { @link timed } object whose timestamps are provided by a specified scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timestamp . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this operator does not operate on any particular scheduler but uses the current time from the specified { @link scheduler } . < / dd > < / dl >
returns a single that emits a single item a list composed of all the items emitted by the finite source observablesource . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tolist . 2 . png alt = > <p > normally an observablesource that returns multiple items will do so by invoking its { @link observer } s { @link observer#onnext onnext } method for each such item . you can change this behavior instructing the observablesource to compose a list of all of these items and then to invoke the observer s { @code onnext } function once passing it the entire list by calling the observablesource s { @code tolist } method prior to calling its { @link #subscribe } method . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated list to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tolist } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a single item a list composed of all the items emitted by the finite source observablesource . <p > <img width = 640 height = 365 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tolist . o . c . png alt = > <p > normally an observablesource that returns multiple items will do so by invoking its { @link observer } s { @link observer#onnext onnext } method for each such item . you can change this behavior instructing the observablesource to compose a list of all of these items and then to invoke the observer s { @code onnext } function once passing it the entire list by calling the observablesource s { @code tolist } method prior to calling its { @link #subscribe } method . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated collection to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tolist } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a single hashmap that contains an arraylist of items emitted by the finite source observablesource keyed by a specified { @code keyselector } function . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tomultimap . 2 . png alt = > <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated map to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tomultimap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts the current observable into a flowable by applying the specified backpressure strategy . <p > marble diagrams for the various backpressure strategies are as follows : <ul > <li > { @link backpressurestrategy#buffer } <p > <img width = 640 height = 274 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / toflowable . o . buffer . png alt = > < / li > <li > { @link backpressurestrategy#drop } <p > <img width = 640 height = 389 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / toflowable . o . drop . png alt = > < / li > <li > { @link backpressurestrategy#latest } <p > <img width = 640 height = 296 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / toflowable . o . latest . png alt = > < / li > <li > { @link backpressurestrategy#error } <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / toflowable . o . error . png alt = > < / li > <li > { @link backpressurestrategy#missing } <p > <img width = 640 height = 411 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / toflowable . o . missing . png alt = > < / li > < / ul > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator applies the chosen backpressure strategy of { @link backpressurestrategy } enum . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code toflowable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a list that contains the items emitted by the finite source observablesource in a sorted order . each item emitted by the observablesource must implement { @link comparable } with respect to all other items in the sequence .
modifies the source observablesource so that subscribers will dispose it on a specified { @link scheduler } . <p > <img width = 640 height = 452 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / unsubscribeon . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping windows each containing { @code count } items . when the source observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window3 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits windows every { @code skip } items each containing no more than { @code count } items . when the source observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 365 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window4 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource starts a new window periodically as determined by the { @code timeskip } argument . it emits each window after a fixed timespan specified by the { @code timespan } argument . when the source observablesource completes or observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window7 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource starts a new window periodically as determined by the { @code timeskip } argument . it emits each window after a fixed timespan specified by the { @code timespan } argument . when the source observablesource completes or observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window7 . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping windows each of a fixed duration specified by the { @code timespan } argument . when the source observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 375 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window5 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping windows each of a fixed duration specified by the { @code timespan } argument or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window6 . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping windows each of a fixed duration specified by the { @code timespan } argument or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source observablesource completes or encounters an error the resulting observablesource emits the current window and propagates the notification from the source observablesource . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window6 . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns an observable that emits non - overlapping windows of items it collects from the source observablesource where the boundary of each window is determined by the items emitted from a specified boundary - governing observablesource . <p > <img width = 640 height = 475 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window8 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits windows that contain those items emitted by the source observablesource between the time when the { @code openingindicator } observablesource emits an item and when the observablesource returned by { @code closingindicator } emits an item . <p > <img width = 640 height = 550 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits windows that contain those items emitted by the source observablesource between the time when the { @code openingindicator } observablesource emits an item and when the observablesource returned by { @code closingindicator } emits an item . <p > <img width = 640 height = 550 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window2 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits windows of items it collects from the source observablesource . the resulting observablesource emits connected non - overlapping windows . it emits the current window and opens a new one whenever the observablesource produced by the specified { @code closingindicator } emits an item . <p > <img width = 640 height = 455 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window1 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items that are the result of applying a specified function to pairs of values one each from the source observablesource and a specified iterable sequence . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / zip . i . png alt = > <p > note that the { @code other } iterable is evaluated as items are observed from the source observablesource ; it is not pre - consumed . this allows you to zip infinite streams on either side . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zipwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that emits items that are the result of applying a specified function to pairs of values one each from the source observablesource and another specified observablesource . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / zip . png alt = > <p > the operator subscribes to its sources in order they are specified and completes eagerly if one of the sources is shorter than the rest while disposing the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will dispose b immediately . for example : <pre > <code > range ( 1 5 ) . dooncomplete ( action1 ) . zipwith ( range ( 6 5 ) . dooncomplete ( action2 ) ( a b ) - &gt ; a + b ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #doondispose ( action ) } as well or use { @code using () } to do cleanup in case of completion or a dispose () call . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zipwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
todo fuse back to observable
returns an {
connects to the upstream {
connects to the upstream {
connects to the upstream {
returns an observable that automatically connects ( at most once ) to this connectableobservable when the specified number of subscribers subscribe to it and calls the specified callback with the subscription associated with the established connection . <p > <img width = 640 height = 348 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / autoconnect . o . png alt = > <p > the connection happens after the given number of subscriptions and happens at most once during the lifetime of the returned observable . if this connectableobservable terminates the connection is never renewed no matter how observers come and go . use { @link #refcount () } to renew a connection or dispose an active connection when all { @code observer } s have disposed their { @code disposable } s .
validates the number of subscribers and returns true if their number matches the parallelism level of this parallelflowable .
take a publisher and prepare to consume it on multiple rails ( number of cpus ) in a round - robin fashion .
take a publisher and prepare to consume it on parallelism number of rails in a round - robin fashion .
take a publisher and prepare to consume it on parallelism number of rails possibly ordered and round - robin fashion and use custom prefetch amount and queue for dealing with the source publisher s values .
calls the specified converter function during assembly time and returns its resulting value . <p > this allows fluent conversion to any other type . <p > history : 2 . 1 . 7 - experimental
maps the source values on each rail to another value . <p > note that the same mapper function may be called from multiple threads concurrently .
maps the source values on each rail to another value and handles errors based on the given {
filters the source values on each rail . <p > note that the same predicate may be called from multiple threads concurrently .
filters the source values on each rail and handles errors based on the given {
specifies where each rail will observe its incoming values with no work - stealing and default prefetch amount . <p > this operator uses the default prefetch size returned by { @code flowable . buffersize () } . <p > the operator will call { @code scheduler . createworker () } as many times as this parallelflowable s parallelism level is . <p > no assumptions are made about the scheduler s parallelism level if the scheduler s parallelism level is lower than the parallelflowable s some rails may end up on the same thread / worker . <p > this operator doesn t require the scheduler to be trampolining as it does its own built - in trampolining logic .
specifies where each rail will observe its incoming values with possibly work - stealing and a given prefetch amount . <p > this operator uses the default prefetch size returned by { @code flowable . buffersize () } . <p > the operator will call { @code scheduler . createworker () } as many times as this parallelflowable s parallelism level is . <p > no assumptions are made about the scheduler s parallelism level if the scheduler s parallelism level is lower than the parallelflowable s some rails may end up on the same thread / worker . <p > this operator doesn t require the scheduler to be trampolining as it does its own built - in trampolining logic .
reduces all values within a rail and across rails with a reducer function into a single sequential value . <p > note that the same reducer function may be called from multiple threads concurrently .
reduces all values within a rail to a single value ( with a possibly different type ) via a reducer function that is initialized on each rail from an initialsupplier value . <p > note that the same mapper function may be called from multiple threads concurrently .
merges the values from each rail in a round - robin or same - order fashion and exposes it as a regular publisher sequence running with a default prefetch value for the rails . <p > this operator uses the default prefetch size returned by {
merges the values from each rail in a round - robin or same - order fashion and exposes it as a regular publisher sequence running with a give prefetch value for the rails . <img width = 640 height = 602 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / parallelflowable . sequential . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
merges the values from each rail in a round - robin or same - order fashion and exposes it as a regular flowable sequence running with a default prefetch value for the rails and delaying errors from all rails till all terminate . <p > this operator uses the default prefetch size returned by {
merges the values from each rail in a round - robin or same - order fashion and exposes it as a regular publisher sequence running with a give prefetch value for the rails and delaying errors from all rails till all terminate . <img width = 640 height = 602 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / parallelflowable . sequential . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
sorts the rails of this parallelflowable and returns a publisher that sequentially picks the smallest next value from the rails . <p > this operator requires a finite source parallelflowable .
sorts the rails according to the comparator and returns a full sorted list as a publisher . <p > this operator requires a finite source parallelflowable .
sorts the rails according to the comparator and returns a full sorted list as a publisher . <p > this operator requires a finite source parallelflowable .
call the specified consumer with the current element passing through any rail .
call the specified consumer with the current element passing through any rail and handles errors based on the given {
call the specified consumer with the current element passing through any rail after it has been delivered to downstream within the rail .
call the specified consumer with the exception passing through any rail .
run the specified action when a rail completes .
run the specified action when a rail completes or signals an error .
call the specified callback when a rail receives a subscription from its upstream .
call the specified consumer with the request amount if any rail receives a request .
run the specified action when a rail receives a cancellation .
collect the elements in each rail into a collection supplied via a collectionsupplier and collected into with a collector action emitting the collection at the end .
wraps multiple publishers into a parallelflowable which runs them in parallel and unordered .
perform a fluent transformation to a value via a converter function which receives this parallelflowable .
allows composing operators in assembly time on top of this parallelflowable and returns another parallelflowable with composed features .
generates and flattens publishers on each rail optionally delaying errors . <p > it uses unbounded concurrency along with default inner prefetch .
generates and flattens publishers on each rail optionally delaying errors having a total number of simultaneous subscriptions to the inner publishers and using the given prefetch amount for the inner publishers .
generates and concatenates publishers on each rail signalling errors immediately and generating 2 publishers upfront .
generates and concatenates publishers on each rail signalling errors immediately and using the given prefetch amount for generating publishers upfront .
generates and concatenates publishers on each rail optionally delaying errors and generating 2 publishers upfront .
generates and concatenates publishers on each rail optionally delaying errors and using the given prefetch amount for generating publishers upfront .
given a connectable observable factory it multicasts over the generated connectableobservable via a selector function .
child observers will observe the events of the connectableobservable on the specified scheduler .
creates a replaying connectableobservable with an unbounded buffer .
creates a replaying connectableobservable with a size bound buffer .
creates a replaying connectableobservable with a time bound buffer .
creates a replaying connectableobservable with a size and time bound buffer .
creates a operatorreplay instance to replay values of the given source observable .
sets the resource at the specified index and disposes the old resource .
replaces the resource at the specified index and returns the old resource .
creates an unicastprocessor with the given internal buffer capacity hint .
creates an unicastprocessor with default internal buffer capacity hint and delay error flag . <p > history : 2 . 0 . 8 - experimental
creates an unicastprocessor with the given internal buffer capacity hint and a callback for the case when the single subscriber cancels its subscription .
tries to subscribe to a possibly callable source s mapped publisher .
maps a scalar value into a publisher and emits its values .
construct a disposable by wrapping a runnable that is executed exactly once when the disposable is disposed .
construct a disposable by wrapping a action that is executed exactly once when the disposable is disposed .
construct a disposable by wrapping a future that is cancelled exactly once when the disposable is disposed .
construct a disposable by wrapping a future that is cancelled exactly once when the disposable is disposed .
construct a disposable by wrapping a subscription that is cancelled exactly once when the disposable is disposed .
block until the first value arrives and return it otherwise return null for an empty source and rethrow any exception .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
called when an undeliverable error occurs . <p > undeliverable errors are those { @code observer . onerror () } invocations that are not allowed to happen on the given consumer type ( { @code observer } { @code subscriber } etc . ) due to protocol restrictions because the consumer has either disposed / cancelled its { @code disposable } / { @code subscription } or has already terminated with an { @code onerror () } or { @code oncomplete () } signal . <p > by default this global error handler prints the stacktrace via { @link throwable#printstacktrace () } and calls { @link java . lang . thread . uncaughtexceptionhandler#uncaughtexception ( thread throwable ) } on the current thread . <p > note that on some platforms the platform runtime terminates the current application with an error if such uncaught exceptions happen . in this case it is recommended the application installs a global error handler via the { @link #seterrorhandler ( consumer ) } plugin method .
calls the associated hook function .
calls the associated hook function .
called when a task is scheduled .
calls the associated hook function .
removes all handlers and resets to default behavior .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
sets the specific hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
calls the associated hook function .
sets the specific hook function . <p > history : 2 . 0 . 6 - experimental ; 2 . 1 - beta
calls the associated hook function . <p > history : 2 . 0 . 6 - experimental ; 2 . 1 - beta
called before an operator attempts a blocking operation such as awaiting a condition or signal and should return true to indicate the operator should not block but throw an illegalargumentexception . <p > history : 2 . 0 . 5 - experimental
create an instance of the default {
wraps the call to the function in try - catch and propagates thrown checked exceptions as runtimeexception .
wraps the call to the function in try - catch and propagates thrown checked exceptions as runtimeexception .
wraps the call to the scheduler creation callable in try - catch and propagates thrown checked exceptions as runtimeexception and enforces that result is not null .
wraps the call to the scheduler creation function in try - catch and propagates thrown checked exceptions as runtimeexception and enforces that result is not null .
runs multiple maybesources and signals the events of the first one that signals ( disposing the rest ) . <p > <img width = 640 height = 519 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . amb . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
runs multiple maybesources and signals the events of the first one that signals ( disposing the rest ) . <p > <img width = 640 height = 519 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . ambarray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
concatenate the single values in a non - overlapping fashion of the maybesource sources provided by a publisher sequence . <p > <img width = 640 height = 416 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . concat . p . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
concatenates a variable number of maybesource sources and delays errors from any of them till all terminate . <p > <img width = 640 height = 425 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . concatarraydelayerror . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
concatenates a sequence of maybesource eagerly into a single stream of values . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source maybesources . the operator buffers the value emitted by these maybesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 489 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . concatarrayeager . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
concatenates a sequence of maybesources eagerly into a single stream of values . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source maybesources . the operator buffers the values emitted by these maybesources and then drains them in order each one after the previous one completes . <p > <img width = 640 height = 526 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . concateager . i . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > backpressure is honored towards the downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
provides an api ( via a cold maybe ) that bridges the reactive world with the callback - style world . <p > example : <pre > <code > maybe . &lt ; event&gt ; create ( emitter - &gt ; { callback listener = new callback () { &#64 ; override public void onevent ( event e ) { if ( e . isnothing () ) { emitter . oncomplete () ; } else { emitter . onsuccess ( e ) ; } }
calls a callable for each individual maybeobserver to return the actual maybesource source to be subscribed to . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a ( singleton ) maybe instance that calls {
returns a maybe that invokes a subscriber s { @link maybeobserver#onerror onerror } method when the subscriber subscribes to it . <p > <img width = 640 height = 447 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . error . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code error } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that invokes a { @link maybeobserver } s { @link maybeobserver#onerror onerror } method when the maybeobserver subscribes to it . <p > <img width = 640 height = 190 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / error . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code error } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
wraps a completablesource into a maybe .
wraps a singlesource into a maybe .
returns a { @link maybe } that invokes the given { @link callable } for each individual { @link maybeobserver } that subscribes and emits the resulting non - null item via { @code onsuccess } while considering a { @code null } result from the { @code callable } as indication for valueless completion via { @code oncomplete } . <p > this operator allows you to defer the execution of the given { @code callable } until a { @code maybeobserver } subscribes to the returned { @link maybe } . in other terms this source operator evaluates the given { @code callable } lazily . <p > note that the { @code null } handling of this operator differs from the similar source operators in the other { @link io . reactivex base reactive classes } . those operators signal a { @code nullpointerexception } if the value returned by their { @code callable } is { @code null } while this { @code fromcallable } considers it to indicate the returned { @code maybe } is empty . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromcallable } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > any non - fatal exception thrown by { @link callable#call () } will be forwarded to { @code onerror } except if the { @code maybeobserver } disposed the subscription in the meantime . in this latter case the exception is forwarded to the global error handler via { @link io . reactivex . plugins . rxjavaplugins#onerror ( throwable ) } wrapped into a { @link io . reactivex . exceptions . undeliverableexception undeliverableexception } . fatal exceptions are rethrown and usually will end up in the executing thread s { @link java . lang . thread . uncaughtexceptionhandler#uncaughtexception ( thread throwable ) } handler . < / dd > < / dl >
converts a { @link future } into a maybe treating a null result as an indication of emptiness . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / from . future . png alt = > <p > you can convert any object that supports the { @link future } interface into a maybe that emits the return value of the { @link future#get } method of that object by passing the object into the { @code from } method . <p > <em > important note : < / em > this maybe is blocking ; you cannot dispose it . <p > unlike 1 . x disposing the maybe won t cancel the future . if necessary one can use composition to achieve the cancellation effect : { @code futuremaybe . doondispose (( ) - > future . cancel ( true )) ; } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromfuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts a { @link future } into a maybe with a timeout on the future . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / from . future . png alt = > <p > you can convert any object that supports the { @link future } interface into a maybe that emits the return value of the { @link future#get } method of that object by passing the object into the { @code fromfuture } method . <p > unlike 1 . x disposing the maybe won t cancel the future . if necessary one can use composition to achieve the cancellation effect : { @code futuremaybe . dooncancel (( ) - > future . cancel ( true )) ; } . <p > <em > important note : < / em > this maybe is blocking on the thread it gets subscribed on ; you cannot dispose it . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromfuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe instance that runs the given action for each subscriber and emits either its exception or simply completes . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a { @code maybe } that emits a specified item . <p > <img width = 640 height = 485 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . just . png alt = > <p > to convert any object into a { @code maybe } that emits that object pass that object into the { @code just } method . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code just } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
merges a flowable sequence of maybesource instances into a single flowable sequence running all maybesources at once . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
flattens an array of maybesources into one flowable in a way that allows a subscriber to receive all successfully emitted items from each of the source maybesources without being interrupted by an error notification from one of them . <p > this behaves like { @link #merge ( publisher ) } except that if any of the merged maybesources notify of an error via { @link subscriber#onerror onerror } { @code mergedelayerror } will refrain from propagating that error notification until all of the merged maybesources have finished emitting items . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergedelayerror . png alt = > <p > even if multiple merged maybesources send { @code onerror } notifications { @code mergedelayerror } will only invoke the { @code onerror } method of its subscribers once . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergearraydelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
flattens an iterable of maybesources into one flowable in a way that allows a subscriber to receive all successfully emitted items from each of the source maybesources without being interrupted by an error notification from one of them . <p > this behaves like { @link #merge ( publisher ) } except that if any of the merged maybesources notify of an error via { @link subscriber#onerror onerror } { @code mergedelayerror } will refrain from propagating that error notification until all of the merged maybesources have finished emitting items . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergedelayerror . png alt = > <p > even if multiple merged maybesources send { @code onerror } notifications { @code mergedelayerror } will only invoke the { @code onerror } method of its subscribers once . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergedelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that never sends any items or notifications to a { @link maybeobserver } . <p > <img width = 640 height = 185 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / never . png alt = > <p > this maybe is useful primarily for testing purposes . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code never } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two maybesource sequences are the same by comparing the items emitted by each maybesource pairwise . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two maybesources are the same by comparing the items emitted by each maybesource pairwise based on the results of a specified equality function . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits { @code 0l } after a specified delay . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timer . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code timer } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a maybe that emits { @code 0l } after a specified delay on a specified scheduler . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timer . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
<strong > advanced use only : < / strong > creates a maybe instance without any safeguards by using a callback that is called with a maybeobserver . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
constructs a maybe that creates a dependent resource object which is disposed of when the upstream terminates or the downstream calls dispose () . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / using . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code using } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
constructs a maybe that creates a dependent resource object which is disposed of just before termination if you have set { @code disposeeagerly } to { @code true } and a downstream dispose () does not occur before termination . otherwise resource disposal will occur on call to dispose () . eager disposal is particularly appropriate for a synchronous maybe that reuses resources . { @code disposeaction } will only be called once per subscription . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / using . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code using } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
wraps a maybesource instance into a new maybe instance if not already a maybe instance . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a maybe that emits the results of a specified combiner function applied to combinations of items emitted in sequence by an iterable of other maybesources . <p > note on method signature : since java doesn t allow creating a generic array with { @code new t [] } the implementation of this operator has to create an { @code object [] } instead . unfortunately a { @code function<integer [] r > } passed to the method would trigger a { @code classcastexception } .
returns a maybe that emits the results of a specified combiner function applied to combinations of items emitted in sequence by an array of other maybesources . <p > note on method signature : since java doesn t allow creating a generic array with { @code new t [] } the implementation of this operator has to create an { @code object [] } instead . unfortunately a { @code function<integer [] r > } passed to the method would trigger a { @code classcastexception } .
mirrors the maybesource ( current or provided ) that first signals an event . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / amb . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code ambwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
waits in a blocking fashion until the current maybe signals a success value ( which is returned ) null if completed or an exception ( which is propagated ) . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
waits in a blocking fashion until the current maybe signals a success value ( which is returned ) defaultvalue if completed or an exception ( which is propagated ) . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a maybe that subscribes to this maybe lazily caches its event and replays it to all the downstream subscribers . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / cache . png alt = > <p > the operator subscribes only when the first downstream subscriber subscribes and maintains a single subscription towards this maybe . <p > <em > note : < / em > you sacrifice the ability to dispose the origin when you use the { @code cache } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code cache } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
transform a maybe by applying a particular transformer function to it . <p > this method operates on the maybe itself whereas { @link #lift } operates on the maybe s maybeobservers . <p > if the operator you are creating is designed to act on the individual item emitted by a maybe use { @link #lift } . if your operator is designed to transform the source maybe as a whole ( for instance by applying a particular set of existing rxjava operators to it ) use { @code compose } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code compose } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that is based on applying a specified function to the item emitted by the source maybe where that function returns a maybesource . <p > <img width = 640 height = 356 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . flatmap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a flowable that emits the items emitted from the current maybesource then the next one after the other without interleaving them . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concat . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean that indicates whether the source maybe emitted a specified item . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / contains . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code contains } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that counts the total number of items emitted ( 0 or 1 ) by the source maybe and emits this count as a 64 - bit long . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / longcount . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code count } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that signals the events emitted by the source maybe shifted forward in time by a specified delay . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code delay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a maybe that signals the events emitted by the source maybe shifted forward in time by a specified delay running on the specified scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a maybe that delays the subscription to this maybe until the other publisher emits an element or completes normally . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the { @code publisher } source is consumed in an unbounded fashion ( without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that delays the subscription to the source maybe by a given amount of time both waiting and subscribing on a given scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delaysubscription . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
calls the shared consumer with the error sent via onerror for each maybeobserver that subscribes to the current maybe . <p > <img width = 640 height = 358 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonerror . m . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
calls the given onevent callback with the ( success value null ) for an onsuccess ( null throwable ) for an onerror or ( null null ) for an oncomplete signal from this maybe before delivering said signal to the downstream . <p > exceptions thrown from the callback will override the event so the downstream receives the error instead of the original signal . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a maybe instance that calls the given onterminate callback just before this maybe completes normally or with an exception . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonterminate . png alt = > <p > this differs from {
returns a maybe that emits the results of a specified function to the pair of values emitted by the source maybe and a specified mapped maybesource . <p > <img width = 640 height = 390 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergemap . r . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps the success value of the upstream { @link maybe } into an { @link iterable } and emits its items as a { @link flowable } sequence . <p > <img width = 640 height = 373 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flattenasflowable . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flattenasflowable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
hides the identity of this maybe and its disposable . <p > <img width = 640 height = 300 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . hide . png alt = > <p > allows preventing certain identity - based optimizations ( fusion ) . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
ignores the item emitted by the source maybe and only calls { @code oncomplete } or { @code onerror } . <p > <img width = 640 height = 389 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . ignoreelement . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code ignoreelement } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits { @code true } if the source maybe is empty otherwise { @code false } . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / isempty . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code isempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
<strong > this method requires advanced knowledge about building operators please consider other standard composition methods first ; < / strong > returns a { @code maybe } which when subscribed to invokes the { @link maybeoperator#apply ( maybeobserver ) apply ( maybeobserver ) } method of the provided { @link maybeoperator } for each individual downstream { @link maybe } and allows the insertion of a custom operator by accessing the downstream s { @link maybeobserver } during this subscription phase and providing a new { @code maybeobserver } containing the custom operator s intended business logic that will be used in the subscription process going further upstream . <p > generally such a new { @code maybeobserver } will wrap the downstream s { @code maybeobserver } and forwards the { @code onsuccess } { @code onerror } and { @code oncomplete } events from the upstream directly or according to the emission pattern the custom operator s business logic requires . in addition such operator can intercept the flow control calls of { @code dispose } and { @code isdisposed } that would have traveled upstream and perform additional actions depending on the same business logic requirements . <p > example : <pre > <code > // step 1 : create the consumer type that will be returned by the maybeoperator . apply () :
returns a maybe that applies a specified function to the item emitted by the source maybe and emits the result of this function application . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / maybe . map . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code map } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
filters the items emitted by a maybe only emitting its success value if that is an instance of the supplied class . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / ofclass . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code oftype } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the specified converter function with the current maybe instance during assembly time and returns its result . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code to } does not operate by default on a particular { @link scheduler } . < / dd > < / dl > @param <r > the result type @param convert the function that is called with the current maybe instance during assembly time that should return some value to be the result
converts this maybe into an observable instance composing disposal through . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
converts this maybe into a single instance composing disposal through and turning an empty maybe into a signal of nosuchelementexception . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a maybe instance that if this maybe emits an error it will emit an oncomplete and swallow the throwable . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
instructs a maybe to pass control to another { @link maybesource } rather than invoking { @link maybeobserver#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorresumenext . png alt = > <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorresumenext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs a maybe to pass control to another maybe rather than invoking { @link maybeobserver#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorresumenext . png alt = > <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorresumenext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs a maybe to emit an item ( returned by a specified function ) rather than invoking { @link maybeobserver#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorreturn . png alt = > <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorreturn } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
nulls out references to the upstream producer and downstream maybeobserver if the sequence is terminated or downstream calls dispose () . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a flowable that repeats the sequence of items emitted by the source maybe until the provided stop function returns true . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeat . on . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator honors downstream backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeatuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the same values as the source publisher with the exception of an { @code oncomplete } . an { @code oncomplete } notification from the source will result in the emission of a { @code void } item to the publisher provided as an argument to the { @code notificationhandler } function . if that publisher calls { @code oncomplete } or { @code onerror } then { @code repeatwhen } will call { @code oncomplete } or { @code onerror } on the child subscription . otherwise this publisher will resubscribe to the source publisher . <p > <img width = 640 height = 430 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeatwhen . f . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeatwhen } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that mirrors the source maybe resubscribing to it if it calls { @code onerror } and the predicate returns true for that specific exception and retry count . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that mirrors the source maybe resubscribing to it if it calls { @code onerror } up to a specified number of retries . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . png alt = > <p > if the source maybe calls { @link maybeobserver#onerror } this method will resubscribe to the source maybe for a maximum of { @code count } resubscriptions rather than propagating the { @code onerror } call . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
retries at most times or until the predicate returns false whichever happens first .
returns a maybe that emits the same values as the source maybe with the exception of an { @code onerror } . an { @code onerror } notification from the source will result in the emission of a { @link throwable } item to the publisher provided as an argument to the { @code notificationhandler } function . if that publisher calls { @code oncomplete } or { @code onerror } then { @code retry } will call { @code oncomplete } or { @code onerror } on the child subscription . otherwise this publisher will resubscribe to the source publisher . <p > <img width = 640 height = 430 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retrywhen . f . png alt = > <p > example :
subscribes to a maybe and ignores { @code onsuccess } and { @code oncomplete } emissions . <p > if the maybe emits an error it is wrapped into an { @link io . reactivex . exceptions . onerrornotimplementedexception onerrornotimplementedexception } and routed to the rxjavaplugins . onerror handler . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to a maybe and provides callbacks to handle the items it emits and any error notification it issues . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits the items emitted by the source maybe or the items of an alternate maybesource if the current maybe is empty . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchifempty . m . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchifempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the items emitted by the source maybe or the item of an alternate singlesource if the current maybe is empty . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchifempty . m . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a maybe that emits the items emitted by the source maybe until a second maybesource emits an item . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takeuntil . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takeuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that mirrors the source maybe but applies a timeout policy for each emitted item . if the next item isn t emitted within the specified timeout duration starting from its predecessor the resulting maybe terminates and notifies maybeobservers of a { @code timeoutexception } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 1 . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a maybe that mirrors the source maybe but applies a timeout policy for each emitted item where this policy is governed on a specified scheduler . if the next item isn t emitted within the specified timeout duration starting from its predecessor the resulting maybe terminates and notifies maybeobservers of a { @code timeoutexception } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 1s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
if the current {
if the current {
returns a maybe which makes sure when a maybeobserver disposes the disposable that call is propagated up on the specified scheduler . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
creates a operatorpublish instance to publish values of the given source observable .
creates a {
verifies if the object is not null and returns it or throws a nullpointerexception with the given message .
returns a bipredicate that compares its parameters via objects . equals () .
emits the given exception if possible or adds it to the given error container to be emitted by a concurrent onnext if one is running . undeliverable exceptions are sent to the rxjavaplugins . onerror .
emits an oncomplete signal or an onerror signal with the given error or indicates the concurrently running onnext should do that .
emits the given exception if possible or adds it to the given error container to be emitted by a concurrent onnext if one is running . undeliverable exceptions are sent to the rxjavaplugins . onerror .
emits an oncomplete signal or an onerror signal with the given error or indicates the concurrently running onnext should do that .
returns an identity function that simply returns its argument .
returns a callable that returns the given value .
returns a function that ignores its parameter and returns the given value .
returns a function that cast the incoming values via a class object .
special handling for printing out a { @code compositeexception } . loops through all inner exceptions and prints them out .
/ * private
creates an unicastsubject with an internal buffer capacity hint 16 .
creates an unicastsubject with the given internal buffer capacity hint .
creates an unicastsubject with the given internal buffer capacity hint and a callback for the case when the single subscriber cancels its subscription .
creates an unicastsubject with an internal buffer capacity hint 16 and given delay error flag .
tries to emit the item to all currently subscribed subscribers if all of them has requested some value returns false otherwise . <p > this method should be called in a sequential manner just like the onxxx methods of the publishprocessor . <p > calling with null will terminate the publishprocessor and a nullpointerexception is signalled to the subscribers . <p > history : 2 . 0 . 8 - experimental
final : fixed protocol steps to support fuseable and non - fuseable upstream
-----------------------------------
rethrows the throwable if it is a fatal exception or calls {
calls the upstream s queuedisposable . requestfusion with the mode and saves the established mode in {
block until the latch is counted down and return the error received or null if no error happened .
block until the latch is counted down and return the error received or when the wait is interrupted or times out null otherwise .
block until the observer terminates and return true ; return false if the wait times out .
creates an unbounded replayprocessor with the specified initial buffer capacity . <p > use this method to avoid excessive array reallocation while the internal buffer grows to accommodate new items . for example if you know that the buffer will hold 32k items you can ask the { @code replayprocessor } to preallocate its internal array with a capacity to hold that many items . once the items start to arrive the internal array won t need to grow creating less garbage and no overhead due to frequent array - copying .
creates a size - bounded replayprocessor . <p > in this setting the { @code replayprocessor } holds at most { @code size } items in its internal buffer and discards the oldest item . <p > when { @code subscriber } s subscribe to a terminated { @code replayprocessor } they are guaranteed to see at most { @code size } { @code onnext } events followed by a termination event . <p > if a { @code subscriber } subscribes while the { @code replayprocessor } is active it will observe all items in the buffer at that point in time and each item observed afterwards even if the buffer evicts items due to the size constraint in the mean time . in other words once a { @code subscriber } subscribes it will receive items without gaps in the sequence .
/ * test
creates a time - bounded replayprocessor . <p > in this setting the { @code replayprocessor } internally tags each observed item with a timestamp value supplied by the { @link scheduler } and keeps only those whose age is less than the supplied time value converted to milliseconds . for example an item arrives at t = 0 and the max age is set to 5 ; at t&gt ; = 5 this first item is then evicted by any subsequent item or termination event leaving the buffer empty . <p > once the processor is terminated { @code subscriber } s subscribing to it will receive items that remained in the buffer after the terminal event regardless of their age . <p > if a { @code subscriber } subscribes while the { @code replayprocessor } is active it will observe only those items from within the buffer that have an age less than the specified time and each item observed thereafter even if the buffer evicts items due to the time constraint in the mean time . in other words once a { @code subscriber } subscribes it observes items without gaps in the sequence except for any outdated items at the beginning of the sequence . <p > note that terminal notifications ( { @code onerror } and { @code oncomplete } ) trigger eviction as well . for example with a max age of 5 the first item is observed at t = 0 then an { @code oncomplete } notification arrives at t = 10 . if a { @code subscriber } subscribes at t = 11 it will find an empty { @code replayprocessor } with just an { @code oncomplete } notification .
final : fixed protocol steps to support fuseable and non - fuseable upstream
rethrows the throwable if it is a fatal exception or calls {
calls the upstream s queuesubscription . requestfusion with the mode and saves the established mode in {
creates a { @link behaviorsubject } that emits the last item it observed and all subsequent items to each { @link observer } that subscribes to it .
returns a single value the subject currently has or null if no such value exists . <p > the method is thread - safe .
returns an object array containing snapshot all values of the subject . <p > the method is thread - safe .
returns a typed array containing a snapshot of all values of the subject . <p > the method follows the conventions of collection . toarray by setting the array element after the last value to null ( if the capacity permits ) . <p > the method is thread - safe .
returns true if the subject has any value . <p > the method is thread - safe .
drain the queue but give up with an error if there aren t enough requests .
creates a queue : spsc - array if capacityhint is positive and spsc - linked - array if capacityhint is negative ; in both cases the capacity is the absolute value of prefetch .
requests long . max_value if prefetch is negative or the exact amount if prefetch is positive .
accumulates requests ( not validated ) and handles the completed mode draining of the queue based on the requests .
drains the queue based on the outstanding requests in post - completed mode ( only! ) .
signals the completion of the main sequence and switches to post - completion replay mode .
creates an unbounded replay subject . <p > the internal buffer is backed by an { @link arraylist } and starts with an initial capacity of 16 . once the number of items reaches this capacity it will grow as necessary ( usually by 50% ) . however as the number of items grows this causes frequent array reallocation and copying and may hurt performance and latency . this can be avoided with the { @link #create ( int ) } overload which takes an initial capacity parameter and can be tuned to reduce the array reallocation frequency as needed .
creates a size - bounded replay subject . <p > in this setting the { @code replaysubject } holds at most { @code size } items in its internal buffer and discards the oldest item . <p > when observers subscribe to a terminated { @code replaysubject } they are guaranteed to see at most { @code size } { @code onnext } events followed by a termination event . <p > if an observer subscribes while the { @code replaysubject } is active it will observe all items in the buffer at that point in time and each item observed afterwards even if the buffer evicts items due to the size constraint in the mean time . in other words once an observer subscribes it will receive items without gaps in the sequence .
/ * test
signals the given value and an oncomplete if the downstream is ready to receive the final value .
returns an object array containing snapshot all values of this processor . <p > the method is thread - safe .
returns a typed array containing a snapshot of all values of this processor . <p > the method follows the conventions of collection . toarray by setting the array element after the last value to null ( if the capacity permits ) . <p > the method is thread - safe .
returns the contained value if this notification is an onnext signal null otherwise .
returns the container throwable error if this notification is an onerror signal null otherwise .
constructs an onnext notification containing the given value .
constructs an onerror notification containing the error .
ensures that the upstream disposable is null and returns true otherwise disposes the next disposable and if the upstream is not the shared disposed instance reports a protocolviolationexception due to multiple subscribe attempts .
atomically updates the target upstream atomicreference from null to the non - null next disposable otherwise disposes next and reports a protocolviolationexception if the atomicreference doesn t contain the shared disposed indicator .
ensures that the upstream subscription is null and returns true otherwise cancels the next subscription and if the upstream is not the shared cancelled instance reports a protocolviolationexception due to multiple subscribe attempts .
atomically updates the target upstream atomicreference from null to the non - null next subscription otherwise cancels next and reports a protocolviolationexception if the atomicreference doesn t contain the shared cancelled indicator .
atomically adds the consumer to the {
atomically removes the consumer from the {
replays the contents of this cache to the given consumer based on its current state and number of items requested by it .
adds two long values and caps the sum at long . max_value .
multiplies two long values and caps the product at long . max_value .
atomically adds the positive value n to the requested value in the atomiclong and caps the result at long . max_value and returns the previous value .
atomically adds the positive value n to the requested value in the atomiclong and caps the result at long . max_value and returns the previous value and considers long . min_value as a cancel indication ( no addition then ) .
atomically subtract the given number ( positive not validated ) from the target field unless it contains long . max_value .
subscribes to the source and calls the observer methods on the current thread . <p >
runs the source observable to a terminal event ignoring any values and rethrowing any exception .
subscribes to the source and calls the given actions on the current thread .
returns a completable which completes only when all sources complete one after another . <p > <img width = 640 height = 283 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . concatarray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which completes only when all sources complete one after another . <p > <img width = 640 height = 303 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . concat . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which completes only when all sources complete one after another . <p > <img width = 640 height = 237 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . concat . p . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
returns a completable which completes only when all sources complete one after another . <p > <img width = 640 height = 237 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . concat . pn . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
provides an api ( via a cold completable ) that bridges the reactive world with the callback - style world . <p > <img width = 640 height = 442 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . create . png alt = > <p > example : <pre > <code > completable . create ( emitter - &gt ; { callback listener = new callback () { &#64 ; override public void onevent ( event e ) { emitter . oncomplete () ; }
creates a completable instance that emits the given throwable exception to subscribers . <p > <img width = 640 height = 462 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . error . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that runs the given action for each subscriber and emits either an unchecked exception or simply completes . <p > <img width = 640 height = 297 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . fromaction . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which when subscribed executes the callable function ignores its normal result and emits onerror or oncomplete only . <p > <img width = 640 height = 286 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . fromcallable . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that reacts to the termination of the given future in a blocking fashion . <p > <img width = 640 height = 628 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . fromfuture . png alt = > <p > note that if any of the observers to this completable call dispose this completable will cancel the future . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that when subscribed to subscribes to the {
returns a completable instance that runs the given runnable for each subscriber and emits either its exception or simply completes . <p > <img width = 640 height = 297 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . fromrunnable . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that when subscribed to subscribes to the single instance and emits a completion event if the single emits onsuccess or forwards any onerror events . <p > <img width = 640 height = 356 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . fromsingle . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that subscribes to all sources at once and completes only when all source completables complete or one of them emits an error . <p > <img width = 640 height = 270 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . mergearray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that subscribes to all sources at once and completes only when all source completables complete or one of them emits an error . <p > <img width = 640 height = 311 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . merge . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that subscribes to all sources at once and completes only when all source completables complete or one of them emits an error . <p > <img width = 640 height = 336 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . merge . p . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
returns a completable instance that keeps subscriptions to a limited number of sources at once and completes only when all source completables complete or one of them emits an error . <p > <img width = 640 height = 269 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . merge . pn . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
returns a completable that subscribes to all completables in the source sequence and delays any error emitted by either the sources observable or any of the inner completables until all of them terminate in a way or another . <p > <img width = 640 height = 466 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . mergedelayerror . p . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
returns a completable that subscribes to a limited number of inner completables at once in the source sequence and delays any error emitted by either the sources observable or any of the inner completables until all of them terminate in a way or another . <p > <img width = 640 height = 440 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . mergedelayerror . pn . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
returns a completable that never calls onerror or oncomplete . <p > <img width = 640 height = 512 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . never . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that fires its oncomplete event after the given delay elapsed . <p > <img width = 640 height = 413 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . timer . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
creates a nullpointerexception instance and sets the given throwable as its initial cause .
returns a completable instance which manages a resource along with a custom completable instance while the subscription is active . <p > <img width = 640 height = 388 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . using . png alt = > <p > this overload disposes eagerly before the terminal event is emitted . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
wraps the given completablesource into a completable if not already completable . <p > <img width = 640 height = 354 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . wrap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that emits the a terminated event of either this completable or the other completable whichever fires first . <p > <img width = 640 height = 484 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . ambwith . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns an observable which will subscribe to this completable and once that is completed then will subscribe to the {
returns a flowable which will subscribe to this completable and once that is completed then will subscribe to the {
returns a single which will subscribe to this completable and once that is completed then will subscribe to the { @code next } singlesource . an error event from this completable will be propagated to the downstream subscriber and will result in skipping the subscription of the single . <p > <img width = 640 height = 437 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . andthen . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code andthen } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a { @link maybe } which will subscribe to this completable and once that is completed then will subscribe to the { @code next } maybesource . an error event from this completable will be propagated to the downstream subscriber and will result in skipping the subscription of the maybe . <p > <img width = 640 height = 280 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . andthen . m . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code andthen } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a completable that first runs this completable and then the other completable . <p > <img width = 640 height = 437 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . andthen . c . png alt = > <p > this is an alias for {
calls the specified converter function during assembly time and returns its resulting value . <p > <img width = 640 height = 751 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . as . png alt = > <p > this allows fluent conversion to any other type . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
subscribes to and awaits the termination of this completable instance in a blocking manner and rethrows any exception emitted . <p > <img width = 640 height = 432 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . blockingawait . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
calls the given transformer function with this instance and returns the function s resulting completable . <p > <img width = 640 height = 625 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . compose . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
concatenates this completable with another completable . <p > <img width = 640 height = 317 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . concatwith . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which delays the emission of the completion event by the given time while running on the specified scheduler . <p > <img width = 640 height = 313 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . delay . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which delays the emission of the completion event and optionally the error as well by the given time while running on the specified scheduler . <p > <img width = 640 height = 253 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . delay . sb . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that delays the subscription to the source completablesource by a given amount of time . <p > <img width = 640 height = 475 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . delaysubscription . t . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code delaysubscription } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a completable that delays the subscription to the source completablesource by a given amount of time both waiting and subscribing on a given scheduler . <p > <img width = 640 height = 420 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . delaysubscription . ts . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a completable which calls the given oncomplete callback if this completable completes . <p > <img width = 640 height = 304 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . dooncomplete . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
calls the shared {
returns a completable which calls the given onerror callback if this completable emits an error . <p > <img width = 640 height = 304 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . doonerror . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that calls the various callbacks on the specific lifecycle events . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that calls the given onsubscribe callback with the disposable that child subscribers receive on subscription . <p > <img width = 640 height = 304 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . doonsubscribe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that calls the given onterminate callback just before this completable completes normally or with an exception . <p > <img width = 640 height = 304 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . doonterminate . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that calls the given onterminate callback after this completable completes normally or with an exception . <p > <img width = 640 height = 304 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . doafterterminate . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which emits the terminal events from the thread of the specified scheduler . <p > <img width = 640 height = 523 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . observeon . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that if this completable emits an error and the predicate returns true it will emit an oncomplete and swallow the throwable . <p > <img width = 640 height = 283 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . onerrorcomplete . f . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that when encounters an error from this completable calls the specified mapper function that returns another completable instance for it and resumes the execution with it . <p > <img width = 640 height = 426 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . onerrorresumenext . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that subscribes repeatedly at most the given times to this completable . <p > <img width = 640 height = 408 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . repeat . n . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that repeatedly subscribes to this completable so long as the given stop supplier returns false . <p > <img width = 640 height = 381 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . repeatuntil . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable instance that repeats when the publisher returned by the handler emits an item or completes when this publisher emits a completed event . <p > <img width = 640 height = 586 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . repeatwhen . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that retries this completable in case of an error as long as the predicate returns true . <p > <img width = 640 height = 325 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . retry . ff . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that when this completable emits an error retries at most the given number of times before giving up and emitting the last error . <p > <img width = 640 height = 451 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . retry . n . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that when this completable emits an error retries at most times or until the predicate returns false whichever happens first and emitting the last error . <p > <img width = 640 height = 361 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . retry . nf . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable which given a publisher and when this completable emits an error delivers that error through a flowable and the publisher should signal a value indicating a retry in response or a terminal event indicating a termination . <p > <img width = 640 height = 586 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . retrywhen . png alt = > <p > note that the inner {
returns an observable which first delivers the events of the other observable then runs this completableconsumable . <p > <img width = 640 height = 289 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . startwith . o . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
subscribes to this completableconsumable and returns a disposable which can be used to dispose the subscription . <p > <img width = 640 height = 352 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . subscribe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
subscribes a given completableobserver ( subclass ) to this completable and returns the given completableobserver as is . <p > <img width = 640 height = 349 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . subscribewith . png alt = > <p > usage example : <pre > <code > completable source = completable . complete () . delay ( 1 timeunit . seconds ) ; compositedisposable composite = new compositedisposable () ;
returns a completable which subscribes the child subscriber on the specified scheduler making sure the subscription side - effects happen on that specific thread of the scheduler . <p > <img width = 640 height = 686 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . subscribeon . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
terminates the downstream if this or the other {
returns a completable that runs this completable and emits a timeoutexception in case this completable doesn t complete within the given time . <p > <img width = 640 height = 348 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . timeout . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that runs this completable and switches to the other completable in case this completable doesn t complete within the given time . <p > <img width = 640 height = 308 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . timeout . c . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that runs this completable and emits a timeoutexception in case this completable doesn t complete within the given time while waiting on the specified scheduler . <p > <img width = 640 height = 348 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . timeout . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a completable that runs this completable and switches to the other completable in case this completable doesn t complete within the given time while waiting on the specified scheduler . <p > <img width = 640 height = 308 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . timeout . sc . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
allows fluent conversion to another type via a function callback . <p > <img width = 640 height = 751 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . to . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a flowable which when subscribed to subscribes to this completable and relays the terminal events to the subscriber . <p > <img width = 640 height = 585 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . toflowable . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
converts this completable into a { @link maybe } . <p > <img width = 640 height = 585 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / completable . tomaybe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tomaybe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
try subscribing to a {
try subscribing to a {
adds a new element to this list .
stops the purge thread .
creates a scheduledexecutorservice with the given factory .
atomically sets a new subscription .
loops until all notifications in the queue has been processed .
todo fuse back to flowable
throws a particular { @code throwable } only if it belongs to a set of fatal error varieties . these varieties are as follows : <ul > <li > { @code virtualmachineerror } < / li > <li > { @code threaddeath } < / li > <li > { @code linkageerror } < / li > < / ul > this can be useful if you are writing an operator that calls user - supplied code and you want to notify subscribers of errors encountered in that code by calling their { @code onerror } methods but only if the errors are not so catastrophic that such a call would be futile in which case you simply want to rethrow the error .
if the provided throwable is an error this method throws it otherwise returns a runtimeexception wrapping the error if that error is a checked exception .
returns a flattened list of throwables from tree - like compositeexception chain .
workaround for java 6 not supporting throwing a final throwable from a catch block .
atomically adds the consumer to the {
atomically removes the consumer from the {
replays the contents of this cache to the given consumer based on its current state and number of items requested by it .
flatmap
adds a disposable to this container or disposes it if the container has been disposed .
atomically adds the given array of disposables to the container or disposes them all if the container has been disposed .
removes and disposes the given disposable if it is part of this container .
removes ( but does not dispose ) the given disposable if it is part of this container .
atomically clears the container then disposes all the previously contained disposables .
returns the number of currently held disposables .
subscribes to the source and calls the subscriber methods on the current thread . <p >
runs the source observable to a terminal event ignoring any values and rethrowing any exception .
subscribes to the source and calls the given actions on the current thread .
subscribes to the source and calls the given actions on the current thread .
adds a resource to this resourceobserver .
tries to subscribe to a possibly callable source s mapped observablesource .
maps a scalar value into an observable and emits its values .
creates a {
wraps an {
shuts down the standard schedulers . <p > the operation is idempotent and thread - safe .
append a non - null value to the list . <p > don t add null to the list!
loops over all elements of the array until a null element is encountered or the given predicate returns true .
interprets the contents as notificationlite objects and calls the appropriate subscriber method .
interprets the contents as notificationlite objects and calls the appropriate observer method .
loops over all elements of the array until a null element is encountered or the given predicate returns true .
runs multiple singlesources and signals the events of the first one that signals ( disposing the rest ) . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . amb . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
runs multiple singlesources and signals the events of the first one that signals ( disposing the rest ) . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . ambarray . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
concatenate the single values in a non - overlapping fashion of the singlesources provided in an array . <p > <img width = 640 height = 319 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . concatarray . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
calls a {
signals a throwable returned by the callback function for each individual singleobserver . <p > <img width = 640 height = 283 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . error . c . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a { @link single } that invokes passed function and emits its result for each new singleobserver that subscribes . <p > allows you to defer execution of passed function until singleobserver subscribes to the { @link single } . it makes passed function lazy . result of the function invocation will be emitted by the { @link single } . <p > <img width = 640 height = 467 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . fromcallable . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromcallable } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the { @link callable } throws an exception the respective { @link throwable } is delivered to the downstream via { @link singleobserver#onerror ( throwable ) } except when the downstream has disposed this { @code single } source . in this latter case the { @code throwable } is delivered to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } as an { @link io . reactivex . exceptions . undeliverableexception undeliverableexception } . < / dd > < / dl >
converts a { @link future } into a { @code single } . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . from . future . png alt = > <p > you can convert any object that supports the { @link future } interface into a single that emits the return value of the { @link future#get } method of that object by passing the object into the { @code from } method . <p > <em > important note : < / em > this single is blocking ; you cannot dispose it . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromfuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts a { @link future } into a { @code single } with a timeout on the future . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . from . future . png alt = > <p > you can convert any object that supports the { @link future } interface into a { @code single } that emits the return value of the { @link future#get } method of that object by passing the object into the { @code from } method . <p > <em > important note : < / em > this { @code single } is blocking ; you cannot dispose it . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromfuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts a { @link future } into a { @code single } with a timeout on the future . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . from . future . png alt = > <p > you can convert any object that supports the { @link future } interface into a { @code single } that emits the return value of the { @link future#get } method of that object by passing the object into the { @code from } method . <p > <em > important note : < / em > this { @code single } is blocking ; you cannot dispose it . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify the { @link scheduler } where the blocking wait will happen . < / dd > < / dl >
flattens a { @code single } that emits a { @code single } into a single { @code single } that emits the item emitted by the nested { @code single } without any transformation . <p > <img width = 640 height = 412 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . merge . oo . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code merge } does not operate by default on a particular { @link scheduler } . < / dd > <dd > the resulting { @code single } emits the outer source s or the inner { @code singlesource } s { @code throwable } as is . unlike the other { @code merge () } operators this operator won t and can t produce a { @code compositeexception } because there is only one possibility for the outer or the inner { @code singlesource } to emit an { @code onerror } signal . therefore there is no need for a { @code mergedelayerror ( singlesource<singlesource<t >> ) } operator . < / dd > < / dl >
merges a flowable sequence of singlesource instances into a single flowable sequence running all singlesources at once and delaying any error ( s ) until all sources succeed or fail . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
returns a singleton instance of a never - signalling single ( only calls onsubscribe ) . <p > <img width = 640 height = 244 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . never . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
signals success with 0l value after the given delay for each singleobserver . <p > <img width = 640 height = 292 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . timer . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify the {
<strong > advanced use only : < / strong > creates a single instance without any safeguards by using a callback that is called with a singleobserver . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
allows using and disposing a resource while running a singlesource instance generated from that resource ( similar to a try - with - resources ) . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
calls the specified converter function during assembly time and returns its resulting value . <p > <img width = 640 height = 553 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . as . png alt = > <p > this allows fluent conversion to any other type . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
hides the identity of the current single including the disposable that is sent to the downstream via {
transform a single by applying a particular transformer function to it . <p > <img width = 640 height = 612 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . compose . png alt = > <p > this method operates on the single itself whereas { @link #lift } operates on the single s singleobservers . <p > if the operator you are creating is designed to act on the individual item emitted by a single use { @link #lift } . if your operator is designed to transform the source single as a whole ( for instance by applying a particular set of existing rxjava operators to it ) use { @code compose } . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code compose } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
stores the success value or exception from the current single and replays it to late singleobservers . <p > the returned single subscribes to the current single when the first singleobserver subscribes . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code cache } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the item emitted by the source single then the item emitted by the specified single . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . concatwith . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned { @code flowable } honors the backpressure of the downstream consumer . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concatwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
delays the emission of the success signal from the current single by the specified amount . an error signal will not be delayed . <p > <img width = 640 height = 457 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . delay . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code delay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
delays the emission of the success signal from the current single by the specified amount . an error signal will not be delayed . <p > <img width = 640 height = 457 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . delay . s . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify the { @link scheduler } where the non - blocking wait and emission happens< / dd > < / dl >
delays the emission of the success or error signal from the current single by the specified amount . <p > <img width = 640 height = 457 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . delay . se . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify the {
delays the actual subscription to the current single until the given other completablesource completes . <p > if the delaying source signals an error that error is re - emitted and no subscription to the current single happens . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
delays the actual subscription to the current single until the given time delay elapsed . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
delays the actual subscription to the current single until the given time delay elapsed . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps the {
calls the specified consumer with the success item after this item has been emitted to the downstream . <p > <img width = 640 height = 460 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . doaftersuccess . png alt = > <p > note that the {
registers an { @link action } to be called after this single invokes either onsuccess or onerror . <p > <img width = 640 height = 460 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . doafterterminate . png alt = > <p > note that the { @code doafterterminate } action is shared between subscriptions and as such should be thread - safe . < / p >
calls the specified action after this single signals onsuccess or onerror or gets disposed by the downstream . <p > in case of a race between a terminal event and a dispose call the provided {
calls the shared consumer with the disposable sent through the onsubscribe for each singleobserver that subscribes to the current single . <p > <img width = 640 height = 347 src = https : // raw . githubusercontent . com / wiki / reactivex / rxjava / images / rx - operators / single . doonsubscribe . png alt = > < / p > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a single instance that calls the given onterminate callback just before this single completes normally or with an exception . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonterminate . png alt = > <p > this differs from {
calls the shared consumer with the success value sent via onsuccess for each singleobserver that subscribes to the current single . <p > <img width = 640 height = 347 src = https : // raw . githubusercontent . com / wiki / reactivex / rxjava / images / rx - operators / single . doonsuccess . 2 . png alt = > < / p > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
calls the shared consumer with the error sent via onerror for each singleobserver that subscribes to the current single . <p > <img width = 640 height = 349 src = https : // raw . githubusercontent . com / wiki / reactivex / rxjava / images / rx - operators / single . doonerror . 2 . png alt = > < / p > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
calls the shared {
returns a single that is based on applying a specified function to the item emitted by the source single where that function returns a singlesource . <p > <img width = 640 height = 300 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . flatmap . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that is based on applying a specified function to the item emitted by the source single where that function returns a maybesource . <p > <img width = 640 height = 191 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . flatmapmaybe . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmapmaybe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an observable that is based on applying a specified function to the item emitted by the source single where that function returns an observablesource . <p > <img width = 640 height = 300 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . flatmapobservable . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmapobservable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
<strong > this method requires advanced knowledge about building operators please consider other standard composition methods first ; < / strong > returns a { @code single } which when subscribed to invokes the { @link singleoperator#apply ( singleobserver ) apply ( singleobserver ) } method of the provided { @link singleoperator } for each individual downstream { @link single } and allows the insertion of a custom operator by accessing the downstream s { @link singleobserver } during this subscription phase and providing a new { @code singleobserver } containing the custom operator s intended business logic that will be used in the subscription process going further upstream . <p > generally such a new { @code singleobserver } will wrap the downstream s { @code singleobserver } and forwards the { @code onsuccess } and { @code onerror } events from the upstream directly or according to the emission pattern the custom operator s business logic requires . in addition such operator can intercept the flow control calls of { @code dispose } and { @code isdisposed } that would have traveled upstream and perform additional actions depending on the same business logic requirements . <p > example : <pre > <code > // step 1 : create the consumer type that will be returned by the singleoperator . apply () :
returns a single that applies a specified function to the item emitted by the source single and emits the result of this function application . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . map . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code map } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps the signal types of this single into a {
signals true if the current single signals a success value that is object - equals with the value provided . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
flattens this and another single into a single flowable without any transformation . <p > <img width = 640 height = 415 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . mergewith . png alt = > <p > you can combine items emitted by multiple singles so that they appear as a single flowable by using the { @code mergewith } method . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned { @code flowable } honors the backpressure of the downstream consumer . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergewith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies a single to emit its item ( or notify of its error ) on a specified { @link scheduler } asynchronously . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . observeon . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
instructs a single to emit an item ( returned by a specified function ) rather than invoking { @link singleobserver#onerror onerror } if it encounters an error . <p > <img width = 640 height = 451 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . onerrorreturn . png alt = > <p > by default when a single encounters an error that prevents it from emitting the expected item to its subscriber the single invokes its subscriber s { @link singleobserver#onerror } method and then quits without invoking any more of its subscriber s methods . the { @code onerrorreturn } method changes this behavior . if you pass a function ( { @code resumefunction } ) to a single s { @code onerrorreturn } method if the original single encounters an error instead of invoking its subscriber s { @link singleobserver#onerror } method it will instead emit the return value of { @code resumefunction } . <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorreturn } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
nulls out references to the upstream producer and downstream singleobserver if the sequence is terminated or downstream calls dispose () . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
repeatedly re - subscribes to the current single and emits each success value . <p > <img width = 640 height = 457 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . repeat . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned {
repeatedly re - subscribes to the current single indefinitely if it fails with an onerror . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
re - subscribe to the current single if the given predicate returns true when the single fails with an onerror . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
repeatedly re - subscribe at most times or until the predicate returns false whichever happens first if it fails with an onerror . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
re - subscribes to the current single if and when the publisher returned by the handler function signals a value . <p > if the publisher signals an oncomplete the resulting single will signal a nosuchelementexception . <p > note that the inner { @code publisher } returned by the handler function should signal either { @code onnext } { @code onerror } or { @code oncomplete } in response to the received { @code throwable } to indicate the operator should retry or terminate . if the upstream to the operator is asynchronous signalling onnext followed by oncomplete immediately may result in the sequence to be completed immediately . similarly if this inner { @code publisher } signals { @code onerror } or { @code oncomplete } while the upstream is active the sequence is terminated with the same signal immediately . <p > the following example demonstrates how to retry an asynchronous source with a delay : <pre > <code > single . timer ( 1 timeunit . seconds ) . doonsubscribe ( s - &gt ; system . out . println ( subscribing )) . map ( v - &gt ; { throw new runtimeexception () ; } ) . retrywhen ( errors - &gt ; { atomicinteger counter = new atomicinteger () ; return errors . takewhile ( e - &gt ; counter . getandincrement () ! = 3 ) . flatmap ( e - &gt ; { system . out . println ( delay retry by + counter . get () + second ( s ) ) ; return flowable . timer ( counter . get () timeunit . seconds ) ; } ) ; } ) . blockingget () ; < / code > < / pre > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retrywhen } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to a single and provides a callback to handle the item it emits . <p > if the single emits an error it is wrapped into an { @link io . reactivex . exceptions . onerrornotimplementedexception onerrornotimplementedexception } and routed to the rxjavaplugins . onerror handler . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to a single and provides callbacks to handle the item it emits or any error notification it issues . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes a given singleobserver ( subclass ) to this single and returns the given singleobserver as is . <p > usage example : <pre > <code > single&lt ; integer&gt ; source = single . just ( 1 ) ; compositedisposable composite = new compositedisposable () ;
asynchronously subscribes subscribers to this single on the specified { @link scheduler } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . subscribeon . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a single that emits the item emitted by the source single until a completable terminates . upon termination of { @code other } this will emit a { @link cancellationexception } rather than go to { @link singleobserver#onsuccess ( object ) } . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takeuntil . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takeuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
signals a timeoutexception if the current single doesn t signal a success value within the specified timeout window . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
signals a timeoutexception if the current single doesn t signal a success value within the specified timeout window . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a { @link completable } that discards result of the { @link single } and calls { @code oncomplete } when this source { @link single } calls { @code onsuccess } . error terminal event is propagated . <p > <img width = 640 height = 436 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . tocompletable . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tocompletable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a { @link future } representing the single value emitted by this { @code single } . <p > <img width = 640 height = 467 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / single . tofuture . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tofuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single which makes sure when a singleobserver disposes the disposable that call is propagated up on the specified scheduler . <dl > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a single that emits the result of applying a specified function to the pair of items emitted by the source single and another specified single . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . zip . png alt = > <dl > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zipwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
constructs a fresh instance with the default flowable . buffersize () prefetch amount and no refcount - behavior .
constructs a fresh instance with the default flowable . buffersize () prefetch amount and the optional refcount - behavior .
initializes this processor by setting an upstream subscription that ignores request amounts uses a fixed buffer and allows using the onxxx and offer methods afterwards .
initializes this processor by setting an upstream subscription that ignores request amounts uses an unbounded buffer and allows using the onxxx and offer methods afterwards .
tries to offer an item into the internal queue and returns false if the queue is full .
{
{
offer two elements at the same time . <p > don t use the regular offer () with this at all!
returns the currently contained disposable or null if this container is empty .
creates a operatorpublish instance to publish values of the given source observable .
complete the target with a single value or indicate there is a value available in fusion mode .
complete the target with an error signal .
complete the target without any value .
returns a flowable that emits the items emitted by each of the publishers emitted by the source publisher one after the other without interleaving them . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concat . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . both the outer and inner { @code publisher } sources are expected to honor backpressure as well . if the outer violates this a { @code missingbackpressureexception } is signaled . if any of the inner { @code publisher } s violates this it <em > may< / em > throw an { @code illegalstateexception } when an inner { @code publisher } completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code concat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
concatenates a variable number of publisher sources . <p > note : named this way because of overload conflict with concat ( publisher&lt ; publisher&gt ; ) . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / concat . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the {
concatenates an array of publishers eagerly into a single stream of values . <p > <img width = 640 height = 406 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flowable . concatarrayeager . nn . png alt = > <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source publishers . the operator buffers the values emitted by these publishers and then drains them in order each one after the previous one completes . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the {
concatenates an array of {
concatenates the publisher sequence of publishers into a single sequence by subscribing to each inner publisher one after the other one at a time and delays any errors till the all inner and the outer publishers terminate .
concatenates the publisher sequence of publishers into a single sequence by subscribing to each inner publisher one after the other one at a time and delays any errors till the all inner and the outer publishers terminate .
provides an api ( via a cold flowable ) that bridges the reactive world with the callback - style generally non - backpressured world . <p > example : <pre > <code > flowable . &lt ; event&gt ; create ( emitter - &gt ; { callback listener = new callback () { &#64 ; override public void onevent ( event e ) { emitter . onnext ( e ) ; if ( e . islast () ) { emitter . oncomplete () ; } }
returns a flowable that emits no items to the { @link subscriber } and immediately invokes its { @link subscriber#oncomplete oncomplete } method . <p > <img width = 640 height = 190 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / empty . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this source doesn t produce any elements and effectively ignores downstream backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code empty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that invokes a { @link subscriber } s { @link subscriber#onerror onerror } method when the subscriber subscribes to it . <p > <img width = 640 height = 190 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / error . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this source doesn t produce any elements and effectively ignores downstream backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code error } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts an { @link iterable } sequence into a publisher that emits the items in the sequence . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / from . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and iterates the given { @code iterable } on demand ( i . e . when requested ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code fromiterable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a cold synchronous stateful and backpressure - aware generator of values . <p > note that the { @link emitter#onnext } { @link emitter#onerror } and { @link emitter#oncomplete } methods provided to the function via the { @link emitter } instance should be called synchronously never concurrently and only while the function body is executing . calling them from multiple threads or outside the function call is not supported and leads to an undefined behavior . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code generate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits a { @code 0l } after the { @code initialdelay } and ever - increasing numbers after each { @code period } of time thereafter on a specified { @link scheduler } . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timer . ps . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator generates values based on time and ignores downstream backpressure which may lead to { @code missingbackpressureexception } at some point in the chain . consumers should consider applying one of the { @code onbackpressurexxx } operators as well . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits a sequential number every specified interval of time . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / interval . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator signals a { @code missingbackpressureexception } if the downstream is not ready to receive the next value . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code interval } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits a sequential number every specified interval of time on a specified scheduler . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / interval . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator generates values based on time and ignores downstream backpressure which may lead to { @code missingbackpressureexception } at some point in the chain . consumers should consider applying one of the { @code onbackpressurexxx } operators as well . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
signals a range of long values the first after some initial delay and the rest periodically after . <p > the sequence completes immediately after the last value ( start + count - 1 ) has been reached . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator signals a {
signals a range of long values the first after some initial delay and the rest periodically after . <p > the sequence completes immediately after the last value ( start + count - 1 ) has been reached . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator signals a {
returns a flowable that signals the given ( constant reference ) item and then completes . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / just . png alt = > <p > note that the item is taken and re - emitted as is and not computed by any means by { @code just } . use { @link #fromcallable ( callable ) } to generate a single item on demand ( when { @code subscriber } s subscribe to it ) . <p > see the multi - parameter overloads of { @code just } to emit more than one ( constant reference ) items one after the other . use { @link #fromarray ( object ... ) } to emit an arbitrary number of items that are known upfront . <p > to emit the items of an { @link iterable } sequence ( such as a { @link java . util . list } ) use { @link #fromiterable ( iterable ) } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code just } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
flattens an iterable of publishers into one publisher without any transformation while limiting the number of concurrent subscriptions to these publishers . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > you can combine the items emitted by multiple publishers so that they appear as a single publisher by using the { @code merge } method . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the source { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergearray } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if any of the source { @code publisher } s signal a { @code throwable } via { @code onerror } the resulting { @code flowable } terminates with that { @code throwable } and all other source { @code publisher } s are canceled . if more than one { @code publisher } signals an error the resulting { @code flowable } may terminate with the first one s error or depending on the concurrency of the sources may terminate with a { @code compositeexception } containing two or more of the various error signals . { @code throwable } s that didn t make into the composite will be sent ( individually ) to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } method as { @code undeliverableexception } errors . similarly { @code throwable } s signaled by source ( s ) after the returned { @code flowable } has been canceled or terminated with a ( composite ) error will be sent to the same global error handler . use { @link #mergearraydelayerror ( int int publisher [] ) } to merge sources and terminate only when all source { @code publisher } s have completed or failed with an error . < / dd > < / dl >
flattens four publishers into a single publisher without any transformation . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > you can combine items emitted by multiple publishers so that they appear as a single publisher by using the { @code merge } method . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the source { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code merge } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if any of the source { @code publisher } s signal a { @code throwable } via { @code onerror } the resulting { @code flowable } terminates with that { @code throwable } and all other source { @code publisher } s are canceled . if more than one { @code publisher } signals an error the resulting { @code flowable } may terminate with the first one s error or depending on the concurrency of the sources may terminate with a { @code compositeexception } containing two or more of the various error signals . { @code throwable } s that didn t make into the composite will be sent ( individually ) to the global error handler via { @link rxjavaplugins#onerror ( throwable ) } method as { @code undeliverableexception } errors . similarly { @code throwable } s signaled by source ( s ) after the returned { @code flowable } has been canceled or terminated with a ( composite ) error will be sent to the same global error handler . use { @link #mergedelayerror ( publisher publisher publisher publisher ) } to merge sources and terminate only when all source { @code publisher } s have completed or failed with an error . < / dd > < / dl >
flattens an iterable of publishers into one publisher in a way that allows a subscriber to receive all successfully emitted items from each of the source publishers without being interrupted by an error notification from one of them . <p > this behaves like { @link #merge ( publisher ) } except that if any of the merged publishers notify of an error via { @link subscriber#onerror onerror } { @code mergedelayerror } will refrain from propagating that error notification until all of the merged publishers have finished emitting items . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergedelayerror . png alt = > <p > even if multiple merged publishers send { @code onerror } notifications { @code mergedelayerror } will only invoke the { @code onerror } method of its subscribers once . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . all inner { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergedelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that never sends any items or notifications to a { @link subscriber } . <p > <img width = 640 height = 185 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / never . png alt = > <p > this publisher is useful primarily for testing purposes . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this source doesn t produce any elements and effectively ignores downstream backpressure . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code never } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits a sequence of integers within a specified range . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / range . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and signals values on - demand ( i . e . when requested ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code range } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits a sequence of longs within a specified range . <p > <img width = 640 height = 195 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / range . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and signals values on - demand ( i . e . when requested ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code rangelong } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two publisher sequences are the same by comparing the items emitted by each publisher pairwise based on the results of a specified equality function . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the source { @code publisher } s are expected to honor backpressure ; if violated the operator signals a { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two publisher sequences are the same by comparing the items emitted by each publisher pairwise based on the results of a specified equality function . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the source { @code publisher } s are expected to honor backpressure ; if violated the operator signals a { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a boolean value that indicates whether two publisher sequences are the same by comparing the items emitted by each publisher pairwise . <p > <img width = 640 height = 385 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sequenceequal . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator honors downstream backpressure and expects both of its sources to honor backpressure as well . if violated the operator will emit a missingbackpressureexception . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sequenceequal } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts a publisher that emits publishers into a publisher that emits the items emitted by the most recently emitted of those publishers . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchdo . png alt = > <p > { @code switchonnext } subscribes to a publisher that emits publishers . each time it observes one of these emitted publishers the publisher returned by { @code switchonnext } begins emitting the items emitted by that publisher . when a new publisher is emitted { @code switchonnext } stops emitting items from the earlier - emitted publisher and begins emitting items from the new one . <p > the resulting publisher completes if both the outer publisher and the last inner publisher if any complete . if the outer publisher signals an onerror the inner publisher is canceled and the error delivered in - sequence . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the outer { @code publisher } is consumed in an unbounded manner ( i . e . without backpressure ) and the inner { @code publisher } s are expected to honor backpressure but it is not enforced ; the operator won t signal a { @code missingbackpressureexception } but the violation <em > may< / em > lead to { @code outofmemoryerror } due to internal buffer bloat . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchonnext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts a publisher that emits publishers into a publisher that emits the items emitted by the most recently emitted of those publishers and delays any exception until all publishers terminate . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchdo . png alt = > <p > { @code switchonnext } subscribes to a publisher that emits publishers . each time it observes one of these emitted publishers the publisher returned by { @code switchonnext } begins emitting the items emitted by that publisher . when a new publisher is emitted { @code switchonnext } stops emitting items from the earlier - emitted publisher and begins emitting items from the new one . <p > the resulting publisher completes if both the main publisher and the last inner publisher if any complete . if the main publisher signals an onerror the termination of the last inner publisher will emit that error as is or wrapped into a compositeexception along with the other possible errors the former inner publishers signaled . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the outer { @code publisher } is consumed in an unbounded manner ( i . e . without backpressure ) and the inner { @code publisher } s are expected to honor backpressure but it is not enforced ; the operator won t signal a { @code missingbackpressureexception } but the violation <em > may< / em > lead to { @code outofmemoryerror } due to internal buffer bloat . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchonnextdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits { @code 0l } after a specified delay and then completes . <p > <img width = 640 height = 200 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timer . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time . if the downstream needs a slower rate it should slow the timer or use something like { @link #onbackpressuredrop } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code timer } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
create a flowable by wrapping a publisher <em > which has to be implemented according to the reactive - streams specification by handling backpressure and cancellation correctly ; no safeguards are provided by the flowable itself< / em > . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator is a pass - through for backpressure and the behavior is determined by the provided publisher implementation . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
constructs a publisher that creates a dependent resource object which is disposed of on cancellation . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / using . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator is a pass - through for backpressure and otherwise depends on the backpressure support of the publisher returned by the { @code resourcefactory } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code using } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the results of a specified combiner function applied to combinations of items emitted in sequence by an iterable of other publishers . <p > { @code zip } applies this function in strict sequence so the first item emitted by the new publisher will be the result of the function applied to the first item emitted by each of the source publishers ; the second item emitted by the new publisher will be the result of the function applied to the second item emitted by each of those publishers ; and so forth . <p > the resulting { @code publisher<r > } returned from { @code zip } will invoke { @code onnext } as many times as the number of { @code onnext } invocations of the source publisher that emits the fewest items . <p > the operator subscribes to its sources in the order they are specified and completes eagerly if one of the sources is shorter than the rest while canceling the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will cancel b immediately . for example : <pre > <code > zip ( arrays . aslist ( range ( 1 5 ) . dooncomplete ( action1 ) range ( 6 5 ) . dooncomplete ( action2 )) ( a ) - &gt ; a ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #dooncancel ( action ) } as well or use { @code using () } to do cleanup in case of completion or cancellation . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / zip . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects backpressure from the sources and honors backpressure from the downstream . ( i . e . zipping with { @link #interval ( long timeunit ) } may result in missingbackpressureexception use one of the { @code onbackpressurex } to handle similar backpressure - ignoring sources . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zip } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the results of a specified combiner function applied to combinations of <i > n< / i > items emitted in sequence by the <i > n< / i > publishers emitted by a specified publisher . <p > { @code zip } applies this function in strict sequence so the first item emitted by the new publisher will be the result of the function applied to the first item emitted by each of the publishers emitted by the source publisher ; the second item emitted by the new publisher will be the result of the function applied to the second item emitted by each of those publishers ; and so forth . <p > the resulting { @code publisher<r > } returned from { @code zip } will invoke { @code onnext } as many times as the number of { @code onnext } invocations of the source publisher that emits the fewest items . <p > the operator subscribes to its sources in the order they are specified and completes eagerly if one of the sources is shorter than the rest while cancel the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will cancel b immediately . for example : <pre > <code > zip ( just ( range ( 1 5 ) . dooncomplete ( action1 ) range ( 6 5 ) . dooncomplete ( action2 )) ( a ) - &gt ; a ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #dooncancel ( action ) } as well or use { @code using () } to do cleanup in case of completion or cancellation . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / zip . o . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects backpressure from the sources and honors backpressure from the downstream . ( i . e . zipping with { @link #interval ( long timeunit ) } may result in missingbackpressureexception use one of the { @code onbackpressurex } to handle similar backpressure - ignoring sources . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zip } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the specified converter function during assembly time and returns its resulting value . <p > this allows fluent conversion to any other type . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the backpressure behavior depends on what happens in the {
returns the first item emitted by this { @code flowable } or throws { @code nosuchelementexception } if it emits no items . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingfirst } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
converts this { @code flowable } into an { @link iterable } . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . toiterable . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects the upstream to honor backpressure otherwise the returned iterable s iterator will throw a { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingiterable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts this { @code flowable } into an { @link iterable } . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . toiterable . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects the upstream to honor backpressure otherwise the returned iterable s iterator will throw a { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingiterable } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns the last item emitted by this { @code flowable } or throws { @code nosuchelementexception } if this { @code flowable } emits no items . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . last . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockinglast } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
returns an { @link iterable } that always returns the item most recently emitted by this { @code flowable } . <p > <img width = 640 height = 490 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . mostrecent . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingmostrecent } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns an { @link iterable } that blocks until this { @code flowable } emits another item then returns that item . <p > <img width = 640 height = 490 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . next . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingnext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
if this { @code flowable } completes after emitting a single item return that item otherwise throw a { @code nosuchelementexception } . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . single . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingsingle } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
if this { @code flowable } completes after emitting a single item return that item ; if it emits more than one item throw an { @code illegalargumentexception } ; if it emits no items return a default value . <p > <img width = 640 height = 315 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / b . singleordefault . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code blockingsingle } does not operate by default on a particular { @link scheduler } . < / dd > <dt > <b > error handling : < / b > < / dt > <dd > if the source signals an error the operator wraps a checked { @link exception } into { @link runtimeexception } and throws that . otherwise { @code runtimeexception } s and { @link error } s are rethrown as they are . < / dd > < / dl >
returns a { @link future } representing the only value emitted by this { @code flowable } . <p > <img width = 640 height = 324 src = https : // github . com / reactivex / rxjava / wiki / images / rx - operators / flowable . tofuture . png alt = > <p > if the { @link flowable } emits more than one item { @link java . util . concurrent . future } will receive an { @link java . lang . indexoutofboundsexception } . if the { @link flowable } is empty { @link java . util . concurrent . future } will receive a { @link java . util . nosuchelementexception } . the { @code flowable } source has to terminate in order for the returned { @code future } to terminate as well . <p > if the { @code flowable } may emit more than one item use { @code flowable . tolist () . tofuture () } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code flowable } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tofuture } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to the source and calls the given callbacks <strong > on the current thread< / strong > . <p > if the flowable emits an error it is wrapped into an {
subscribes to the source and calls the given callbacks <strong > on the current thread< / strong > . <p > note that calling this method will block the caller thread until the upstream terminates normally or with an error . therefore calling this method from special threads such as the android main thread or the swing event dispatch thread is not recommended . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source {
subscribes to the source and calls the {
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits connected non - overlapping buffers each containing { @code count } items . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer3 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and expects the source { @code publisher } to honor it as well although not enforced ; violation <em > may< / em > lead to { @code missingbackpressureexception } somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits buffers every { @code skip } items each containing { @code count } items . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer4 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and expects the source { @code publisher } to honor it as well although not enforced ; violation <em > may< / em > lead to { @code missingbackpressureexception } somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits buffers every { @code skip } items each containing { @code count } items . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer4 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and expects the source { @code publisher } to honor it as well although not enforced ; violation <em > may< / em > lead to { @code missingbackpressureexception } somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits connected non - overlapping buffers each containing { @code count } items . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer3 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and expects the source { @code publisher } to honor it as well although not enforced ; violation <em > may< / em > lead to { @code missingbackpressureexception } somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher starts a new buffer periodically as determined by the { @code timeskip } argument . it emits each buffer after a fixed timespan specified by the { @code timespan } argument . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer7 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher starts a new buffer periodically as determined by the { @code timeskip } argument and on the specified { @code scheduler } . it emits each buffer after a fixed timespan specified by the { @code timespan } argument . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer7 . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits connected non - overlapping buffers each of a fixed duration specified by the { @code timespan } argument . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer5 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits connected non - overlapping buffers each of a fixed duration specified by the { @code timespan } argument as measured on the specified { @code scheduler } or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer6 . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits connected non - overlapping buffers each of a fixed duration specified by the { @code timespan } argument as measured on the specified { @code scheduler } or a maximum size specified by the { @code count } argument ( whichever is reached first ) . when the source publisher completes the resulting publisher emits the current buffer and propagates the notification from the source publisher . note that if the source publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer6 . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits buffers that it creates when the specified { @code openingindicator } publisher emits an item and closes when the publisher returned from { @code closingindicator } emits an item . if any of the source publisher { @code openingindicator } or { @code closingindicator } issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 470 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer2 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it is instead controlled by the given publishers and buffers data . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits buffers of items it collects from the source publisher . the resulting publisher emits buffers that it creates when the specified { @code openingindicator } publisher emits an item and closes when the publisher returned from { @code closingindicator } emits an item . if any of the source publisher { @code openingindicator } or { @code closingindicator } issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <p > <img width = 640 height = 470 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer2 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it is instead controlled by the given publishers and buffers data . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits non - overlapping buffered items from the source publisher each time the specified boundary publisher emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer8 . png alt = > <p > completion of either the source or the boundary publisher causes the returned publisher to emit the latest buffer and complete . if either the source publisher or the boundary publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it is instead controlled by the { @code publisher } { @code boundary } and buffers data . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits non - overlapping buffered items from the source publisher each time the specified boundary publisher emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer8 . png alt = > <p > completion of either the source or the boundary publisher causes the returned publisher to emit the latest buffer and complete . if either the source publisher or the boundary publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it is instead controlled by the { @code publisher } { @code boundary } and buffers data . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits non - overlapping buffered items from the source publisher each time the specified boundary publisher emits an item . <p > <img width = 640 height = 395 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / buffer8 . png alt = > <p > completion of either the source or the boundary publisher causes the returned publisher to emit the latest buffer and complete . if either the source publisher or the boundary publisher issues an onerror notification the event is passed on immediately without first emitting the buffer it is in the process of assembling . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it is instead controlled by the { @code publisher } { @code boundary } and buffers data . it requests { @code long . max_value } upstream and does not obey downstream requests . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code buffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that subscribes to this publisher lazily caches all of its events and replays them in the same order as received to all the downstream subscribers . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / cache . png alt = > <p > this is useful when you want a publisher to cache responses and you can t control the subscribe / cancel behavior of all the { @link subscriber } s . <p > the operator subscribes only when the first downstream subscriber subscribes and maintains a single subscription towards this publisher . in contrast the operator family of { @link #replay () } that return a { @link connectableflowable } require an explicit call to { @link connectableflowable#connect () } . <p > <em > note : < / em > you sacrifice the ability to cancel the origin when you use the { @code cache } subscriber so be careful not to use this subscriber on publishers that emit an infinite or very large number of items that will use up memory . a possible workaround is to apply takeuntil with a predicate or another source before ( and perhaps after ) the application of cache () . <pre > <code > atomicboolean shouldstop = new atomicboolean () ;
returns a flowable that subscribes to this publisher lazily caches all of its events and replays them in the same order as received to all the downstream subscribers . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / cache . png alt = > <p > this is useful when you want a publisher to cache responses and you can t control the subscribe / cancel behavior of all the { @link subscriber } s . <p > the operator subscribes only when the first downstream subscriber subscribes and maintains a single subscription towards this publisher . in contrast the operator family of { @link #replay () } that return a { @link connectableflowable } require an explicit call to { @link connectableflowable#connect () } . <p > <em > note : < / em > you sacrifice the ability to cancel the origin when you use the { @code cache } subscriber so be careful not to use this subscriber on publishers that emit an infinite or very large number of items that will use up memory . a possible workaround is to apply takeuntil with a predicate or another source before ( and perhaps after ) the application of cache () . <pre > <code > atomicboolean shouldstop = new atomicboolean () ;
collects items emitted by the finite source publisher into a single mutable data structure and returns a single that emits this structure . <p > <img width = 640 height = 330 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / collect . png alt = > <p > this is a simplified version of { @code reduce } that does not need to return the state on each pass . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure because by intent it will receive all values and reduce them to a single { @code onnext } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code collect } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
transform a publisher by applying a particular transformer function to it . <p > this method operates on the publisher itself whereas { @link #lift } operates on the publisher s subscribers or subscribers . <p > if the operator you are creating is designed to act on the individual items emitted by a source publisher use { @link #lift } . if your operator is designed to transform the source publisher as a whole ( for instance by applying a particular set of existing rxjava operators to it ) use { @code compose } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator itself doesn t interfere with the backpressure behavior which only depends on what kind of { @code publisher } the transformer returns . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code compose } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
maps each of the items into a publisher subscribes to them one after the other one at a time and emits their values in order while delaying any error from either this or any of the inner publishers till all of them terminate .
maps a sequence of values into publishers and concatenates these publishers eagerly into a single publisher . <p > eager concatenation means that once a subscriber subscribes this operator subscribes to all of the source publishers . the operator buffers the values emitted by these publishers and then drains them in order each one after the previous one completes . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > backpressure is honored towards the downstream however due to the eagerness requirement sources are subscribed to in unbounded mode and their values are queued up in an unbounded buffer . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this method does not operate by default on a particular {
returns a flowable that concatenate each item emitted by the source publisher with the values in an iterable corresponding to that item that is generated by a selector .
maps the upstream items into {
maps the upstream items into {
maps the upstream items into {
returns a {
returns a {
returns a {
returns a single that emits a boolean that indicates whether the source publisher emitted a specified item . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / contains . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code contains } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that counts the total number of items emitted by the source publisher and emits this count as a 64 - bit long . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / longcount . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code count } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that mirrors the source publisher except that it drops items emitted by the source publisher that are followed by another item within a computed debounce duration . <p > <img width = 640 height = 425 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / debounce . f . png alt = > <p > the delivery of the item happens on the thread of the first { @code onnext } or { @code oncomplete } signal of the generated { @code publisher } sequence which if takes too long a newer item may arrive from the upstream causing the generated sequence to get cancelled which may also interrupt any downstream blocking operation ( yielding an { @code interruptedexception } ) . it is recommended processing items that may take long time to be moved to another thread via { @link #observeon } applied after { @code debounce } itself . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses the { @code debounceselector } to mark boundaries . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code debounce } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that mirrors the source publisher except that it drops items emitted by the source publisher that are followed by newer items before a timeout value expires on a specified scheduler . the timer resets on each emission . <p > <em > note : < / em > if items keep being emitted by the source publisher faster than the timeout then no items will be emitted by the resulting publisher . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / debounce . s . png alt = > <p > delivery of the item after the grace period happens on the given { @code scheduler } s { @code worker } which if takes too long a newer item may arrive from the upstream causing the { @code worker } s task to get disposed which may also interrupt any downstream blocking operation ( yielding an { @code interruptedexception } ) . it is recommended processing items that may take long time to be moved to another thread via { @link #observeon } applied after { @code debounce } itself . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits the items emitted by the source publisher shifted forward in time by a specified delay . if { @code delayerror } is true error notifications will also be delayed . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with the backpressure behavior which is determined by the source { @code publisher } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code delay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the items emitted by the source publisher shifted forward in time by a specified delay . error notifications from the source publisher are not delayed . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with the backpressure behavior which is determined by the source { @code publisher } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that delays the subscription to and emissions from the source publisher via another publisher on a per - item basis . <p > <img width = 640 height = 450 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / delay . oo . png alt = > <p > <em > note : < / em > the resulting publisher will immediately propagate any { @code onerror } notification from the source publisher . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with the backpressure behavior which is determined by the source { @code publisher } . all of the other { @code publisher } s supplied by the functions are consumed in an unbounded manner ( i . e . no backpressure applied to them ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code delay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that reverses the effect of { @link #materialize materialize } by transforming the { @link notification } objects emitted by the source publisher into the items or notifications they represent . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dematerialize . png alt = > <p > when the upstream signals an { @link notification#createonerror ( throwable ) onerror } or { @link notification#createoncomplete () oncomplete } item the returned flowable cancels the flow and terminates with that type of terminal event : <pre > <code > flowable . just ( createonnext ( 1 ) createoncomplete () createonnext ( 2 )) . dooncancel (( ) - &gt ; system . out . println ( cancelled! )) ; . dematerialize () . test () . assertresult ( 1 ) ; < / code > < / pre > if the upstream signals { @code onerror } or { @code oncomplete } directly the flow is terminated with the same event . <pre > <code > flowable . just ( createonnext ( 1 ) createonnext ( 2 )) . dematerialize () . test () . assertresult ( 1 2 ) ; < / code > < / pre > if this behavior is not desired the completion can be suppressed by applying { @link #concatwith ( publisher ) } with a { @link #never () } source . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dematerialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that reverses the effect of { @link #materialize materialize } by transforming the { @link notification } objects extracted from the source items via a selector function into their respective { @code subscriber } signal types . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dematerialize . png alt = > <p > the intended use of the { @code selector } function is to perform a type - safe identity mapping ( see example ) on a source that is already of type { @code notification<t > } . the java language doesn t allow limiting instance methods to a certain generic argument shape therefore a function is used to ensure the conversion remains type safe . <p > when the upstream signals an { @link notification#createonerror ( throwable ) onerror } or { @link notification#createoncomplete () oncomplete } item the returned flowable cancels of the flow and terminates with that type of terminal event : <pre > <code > flowable . just ( createonnext ( 1 ) createoncomplete () createonnext ( 2 )) . dooncancel (( ) - &gt ; system . out . println ( canceled! )) ; . dematerialize ( notification - &gt ; notification ) . test () . assertresult ( 1 ) ; < / code > < / pre > if the upstream signals { @code onerror } or { @code oncomplete } directly the flow is terminated with the same event . <pre > <code > flowable . just ( createonnext ( 1 ) createonnext ( 2 )) . dematerialize ( notification - &gt ; notification ) . test () . assertresult ( 1 2 ) ; < / code > < / pre > if this behavior is not desired the completion can be suppressed by applying { @link #concatwith ( publisher ) } with a { @link #never () } source . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dematerialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits all items emitted by the source publisher that are distinct based on { @link object#equals ( object ) } comparison . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinct . png alt = > <p > it is recommended the elements class { @code t } in the flow overrides the default { @code object . equals () } and { @link object#hashcode () } to provide a meaningful comparison between items as the default java implementation only considers reference equivalence . <p > by default { @code distinct () } uses an internal { @link java . util . hashset } per subscriber to remember previously seen items and uses { @link java . util . set#add ( object ) } returning { @code false } as the indicator for duplicates . <p > note that this internal { @code hashset } may grow unbounded as items won t be removed from it by the operator . therefore using very long or infinite upstream ( with very distinct elements ) may lead to { @code outofmemoryerror } . <p > customizing the retention policy can happen only by providing a custom { @link java . util . collection } implementation to the { @link #distinct ( function callable ) } overload . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinct } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits all items emitted by the source publisher that are distinct according to a key selector function and based on { @link object#equals ( object ) } comparison of the objects returned by the key selector function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinct . key . png alt = > <p > it is recommended the keys class { @code k } overrides the default { @code object . equals () } and { @link object#hashcode () } to provide a meaningful comparison between the key objects as the default java implementation only considers reference equivalence . <p > by default { @code distinct () } uses an internal { @link java . util . hashset } per subscriber to remember previously seen keys and uses { @link java . util . set#add ( object ) } returning { @code false } as the indicator for duplicates . <p > note that this internal { @code hashset } may grow unbounded as keys won t be removed from it by the operator . therefore using very long or infinite upstream ( with very distinct keys ) may lead to { @code outofmemoryerror } . <p > customizing the retention policy can happen only by providing a custom { @link java . util . collection } implementation to the { @link #distinct ( function callable ) } overload . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinct } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits all items emitted by the source publisher that are distinct according to a key selector function and based on { @link object#equals ( object ) } comparison of the objects returned by the key selector function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinct . key . png alt = > <p > it is recommended the keys class { @code k } overrides the default { @code object . equals () } and { @link object#hashcode () } to provide a meaningful comparison between the key objects as the default java implementation only considers reference equivalence . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinct } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits all items emitted by the source publisher that are distinct from their immediate predecessors based on { @link object#equals ( object ) } comparison . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinctuntilchanged . png alt = > <p > it is recommended the elements class { @code t } in the flow overrides the default { @code object . equals () } to provide a meaningful comparison between items as the default java implementation only considers reference equivalence . alternatively use the { @link #distinctuntilchanged ( bipredicate ) } overload and provide a comparison function in case the class { @code t } can t be overridden with custom { @code equals () } or the comparison itself should happen on different terms or properties of the class { @code t } . <p > note that the operator always retains the latest item from upstream regardless of the comparison result and uses it in the next comparison with the next upstream item . <p > note that if element type { @code t } in the flow is mutable the comparison of the previous and current item may yield unexpected results if the items are mutated externally . common cases are mutable { @code charsequence } s or { @code list } s where the objects will actually have the same references when they are modified and { @code distinctuntilchanged } will evaluate subsequent items as same . to avoid such situation it is recommended that mutable data is converted to an immutable one for example using { @code map ( charsequence :: tostring ) } or { @code map ( list - > collections . unmodifiablelist ( new arraylist< > ( list ))) } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinctuntilchanged } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits all items emitted by the source publisher that are distinct from their immediate predecessors according to a key selector function and based on { @link object#equals ( object ) } comparison of those objects returned by the key selector function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinctuntilchanged . key . png alt = > <p > it is recommended the keys class { @code k } overrides the default { @code object . equals () } to provide a meaningful comparison between the key objects as the default java implementation only considers reference equivalence . alternatively use the { @link #distinctuntilchanged ( bipredicate ) } overload and provide a comparison function in case the class { @code k } can t be overridden with custom { @code equals () } or the comparison itself should happen on different terms or properties of the item class { @code t } ( for which the keys can be derived via a similar selector ) . <p > note that the operator always retains the latest key from upstream regardless of the comparison result and uses it in the next comparison with the next key derived from the next upstream item . <p > note that if element type { @code t } in the flow is mutable the comparison of the previous and current item may yield unexpected results if the items are mutated externally . common cases are mutable { @code charsequence } s or { @code list } s where the objects will actually have the same references when they are modified and { @code distinctuntilchanged } will evaluate subsequent items as same . to avoid such situation it is recommended that mutable data is converted to an immutable one for example using { @code map ( charsequence :: tostring ) } or { @code map ( list - > collections . unmodifiablelist ( new arraylist< > ( list ))) } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinctuntilchanged } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits all items emitted by the source publisher that are distinct from their immediate predecessors when compared with each other via the provided comparator function . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / distinctuntilchanged . png alt = > <p > note that the operator always retains the latest item from upstream regardless of the comparison result and uses it in the next comparison with the next upstream item . <p > note that if element type { @code t } in the flow is mutable the comparison of the previous and current item may yield unexpected results if the items are mutated externally . common cases are mutable { @code charsequence } s or { @code list } s where the objects will actually have the same references when they are modified and { @code distinctuntilchanged } will evaluate subsequent items as same . to avoid such situation it is recommended that mutable data is converted to an immutable one for example using { @code map ( charsequence :: tostring ) } or { @code map ( list - > collections . unmodifiablelist ( new arraylist< > ( list ))) } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code distinctuntilchanged } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the specified action after this flowable signals onerror or oncompleted or gets canceled by the downstream . <p > in case of a race between a terminal event and a cancellation the provided {
calls the specified consumer with the current item after this item has been emitted to the downstream . <p > note that the {
registers an { @link action } to be called when this publisher invokes either { @link subscriber#oncomplete oncomplete } or { @link subscriber#onerror onerror } . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / finallydo . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doafterterminate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the cancel { @code action } if the downstream cancels the sequence . <p > the action is shared between subscriptions and thus may be called concurrently from multiple threads ; the action must be thread - safe . <p > if the action throws a runtime exception that exception is rethrown by the { @code oncancel () } call sometimes as a { @code compositeexception } if there were multiple exceptions along the way . <p > note that terminal events trigger the action unless the { @code publisher } is subscribed to via { @code unsafesubscribe () } . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonunsubscribe . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > { @code dooncancel } does not interact with backpressure requests or value delivery ; backpressure behavior is preserved between its upstream and its downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooncancel } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source publisher so that it invokes an action when it calls { @code oncomplete } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooncomplete . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooncomplete } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
calls the appropriate onxxx consumer ( shared between all subscribers ) whenever a signal with the same type passes through before forwarding them to downstream . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooneach . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooneach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source publisher so that it invokes an action for each item it emits . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooneach . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooneach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source publisher so that it notifies a subscriber for each item and terminal event it emits . <p > in case the { @code onerror } of the supplied subscriber throws the downstream will receive a composite exception containing the original exception and the exception thrown by { @code onerror } . if either the { @code onnext } or the { @code oncomplete } method of the supplied subscriber throws the downstream will be terminated and will receive this thrown exception . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / dooneach . o . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code dooneach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source publisher so that it invokes an action if it calls { @code onerror } . <p > in case the { @code onerror } action throws the downstream will receive a composite exception containing the original exception and the exception thrown by { @code onerror } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonerror . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source publisher so that it invokes an action when it calls { @code onnext } . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonnext . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonnext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source { @code publisher } so that it invokes the given action when it receives a request for more items . <p > <b > note : < / b > this operator is for tracing the internal behavior of back - pressure request patterns and generally intended for debugging use . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonrequest } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source { @code publisher } so that it invokes the given action when it is subscribed from its subscribers . each subscription will result in an invocation of the given action except when the source { @code publisher } is reference counted in which case the source { @code publisher } will invoke the given action for the first subscription . <p > <img width = 640 height = 390 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonsubscribe . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonsubscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
modifies the source publisher so that it invokes an action when it calls { @code oncomplete } or { @code onerror } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / doonterminate . png alt = > <p > this differs from { @code doafterterminate } in that this happens <em > before< / em > the { @code oncomplete } or { @code onerror } notification . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code doonterminate } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits the single item at a specified index in a sequence of emissions from this flowable or completes if this flowable sequence has fewer elements than index . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / elementat . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code elementat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the item found at a specified index in a sequence of emissions from this flowable or signals a { @link nosuchelementexception } if this flowable has fewer elements than index . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / elementatordefault . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code elementatorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
filters items emitted by a publisher by only emitting those that satisfy a specified predicate . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / filter . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code filter } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits only the very first item emitted by this flowable or completes if this flowable is empty . <p > <img width = 640 height = 237 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / firstelement . m . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code firstelement } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits only the very first item emitted by this flowable or a default item if this flowable completes without emitting anything . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / first . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code first } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits only the very first item emitted by this flowable or signals a { @link nosuchelementexception } if this flowable is empty . <p > <img width = 640 height = 237 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / firstorerror . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code firstorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits items based on applying a function that you supply to each item emitted by the source publisher where that function returns a publisher and then merging those resulting publishers and emitting the results of this merger while limiting the maximum number of concurrent subscriptions to these publishers . <! -- <p > -- > <! -- <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / flatmap . png alt = > -- > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the upstream flowable is consumed in a bounded manner ( up to { @code maxconcurrency } outstanding request amount for items ) . the inner { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that applies a function to each item emitted or notification raised by the source publisher and then flattens the publishers returned from these functions and emits the resulting items . <p > <img width = 640 height = 410 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergemap . nce . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the upstream flowable is consumed in a bounded manner ( up to { @link #buffersize () } outstanding request amount for items ) . the inner { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the results of a specified function to the pair of values emitted by the source publisher and a specified collection publisher while limiting the maximum number of concurrent subscriptions to these publishers . <! -- <p > -- > <! -- <img width = 640 height = 390 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / mergemap . r . png alt = > -- > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the upstream flowable is consumed in a bounded manner ( up to { @code maxconcurrency } outstanding request amount for items ) . the inner { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code flatmap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps each element of the upstream flowable into completablesources subscribes to them and waits until the upstream and all completablesources complete . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the upstream in an unbounded manner . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream flowable into completablesources subscribes to them and waits until the upstream and all completablesources complete optionally delaying all errors . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > if {
maps each element of the upstream flowable into maybesources subscribes to all of them and merges their onsuccess values in no particular order into a single flowable sequence . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the upstream in an unbounded manner . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream flowable into singlesources subscribes to all of them and merges their onsuccess values in no particular order into a single flowable sequence . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the upstream in an unbounded manner . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
maps each element of the upstream flowable into singlesources subscribes to at most {
subscribes to the { @link publisher } and receives notifications for each element . <p > alias to { @link #subscribe ( consumer ) } <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code foreach } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to the { @link publisher } and receives notifications for each element until the onnext predicate returns false . <p > if the flowable emits an error it is wrapped into an { @link io . reactivex . exceptions . onerrornotimplementedexception onerrornotimplementedexception } and routed to the rxjavaplugins . onerror handler . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code foreachwhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to the { @link publisher } and receives notifications for each element and error events until the onnext predicate returns false . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code foreachwhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to the { @link publisher } and receives notifications for each element and the terminal events until the onnext predicate returns false . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code foreachwhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
groups the items emitted by a { @code publisher } according to a specified criterion and emits these grouped items as { @link groupedflowable } s . the emitted { @code groupedpublisher } allows only a single { @link subscriber } during its lifetime and if this { @code subscriber } cancels before the source terminates the next emission by the source having the same key will trigger a new { @code groupedpublisher } emission . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / groupby . png alt = > <p > <em > note : < / em > a { @link groupedflowable } will cache the items it is to emit until such time as it is subscribed to . for this reason in order to avoid memory leaks you should not simply ignore those { @code groupedpublisher } s that do not concern you . instead you can signal to them that they may discard their buffers by applying an operator like { @link #ignoreelements } to them . <p > note that the { @link groupedflowable } s should be subscribed to as soon as possible otherwise the unconsumed groups may starve other groups due to the internal backpressure coordination of the { @code groupby } operator . such hangs can be usually avoided by using { @link #flatmap ( function int ) } or { @link #concatmapeager ( function int int ) } and overriding the default maximum concurrency value to be greater or equal to the expected number of groups possibly using { @code integer . max_value } if the number of expected groups is unknown .
groups the items emitted by a { @code publisher } according to a specified criterion and emits these grouped items as { @link groupedflowable } s . the emitted { @code groupedpublisher } allows only a single { @link subscriber } during its lifetime and if this { @code subscriber } cancels before the source terminates the next emission by the source having the same key will trigger a new { @code groupedpublisher } emission . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / groupby . png alt = > <p > <em > note : < / em > a { @link groupedflowable } will cache the items it is to emit until such time as it is subscribed to . for this reason in order to avoid memory leaks you should not simply ignore those { @code groupedpublisher } s that do not concern you . instead you can signal to them that they may discard their buffers by applying an operator like { @link #ignoreelements } to them . <p > note that the { @link groupedflowable } s should be subscribed to as soon as possible otherwise the unconsumed groups may starve other groups due to the internal backpressure coordination of the { @code groupby } operator . such hangs can be usually avoided by using { @link #flatmap ( function int ) } or { @link #concatmapeager ( function int int ) } and overriding the default maximum concurrency value to be greater or equal to the expected number of groups possibly using { @code integer . max_value } if the number of expected groups is unknown .
groups the items emitted by a { @code publisher } according to a specified criterion and emits these grouped items as { @link groupedflowable } s . the emitted { @code groupedpublisher } allows only a single { @link subscriber } during its lifetime and if this { @code subscriber } cancels before the source terminates the next emission by the source having the same key will trigger a new { @code groupedpublisher } emission . <p > <img width = 640 height = 360 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / groupby . png alt = > <p > <em > note : < / em > a { @link groupedflowable } will cache the items it is to emit until such time as it is subscribed to . for this reason in order to avoid memory leaks you should not simply ignore those { @code groupedpublisher } s that do not concern you . instead you can signal to them that they may discard their buffers by applying an operator like { @link #ignoreelements } to them . <p > note that the { @link groupedflowable } s should be subscribed to as soon as possible otherwise the unconsumed groups may starve other groups due to the internal backpressure coordination of the { @code groupby } operator . such hangs can be usually avoided by using { @link #flatmap ( function int ) } or { @link #concatmapeager ( function int int ) } and overriding the default maximum concurrency value to be greater or equal to the expected number of groups possibly using { @code integer . max_value } if the number of expected groups is unknown .
hides the identity of this flowable and its subscription . <p > allows hiding extra features such as { @link processor } s { @link subscriber } methods or preventing certain identity - based optimizations ( fusion ) . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator is a pass - through for backpressure the behavior is determined by the upstream s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code hide } does not operate by default on a particular { @link scheduler } . < / dd > < / dl > @return the new flowable instance
ignores all items emitted by the source publisher and only calls { @code oncomplete } or { @code onerror } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / ignoreelements . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator ignores backpressure as it doesn t emit any elements and consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code ignoreelements } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits { @code true } if the source publisher is empty otherwise { @code false } . <p > in rx . net this is negated as the { @code any } subscriber but we renamed this in rxjava to better match java naming idioms . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / isempty . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code isempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that emits the last item emitted by this flowable or completes if this flowable is empty . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / last . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code lastelement } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits only the last item emitted by this flowable or signals a { @link nosuchelementexception } if this flowable is empty . <p > <img width = 640 height = 236 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / lastorerror . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code lastorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
limits both the number of upstream items ( after which the sequence completes ) and the total downstream request amount requested from the upstream to possibly prevent the creation of excess items by the upstream . <p > the operator requests at most the given {
returns a flowable that represents all of the emissions <em > and< / em > notifications from the source publisher into emissions marked with their original types within { @link notification } objects . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / materialize . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and expects it from the source { @code publisher } . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code materialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
flattens this and another publisher into a single publisher without any transformation . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > you can combine items emitted by multiple publishers so that they appear as a single publisher by using the { @code mergewith } method . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . this and the other { @code publisher } s are expected to honor backpressure ; if violated the operator <em > may< / em > signal { @code missingbackpressureexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code mergewith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
merges the sequence of items of this flowable with the success value of the other singlesource . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > the success value of the other {
merges the sequence of items of this flowable with the success value of the other maybesource or waits for both to complete normally if the maybesource is empty . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / merge . png alt = > <p > the success value of the other {
modifies a publisher to perform its emissions and notifications on a specified { @link scheduler } asynchronously with a bounded buffer of { @link #buffersize () } slots .
instructs a publisher that is emitting items faster than its subscriber can consume them to buffer these items indefinitely until they can be emitted . <p > <img width = 640 height = 300 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / bp . obp . buffer . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . not applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onbackpressurebuffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs a publisher that is emitting items faster than its subscriber can consume them to buffer up to a given amount of items until they can be emitted . the resulting publisher will signal a { @code bufferoverflowexception } via { @code onerror } as soon as the buffer s capacity is exceeded dropping all undelivered items and canceling the source . <p > <img width = 640 height = 300 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / bp . obp . buffer . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . not applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onbackpressurebuffer } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs a publisher that is emitting items faster than its subscriber can consume them to discard rather than emit those items that its subscriber is not prepared to observe . <p > <img width = 640 height = 245 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / bp . obp . drop . png alt = > <p > if the downstream request count hits 0 then the publisher will refrain from calling { @code onnext } until the subscriber invokes { @code request ( n ) } again to increase the request count . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . not applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onbackpressuredrop } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs a publisher that is emitting items faster than its subscriber can consume them to discard rather than emit those items that its subscriber is not prepared to observe . <p > <img width = 640 height = 245 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / bp . obp . drop . png alt = > <p > if the downstream request count hits 0 then the publisher will refrain from calling { @code onnext } until the subscriber invokes { @code request ( n ) } again to increase the request count . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . not applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onbackpressuredrop } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
instructs a publisher to pass control to another publisher rather than invoking { @link subscriber#onerror onerror } if it encounters an error . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / onerrorresumenext . png alt = > <p > by default when a publisher encounters an error that prevents it from emitting the expected item to its { @link subscriber } the publisher invokes its subscriber s { @code onerror } method and then quits without invoking any more of its subscriber s methods . the { @code onerrorresumenext } method changes this behavior . if you pass a function that returns a publisher ( { @code resumefunction } ) to { @code onerrorresumenext } if the original publisher encounters an error instead of invoking its subscriber s { @code onerror } method it will instead relinquish control to the publisher returned from { @code resumefunction } which will invoke the subscriber s { @link subscriber#onnext onnext } method if it is able to do so . in such a case because no publisher necessarily invokes { @code onerror } the subscriber may never know that an error happened . <p > you can use this to prevent errors from propagating or to supply fallback data should errors be encountered . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . this and the resuming { @code publisher } s are expected to honor backpressure as well . if any of them violate this expectation the operator <em > may< / em > throw an { @code illegalstateexception } when the source { @code publisher } completes or a { @code missingbackpressureexception } is signaled somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code onerrorresumenext } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
nulls out references to the upstream producer and downstream subscriber if the sequence is terminated or downstream cancels . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source {
parallelizes the flow by creating multiple rails ( equal to the number of cpus ) and dispatches the upstream items to them in a round - robin fashion . <p > note that the rails don t execute in parallel on their own and one needs to apply {
parallelizes the flow by creating the specified number of rails and dispatches the upstream items to them in a round - robin fashion . <p > note that the rails don t execute in parallel on their own and one needs to apply {
returns a { @link connectableflowable } which is a variety of publisher that waits until its { @link connectableflowable#connect connect } method is called before it begins emitting items to those { @link subscriber } s that have subscribed to it . <p > <img width = 640 height = 510 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / publishconnect . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned { @code connectableflowable } honors backpressure for each of its { @code subscriber } s and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator will signal a { @code missingbackpressureexception } to its { @code subscriber } s and disconnect . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code publish } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the results of invoking a specified selector on items emitted by a { @link connectableflowable } that shares a single subscription to the underlying sequence . <p > <img width = 640 height = 510 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / publishconnect . f . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects the source { @code publisher } to honor backpressure and if this expectation is violated the operator will signal a { @code missingbackpressureexception } through the { @code publisher } provided to the function . since the { @code publisher } returned by the { @code selector } may be independent of the provided { @code publisher } to the function the output s backpressure behavior is determined by this returned { @code publisher } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code publish } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a { @link connectableflowable } which is a variety of publisher that waits until its { @link connectableflowable#connect connect } method is called before it begins emitting items to those { @link subscriber } s that have subscribed to it . <p > <img width = 640 height = 510 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / publishconnect . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the returned { @code connectableflowable } honors backpressure for each of its { @code subscriber } s and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator will signal a { @code missingbackpressureexception } to its { @code subscriber } s and disconnect . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code publish } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
requests { @code n } initially from the upstream and then 75% of { @code n } subsequently after 75% of { @code n } values have been emitted to the downstream .
returns a maybe that applies a specified accumulator function to the first item emitted by a source publisher then feeds the result of that function along with the second item emitted by the source publisher into the same function and so on until all items have been emitted by the finite source publisher and emits the final result from the final call to your function as its sole item . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / reduce . png alt = > <p > this technique which is called reduce here is sometimes called aggregate fold accumulate compress or inject in other programming contexts . groovy for instance has an { @code inject } method that does a similar operation on lists . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure of its downstream consumer and consumes the upstream source in unbounded mode . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code reduce } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that applies a specified accumulator function to the first item emitted by a source publisher and a specified seed value then feeds the result of that function along with the second item emitted by a publisher into the same function and so on until all items have been emitted by the finite source publisher emitting the final result from the final call to your function as its sole item . <p > <img width = 640 height = 325 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / reduceseed . png alt = > <p > this technique which is called reduce here is sometimes called aggregate fold accumulate compress or inject in other programming contexts . groovy for instance has an { @code inject } method that does a similar operation on lists . <p > note that the { @code seed } is shared among all subscribers to the resulting publisher and may cause problems if it is mutable . to make sure each subscriber gets its own value defer the application of this operator via { @link #defer ( callable ) } : <pre > <code > publisher&lt ; t&gt ; source = ... single . defer (( ) - &gt ; source . reduce ( new arraylist&lt ; &gt ; () ( list item ) - &gt ; list . add ( item ))) ;
returns a single that applies a specified accumulator function to the first item emitted by a source publisher and a seed value derived from calling a specified seedsupplier then feeds the result of that function along with the second item emitted by a publisher into the same function and so on until all items have been emitted by the finite source publisher emitting the final result from the final call to your function as its sole item . <p > <img width = 640 height = 325 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / reduceseed . png alt = > <p > this technique which is called reduce here is sometimes called aggregate fold accumulate compress or inject in other programming contexts . groovy for instance has an { @code inject } method that does a similar operation on lists . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulator object to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure of its downstream consumer and consumes the upstream source in unbounded mode . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code reducewith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that repeats the sequence of items emitted by the source publisher indefinitely . <p > <img width = 640 height = 309 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeat . o . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that repeats the sequence of items emitted by the source publisher at most { @code count } times . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / repeat . on . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code repeat } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a { @link connectableflowable } that shares a single subscription to the underlying publisher that will replay all of its items and notifications to any future { @link subscriber } . a connectable publisher resembles an ordinary publisher except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits items that are the results of invoking a specified selector on items emitted by a { @link connectableflowable } that shares a single subscription to the source publisher replaying no more than { @code buffersize } items that were emitted within a specified time window . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . fnt . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits items that are the results of invoking a specified selector on items emitted by a { @link connectableflowable } that shares a single subscription to the source publisher . <p > <img width = 640 height = 445 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . fs . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a { @link connectableflowable } that shares a single subscription to the source publisher that replays at most { @code buffersize } items emitted by that publisher . a connectable publisher resembles an ordinary publisher except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . n . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a { @link connectableflowable } that shares a single subscription to the source publisher and replays at most { @code buffersize } items that were emitted during a specified time window . a connectable publisher resembles an ordinary publisher except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . nt . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code replay } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a { @link connectableflowable } that shares a single subscription to the source publisher and that replays a maximum of { @code buffersize } items that are emitted within a specified time window . a connectable publisher resembles an ordinary publisher except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . nts . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a { @link connectableflowable } that shares a single subscription to the source publisher and replays at most { @code buffersize } items emitted by that publisher . a connectable publisher resembles an ordinary publisher except that it does not begin emitting items when it is subscribed to but only when its { @code connect } method is called . <p > note that due to concurrency requirements { @code replay ( buffersize ) } may hold strong references to more than { @code buffersize } source emissions . <p > <img width = 640 height = 515 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / replay . ns . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator supports backpressure . note that the upstream requests are determined by the child subscriber which requests the largest amount : i . e . two child subscribers with requests of 10 and 100 will request 100 elements from the underlying publisher sequence . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that mirrors the source publisher resubscribing to it if it calls { @code onerror } ( infinite retry count ) . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . png alt = > <p > if the source publisher calls { @link subscriber#onerror } this method will resubscribe to the source publisher rather than propagating the { @code onerror } call . <p > any and all items emitted by the source publisher will be emitted by the resulting publisher even those emitted during failed subscriptions . for example if a publisher fails at first but emits { @code [ 1 2 ] } then succeeds the second time and emits { @code [ 1 2 3 4 5 ] } then the complete sequence of emissions and notifications would be { @code [ 1 2 1 2 3 4 5 oncomplete ] } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that mirrors the source publisher resubscribing to it if it calls { @code onerror } up to a specified number of retries . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / retry . png alt = > <p > if the source publisher calls { @link subscriber#onerror } this method will resubscribe to the source publisher for a maximum of { @code count } resubscriptions rather than propagating the { @code onerror } call . <p > any and all items emitted by the source publisher will be emitted by the resulting publisher even those emitted during failed subscriptions . for example if a publisher fails at first but emits { @code [ 1 2 ] } then succeeds the second time and emits { @code [ 1 2 3 4 5 ] } then the complete sequence of emissions and notifications would be { @code [ 1 2 1 2 3 4 5 oncomplete ] } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
retries the current flowable if the predicate returns true . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator <em > may< / em > throw an { @code illegalstateexception } . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code retry } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to the current flowable and wraps the given subscriber into a safesubscriber ( if not already a safesubscriber ) that deals with exceptions thrown by a misbehaving subscriber ( that doesn t follow the reactive - streams specification ) . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator leaves the reactive world and the backpressure behavior depends on the subscriber s behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > {
returns a flowable that emits the most recently emitted item ( if any ) emitted by the source publisher within periodic time intervals . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sample . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code sample } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the most recently emitted item ( if any ) emitted by the source publisher within periodic time intervals where the intervals are defined on a particular scheduler . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sample . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that when the specified { @code sampler } publisher emits an item or completes emits the most recently emitted item ( if any ) emitted by the source publisher since the previous emission from the { @code sampler } publisher . <p > <img width = 640 height = 289 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / sample . o . nolast . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses the emissions of the { @code sampler } publisher to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code sample } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that applies a specified accumulator function to the first item emitted by a source publisher and a seed value then feeds the result of that function along with the second item emitted by the source publisher into the same function and so on until all items have been emitted by the source publisher emitting the result of each of these iterations . <p > <img width = 640 height = 320 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / scanseed . png alt = > <p > this sort of function is sometimes called an accumulator . <p > note that the publisher that results from this method will emit the value returned by the { @code seedsupplier } as its first item . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors downstream backpressure and expects the source { @code publisher } to honor backpressure as well . violating this expectation a { @code missingbackpressureexception } <em > may< / em > get signaled somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code scanwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
forces a publisher s emissions and notifications to be serialized and for it to obey <a href = http : // reactivex . io / documentation / contract . html > the publisher contract< / a > in other ways . <p > it is possible for a publisher to invoke its subscribers methods asynchronously perhaps from different threads . this could make such a publisher poorly - behaved in that it might try to invoke { @code oncomplete } or { @code onerror } before one of its { @code onnext } invocations or it might call { @code onnext } from two different threads concurrently . you can force such a publisher to be well - behaved and sequential by applying the { @code serialize } method to it . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / synchronize . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code serialize } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a new { @link publisher } that multicasts ( and shares a single subscription to ) the original { @link publisher } . as long as there is at least one { @link subscriber } this { @link publisher } will be subscribed and emitting data . when all subscribers have canceled it will cancel the source { @link publisher } . <p > this is an alias for { @link #publish () } . { @link connectableflowable#refcount () refcount () } . <p > <img width = 640 height = 510 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / publishrefcount . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure and expects the source { @code publisher } to honor backpressure as well . if this expectation is violated the operator will signal a { @code missingbackpressureexception } to its { @code subscriber } s . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code share } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a maybe that completes if this flowable is empty signals one item if this flowable signals exactly one item or signals an { @code illegalargumentexception } if this flowable signals more than one item . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / single . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code singleelement } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits the single item emitted by this flowable if this flowable emits only a single item otherwise if this flowable completes without emitting any items a { @link nosuchelementexception } will be signaled and if this flowable emits more than one item an { @code illegalargumentexception } will be signaled . <p > <img width = 640 height = 205 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / singleorerror . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code singleorerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that skips the first { @code count } items emitted by the source publisher and emits the remainder . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skip . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code skip } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that skips values emitted by the source publisher before a specified time window elapses . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skip . t . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t support backpressure as it uses time to skip an arbitrary number of elements and thus has to consume the source { @code publisher } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skip } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that skips values emitted by the source publisher before a specified time window on a specified { @link scheduler } elapses . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skip . ts . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t support backpressure as it uses time to skip an arbitrary number of elements and thus has to consume the source { @code publisher } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use for the timed skipping< / dd > < / dl >
returns a flowable that drops a specified number of items from the end of the sequence emitted by the source publisher . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . png alt = > <p > this subscriber accumulates a queue long enough to store the first { @code count } items . as more items are received items are taken from the front of the queue and emitted by the returned publisher . this causes such items to be delayed . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code skiplast } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that drops items emitted by the source publisher during a specified time window before the source completes . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . t . png alt = > <p > note : this action will cache the latest items arriving in the specified time window . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t support backpressure as it uses time to skip an arbitrary number of elements and thus has to consume the source { @code publisher } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skiplast } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that drops items emitted by the source publisher during a specified time window ( defined on a specified scheduler ) before the source completes . <p > <img width = 640 height = 340 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skiplast . ts . png alt = > <p > note : this action will cache the latest items arriving in the specified time window . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t support backpressure as it uses time to skip an arbitrary number of elements and thus has to consume the source { @code publisher } in an unbounded manner ( i . e . no backpressure applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use for tracking the current time< / dd > < / dl >
returns a flowable that skips all items emitted by the source publisher as long as a specified condition holds true but emits all further source items as soon as the condition becomes false . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / skipwhile . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code skipwhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the events emitted by source publisher in a sorted order . each item emitted by the publisher must implement { @link comparable } with respect to all other items in the sequence .
returns a flowable that emits the events emitted by source publisher in a sorted order based on a specified comparison function .
returns a flowable that emits the items in a specified { @link iterable } before it begins to emit items emitted by the source publisher . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / startwith . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the source { @code publisher } is expected to honor backpressure as well . if it violates this rule it <em > may< / em > throw an { @code illegalstateexception } when the source { @code publisher } completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code startwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits the specified items before it begins to emit items emitted by the source publisher . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / startwith . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the source { @code publisher } is expected to honor backpressure as well . if it violates this rule it <em > may< / em > throw an { @code illegalstateexception } when the source { @code publisher } completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code startwitharray } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to a publisher and ignores { @code onnext } and { @code oncomplete } emissions . <p > if the flowable emits an error it is wrapped into an { @link io . reactivex . exceptions . onerrornotimplementedexception onerrornotimplementedexception } and routed to the rxjavaplugins . onerror handler . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
subscribes to a publisher and provides a callback to handle the items it emits . <p > if the flowable emits an error it is wrapped into an { @link io . reactivex . exceptions . onerrornotimplementedexception onerrornotimplementedexception } and routed to the rxjavaplugins . onerror handler . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code subscribe } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
establish a connection between this flowable and the given flowablesubscriber and start streaming events based on the demand of the flowablesubscriber . <p > this is a factory method and can be called multiple times each time starting a new {
subscribes a given subscriber ( subclass ) to this flowable and returns the given subscriber as is . <p > usage example : <pre > <code > flowable&lt ; integer&gt ; source = flowable . range ( 1 10 ) ; compositedisposable composite = new compositedisposable () ;
asynchronously subscribes subscribers to this publisher on the specified {
returns a flowable that emits the items emitted by the source publisher or the items of an alternate publisher if the source publisher is empty . <p > <img width = 640 height = 255 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchifempty . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > if the source { @code publisher } is empty the alternate { @code publisher } is expected to honor backpressure . if the source { @code publisher } is non - empty it is expected to honor backpressure as instead . in either case if violated a { @code missingbackpressureexception } <em > may< / em > get signaled somewhere downstream . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchifempty } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
maps the upstream values into {
returns a new publisher by applying a function that you supply to each item emitted by the source publisher that returns a publisher and then emitting the items emitted by the most recently emitted of these publishers and delays any error until all publishers terminate . <p > the resulting publisher completes if both the upstream publisher and the last inner publisher if any complete . if the upstream publisher signals an onerror the termination of the last inner publisher will emit that error as is or wrapped into a compositeexception along with the other possible errors the former inner publishers signaled . <p > <img width = 640 height = 350 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / switchmap . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the outer { @code publisher } is consumed in an unbounded manner ( i . e . without backpressure ) and the inner { @code publisher } s are expected to honor backpressure but it is not enforced ; the operator won t signal a { @code missingbackpressureexception } but the violation <em > may< / em > lead to { @code outofmemoryerror } due to internal buffer bloat . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code switchmapdelayerror } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits only the first { @code count } items emitted by the source publisher . if the source emits fewer than { @code count } items then all of its items are emitted . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / take . png alt = > <p > this method returns a publisher that will invoke a subscribing { @link subscriber } s { @link subscriber#onnext onnext } function a maximum of { @code count } times before invoking { @link subscriber#oncomplete oncomplete } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior in case the first request is smaller than the { @code count } . otherwise the source { @code publisher } is consumed in an unbounded manner ( i . e . without applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code take } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits those items emitted by source publisher before a specified time runs out . <p > if time runs out before the { @code flowable } completes normally the { @code oncomplete } event will be signaled on the default { @code computation } { @link scheduler } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / take . t . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code take } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits those items emitted by source publisher before a specified time ( on a specified scheduler ) runs out . <p > if time runs out before the { @code flowable } completes normally the { @code oncomplete } event will be signaled on the provided { @link scheduler } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / take . ts . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits at most the last { @code count } items emitted by the source publisher . if the source emits fewer than { @code count } items then all of its items are emitted . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takelast . n . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream if the { @code count } is non - zero ; ignores backpressure if the { @code count } is zero as it doesn t signal any values . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code takelast } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits at most a specified number of items from the source publisher that were emitted in a specified window of time before the publisher completed . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takelast . tn . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takelast } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits at most a specified number of items from the source publisher that were emitted in a specified window of time before the publisher completed where the timing information is provided by a given scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takelast . tns . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use for tracking the current time< / dd > < / dl >
returns a flowable that emits the items from the source publisher that were emitted in a specified window of time before the publisher completed where the timing information is provided by a specified scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takelast . ts . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . no backpressure is applied to it ) but note that this <em > may< / em > lead to { @code outofmemoryerror } due to internal buffer bloat . consider using { @link #takelast ( long long timeunit scheduler ) } in this case . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits items emitted by the source publisher checks the specified predicate for each item and then completes when the condition is satisfied . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takeuntil . p . png alt = > <p > the difference between this operator and { @link #takewhile ( predicate ) } is that here the condition is evaluated <em > after< / em > the item is emitted .
returns a flowable that emits the items emitted by the source publisher until a second publisher emits an item . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takeuntil . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takeuntil } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits items emitted by the source publisher so long as each item satisfied a specified condition and then completes as soon as this condition is not satisfied . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / takewhile . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code takewhile } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits only the first item emitted by the source publisher during sequential time windows of a specified duration . <p > this differs from { @link #throttlelast } in that this only tracks the passage of time whereas { @link #throttlelast } ticks at scheduled intervals . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlefirst . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code throttlefirst } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits only the last item emitted by the source publisher during sequential time windows of a specified duration . <p > this differs from { @link #throttlefirst } in that this ticks along at a scheduled interval whereas { @link #throttlefirst } does not tick it just tracks the passage of time . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlelast . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code throttlelast } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits only the last item emitted by the source publisher during sequential time windows of a specified duration where the duration is governed by a specified scheduler . <p > this differs from { @link #throttlefirst } in that this ticks along at a scheduled interval whereas { @link #throttlefirst } does not tick it just tracks the passage of time . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlelast . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that mirrors the source publisher except that it drops items emitted by the source publisher that are followed by newer items before a timeout value expires on a specified scheduler . the timer resets on each emission ( alias to { @link #debounce ( long timeunit scheduler ) } ) . <p > <em > note : < / em > if items keep being emitted by the source publisher faster than the timeout then no items will be emitted by the resulting publisher . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / throttlewithtimeout . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > this operator does not support backpressure as it uses time to control data flow . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits records of the time interval between consecutive items emitted by the source publisher . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeinterval . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code timeinterval } does not operate on any particular scheduler but uses the current time from the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits records of the time interval between consecutive items emitted by the source publisher where this interval is computed on a specified scheduler . <p > <img width = 640 height = 315 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeinterval . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > the operator does not operate on any particular scheduler but uses the current time from the specified { @link scheduler } . < / dd > < / dl >
returns a flowable that mirrors the source publisher but notifies subscribers of a { @code timeoutexception } if an item emitted by the source publisher doesn t arrive within a window of time after the emission of the previous item where that period of time is measured by a publisher that is a function of the previous item . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout3 . png alt = > <p > note : the arrival of the first source item is never timed out . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . the { @code publisher } sources are expected to honor backpressure as well . if any of the source { @code publisher } s violate this it <em > may< / em > throw an { @code illegalstateexception } when the source { @code publisher } completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code immediate } { @link scheduler } . < / dd > < / dl >
returns a flowable that mirrors the source publisher but applies a timeout policy for each emitted item . if the next item isn t emitted within the specified timeout duration starting from its predecessor the resulting publisher terminates and notifies subscribers of a { @code timeoutexception } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 1 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code timeout } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that mirrors the source publisher but applies a timeout policy for each emitted item where this policy is governed by a specified scheduler . if the next item isn t emitted within the specified timeout duration starting from its predecessor the resulting publisher terminates and notifies subscribers of a { @code timeoutexception } . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout . 1s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that mirrors the source publisher but notifies subscribers of a { @code timeoutexception } if either the first item emitted by the source publisher or any subsequent item doesn t arrive within time windows defined by other publishers . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timeout5 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream . both this and the returned { @code publisher } s are expected to honor backpressure as well . if any of then violates this rule it <em > may< / em > throw an { @code illegalstateexception } when the { @code publisher } completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code timeout } does not operate by default on any { @link scheduler } . < / dd > < / dl >
returns a flowable that emits each item emitted by the source publisher wrapped in a { @link timed } object whose timestamps are provided by a specified scheduler . <p > <img width = 640 height = 310 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / timestamp . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this operator does not operate on any particular scheduler but uses the current time from the specified { @link scheduler } . < / dd > < / dl >
calls the specified converter function during assembly time and returns its resulting value . <p > this allows fluent conversion to any other type . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the backpressure behavior depends on what happens in the {
returns a single that emits a single item a list composed of all the items emitted by the finite upstream source publisher . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tolist . png alt = > <p > normally a publisher that returns multiple items will do so by invoking its { @link subscriber } s { @link subscriber#onnext onnext } method for each such item . you can change this behavior instructing the publisher to compose a list of all of these items and then to invoke the subscriber s { @code onnext } function once passing it the entire list by calling the publisher s { @code tolist } method prior to calling its { @link #subscribe } method . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated list to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tolist } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a single item a list composed of all the items emitted by the finite source publisher . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tolist . png alt = > <p > normally a publisher that returns multiple items will do so by invoking its { @link subscriber } s { @link subscriber#onnext onnext } method for each such item . you can change this behavior instructing the publisher to compose a list of all of these items and then to invoke the subscriber s { @code onnext } function once passing it the entire list by calling the publisher s { @code tolist } method prior to calling its { @link #subscribe } method . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated list to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tolist } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a single item a list composed of all the items emitted by the finite source publisher . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tolist . png alt = > <p > normally a publisher that returns multiple items will do so by invoking its { @link subscriber } s { @link subscriber#onnext onnext } method for each such item . you can change this behavior instructing the publisher to compose a list of all of these items and then to invoke the subscriber s { @code onnext } function once passing it the entire list by calling the publisher s { @code tolist } method prior to calling its { @link #subscribe } method . <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated collection to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tolist } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a single that emits a single map returned by a specified { @code mapfactory } function that contains a custom collection of values extracted by a specified { @code valueselector } function from items emitted by the finite source publisher and keyed by the { @code keyselector } function . <p > <img width = 640 height = 305 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / tomultimap . png alt = > <p > note that this operator requires the upstream to signal { @code oncomplete } for the accumulated map to be emitted . sources that are infinite and never complete will never emit anything through this operator and an infinite source may lead to a fatal { @code outofmemoryerror } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure from downstream and consumes the source { @code publisher } in an unbounded manner ( i . e . without applying backpressure to it ) . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code tomultimap } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
converts the current flowable into a non - backpressured {
returns a single that emits a list that contains the items emitted by the finite source publisher in a sorted order . each item emitted by the publisher must implement { @link comparable } with respect to all other items in the sequence .
modifies the source publisher so that subscribers will cancel it on a specified { @link scheduler } . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator doesn t interfere with backpressure which is determined by the source { @code publisher } s backpressure behavior . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits connected non - overlapping windows each containing { @code count } items . when the source publisher completes or encounters an error the resulting publisher emits the current window and propagates the notification from the source publisher . <p > <img width = 640 height = 400 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window3 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure of its inner and outer subscribers however the inner publisher uses an unbounded buffer that may hold at most { @code count } elements . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits windows every { @code skip } items each containing no more than { @code count } items . when the source publisher completes or encounters an error the resulting publisher emits the current window and propagates the notification from the source publisher . <p > <img width = 640 height = 365 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window4 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator honors backpressure of its inner and outer subscribers however the inner publisher uses an unbounded buffer that may hold at most { @code count } elements . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher starts a new window periodically as determined by the { @code timeskip } argument . it emits each window after a fixed timespan specified by the { @code timespan } argument . when the source publisher completes or publisher completes or encounters an error the resulting publisher emits the current window and propagates the notification from the source publisher . <p > <img width = 640 height = 335 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window7 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner . the returned { @code publisher } doesn t support backpressure as it uses time to control the creation of windows . the returned inner { @code publisher } s honor backpressure but have an unbounded inner buffer that <em > may< / em > lead to { @code outofmemoryerror } if left unconsumed . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits connected non - overlapping windows each of a fixed duration as specified by the { @code timespan } argument or a maximum size as specified by the { @code count } argument ( whichever is reached first ) . when the source publisher completes or encounters an error the resulting publisher emits the current window and propagates the notification from the source publisher . <p > <img width = 640 height = 370 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window6 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner . the returned { @code publisher } doesn t support backpressure as it uses time to control the creation of windows . the returned inner { @code publisher } s honor backpressure and may hold up to { @code count } elements at most . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } operates by default on the { @code computation } { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits connected non - overlapping windows each of a fixed duration as specified by the { @code timespan } argument . when the source publisher completes or encounters an error the resulting publisher emits the current window and propagates the notification from the source publisher . <p > <img width = 640 height = 375 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window5 . s . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner . the returned { @code publisher } doesn t support backpressure as it uses time to control the creation of windows . the returned inner { @code publisher } s honor backpressure but have an unbounded inner buffer that <em > may< / em > lead to { @code outofmemoryerror } if left unconsumed . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > you specify which { @link scheduler } this operator will use . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits windows that contain those items emitted by the source publisher between the time when the { @code windowopenings } publisher emits an item and when the publisher returned by { @code closingselector } emits an item . <p > <img width = 640 height = 550 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window2 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the outer publisher of this operator doesn t support backpressure because the emission of new inner publishers are controlled by the { @code windowopenings } publisher . the inner publishers honor backpressure and buffer everything until the associated closing publisher signals or completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits windows that contain those items emitted by the source publisher between the time when the { @code windowopenings } publisher emits an item and when the publisher returned by { @code closingselector } emits an item . <p > <img width = 640 height = 550 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window2 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the outer publisher of this operator doesn t support backpressure because the emission of new inner publishers are controlled by the { @code windowopenings } publisher . the inner publishers honor backpressure and buffer everything until the associated closing publisher signals or completes . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits connected non - overlapping windows . it emits the current window and opens a new one whenever the publisher produced by the specified { @code closingselector } emits an item . <p > <img width = 640 height = 455 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window1 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner . the returned { @code publisher } doesn t support backpressure as it uses the { @code closingselector } to control the creation of windows . the returned inner { @code publisher } s honor backpressure but have an unbounded inner buffer that <em > may< / em > lead to { @code outofmemoryerror } if left unconsumed . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits windows of items it collects from the source publisher . the resulting publisher emits connected non - overlapping windows . it emits the current window and opens a new one whenever the publisher produced by the specified { @code closingselector } emits an item . <p > <img width = 640 height = 455 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / window1 . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator consumes the source { @code publisher } in an unbounded manner . the returned { @code publisher } doesn t support backpressure as it uses the { @code closingselector } to control the creation of windows . the returned inner { @code publisher } s honor backpressure but have an unbounded inner buffer that <em > may< / em > lead to { @code outofmemoryerror } if left unconsumed . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > this version of { @code window } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits items that are the result of applying a specified function to pairs of values one each from the source publisher and a specified iterable sequence . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / zip . i . png alt = > <p > note that the { @code other } iterable is evaluated as items are observed from the source publisher ; it is not pre - consumed . this allows you to zip infinite streams on either side . <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects backpressure from the sources and honors backpressure from the downstream . ( i . e . zipping with { @link #interval ( long timeunit ) } may result in missingbackpressureexception use one of the { @code onbackpressurex } to handle similar backpressure - ignoring sources . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zipwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
returns a flowable that emits items that are the result of applying a specified function to pairs of values one each from the source publisher and another specified publisher . <p > the operator subscribes to its sources in the order they are specified and completes eagerly if one of the sources is shorter than the rest while canceling the other sources . therefore it is possible those other sources will never be able to run to completion ( and thus not calling { @code dooncomplete () } ) . this can also happen if the sources are exactly the same length ; if source a completes and b has been consumed and is about to complete the operator detects a won t be sending further values and it will cancel b immediately . for example : <pre > <code > range ( 1 5 ) . dooncomplete ( action1 ) . zipwith ( range ( 6 5 ) . dooncomplete ( action2 ) ( a b ) - &gt ; a + b ) < / code > < / pre > { @code action1 } will be called but { @code action2 } won t . <br > to work around this termination property use { @link #dooncancel ( action ) } as well or use { @code using () } to do cleanup in case of completion or cancellation . <p > <img width = 640 height = 380 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / zip . png alt = > <dl > <dt > <b > backpressure : < / b > < / dt > <dd > the operator expects backpressure from the sources and honors backpressure from the downstream . ( i . e . zipping with { @link #interval ( long timeunit ) } may result in missingbackpressureexception use one of the { @code onbackpressurex } to handle similar backpressure - ignoring sources . < / dd > <dt > <b > scheduler : < / b > < / dt > <dd > { @code zipwith } does not operate by default on a particular { @link scheduler } . < / dd > < / dl >
{ @inheritdoc } <br > <p > implementation notes : <br > offer is allowed from multiple threads . <br > offer allocates a new node and : <ol > <li > swaps it atomically with current producer node ( only one producer wins ) <li > sets the new node as the node following from the swapped producer node < / ol > this works because each producer is guaranteed to plant a new node and link the old node . no 2 producers can get the same producer node as part of xchg guarantee .
{ @inheritdoc } <br > <p > implementation notes : <br > poll is allowed from a single thread . <br > poll reads the next node from the consumernode and : <ol > <li > if it is null the queue is assumed empty ( though it might not be ) . <li > if it is not null set it as the consumer node and return it s now evacuated value . < / ol > this means the consumernode . value is always null which is also the starting point for the queue . because null values are not allowed to be offered this is the only node with it s value set to null at any one time .
wraps the given runnable into a scheduledrunnable and schedules it on the underlying scheduledexecutorservice . <p > if the schedule has been rejected the scheduledrunnable . wasscheduled will return false .
wait for the terminal signal .
completes this subscription by indicating the given value should be emitted when the first request arrives . <p > make sure this is called exactly once .
creates a { @link behaviorprocessor } that emits the last item it observed and all subsequent items to each { @link subscriber } that subscribes to it .
tries to emit the item to all currently subscribed subscribers if all of them has requested some value returns false otherwise . <p > this method should be called in a sequential manner just like the onxxx methods of the publishprocessor . <p > calling with null will terminate the publishprocessor and a nullpointerexception is signalled to the subscribers . <p > history : 2 . 0 . 8 - experimental
todo fuse back to flowable
checks if the {
returns a {
connects to the upstream {
connects to the upstream {
connects to the upstream {
connects to the upstream {
returns a flowable that automatically connects ( at most once ) to this connectableflowable when the specified number of subscribers subscribe to it and calls the specified callback with the subscription associated with the established connection . <p > <img width = 640 height = 392 src = https : // raw . github . com / wiki / reactivex / rxjava / images / rx - operators / autoconnect . f . png alt = > <p > the connection happens after the given number of subscriptions and happens at most once during the lifetime of the returned flowable . if this connectableflowable terminates the connection is never renewed no matter how subscribers come and go . use { @link #refcount () } to renew a connection or dispose an active connection when all { @code subscriber } s have cancelled their { @code subscription } s .
requests from the upstream subscription .
sets the resource at the specified index and disposes the old resource .
replaces the resource at the specified index and returns the old resource .
block until the first value arrives and return it otherwise return null for an empty source and rethrow any exception .
tries to add the given subscriber to the subscribers array atomically or returns false if the subject has terminated .
atomically removes the given subscriber if it is subscribed to the subject .
given a connectable observable factory it multicasts over the generated connectableobservable via a selector function .
child subscribers will observe the events of the connectableobservable on the specified scheduler .
creates a replaying connectableobservable with an unbounded buffer .
creates a replaying connectableobservable with a size bound buffer .
creates a replaying connectableobservable with a time bound buffer .
creates a replaying connectableobservable with a size and time bound buffer .
creates a operatorreplay instance to replay values of the given source observable .
create an instance using {
returns an instance which creates synchronous observables that {
create an instance using {
returns the generic supertype for {
invokes {
create an implementation of the api endpoints defined by the {
returns the { @link calladapter } for { @code returntype } from the available { @linkplain #calladapterfactories () factories } .
returns the { @link calladapter } for { @code returntype } from the available { @linkplain #calladapterfactories () factories } except { @code skippast } .
returns a { @link converter } for { @code type } to { @link requestbody } from the available { @linkplain #converterfactories () factories } .
returns a { @link converter } for { @code type } to { @link requestbody } from the available { @linkplain #converterfactories () factories } except { @code skippast } .
returns a { @link converter } for { @link responsebody } to { @code type } from the available { @linkplain #converterfactories () factories } .
returns a { @link converter } for { @link responsebody } to { @code type } from the available { @linkplain #converterfactories () factories } except { @code skippast } .
returns a {
create an instance using {
create an instance using {
returns an instance which creates synchronous observables that {
create an instance using {
inspects the annotations on an interface method to construct a reusable service method that speaks http . this requires potentially - expensive reflection so it is best to build each service method only once and reuse it .
create an instance with default behavior which uses {
set the network round trip delay .
set the error response factory to be used when an error is triggered . this factory may only return responses for which {
the http error to be used when an error is triggered .
get the delay that should be used for delaying a response in accordance with configured behavior .
create a synthetic successful response with {
create a successful response from {
create a synthetic error response with an http status code of {
create an error response from {
 windos2000 | linliangyi2005





 *

 *
 *
analyzer
contextsegmentbuff
buff
  --- >  
 1 . buffthis . cursor 2 . mapresults 3 . mapcjdkresults
cjk
lexeme


lexemepathlexeme
lexemepathlexeme
lexeme

x

 ik analyzerdictionary dictionary  



hitdictsegment







/ * ( non - javadoc )
 head last - modifyetags 1min  1min









keycharsegment *
map 
segmentmap
/ * 


sets the { @link converter } used for converting the oauth 2 . 0 error parameters to an { @link oauth2error } .
sets the { @link converter } used for converting the { @link oauth2error } to a { @code map } representation of the oauth 2 . 0 error parameters .
clears the { @link csrftoken }
sets the maximum acceptable clock skew . the default is 60 seconds . the clock skew is used when validating the { @link jwtclaimnames#exp exp } and { @link jwtclaimnames#iat iat } claims .
sets the { @link converter converter&lt ; jwt collection&lt ; grantedauthority&gt ; &gt ; } to use . defaults to { @link jwtgrantedauthoritiesconverter } .
set to override the default http port to https port mappings of 80 : 443 and 8080 : 8443 . in a spring xml applicationcontext a definition would look something like this :
creates a directory for the user and a series of sub - directories . the root directory is the parent for the user directory . the sub - directories are confidential and shared . the role_user will be given read and write access to shared .
sets the algorithm to use . see <a href = https : // docs . oracle . com / javase / 8 / docs / technotes / guides / security / standardnames . html#secretkeyfactory > secretkeyfactory algorithms< / a >
if the callback passed to the handle method is an instance of passwordcallback the jaaspasswordcallbackhandler will call callback . setpassword ( authentication . getcredentials () . tostring () ) .
provides a save way of obtaining the httpmethod from a string . if the method is invalid returns null .
========================================================================================================
return the ldapuserdetails containing the user s information
========================================================================================================
encodes the rawpass using a messagedigest . if a salt is specified it will be merged with the password before encoding .
takes a previously encoded password and compares it with a rawpassword after mixing in the salt and encoding that value
perform version checks with specific min spring version
disable if springversion and springsecurityversion are the same to allow working with uber jars .
loads the spring version or null if it cannot be found .
attempts to load the client registration id from the current {
iterates through all <code > afterinvocationprovider< / code > s and ensures each can support the presented class . <p > if one or more providers cannot support the presented class <code > false< / code > is returned .
shortcut for invoking { @link #authenticationuserdetailsservice ( authenticationuserdetailsservice ) } with a { @link userdetailsbynameservicewrapper } .
specifies the regex to extract the principal from the certificate . if not specified the default expression from { @link subjectdnx509principalextractor } is used .
/ * ( non - javadoc )
========================================================================================================
gets a non - null and mutable map of {
========================================================================================================
sets up openid attribute exchange for openid s matching the specified pattern .
gets the {
creates an { @link regexbasedaxfetchlistfactory } using the attributes populated by { @link attributeexchangeconfigurer }
gets the { @link authenticationuserdetailsservice } that was configured or defaults to { @link userdetailsbynameservicewrapper } that uses a { @link userdetailsservice } looked up using { @link httpsecurity#getsharedobject ( class ) }
if available initializes the { @link defaultloginpagegeneratingfilter } shared object .
allows restricting access based upon the { @link httpservletrequest } using
adds csrf support . this is activated by default when using { @link websecurityconfigureradapter } s default constructor . you can disable it using :
configures oauth 2 . 0 client support .
configures oauth 2 . 0 resource server support .
configures channel security . in order for this configuration to be useful at least one mapping to a required channel must be provided .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
adds the filter at the location of the specified filter class . for example if you want the filter customfilter to be registered in the same position as { @link usernamepasswordauthenticationfilter } you can invoke :
allows configuring the { @link httpsecurity } to only be invoked when matching the provided spring mvc pattern . if more advanced configuration is necessary consider using { @link #requestmatchers () } or { @link #requestmatcher ( requestmatcher ) } .
if the { @link securityconfigurer } has already been specified get the original otherwise apply the new { @link securityconfigureradapter } .
maps a { @link list } of { @link pathpatternparserserverwebexchangematcher } instances .
performs an ldap compare operation of the value of an attribute for a particular directory entry .
composes an object from the attributes of the given dn .
performs a search using the supplied filter and returns the union of the values of the named attribute found in all entries matched by the search . note that one directory entry may have several values for the attribute . intended for role searches and similar scenarios .
performs a search using the supplied filter and returns the values of each named attribute found in all entries matched by the search . note that one directory entry may have several values for the attribute . intended for role searches and similar scenarios .
extracts string values for a specified attribute name and places them in the map representing the ldap record if a value is not of type string it will derive it s value from the { @link object#tostring () }
performs a search with the requirement that the search shall return a single directory entry and uses the supplied mapper to create the object from that entry . <p > ignores <tt > partialresultexception< / tt > if thrown for compatibility with active directory ( see { @link ldaptemplate#setignorepartialresultexception ( boolean ) } ) .
internal method extracted to avoid code duplication in ad search .
we need to make sure the search controls has the return object flag set to true in order for the search to return dircontextadapter instances .
========================================================================================================
locates the primary key ids specified in findnow adding aclimpl instances with stubaclparents to the acls map .
the main method . <p > warning : this implementation completely disregards the sids argument! every item in the cache is expected to contain all sids . if you have serious performance needs ( e . g . a very large number of sids per object identity ) you ll probably want to develop a custom { @link lookupstrategy } implementation instead . <p > the implementation works in batch sizes specified by { @link #batchsize } .
looks up a batch of <code > objectidentity< / code > s directly from the database . <p > the caller is responsible for optimization issues such as selecting the identities to lookup ensuring the cache doesn t contain them already and adding the returned elements to the cache etc . <p > this subclass is required to return fully valid <code > acl< / code > s including properly - configured parent acls .
the final phase of converting the <code > map< / code > of <code > aclimpl< / code > instances which contain <code > stubaclparent< / code > s into proper valid <code > aclimpl< / code > s with correct acl parents .
creates a particular implementation of { @link sid } depending on the arguments .
obtains the list of user roles based on the current user s jee roles . the { @link javax . servlet . http . httpservletrequest#isuserinrole ( string ) } method is called for each of the values in the { @code j2eemappableroles } set to determine if that role should be assigned to the user .
builds the authentication details object .
sets the factory that provides an { @link oauth2tokenvalidator } which is used by the { @link jwtdecoder } . the default is { @link oidcidtokenvalidator } .
sets the resolver that provides the expected { @link jwsalgorithm jws algorithm } used for the signature or mac on the { @link oidcidtoken id token } . the default resolves to { @link signaturealgorithm#rs256 rs256 } for all { @link clientregistration clients } .
will be called if no url attribute is supplied .
/ * ( non - javadoc )
adds the servlet - api integration filter if required
adds the jaas - api integration filter if required
parses the intercept - url elements to obtain the map used by channel security . this will be empty unless the <tt > requires - channel< / tt > attribute has been used on a url path .
/ * ( non - javadoc )
/ * ( non - javadoc )
invoked on the server - side . <p > the transmitted principal and credentials will be used to create an unauthenticated { @code authentication } instance for processing by the { @code authenticationmanager } .
loads the web . xml file using the configured <tt > resourceloader< / tt > and parses the role - name elements from it using these as the set of <tt > mappableattributes< / tt > .
========================================================================================================
creates a typeresolverbuilder that performs whitelisting .
/ * ( non - javadoc )
registers the springsecurityfilterchain
registers the provided { @link filter } s using default generated names { @link #getsecuritydispatchertypes () } and { @link #isasyncsecuritysupported () } .
registers the provided filter using the { @link #isasyncsecuritysupported () } and { @link #getsecuritydispatchertypes () } .
returns the { @link delegatingfilterproxy#getcontextattribute () } or null if the parent { @link applicationcontext } should be used . the default behavior is to use the parent { @link applicationcontext } .
get the {
loads the token data for the supplied series identifier .
registers the public static fields of type { @link permission } for a give class . <p > these permissions will be registered under the name of the field . see { @link basepermission } for an example .
extract any <a href = https : // tools . ietf . org / html / rfc6750#section - 1 . 2 target = _blank > bearer token< / a > from the request and attempt an authentication .
map the given list of string attributes one - to - one to spring security grantedauthorities .
map the given role one - on - one to a spring security grantedauthority optionally doing case conversion and / or adding a prefix .
if available initializes the { @link defaultloginpagegeneratingfilter } shared object .
{
setting this attribute will inject the provided invalidsessionstrategy into the {
allows specifying the {
gets the { @link invalidsessionstrategy } to use . if null and { @link #invalidsessionurl } is not null defaults to { @link simpleredirectinvalidsessionstrategy } .
gets the {
returns true if the {
gets the customized { @link sessionauthenticationstrategy } if { @link #sessionauthenticationstrategy ( sessionauthenticationstrategy ) } was specified . otherwise creates a default { @link sessionauthenticationstrategy } .
========================================================================================================
invokes the {
default behaviour for successful authentication . <ol > <li > sets the successful <tt > authentication< / tt > object on the { @link securitycontextholder } < / li > <li > informs the configured <tt > remembermeservices< / tt > of the successful login< / li > <li > fires an { @link interactiveauthenticationsuccessevent } via the configured <tt > applicationeventpublisher< / tt > < / li > <li > delegates additional behaviour to the { @link authenticationsuccesshandler } . < / li > < / ol >
default behaviour for unsuccessful authentication . <ol > <li > clears the {
populate the accessdeniedhandler on the { @link csrffilter }
creates the { @link accessdeniedhandler } from the result of { @link #getdefaultaccessdeniedhandler ( httpsecuritybuilder ) } and { @link #getinvalidsessionstrategy ( httpsecuritybuilder ) } . if { @link #getinvalidsessionstrategy ( httpsecuritybuilder ) } is non - null then a { @link delegatingaccessdeniedhandler } is used in combination with { @link invalidsessionaccessdeniedhandler } and the { @link #getdefaultaccessdeniedhandler ( httpsecuritybuilder ) } . otherwise only { @link #getdefaultaccessdeniedhandler ( httpsecuritybuilder ) } is used .
generates a secretkey .
generates a secretkey .
constructs a new cipher .
initializes the cipher for use .
initializes the cipher for use .
initializes the cipher for use .
initializes the cipher for use .
invokes the cipher to perform encryption or decryption ( depending on the initialized mode ) .
check whether all required properties have been set .
try to authenticate a pre - authenticated user with spring security if the user has not yet been authenticated .
determines if the current principal has changed . the default implementation tries
do the actual authentication for a pre - authenticated user .
puts the <code > authentication< / code > instance returned by the authentication manager into the secure context .
ensures the authentication object in the secure context is set to null when authentication fails . <p > caches the failure exception as a request attribute
makes sure {
adds the contentlengthtowrite to the total contentwritten size and checks to see if the response should be written .
delay the lookup of the { @link expressionparser } to prevent sec - 2136
<p > determines which http methods should be allowed . the default is to allow delete get head options patch post and put . < / p >
<p > determines if a percent % that is url encoded %25 should be allowed in the path or not . the default is not to allow this behavior because it is a frequent source of security exploits . < / p > <p > for example this can lead to exploits that involve double url encoding that lead to bypassing security constraints . < / p >
creates a mapping of the supplied authorities based on the case - conversion and prefix settings . the mapping will be one - to - one unless duplicates are produced during the conversion . if a default authority has been set this will also be assigned to each mapping .
specifies where users will go after authenticating successfully if they have not visited a secured page prior to authenticating or { @code alwaysuse } is true . this is a shortcut for calling { @link #successhandler ( authenticationsuccesshandler ) } .
specifies the url to validate the credentials .
the url to send users if authentication fails . this is a shortcut for invoking { @link #failurehandler ( authenticationfailurehandler ) } . the default is / login?error .
<p > specifies the url to send users to if login is required . if used with { @link websecurityconfigureradapter } a default login page will be generated when this attribute is not specified . < / p >
updates the default values for authentication .
updates the default values for access .
sets the repository of client registrations .
sets the repository for authorized client ( s ) .
sets the service for authorized client ( s ) .
allows registering multiple { @link requestmatcher } instances to a collection of { @link configattribute } instances
{
register escalate and configure the aspectj auto proxy creator based on the value of the
========================================================================================================
extension point to allow customized creation of the user s password from the attribute stored in the directory .
creates a grantedauthority from a role attribute . override to customize authority object creation . <p > the default implementation converts string attributes to roles making use of the <tt > roleprefix< / tt > and <tt > converttouppercase< / tt > properties . non - string attributes are ignored . < / p >
use this { @link jwt } validator
sets the { @link restoperations } used when requesting the json web key ( jwk ) set .
resolve the argument to inject into the controller parameter . @param parameter the method parameter . @param mavcontainer the model and view container . @param webrequest the web request . @param binderfactory the web data binder factory .
obtains the specified { @link annotation } on the specified { @link methodparameter } .
/ * ( non - javadoc )
<p > create a {
{
template implementation which locates the spring security cookie decodes it into a delimited array of tokens and submits it to subclasses for processing via the <tt > processautologincookie< / tt > method . <p > the returned username is then used to load the userdetails object for the user which in turn is used to create a valid authentication token .
locates the spring security remember me cookie in the request and returns its value . the cookie is searched for by name and also by matching the context path to the cookie path .
creates the final <tt > authentication< / tt > object returned from the <tt > autologin< / tt > method . <p > by default it will create a <tt > remembermeauthenticationtoken< / tt > instance .
decodes the cookie and splits it into a set of token strings using the : delimiter .
inverse operation of decodecookie .
{ @inheritdoc }
allows customization of whether a remember - me login has been requested . the default is to return true if <tt > alwaysremember< / tt > is set or the configured parameter name has been included in the request and is set to the value true .
sets a cancel cookie ( with maxage = 0 ) on the response to disable persistent logins .
sets the cookie on the response .
implementation of {
construct a { @link converter } for converting a pem - encoded pkcs#8 rsa private key into a { @link rsaprivatekey } .
construct a { @link converter } for converting a pem - encoded x . 509 rsa public key into a { @link rsapublickey } .
/ * ( non - javadoc )
executes the sql <tt > usersbyusernamequery< / tt > and returns a list of userdetails objects . there should normally only be one matching user .
loads authorities by executing the sql from <tt > authoritiesbyusernamequery< / tt > .
loads authorities by executing the sql from <tt > groupauthoritiesbyusernamequery< / tt > .
can be overridden to customize the creation of the final userdetailsobject which is returned by the <tt > loaduserbyusername< / tt > method .
/ * ( non - javadoc )
this concrete implementation simply polls all configured { @link accessdecisionvoter } s and grants access if any <code > accessdecisionvoter< / code > voted affirmatively . denies access only if there was a deny vote and no affirmative votes . <p > if every <code > accessdecisionvoter< / code > abstained from voting the decision will be based on the { @link #isallowifallabstaindecisions () } property ( defaults to false ) . < / p >
========================================================================================================
the error page to use . must begin with a / and is interpreted relative to the current context root .
resolve the argument to inject into the controller parameter .
resolve the expression from {
if present removes the artifactparametername and the corresponding value from the query string .
creates a { @link pattern } that can be passed into the constructor . this allows the { @link pattern } to be reused for every instance of { @link defaultserviceauthenticationdetails } .
gets the port from the casserviceurl ensuring to return the proper value if the default port is being used .
get the principals of the logged in user in this case the distinguished name .
/ * ( non - javadoc )
========================================================================================================
creates the default methodinterceptor which is a methodsecurityinterceptor using the following methods to construct it . <ul > <li > { @link #accessdecisionmanager () } < / li > <li > { @link #afterinvocationmanager () } < / li > <li > { @link #authenticationmanager () } < / li > <li > { @link #methodsecuritymetadatasource () } < / li > <li > { @link #runasmanager () } < / li >
/ * ( non - javadoc )
provide a custom { @link afterinvocationmanager } for the default implementation of { @link #methodsecurityinterceptor () } . the default is null if pre post is not enabled . otherwise it returns a { @link afterinvocationprovidermanager } .
allows subclasses to provide a custom { @link accessdecisionmanager } . the default is a { @link affirmativebased } with the following voters :
allows providing a custom { @link authenticationmanager } . the default is to use any authentication mechanisms registered by { @link #configure ( authenticationmanagerbuilder ) } . if { @link #configure ( authenticationmanagerbuilder ) } was not overridden then an { @link authenticationmanager } is attempted to be autowired by type .
provides the default { @link methodsecuritymetadatasource } that will be used . it creates a { @link delegatingmethodsecuritymetadatasource } based upon { @link #custommethodsecuritymetadatasource () } and the attributes on { @link enableglobalmethodsecurity } .
creates the { @link preinvocationauthorizationadvice } to be used . the default is { @link expressionbasedpreinvocationadvice } .
obtains the attributes from {
========================================================================================================
{
construct a { @link mappedjwtclaimsetconverter } overriding individual claim converters with the provided { @link map } of { @link converter } s .
{
returns true if the configured pattern ( and http - method ) match those of the supplied request .
method that is actually called by the filter chain . simply delegates to the { @link #invoke ( filterinvocation ) } method .
sets the map of exception types ( by name ) to urls .
adds a {
builds the {
requires the request to be passed in .
implementation of { @link serverlogoutsuccesshandler#onlogoutsuccess ( webfilterexchange authentication ) } . sets the status on the { @link webfilterexchange } .
validates the required properties are set . in addition if {
attempts to login the user given the authentication objects principal and credential
handles the logout by getting the security contexts for the destroyed session and invoking { @code logincontext . logout () } for any which contain a { @code jaasauthenticationtoken } .
publishes the { @link jaasauthenticationfailedevent } . can be overridden by subclasses for different functionality
factory method for creating a { @link delegatingsecuritycontextrunnable } .
========================================================================================================
set all authorities for this user from string values . it will create the necessary { @link grantedauthority } objects .
sets the provided value as a bearer token in a header with the name of {
builds a spring ldap - compliant provider url string i . e . a space - separated list of ldap servers with their base dns . as the base dn must be identical for all servers it needs to be supplied only once .
creates the user authority list from the values of the {
allows a custom environment properties to be used to create initial ldap context .
gets the state parameter from the {
determines if the current request matches the <code > defaultsavedrequest< / code > . <p > all url arguments are considered but not cookies locales headers or parameters .
indicates the url that the user agent used for this request .
use the following { @link converter } for manipulating the jwt s claim set
sets the { @link converter } used for converting the { @link oauth2userrequest } to a { @link requestentity } representation of the userinfo request .
/ * ( non - javadoc )
creates a { @link jwtdecoder } using the provided <a href = https : // openid . net / specs / openid - connect - core - 1_0 . html#issueridentifier > issuer< / a > by making an <a href = https : // openid . net / specs / openid - connect - discovery - 1_0 . html#providerconfigurationrequest > openid provider configuration request< / a > and using the values in the <a href = https : // openid . net / specs / openid - connect - discovery - 1_0 . html#providerconfigurationresponse > openid provider configuration response< / a > to initialize the { @link jwtdecoder } .
the aim of this method is to build the list of filters which have been defined by the namespace elements and attributes within the &lt ; http&gt ; configuration along with any custom - filter s linked to user - defined filter beans . <p > by the end of this method the default <tt > filterchainproxy< / tt > bean should have been registered and will have the map of filter chains defined with the universal match pattern mapped to the list of beans which have been parsed here .
creates the {
creates the internal authenticationmanager bean which uses either the externally registered ( global ) one as a parent or the bean specified by authentication - manager - ref .
{
invokes the base class { @link abstractauthorizetag#authorize () } method to decide if the body of the tag should be skipped or not .
default processing of the end tag returning eval_page .
populates the users that have been added .
allows adding a user to the { @link userdetailsmanager } that is being created . this method can be invoked multiple times to add multiple users .
allows adding a user to the { @link userdetailsmanager } that is being created . this method can be invoked multiple times to add multiple users .
the default {
checks the value of an xml attribute which represents a redirect url . if not empty or starting with $ ( potential placeholder ) or starting with # ( potential spel ) / or http it will raise an error .
computes the <code > response< / code > portion of a digest authentication header . both the server and user agent should compute the <code > response< / code > independently . provided as a static method to simplify the coding of user agents .
takes an array of <code > string< / code > s and for each element removes any instances of <code > removecharacter< / code > and splits the element based on the <code > delimiter< / code > . a <code > map< / code > is then generated with the left of the delimiter providing the key and the right of the delimiter providing the value . <p > will trim both the key and value before adding to the <code > map< / code > . < / p >
splits a <code > string< / code > at the first instance of the delimiter . <p > does not include the delimiter in the response . < / p >
========================================================================================================
cleans up the work of the <tt > abstractsecurityinterceptor< / tt > after the secure object invocation has been completed . this method should be invoked after the secure object invocation and before afterinvocation regardless of the secure object invocation returning successfully ( i . e . it should be done in a finally block ) .
completes the work of the <tt > abstractsecurityinterceptor< / tt > after the secure object invocation has been completed .
checks the current authentication token and passes it to the authenticationmanager if { @link org . springframework . security . core . authentication#isauthenticated () } returns false or the property <tt > alwaysreauthenticate< / tt > has been set to true .
helper method which generates an exception containing the passed reason and publishes an event to the application context . <p > always throws an exception .
obtains a user details service for use in remembermeservices etc . will return a caching version if available so should not be used for beans which need to separate the two .
creates and adds additional pkce parameters for use in the oauth 2 . 0 authorization and access token requests
========================================================================================================
overridden to provide proxying capabilities .
indicates if the request is elgible to process a service ticket . this method exists for readability .
indicates if the request is elgible to process a proxy ticket .
determines if a user is already authenticated .
indicates if the request is elgible to be processed as the proxy receptor .
determines if the { @link casauthenticationfilter } is configured to handle the proxy receptor requests .
executes the sql <tt > usersbyusernamequery< / tt > and returns a list of userdetails objects . there should normally only be one matching user .
find a unique {
copy of {
uses a {
creates the root object for expression evaluation .
filters the {
updates the cached jwk set from the configured url .
returns the first specified key id ( kid ) for a jwk matcher .
redirects the response to the supplied url . <p > if <tt > contextrelative< / tt > is set the redirect value will be the value after the request context path . note that this will result in the loss of protocol information ( http or https ) so will cause problems if a redirect is being performed to change to https for example .
/ * ( non - javadoc )
handles the creation of the final <tt > authentication< / tt > object which will be returned by the provider . <p > the default implementation just creates a new openidauthenticationtoken from the original but with the userdetails as the principal and including the authorities loaded by the userdetailsservice .
votes according to jsr 250 . <p > if no jsr - 250 attributes are found it will abstain otherwise it will grant or deny access based on the attributes that are found .
========================================================================================================
authentication has two phases . <ol > <li > the initial submission of the claimed openid . a redirect to the url returned from the consumer will be performed and null will be returned . < / li > <li > the redirection from the openid server to the return_to url once it has authenticated the user< / li > < / ol >
builds the <tt > return_to< / tt > url that will be sent to the openid service provider . by default returns the url of the current request .
reads the <tt > claimedidentityfieldname< / tt > from the submitted request .
performs url encoding with utf - 8
========================================================================================================
obtain the current active <code > authentication< / code >
returns the principal s name as obtained from the <code > securitycontextholder< / code > . properly handles both <code > string< / code > - based and <code > userdetails< / code > - based principals .
returns the <code > authentication< / code > ( which is a subclass of <code > principal< / code > ) or <code > null< / code > if unavailable .
gets the { @link ldapauthoritiespopulator } and defaults to { @link defaultldapauthoritiespopulator }
gets the { @link grantedauthoritiesmapper } and defaults to { @link simpleauthoritymapper } .
creates the { @link ldapauthenticator } to use
creates { @link passwordcomparisonauthenticator }
specifies the { @link org . springframework . security . crypto . password . passwordencoder } to be used when authenticating with password comparison .
sets the { @link converter } used for converting the { @link oauth2clientcredentialsgrantrequest } to a { @link requestentity } representation of the oauth 2 . 0 access token request .
{
========================================================================================================
sets the { @link converter } used for converting the oauth 2 . 0 access token response parameters to an { @link oauth2accesstokenresponse } .
sets the { @link converter } used for converting the { @link oauth2accesstokenresponse } to a { @code map } representation of the oauth 2 . 0 access token response parameters .
get a list of granted authorities based on the current user s websphere groups .
creates an instance of passwordpolicyresponsecontrol if the passed control is a response control of this type . attributes of the result are filled with the correct values ( e . g . error code ) .
========================================================================================================
gets the serviceurl . if the { @link authentication#getdetails () } is an instance of { @link serviceauthenticationdetails } then { @link serviceauthenticationdetails#getserviceurl () } is used . otherwise the { @link serviceproperties#getservice () } is used .
template method for retrieving the userdetails based on the assertion . default is to call configured userdetailsservice and pass the username . deployers can override this method and retrieve the user based on any criteria they desire .
sets the repository of client registrations .
sets the repository for authorized client ( s ) .
sets the service for authorized client ( s ) .
get s the url ( i . e . http : // localhost : 123456 )
return the websphere user name .
implementation of {
implementation of {
provides defaults for the {
modifies the { @link clientrequest#attributes () } to include the { @link oauth2authorizedclient } to be used for providing the bearer token .
modifies the { @link clientrequest#attributes () } to include the { @link clientregistration#getregistrationid () } to be used to look up the { @link oauth2authorizedclient } .
modifies the { @link clientrequest#attributes () } to include the { @link authentication } used to look up and save the { @link oauth2authorizedclient } . the value is defaulted in { @link servletoauth2authorizedclientexchangefilterfunction#defaultrequest () }
modifies the { @link clientrequest#attributes () } to include the { @link httpservletrequest } used to look up and save the { @link oauth2authorizedclient } . the value is defaulted in { @link servletoauth2authorizedclientexchangefilterfunction#defaultrequest () }
modifies the { @link clientrequest#attributes () } to include the { @link httpservletresponse } used to save the { @link oauth2authorizedclient } . the value is defaulted in { @link servletoauth2authorizedclientexchangefilterfunction#defaultrequest () }
determines whether the user has the given permission ( s ) on the domain object using the acl configuration . if the domain object is null returns false ( this can always be overridden using a null check in the expression itself ) .
========================================================================================================
calculates the digital signature to be put in the cookie . default value is md5 ( username : tokenexpirytime : password : key )
combine the individual byte arrays into one array .
extract a sub array of bytes out of the byte array .
map the given array of attributes to spring security grantedauthorities .
preprocess the given map to convert all the values to grantedauthority collections
convert the given value to a collection of granted authorities
convert the given value to a collection of granted authorities adding the result to the given result collection .
return the j2ee user name .
similar to { @link #build () } and { @link #getobject () } but checks the state to determine if { @link #build () } needs to be called first .
applies a { @link securityconfigureradapter } to this { @link securitybuilder } and invokes { @link securityconfigureradapter#setbuilder ( securitybuilder ) } .
applies a { @link securityconfigurer } to this { @link securitybuilder } overriding any { @link securityconfigurer } of the exact same class . note that object hierarchies are not considered .
sets an object that is shared by multiple { @link securityconfigurer } .
gets a shared object . note that object heirarchies are not considered .
adds { @link securityconfigurer } ensuring that it is allowed and invoking { @link securityconfigurer#init ( securitybuilder ) } immediately if necessary .
gets all the { @link securityconfigurer } instances by its class name or an empty list if not found . note that object hierarchies are not considered .
removes all the { @link securityconfigurer } instances by its class name or an empty list if not found . note that object hierarchies are not considered .
removes and returns the { @link securityconfigurer } by its class name or <code > null< / code > if not found . note that object hierarchies are not considered .
specifies the {
executes the build using the { @link securityconfigurer } s that have been applied using the following steps :
========================================================================================================
========================================================================================================
performs the redirect ( or forward ) to the login form url .
builds a url to redirect the supplied request to https . used to redirect the current request to https before doing a forward to the login page .
method that is suitable for user with traditional aspectj - code aspects .
creates the default { @link accessdecisionvoter } instances used if an { @link accessdecisionmanager } was not specified .
creates a string for specifying a user requires a role .
creates a string for specifying that a user requires one of many roles .
sets the regular expression which will by used to extract the user name from the certificate s subject dn . <p > it should contain a single group ; for example the default expression cn = ( . * ? ) ( ? : |$ ) matches the common name field . so cn = jimi hendrix ou = ... will give a user name of jimi hendrix . <p > the matches are case insensitive . so emailaddress = ( . ? ) will match emailaddress = jimi@hendrix . org cn = ... giving a user name jimi@hendrix . org
/ * ( non - javadoc )
locates the presented cookie data in the token repository using the series id . if the data compares successfully with that in the persistent store a new token is generated and stored with the same series . the corresponding cookie value is set on the response .
creates a new persistent login token with a new series number stores the data in the persistent token repository and adds the corresponding cookie to the response .
========================================================================================================
attempt to switch to another user . if the user does not exist or is not active return null .
attempt to exit from an already switched user .
create a switch user token that contains an additional <tt > grantedauthority< / tt > that contains the original <code > authentication< / code > object .
find the original <code > authentication< / code > object from the current user s granted authorities . a successfully switched user should have a <code > switchusergrantedauthority< / code > that contains the original source user <code > authentication< / code > object .
set the url to respond to exit user processing .
set the url to respond to switch user processing . this is a shortcut for { @link #setswitchusermatcher ( requestmatcher ) }
sets the url to which a user should be redirected if the switch fails . for example this might happen because the account they are attempting to switch to is invalid ( the user doesn t exist account is locked etc ) . <p > if not set an error message will be written to the response . <p > use { @link #setfailurehandler ( authenticationfailurehandler ) failurehandler } instead if you need more customized behaviour .
the public index page used for unauthenticated users .
the index page for an authenticated user . <p > this controller displays a list of all the contacts for which the current user has read or admin permissions . it makes a call to {
removes path parameters from each path segment in the supplied path and truncates sequences of multiple / characters to a single / .
creates the spring security filter chain
sets the { @code <securityconfigurer<filterchainproxy websecuritybuilder > } instances used to create the web configuration .
/ * ( non - javadoc )
create a { @link messagesecuritymetadatasource } that uses { @link messagematcher } mapped to spring expressions . each entry is considered in order and only the first match is used .
decode and validate the jwt from its compact claims representation format
{
iterates through all <code > accessdecisionvoter< / code > s and ensures each can support the presented class . <p > if one or more voters cannot support the presented class <code > false< / code > is returned .
{
make an authorization decision by considering all &lt ; authorize&gt ; tag attributes . the following are valid combinations of attributes : <ul > <li > access< / li > <li > url method< / li > < / ul > the above combinations are mutually exclusive and evaluated in the given order .
make an authorization decision based on a spring el expression . see the expression - based access control chapter in spring security for details on what expressions can be used .
allows the {
make an authorization decision based on the url and http method attributes . true is returned if the user is allowed to access the given url as defined .
/ * ------------- private helper methods -----------------
this method construct {
if available initializes the { @link defaultloginpagegeneratingfilter } shared object .
gets the {
creates the { @link remembermeservices } to use when none is provided . the result is either { @link persistenttokenrepository } ( if a { @link persistenttokenrepository } is specified else { @link tokenbasedremembermeservices } .
creates { @link tokenbasedremembermeservices }
creates { @link persistenttokenbasedremembermeservices }
gets the { @link userdetailsservice } to use . either the explicitly configure { @link userdetailsservice } from { @link #userdetailsservice ( userdetailsservice ) } or a shared object from { @link httpsecurity#getsharedobject ( class ) } .
sets the strategy used for converting from a {
========================================================================================================
specifies roles to use map from the { @link httpservletrequest } to the { @link userdetails } . if { @link httpservletrequest#isuserinrole ( string ) } returns true the role is added to the { @link userdetails } . this method is the equivalent of invoking { @link #mappableauthorities ( set ) } . multiple invocations of { @link #mappableauthorities ( string ... ) } will override previous invocations .
populates a { @link preauthenticatedauthenticationprovider } into { @link httpsecurity#authenticationprovider ( org . springframework . security . authentication . authenticationprovider ) } and a { @link http403forbiddenentrypoint } into { @link httpsecuritybuilder#setsharedobject ( class object ) }
gets the {
creates the { @link j2eebasedpreauthenticatedwebauthenticationdetailssource } to set on the { @link j2eepreauthenticatedprocessingfilter } . it is populated with a { @link simplemappableattributesretriever } .
/ * ( non - javadoc )
adds a { @link headerwriter } instance
clears all of the default headers from the response . after doing so one can add headers back . for example if you only want to use spring security s cache control you can use the following :
creates the { @link headerwriter }
gets the { @link headerwriter } instances and possibly initializes with the defaults .
registers a {
registers a {
registers a {
gets the order of a particular { @link filter } class taking into consideration superclasses .
extracts the authorities
gets the scopes from a {
allows providing a parent { @link authenticationmanager } that will be tried if this { @link authenticationmanager } was unable to attempt to authenticate the provided { @link authentication } .
add authentication based upon the custom { @link userdetailsservice } that is passed in . it then returns a { @link daoauthenticationconfigurer } to allow customization of the authentication .
captures the { @link userdetailsservice } from any { @link userdetailsawareconfigurer } .
generates a new token
does nothing if the {
displays the permission admin page for a particular contact .
displays the add permission page for a contact .
handles submission of the add permission form .
deletes a permission
prefixes role with defaultroleprefix if defaultroleprefix is non - null and if role does not already start with defaultroleprefix .
========================================================================================================
returns a new { @link builder } initialized with the authorization code .
returns a new { @link builder } initialized with the error code .
/ * ( non - javadoc )
create a reactiveuserdetailsserviceresourcefactorybean with the location of a resource that is a properties file in the format defined in { @link userdetailsresourcefactorybean } .
create a reactiveuserdetailsserviceresourcefactorybean with a resource that is a properties file in the format defined in { @link userdetailsresourcefactorybean } .
create a reactiveuserdetailsserviceresourcefactorybean with a string that is in the format defined in { @link userdetailsresourcefactorybean } .
this method will create { @link user } object . it will ensure successful object creation even if password key is null in serialized json because credentials may be removed from the { @link user } by invoking { @link user#erasecredentials () } . in that case there won t be any password key in serialized json .
creates the default {
if currently null creates a default { @link accessdecisionmanager } using { @link #createdefaultaccessdecisionmanager ( httpsecuritybuilder ) } . otherwise returns the { @link accessdecisionmanager } .
creates the { @link filtersecurityinterceptor }
create a userdetailsresourcefactorybean with the location of a resource that is a properties file in the format defined in { @link userdetailsresourcefactorybean } .
create a userdetailsresourcefactorybean with a resource that is a properties file in the format defined in { @link userdetailsresourcefactorybean } .
creates a userdetailsresourcefactorybean with a resource from the provided string
<p > creates a new instance with the specified pattern { @code simpmessagetype . subscribe } and { @link pathmatcher } .
<p > creates a new instance with the specified pattern { @code simpmessagetype . message } and { @link pathmatcher } .
returns the values for a specific attribute
returns the first attribute value for a specified attribute
if the callback passed to the handle method is an instance of namecallback the jaasnamecallbackhandler will call callback . setname ( authentication . getprincipal () . tostring () ) .
get the bytes of the string in utf - 8 encoded form .
decode the bytes in utf - 8 form into a string .
========================================================================================================
/ * ( non - javadoc )
gets the parameter names or null if not found .
finds the parameter name from the provided { @link annotation } s or null if it could not find it . the search is done by looking at the value property of the { @link #annotationclassestouse } .
handles the submission of the contact form creating a new instance if the username and email are valid .
/ * ( non - javadoc )
<p > sets the value for the pin - directive of the public - key - pins header . < / p >
<p > adds a list of sha256 hashed pins for the pin - directive of the public - key - pins header . < / p >
<p > sets the uri to which the browser should report pin validation failures . < / p >
will walk the method inheritance tree to find the most specific declaration applicable .
add configuration attributes for a secure method . method names can end or start with <code > * < / code > for matching multiple methods .
add configuration attributes for a secure method . mapped method names can end or start with <code > * < / code > for matching multiple methods .
adds configuration attributes for a specific method for example where the method has been matched using a pointcut expression . if a match already exists in the map for the method then the existing match will be retained so that if this method is called for a more general pointcut it will not override a more specific one which has already been added . <p > this method should only be called during initialization of the {
add configuration attributes for a secure method .
obtains the configuration attributes explicitly defined against this bean .
return if the given method name matches the mapped name . the default implementation checks for xxx and xxx matches .
gets the { @link portmapper } to use . if { @link #portmapper ( portmapper ) } was not invoked builds a { @link portmapperimpl } using the port mappings specified with { @link #http ( int ) } .
/ * ( non - javadoc )
/ * ( non - javadoc )
creates a { @link reactivejwtdecoder } using the provided <a href = https : // openid . net / specs / openid - connect - core - 1_0 . html#issueridentifier > issuer< / a > by making an <a href = https : // openid . net / specs / openid - connect - discovery - 1_0 . html#providerconfigurationrequest > openid provider configuration request< / a > and using the values in the <a href = https : // openid . net / specs / openid - connect - discovery - 1_0 . html#providerconfigurationresponse > openid provider configuration response< / a > to initialize the { @link reactivejwtdecoder } .
/ * ( non - javadoc )
creates an instance of { @link authorityreactiveauthorizationmanager } with the provided authority .
creates an instance of { @link authorityreactiveauthorizationmanager } with the provided authorities .
creates an instance of { @link authorityreactiveauthorizationmanager } with the provided authority .
gets the security context for the current request ( if available ) and returns it . <p > if the session is null the context object is null or the context object stored in the session is not an instance of {
maps any request .
maps a { @link list } of { @link org . springframework . security . web . util . matcher . antpathrequestmatcher } instances that do not care which { @link httpmethod } is used .
creates { @link mvcrequestmatcher } instances for the method and patterns passed in
maps a { @link list } of { @link org . springframework . security . web . util . matcher . regexrequestmatcher } instances .
associates a list of { @link requestmatcher } instances with the { @link abstractconfigattributerequestmatcherregistry }
/ * ( non - javadoc )
creates a logincontext using the configuration that was specified in {
========================================================================================================
allows subclasses to inspect the exception thrown by an attempt to bind with a particular dn . the default implementation just reports the failure to the debug logger .
returns the { @link requestentity } used for the userinfo request .
/ * ( non - javadoc )
/ * ( non - javadoc )
builds list of possible dns for the user worked out from the <tt > userdnpatterns< / tt > property .
sets the pattern which will be used to supply a dn for the user . the pattern should be the name relative to the root dn . the pattern argument { 0 } will contain the username . an example would be cn = { 0 } ou = people .
========================================================================================================
creates the mapping of { @link requestmatcher } to { @link collection } of { @link configattribute } instances
implementation of {
determines whether the user represented by the supplied <tt > authentication< / tt > object is allowed to invoke the supplied uri .
determines whether the user represented by the supplied <tt > authentication< / tt > object is allowed to invoke the supplied uri with the given . <p > note the default implementation of <tt > filterinvocationsecuritymetadatasource< / tt > disregards the <code > contextpath< / code > when evaluating which secure object metadata applies to a given request uri so generally the <code > contextpath< / code > is unimportant unless you are using a custom <code > filterinvocationsecuritymetadatasource< / code > .
/ * ( non - javadoc )
initialize the target url . it allows for the host to change based upon the cas . service . host system property . if the property is not set the default is localhost : 8443 .
========================================================================================================
if the parameter is available from the wrapped request then the request has been forwarded / included to a url with parameters either supplementing or overriding the saved request values . <p > in this case the value from the wrapped request should be used . <p > if the value from the wrapped request is null an attempt will be made to retrieve the parameter from the saved request .
read and returns the variable named by { @code principalenvironmentvariable } from the request .
in addition to the steps from the superclass the sessionregistry will be updated with the new session information .
this method should be used to enforce security on a <code > methodinvocation< / code > .
this is a public method .
========================================================================================================
performs post processing of an object . the default is to delegate to the { @link objectpostprocessor } .
calls the parent class {
removes temporary authentication - related data which may have been stored in the session during the authentication process .
attempts to locate the specified field on the class .
returns the value of a ( nested ) field on a bean . intended for testing .
========================================================================================================
constructs a new service url . the default implementation relies on the cas client to do the bulk of the work .
constructs the url for redirection to the cas server . default implementation relies on the cas client to do the bulk of the work .
set the role hierarchy and pre - calculate for every role the set of all reachable roles i . e . all roles lower in the hierarchy of every given role . pre - calculation is done for performance reasons ( reachable roles can then be calculated in o ( 1 ) time ) . during pre - calculation cycles in role hierarchy are detected and will cause a <tt > cycleinrolehierarchyexception< / tt > to be thrown .
sec - 863
sec - 863
parse input and build the map for the roles reachable in one step : the higher role will become a key that references a set of the reachable lower roles .
for every higher role from rolesreachableinonestepmap store all roles that are reachable from it in the map of roles reachable in one or more steps . ( or throw a cycleinrolehierarchyexception if a cycle in the role hierarchy definition is detected )
internal helpers
adds a { @link logouthandler } . the { @link securitycontextlogouthandler } is added as the last { @link logouthandler } by default .
sets the { @link logoutsuccesshandler } to use . if this is specified { @link #logoutsuccessurl ( string ) } is ignored .
sets a default { @link logoutsuccesshandler } to be used which prefers being invoked for the provided { @link requestmatcher } . if no { @link logoutsuccesshandler } is specified a { @link simpleurllogoutsuccesshandler } will be used . if any default { @link logoutsuccesshandler } instances are configured then a { @link delegatinglogoutsuccesshandler } will be used that defaults to a { @link simpleurllogoutsuccesshandler } .
gets the { @link logoutsuccesshandler } if not null otherwise creates a new { @link simpleurllogoutsuccesshandler } using the { @link #logoutsuccessurl ( string ) } .
creates the { @link logoutfilter } using the { @link logouthandler } instances the { @link #logoutsuccesshandler ( logoutsuccesshandler ) } and the { @link #logouturl ( string ) } .
========================================================================================================
========================================================================================================
calculates the hash of password ( and salt bytes if supplied ) and returns a base64 encoded concatenation of the hash and salt prefixed with { sha } ( or { ssha } if salt was used ) .
checks the validity of an unencoded password against an encoded one in the form { ssha } squqf8vj8eg2y1hpdh3bkqhckqbgjhqi .
returns the hash prefix or null if there isn t one .
demonstrates that { @link httpservletrequest#authenticate ( httpservletresponse ) } will send the user to the log in page configured within spring security if the user is not already authenticated .
demonstrates that you can authenticate with spring security using { @link httpservletrequest#login ( string string ) } .
demonstrates that invoking {
demonstrates spring security with {
always returns a 403 error code to the client .
========================================================================================================
checks whether a path is normalized ( doesn t contain path traversal sequences like . / / .. / or / . )
checks the filter list for possible errors and logs them
/ * checks for the common error of having a login page url protected by the security interceptor
registers a <code > throwablecauseextractor< / code > for the specified type . <i > can be used in subclasses overriding { @link #initextractormap () } . < / i >
returns an array containing the classes for which extractors are registered . the order of the classes is the order in which comparisons will occur for resolving a matching extractor .
determines the cause chain of the provided <code > throwable< / code > . the returned array contains all throwables extracted from the stacktrace using the registered { @link throwablecauseextractor extractors } . the elements of the array are ordered : the first element is the passed in throwable itself . the following elements appear in their order downward the stacktrace . <p > note : if no { @link throwablecauseextractor } is registered for this instance then the returned array will always only contain the passed in throwable .
extracts the cause of the given throwable using an appropriate extractor .
returns the first throwable from the passed in array that is assignable to the provided type . a returned instance is safe to be cast to the specified type . <p > if the passed in array is null or empty this method returns <code > null< / code > .
verifies that the provided throwable is a valid subclass of the provided type ( or of the type itself ) . if <code > expectdbasetype< / code > is <code > null< / code > no check will be performed . <p > can be used for verification purposes in implementations of { @link throwablecauseextractor extractors } .
return the imports to use if the {
register the default accessdecisionmanager . adds the special jsr 250 voter jsr - 250 is enabled and an expression voter if expression - based access control is enabled .
set the policy directive ( s ) to be used in the response header .
sets the { @link converter } used for converting the { @link oauth2authorizationcodegrantrequest } to a { @link requestentity } representation of the oauth 2 . 0 access token request .
sets additional exception to event mappings . these are automatically merged with the default exception to event mappings that <code > providermanager< / code > defines .
modifies the { @link clientrequest#attributes () } to include the { @link oauth2authorizedclient } to be used for providing the bearer token . example usage :
handles the httpsessionevent by publishing a { @link httpsessioncreatedevent } to the application appcontext .
handles the httpsessionevent by publishing a { @link httpsessiondestroyedevent } to the application appcontext .
converts an array of grantedauthority objects to a set .
constant time comparison to prevent against timing attacks .
returns the { @link requestentity } used for the access token request .
returns a { @link multivaluemap } of the form parameters used for the access token request body .
sets the base { @code uri } used for authorization requests .
sets the repository of client registrations .
performs the redirect or forward to the {
caches the {
the url which will be used as the failure destination .
authenticate the given preauthenticatedauthenticationtoken . <p > if the principal contained in the authentication object is null the request will be ignored to allow other providers to authenticate it .
sets a function used to resolve a map of the hidden inputs where the key is the name of the input and the value is the value of the input . typically this is used to resolve the csrf token .
introspect and validate the opaque <a href = https : // tools . ietf . org / html / rfc6750#section - 1 . 2 target = _blank > bearer token< / a > .
get a userdetails object based on the user name contained in the given token and the grantedauthorities as returned by the grantedauthoritiescontainer implementation as returned by the token . getdetails () method .
creates the final <tt > userdetails< / tt > object . can be overridden to customize the contents .
construct a failure { @link oauth2tokenvalidatorresult } with the provided detail
gets the { @link requestcache } to use . if one is defined using { @link #requestcache ( org . springframework . security . web . savedrequest . requestcache ) } then it is used . otherwise an attempt to find a { @link requestcache } shared object is made . if that fails an { @link httpsessionrequestcache } is used
========================================================================================================
obtains the full url the client used to make the request . <p > note that the server port will not be shown if it is the default server port for http or https ( 80 and 443 respectively ) .
obtains the web application - specific fragment of the request url . <p > under normal spec conditions
obtains the web application - specific fragment of the url .
decides if a url is absolute based on whether it contains a valid scheme name as defined in rfc 1738 .
iterates through the patterns stored in the map and returns the list of attributes defined for the first match . if no match is found returns an empty list .
========================================================================================================
returns a representation of the active bits in the presented mask with each active bit being denoted by the passed character . <p > inactive bits will be denoted by character { @link permission#reserved_off } .
converts the raw type from the database into the right java type . for most applications the raw type will be long for some applications it could be string .
converts to a {
<p > <b > warning : < / b > this method is considered unsafe for production and is only intended for sample applications . < / p > <p > creates a user and automatically encodes the provided password using { @code passwordencoderfactories . createdelegatingpasswordencoder () } . for example : < / p >
creates a { @link clientregistration . builder } using the provided <a href = https : // openid . net / specs / openid - connect - core - 1_0 . html#issueridentifier > issuer< / a > by making an <a href = https : // openid . net / specs / openid - connect - discovery - 1_0 . html#providerconfigurationrequest > openid provider configuration request< / a > and using the values in the <a href = https : // openid . net / specs / openid - connect - discovery - 1_0 . html#providerconfigurationresponse > openid provider configuration response< / a > to initialize the { @link clientregistration . builder } .
========================================================================================================
clears the { @link csrftoken }
shortcut to specify the { @link accessdeniedhandler } to be used is a specific error page
sets a default { @link accessdeniedhandler } to be used which prefers being invoked for the provided { @link requestmatcher } . if only a single default { @link accessdeniedhandler } is specified it will be what is used for the default { @link accessdeniedhandler } . if multiple default { @link accessdeniedhandler } instances are configured then a { @link requestmatcherdelegatingaccessdeniedhandler } will be used .
sets a default { @link authenticationentrypoint } to be used which prefers being invoked for the provided { @link requestmatcher } . if only a single default { @link authenticationentrypoint } is specified it will be what is used for the default { @link authenticationentrypoint } . if multiple default { @link authenticationentrypoint } instances are configured then a { @link delegatingauthenticationentrypoint } will be used .
gets the {
gets the {
gets the { @link requestcache } to use . if one is defined using { @link #requestcache ( org . springframework . security . web . savedrequest . requestcache ) } then it is used . otherwise an attempt to find a { @link requestcache } shared object is made . if that fails an { @link httpsessionrequestcache } is used
converts the supplied { @link map } of role name to implied role name ( s ) to a string representation understood by { @link rolehierarchyimpl#sethierarchy ( string ) } . the map key is the role name and the map value is a { @link list } of implied role name ( s ) .
========================================================================================================
creates a new row in acl_entry for every ace defined in the passed mutableacl object .
creates an entry in the acl_object_identity table for the passed objectidentity . the sid is also necessary as acl_object_identity has defined the sid column as non - null .
retrieves the primary key from { @code acl_class } creating a new row if needed and the { @code allowcreate } property is { @code true } .
retrieves the primary key from acl_sid creating a new row if needed and the allowcreate property is true .
retrieves the primary key from acl_sid creating a new row if needed and the allowcreate property is true .
retrieves the primary key from the acl_object_identity table for the passed objectidentity . unlike some other methods in this implementation this method will not create a row ( use { @link #createobjectidentity ( objectidentity sid ) } instead ) .
this implementation will simply delete all aces in the database and recreate them on each invocation of this method . a more comprehensive implementation might use dirty state checking or more likely use orm capabilities for create update and delete operations of {
updates an existing acl_object_identity row with new information presented in the passed mutableacl object . also will create an acl_sid entry if needed for the sid that owns the mutableacl .
stores the current request provided the configuration properties allow it .
creates a { @link delegatingsecuritycontextcallable } and with the given { @link callable } and { @link securitycontext } but if the securitycontext is null will defaults to the current { @link securitycontext } on the { @link securitycontextholder }
<p > sets the { @link logouthandler } s used when integrating with { @link httpservletrequest } with servlet 3 apis . specifically it will be used when { @link httpservletrequest#logout () } is invoked in order to log the user out . so long as the { @link logouthandler } s do not commit the { @link httpservletresponse } ( expected ) then the user is in charge of handling the response . < / p > <p > if the value is null ( default ) the default container behavior will be retained when invoking { @link httpservletrequest#logout () } . < / p >
creates a matcher that matches on the specific method and any of the provided patterns .
matches any exchange
creates a standard password - based bytes encryptor using 256 bit aes encryption with galois counter mode ( gcm ) . derives the secret key using pkcs #5 s pbkdf2 ( password - based key derivation function #2 ) . salts the password to prevent dictionary attacks against the key . the provided salt is expected to be hex - encoded ; it should be random and at least 8 bytes in length . also applies a random 16 byte initialization vector to ensure each encrypted message will be unique . requires java 6 .
creates a standard password - based bytes encryptor using 256 bit aes encryption . derives the secret key using pkcs #5 s pbkdf2 ( password - based key derivation function #2 ) . salts the password to prevent dictionary attacks against the key . the provided salt is expected to be hex - encoded ; it should be random and at least 8 bytes in length . also applies a random 16 byte initialization vector to ensure each encrypted message will be unique . requires java 6 .
creates a text encryptor that uses stronger password - based encryption . encrypted text is hex - encoded .
creates a text encryptor that uses standard password - based encryption . encrypted text is hex - encoded .
creates an encryptor for queryable text strings that uses standard password - based encryption . uses a 16 - byte all - zero initialization vector so encrypting the same data results in the same encryption result . this is done to allow encrypted data to be queried against . encrypted text is hex - encoded .
set the { @link securityexpressionhandler } to be used . if this is null then a { @link defaultwebsecurityexpressionhandler } will be used .
gets the {
this concrete implementation polls all configured { @link accessdecisionvoter } s for each { @link configattribute } and grants access if <b > only< / b > grant ( or abstain ) votes were received . <p > other voting implementations usually pass the entire list of <tt > configattribute< / tt > s to the <code > accessdecisionvoter< / code > . this implementation differs in that each <code > accessdecisionvoter< / code > knows only about a single <code > configattribute< / code > at a time . <p > if every <code > accessdecisionvoter< / code > abstained from voting the decision will be based on the { @link #isallowifallabstaindecisions () } property ( defaults to false ) .
creates a { @link delegatingpasswordencoder } with default mappings . additional mappings may be added and the encoding will be updated to conform with best practices . however due to the nature of { @link delegatingpasswordencoder } the updates should not impact users . the mappings current are :
collect error details from the provided parameters and format according to rfc 6750 specifically { @code error } { @code error_description } { @code error_uri } and { @scope scope } .
writes the x - frame - options header value overwritting any previous value .
<p > attempts to obtain and run as a jaas <code > subject< / code > using { @link #obtainsubject ( servletrequest ) } . < / p >
<p > obtains the <code > subject< / code > to run as or <code > null< / code > if no <code > subject< / code > is available . < / p > <p > the default implementation attempts to obtain the <code > subject< / code > from the <code > securitycontext< / code > s <code > authentication< / code > . if it is of type <code > jaasauthenticationtoken< / code > and is authenticated the <code > subject< / code > is returned from it . otherwise <code > null< / code > is returned . < / p >
specify the { @link csrftokenrepository } to use . the default is an { @link httpsessioncsrftokenrepository } wrapped by { @link lazycsrftokenrepository } .
specify the { @link requestmatcher } to use for determining when csrf should be applied . the default is to ignore get head trace options and process all other requests .
<p > allows specifying { @link httpservletrequest } that should not use csrf protection even if they match the { @link #requirecsrfprotectionmatcher ( requestmatcher ) } . < / p >
<p > allows specifying { @link httpservletrequest } s that should not use csrf protection even if they match the { @link #requirecsrfprotectionmatcher ( requestmatcher ) } . < / p >
gets the final { @link requestmatcher } to use by combining the { @link #requirecsrfprotectionmatcher ( requestmatcher ) } and any { @link #ignore () } .
gets the default { @link accessdeniedhandler } from the { @link exceptionhandlingconfigurer#getaccessdeniedhandler () } or create a { @link accessdeniedhandlerimpl } if not available .
gets the default { @link invalidsessionstrategy } from the { @link sessionmanagementconfigurer#getinvalidsessionstrategy () } or null if not available .
creates the { @link accessdeniedhandler } from the result of { @link #getdefaultaccessdeniedhandler ( httpsecuritybuilder ) } and { @link #getinvalidsessionstrategy ( httpsecuritybuilder ) } . if { @link #getinvalidsessionstrategy ( httpsecuritybuilder ) } is non - null then a { @link delegatingaccessdeniedhandler } is used in combination with { @link invalidsessionaccessdeniedhandler } and the { @link #getdefaultaccessdeniedhandler ( httpsecuritybuilder ) } . otherwise only { @link #getdefaultaccessdeniedhandler ( httpsecuritybuilder ) } is used .
invokes the configured {
builds the target url according to the logic defined in the main class javadoc
builds the target url according to the logic defined in the main class javadoc .
supplies the default target url that will be used if no saved request is found in the session or the { @code alwaysusedefaulttargeturl } property is set to true . if not set defaults to { @code / } . it will be treated as relative to the web - app s context path and should include the leading <code > / < / code > . alternatively inclusion of a scheme name ( such as http : // or https : // ) as the prefix will denote a fully - qualified url and this is also supported .
if this property is set the current request will be checked for this a parameter with this name and the value used as the target url if present .
executes recursive sql as needed to build a full directory hierarchy of objects
read and returns the header named by { @code principalrequestheader } from the request .
========================================================================================================
assembles the distinguished name that should be used the given username .
returns a new { @link builder } initialized with the values from the provided { @code authorizationrequest } .
{
creates the { @link httpsecurity } or returns the current instance
gets the { @link authenticationmanager } to use . the default strategy is if { @link #configure ( authenticationmanagerbuilder ) } method is overridden to use the { @link authenticationmanagerbuilder } that was passed in . otherwise autowire the { @link authenticationmanager } by type .
override this method to expose a { @link userdetailsservice } created from { @link #configure ( authenticationmanagerbuilder ) } as a bean . in general only the following override should be done of this method :
allows modifying and accessing the { @link userdetailsservice } from { @link #userdetailsservicebean () } without interacting with the { @link applicationcontext } . developers should override this method when changing the instance of { @link #userdetailsservicebean () } .
creates the shared objects
========================================================================================================
loops through the login . config . url . 1 login . config . url . 2 properties looking for the login configuration . if it is not set it will be set to the last available login . config . url . x property .
publishes the { @link jaasauthenticationfailedevent } . can be overridden by subclasses for different functionality
invokes the internal template methods to create { @code standardevaluationcontext } and { @code securityexpressionroot } objects .
/ * ( non - javadoc )
/ * ( non - javadoc )
resolveserviceipaddress () .
resolveserviceipaddress () .
called every time a http invocation is made . <p > simply allows the parent to setup the connection and then adds an <code > authorization< / code > http header property that will be used for basic authentication . < / p > <p > the <code > securitycontextholder< / code > is used to obtain the relevant principal and credentials . < / p >
gets the {
/ * ( non - javadoc )
/ * ( non - javadoc )
========================================================================================================
sets the { @link oauth2userservice } used when requesting the user info resource .
formats a specified date to http format . if local format is not <code > null< / code > it s used instead .
gets the current date in http format .
parses date with given formatters .
tries to parse the given date as an http date . if local format list is not <code > null< / code > it s used instead .
updates cache .
generates a <code > methodinvocation< / code > for specified <code > methodname< / code > on the passed object using the <code > args< / code > to locate the method .
generates a <code > methodinvocation< / code > for the specified <code > methodname< / code > on the passed class .
generates a <code > methodinvocation< / code > for specified <code > methodname< / code > on the passed class using the <code > args< / code > to locate the method .
========================================================================================================
provided so that subclasses may configure what is put into the authentication request s details property .
maps a { @link list } of { @link simpdestinationmessagematcher } instances .
maps a { @link list } of { @link simpdestinationmessagematcher } instances . if no destination is found on the message then the matcher returns false .
the { @link pathmatcher } to be used with the { @link messagesecuritymetadatasourceregistry#simpdestmatchers ( string ... ) } . the default is to use the default constructor of { @link antpathmatcher } .
maps a { @link list } of { @link messagematcher } instances to a security expression .
the { @link securityexpressionhandler } to be used . the default is to use { @link defaultmessagesecurityexpressionhandler } .
allows subclasses to create creating a { @link messagesecuritymetadatasource } .
creates a successful { @link authentication } object . <p > protected so subclasses can override . < / p > <p > subclasses will usually store the original credentials the user supplied ( not salted or encoded passwords ) in the returned <code > authentication< / code > object . < / p >
allows easily changing the realm but leaving the remaining defaults in place . if { @link #authenticationentrypoint ( authenticationentrypoint ) } has been invoked invoking this method will result in an error .
populates the { @link datasource } to be used . this is the only required attribute .
an sql statement to query user s group authorities given a username . for example :
the keystore must not be null and must be a valid file . will set the keystore file on the underlying {
========================================================================================================
sets the passwordencoder instance to be used to encode and validate passwords . if not set the password will be compared using { @link passwordencoderfactories#createdelegatingpasswordencoder () }
authenticate the <code > subject< / code > ( phase two ) by adding the spring security <code > authentication< / code > to the <code > subject< / code > s principals .
initialize this <code > loginmodule< / code > . ignores the callback handler since the code establishing the <code > logincontext< / code > likely won t provide one that understands spring security . also ignores the <code > sharedstate< / code > and <code > options< / code > parameters since none are recognized .
authenticate the <code > subject< / code > ( phase one ) by extracting the spring security <code > authentication< / code > from the current <code > securitycontext< / code > .
log out the <code > subject< / code > .
create a userdetailsmanagerresourcefactorybean with the location of a resource that is a properties file in the format defined in { @link userdetailsresourcefactorybean } .
create a userdetailsmanagerresourcefactorybean with a resource that is a properties file in the format defined in { @link userdetailsresourcefactorybean } .
create a userdetailsmanagerresourcefactorybean with a string that is in the format defined in { @link userdetailsresourcefactorybean } .
========================================================================================================
delegates to the { @link permissiongrantingstrategy } .
see {
get the security name for the given subject .
get the websphere group names for the given security name .
changes the password for the current user . the username is obtained from the security context .
creates a dn from a group name .
sets the name of the multi - valued attribute which holds the dns of users who are members of a group . <p > usually this will be <tt > uniquemember< / tt > ( the default value ) or <tt > member< / tt > . < / p >
========================================================================================================
========================================================================================================
in addition to the steps from the superclass the sessionregistry will be updated with the new session information .
allows subclasses to customise behaviour when too many sessions are detected .
collect error details from the provided parameters and format according to rfc 6750 specifically { @code error } { @code error_description } { @code error_uri } and { @scope scope } .
decode and validate the <a href = https : // tools . ietf . org / html / rfc6750#section - 1 . 2 target = _blank > bearer token< / a > .
returns a { @link multivaluemap } of the form parameters used for the access token request body .
attempts to authenticate the passed { @link authentication } object . <p > the list of { @link authenticationprovider } s will be successively tried until an <code > authenticationprovider< / code > indicates it is capable of authenticating the type of <code > authentication< / code > object passed . authentication will then be attempted with that <code > authenticationprovider< / code > . <p > if more than one <code > authenticationprovider< / code > supports the passed <code > authentication< / code > object the first one able to successfully authenticate the <code > authentication< / code > object determines the <code > result< / code > overriding any possible <code > authenticationexception< / code > thrown by earlier supporting <code > authenticationprovider< / code > s . on successful authentication no subsequent <code > authenticationprovider< / code > s will be tried . if authentication was not successful by any supporting <code > authenticationprovider< / code > the last thrown <code > authenticationexception< / code > will be rethrown .
copies the authentication details from a source authentication object to a destination one provided the latter does not already have one set .
called when a user is newly authenticated . <p > if a session already exists and matches the session id from the client a new session will be created and the session attributes copied to it ( if {
called when the session has been changed and the old attributes have been migrated to the new session . only called if a session existed to start with . allows subclasses to plug in additional behaviour . * <p > the default implementation of this method publishes a { @link sessionfixationprotectionevent } to notify the application that the session id has changed . if you override this method and still wish these events to be published you should call { @code super . onsessionchange () } within your overriding method .
calls the <tt > rolehierarchy< / tt > to obtain the complete set of user authorities .
returns the first filter chain matching the supplied url .
convenience method mainly for testing .
========================================================================================================
allows test cases to override where application context obtained from .
creates the final { @code authentication } object which will be returned from the { @code authenticate } method .
========================================================================================================
register escalate and configure the aspectj auto proxy creator based on the value of the
========================================================================================================
obtains the part of a dn relative to a supplied base context . <p > if the dn is cn = bob ou = people dc = springframework dc = org and the base context name is ou = people dc = springframework dc = org it would return cn = bob . < / p >
gets the full dn of a name by prepending the name of the context it is relative to . if the name already contains the base name it is returned unaltered .
sets the { @link converter converter&lt ; jwt flux&lt ; grantedauthority&gt ; &gt ; } to use . defaults to a reactive { @link jwtgrantedauthoritiesconverter } .
{
set session attributes .
set a session attribute .
enable cross - site request forgery ( csrf ) support when using form authentication by including the csrf value of the input field with the specified name . for example if the login page looks like this : <pre > &lt ; html&gt ; &lt ; head&gt ; &lt ; title&gt ; login&lt ; / title&gt ; &lt ; / head&gt ; &lt ; body&gt ; &lt ; form action = &quot ; j_spring_security_check_with_csrf&quot ; method = &quot ; post&quot ; &gt ; &lt ; table&gt ; &lt ; tr&gt ; &lt ; td&gt ; user : &amp ; nbsp ; &lt ; / td&gt ; &lt ; td&gt ; &lt ; input type = &quot ; text&quot ; name = &quot ; j_username&quot ; &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; tr&gt ; &lt ; td&gt ; password : &lt ; / td&gt ; &lt ; td&gt ; &lt ; input type = &quot ; password&quot ; name = &quot ; j_password&quot ; &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; tr&gt ; &lt ; td colspan = &quot ; 2&quot ; &gt ; &lt ; input name = &quot ; submit&quot ; type = &quot ; submit&quot ; / &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; / table&gt ; &lt ; input type = &quot ; hidden&quot ; name = &quot ; _csrf&quot ; value = &quot ; 8adf2ea1 - b246 - 40aa - 8e13 - a85fb7914341&quot ; / &gt ; &lt ; / form&gt ; &lt ; / body&gt ; &lt ; / html&gt ; < / pre > the csrf field name is called <code > _csrf< / code > . <p / > <b > important : < / b > when enabling csrf support then rest assured <b > must always< / b > make an additional request to the server in order to be able to include in the csrf value which will slow down the tests .
include additional field when using form authentication by including input field value with the specified name . for example if the login page looks like this : <pre > &lt ; html&gt ; &lt ; head&gt ; &lt ; title&gt ; login&lt ; / title&gt ; &lt ; / head&gt ; &lt ; body&gt ; &lt ; form action = &quot ; j_spring_security_check_with_csrf&quot ; method = &quot ; post&quot ; &gt ; &lt ; table&gt ; &lt ; tr&gt ; &lt ; td&gt ; user : &amp ; nbsp ; &lt ; / td&gt ; &lt ; td&gt ; &lt ; input type = &quot ; text&quot ; name = &quot ; j_username&quot ; &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; tr&gt ; &lt ; td&gt ; password : &lt ; / td&gt ; &lt ; td&gt ; &lt ; input type = &quot ; password&quot ; name = &quot ; j_password&quot ; &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; tr&gt ; &lt ; td colspan = &quot ; 2&quot ; &gt ; &lt ; input name = &quot ; submit&quot ; type = &quot ; submit&quot ; / &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; / table&gt ; &lt ; input type = &quot ; hidden&quot ; name = &quot ; something&quot ; value = &quot ; 8adf2ea1 - b246 - 40aa - 8e13 - a85fb7914341&quot ; / &gt ; &lt ; / form&gt ; &lt ; / body&gt ; &lt ; / html&gt ; < / pre > and you d like to include the field named <code > something< / code > as an additional form parameter in the request you can do like this :
include multiple additional fields when using form authentication by including input field values with the specified name . this is the same as { @link #withadditionalfield ( string ) } but for multiple fields .
enable cross - site request forgery ( csrf ) support when using form authentication by automatically trying to find the name and value of the csrf input field . for example if the login page looks like this : <pre > &lt ; html&gt ; &lt ; head&gt ; &lt ; title&gt ; login&lt ; / title&gt ; &lt ; / head&gt ; &lt ; body&gt ; &lt ; form action = &quot ; j_spring_security_check_with_csrf&quot ; method = &quot ; post&quot ; &gt ; &lt ; table&gt ; &lt ; tr&gt ; &lt ; td&gt ; user : &amp ; nbsp ; &lt ; / td&gt ; &lt ; td&gt ; &lt ; input type = &quot ; text&quot ; name = &quot ; j_username&quot ; &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; tr&gt ; &lt ; td&gt ; password : &lt ; / td&gt ; &lt ; td&gt ; &lt ; input type = &quot ; password&quot ; name = &quot ; j_password&quot ; &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; tr&gt ; &lt ; td colspan = &quot ; 2&quot ; &gt ; &lt ; input name = &quot ; submit&quot ; type = &quot ; submit&quot ; / &gt ; &lt ; / td&gt ; &lt ; / tr&gt ; &lt ; / table&gt ; &lt ; input type = &quot ; hidden&quot ; name = &quot ; _csrf&quot ; value = &quot ; 8adf2ea1 - b246 - 40aa - 8e13 - a85fb7914341&quot ; / &gt ; &lt ; / form&gt ; &lt ; / body&gt ; &lt ; / html&gt ; < / pre > the csrf field name is called <code > _csrf< / code > and rest assured will autodetect its name since the field name is the only <code > hidden< / code > field on this page . if auto - detection fails you can consider using { @link #withcsrffieldname ( string ) } . <p / > <b > important : < / b > when enabling csrf support then rest assured <b > must always< / b > make an additional request to the server in order to be able to include in the csrf value which will slow down the tests .
enables logging with the supplied log detail of the request made to authenticate using form authentication using the specified { @link logconfig } . both the request and the response is logged .
use preemptive http basic authentication . this means that the authentication details are sent in the request header regardless if the server has challenged for authentication or not .
add default filters that will be applied to each request .
add default filters to apply to each request .
sets the default filters to apply to each request .
sets the default filters to apply to each request .
set a object mapper that ll be used when serializing and deserializing java objects to and from it s document representation ( xml json etc ) .
create a list of arguments that can be used to create parts of the path in a body / content expression . this is useful in situations where you have e . g . pre - defined variables that constitutes the key . for example : <pre > string somesubpath = else ; int index = 1 ; when () . get () . then () . body ( something . %s [ %d ] withargs ( somesubpath index ) equalto ( some value )) . .. < / pre > <p / > or if you have complex root paths and don t wish to duplicate the path for small variations : <pre > get ( / x ) . then () . assertthat () . root ( filters . filterconfig [ %d ] . filterconfiggroups . find { it . name == gold } . includes ) . body ( withargs ( 0 ) hasitem ( first )) . body ( withargs ( 1 ) hasitem ( second )) . .. < / pre > <p / > the key and arguments follows the standard <a href = http : // download . oracle . com / javase / 1 5 . 0 / docs / api / java / util / formatter . html#syntax > formatting syntax< / a > of java .
perform a get request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a get request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a post request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a post request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a put request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a delete request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a delete request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a head request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a head request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a patch request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a patch request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a options request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a options request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a request to a <code > uri< / code > .
perform a request to a <code > url< / code > .
perform a custom http request to a <code > uri< / code > .
perform a custom http request to a <code > url< / code > .
create a http basic authentication scheme .
create a ntlm authentication scheme .
use form authentication . rest assured will try to parse the response login page and determine and try find the action username and password input field automatically . <p > note that the request will be much faster if you also supply a form auth configuration . < / p >
use form authentication with the supplied configuration .
sets a certificate to be used for ssl authentication . see { @link java . lang . class#getresource ( string ) } for how to get a url from a resource on the classpath . <p > uses ssl settings defined in { @link sslconfig } . < / p >
sets a certificate to be used for ssl authentication . see { @link class#getresource ( string ) } for how to get a url from a resource on the classpath . <p / >
sets a certificate to be used for ssl authentication . see { @link class#getresource ( string ) } for how to get a url from a resource on the classpath . <p / >
excerpt from the httpbuilder docs : <br > oauth sign the request . note that this currently does not wait for a www - authenticate challenge before sending the the oauth header . all requests to all domains will be signed for this instance . this assumes you ve already generated an accesstoken and secrettoken for the site you re targeting . for more information on how to achieve this see the <a href = https : // github . com / mttkay / signpost / blob / master / docs / gettingstarted . md#using - signpost > signpost documentation< / a > .
oauth sign the request . note that this currently does not wait for a www - authenticate challenge before sending the the oauth header . all requests to all domains will be signed for this instance .
oauth sign the request . note that this currently does not wait for a www - authenticate challenge before sending the the oauth header . all requests to all domains will be signed for this instance .
resets the {
use relaxed http validation with a specific protocol . this means that you ll trust all hosts regardless if the ssl certificate is invalid . by using this method you don t need to specify a keystore ( see { @link #keystore ( string string ) } or trust store ( see { @link #truststore ( java . security . keystore ) } . <p > this is just a shortcut for : < / p > <pre > restassured . config = restassured . config () . sslconfig ( sslconfig () . relaxedhttpsvalidation ( &lt ; protocol&gt ; )) ; < / pre >
enable logging of both the request and the response if rest assureds test validation fails with the specified log detail . <p / > <p > this is just a shortcut for : < / p > <pre > restassured . config = restassured . config () . logconfig ( logconfig () . enableloggingofrequestandresponseifvalidationfails ( logdetail )) ; < / pre >
apply a keystore for all requests <pre > given () . keystore ( / truststore_javanet . jks test1234 ) . .. < / pre > < / p > <p > note that this is just a shortcut for : < / p > <pre > restassured . config = restassured . config () . sslconfig ( sslconfig () . keystore ( pathtojks password )) ; < / pre >
the following documentation is taken from <a href = http builder > https : // github . com / jgritman / httpbuilder / wiki / ssl< / a > : <p > <h1 > ssl configuration< / h1 > <p / > ssl should for the most part just work . there are a few situations where it is not completely intuitive . you can follow the example below or see httpclient s sslsocketfactory documentation for more information . <p / > <h1 > sslpeerunverifiedexception< / h1 > <p / > if you can t connect to an ssl website it is likely because the certificate chain is not trusted . this is an apache httpclient issue but explained here for convenience . to correct the untrusted certificate you need to import a certificate into an ssl truststore . <p / > first export a certificate from the website using your browser . for example if you go to https : // dev . java . net in firefox you will probably get a warning in your browser . choose add exception get certificate view details tab . choose a certificate in the chain and export it as a pem file . you can view the details of the exported certificate like so : <pre > $ keytool - printcert - file equifaxsecureglobalebusinessca - 1 . crt owner : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us issuer : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us serial number : 1 valid from : mon jun 21 00 : 00 : 00 edt 1999 until : sun jun 21 00 : 00 : 00 edt 2020 certificate fingerprints : md5 : 8f : 5d : 77 : 06 : 27 : c4 : 98 : 3c : 5b : 93 : 78 : e7 : d7 : 7d : 9b : cc sha1 : 7e : 78 : 4a : 10 : 1c : 82 : 65 : cc : 2d : e1 : f1 : 6d : 47 : b4 : 40 : ca : d9 : 0a : 19 : 45 signature algorithm name : md5withrsa version : 3 .... < / pre > now import that into a java keystore file : <pre > $ keytool - importcert - alias equifax - ca - file equifaxsecureglobalebusinessca - 1 . crt - keystore truststore_javanet . jks - storepass test1234 owner : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us issuer : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us serial number : 1 valid from : mon jun 21 00 : 00 : 00 edt 1999 until : sun jun 21 00 : 00 : 00 edt 2020 certificate fingerprints : md5 : 8f : 5d : 77 : 06 : 27 : c4 : 98 : 3c : 5b : 93 : 78 : e7 : d7 : 7d : 9b : cc sha1 : 7e : 78 : 4a : 10 : 1c : 82 : 65 : cc : 2d : e1 : f1 : 6d : 47 : b4 : 40 : ca : d9 : 0a : 19 : 45 signature algorithm name : md5withrsa version : 3 ... trust this certificate? [ no ] : yes certificate was added to keystore < / pre > now you want to use this truststore in your client : <pre > restassured . truststure ( / truststore_javanet . jks test1234 ) ; < / pre > or <pre > given () . truststore ( / truststore_javanet . jks test1234 ) . .. < / pre > < / p > <p > note that this is just a shortcut for : < / p > <pre > restassured . config = restassured . config () . sslconfig ( sslconfig () . truststore ( pathtojks password )) ; < / pre >
specify a trust store that ll be used for https requests . a trust store is a { @link java . security . keystore } that has been loaded with the password . if you wish that rest assured loads the keystore store and applies the password ( thus making it a trust store ) please see some of the <code > keystore< / code > methods such as { @link #keystore ( java . io . file string ) } .
use a keystore located on the file - system . see { @link #keystore ( string string ) } for more details . * <p > note that this is just a shortcut for : < / p > <pre > restassured . config = restassured . config () . sslconfig ( sslconfig () . keystore ( pathtojks password )) ; < / pre >
use a trust store located on the file - system . see { @link #truststore ( string string ) } for more details . * <p > note that this is just a shortcut for : < / p > <pre > restassured . config = restassured . config () . sslconfig ( sslconfig () . truststore ( pathtojks password )) ; < / pre >
instruct rest assured to connect to a proxy on the specified host on port <code > 8888< / code > .
instruct rest assured to connect to a proxy on the specified port on localhost with a specific scheme .
instruct rest assured to connect to a proxy using a uri .
prints the response to the print stream
set the redirect config .
specify the default charset to use for the specific content - type if it s not specified in the content - type header explicitly
specify the default charset to use for the specific content - type if it s not specified in the content - type header explicitly
specify the default charset to use for the specific content - type if it s not specified in the content - type header explicitly
specify the default charset for the body / content in the request specification
specify the default charset for query parameters
tells whether rest assured should automatically append the content charset to the content - type header if not defined explicitly . <p > note that this does not affect multipart form data . < / p > <p > default is <code > true< / code > . < / p >
encodes the content ( body ) of the request specified with the given <code > contenttype< / code > with the same encoder used by the supplied <code > encoder< / code > . this is useful only if rest assured picks the wrong encoder ( or can t recognize it ) for the given content - type .
creates an object mapper configuration that uses the specified object mapper as default .
specify a custom gson object mapper factory .
specify a custom jackson 1 . 0 object mapper factory .
specify a custom jackson 1 . 0 object mapper factory .
specify a custom jaxb object mapper factory .
set the log config .
set the session config .
set the object mapper config .
set the json config .
set the xml config .
set the encoder config
set the header config
set the async config
set the mockmvc config
set the multi - part config
set the parameter config
set the matcher config
decode / unescape a portion of a url to use with the query part ensure { @code plusasblank } is true .
/ * if body expectations are defined we need to return a new response otherwise the stream has been closed due to the logging .
configure the certificateauthsettings to use strict host name verification ( this is the default behavior ) .
configure the certificateauthsettings to allow all host names .
configure the certificateauthsettings to use the provided { @link x509hostnameverifier } instance .
specify features that will be used when parsing xml .
set a value of a feature flag .
specify properties that will be used when parsing xml .
set a value of a property .
disables external dtd loading . <p > this is a shortcut for doing : <br > <pre > setfeature ( http : // apache . org / xml / features / nonvalidating / load - external - dtd false ) ; < / pre > < / p >
creates an json path configuration that uses the specified object de - serializer as default .
specify declared namespaces that will be used when parsing xml .
declares a namespace .
<p > convenience method to perform an http get . it will use the httpbuilder s { @link #gethandler () registered response handlers } to handle success or failure status codes . by default the <code > success< / code > response handler will attempt to parse the data and simply return the parsed object . < / p > <p > <p > <strong > note : < / strong > if using the { @link #defaultsuccesshandler ( httpresponsedecorator object ) default <code > success< / code > response handler } be sure to read the caveat regarding streaming response data . < / p >
<p > convenience method to perform an http get . the response closure will be called only on a successful response . < / p > <p > <p > a failed response ( i . e . any http status code > 399 ) will be handled by the registered failure handler . the { @link #defaultfailurehandler ( httpresponsedecorator ) default failure handler } throws an { @link httpresponseexception } . < / p >
<p > convenience method to perform an http post . it will use the httpbuilder s { @link #gethandler () registered response handlers } to handle success or failure status codes . by default the <code > success< / code > response handler will attempt to parse the data and simply return the parsed object . < / p > <p > <p > <strong > note : < / strong > if using the { @link #defaultsuccesshandler ( httpresponsedecorator object ) default <code > success< / code > response handler } be sure to read the caveat regarding streaming response data . < / p >
<p > convenience method to perform an http patch . it will use the httpbuilder s { @link #gethandler () registered response handlers } to handle success or failure status codes . by default the <code > success< / code > response handler will attempt to parse the data and simply return the parsed object . < / p > <p > <p > <strong > note : < / strong > if using the { @link #defaultsuccesshandler ( httpresponsedecorator object ) default <code > success< / code > response handler } be sure to read the caveat regarding streaming response data . < / p >
<p > convenience method to perform an http form patch . the response closure will be called only on a successful response . < / p > <p > <p > a failed response ( i . e . any http status code > 399 ) will be handled by the registered failure handler . the { @link #defaultfailurehandler ( httpresponsedecorator ) default failure handler } throws an { @link httpresponseexception } . < / p > <p > <p > the request body ( specified by a <code > body< / code > named parameter ) will be converted to a url - encoded form string unless a different <code > requestcontenttype< / code > named parameter is passed to this method . ( see { @link encoderregistry#encodeform ( map ) } . ) < / p >
make an http request to the default uri and parse using the default content - type .
make a request for the given http method and content - type with additional options configured in the <code > configclosure< / code > . see { @link requestconfigdelegate } for options .
create a {
parse the response data based on the given content - type . if the given content - type is { @link contenttype#any } the <code > content - type< / code > header from the response will be used to determine how to parse the response .
creates default response handlers for { @link status#success success } and { @link status#failure failure } status codes . this is used to populate the handler map when a new httpbuilder instance is created .
<p > this is the default <code > response . success< / code > handler . it will be executed if the response is not handled by a status - code - specific handler ( i . e . <code > response . 200 = { .. } < / code > ) and no generic success handler is given ( i . e . <code > response . success = { .. } < / code > . ) this handler simply returns the parsed data from the response body . in most cases you will probably want to define a <code > response . success = { ... } < / code > handler from the request closure which will replace the response handler defined by this method . < / p > <p > <p > in practice a user - supplied response handler closure is <i > designed< / i > to handle streaming content so it can be read directly from the response stream without buffering which will be much more efficient . therefore it is recommended that request method variants be used which explicitly accept a response handler closure in these cases . < / p >
set the default uri used for requests that do not explicitly take a <code > uri< / code > param .
set the default headers to add to all requests made by this builder instance . these values will replace any previously set default headers .
set the default http proxy to be used for all requests .
specify the control name of this multi - part .
add a header to this multipart specification .
set the headers for this multipart specification ( replaces previous headers )
specify the charset for this charset .
specify the charset for this charset .
this implementation adds a { @link gzipencoding } and { @link deflateencoding } handler to the registry . override this method to provide a different set of defaults .
add the request and response interceptors to the { @link httpclient } which will provide transparent decoding of the given content - encoding types . this method is called by httpbuilder and probably should not need be modified by sub - classes .
set authentication credentials to be used for the current { @link httpbuilder#geturi () default host } . this method name is a bit of a misnomer since these credentials will actually work for digest authentication as well .
set authentication credentials to be used for the given host and port .
set ntlm authentication credentials to be used for the current { @link httpbuilder#geturi () default host } .
set ntlm authentication credentials to be used for the given host and port .
sets a certificate to be used for ssl authentication . see { @link class#getresource ( string ) } for how to get a url from a resource on the classpath .
< / p > oauth sign all requests . note that this currently does <strong > not< / strong > wait for a <code > www - authenticate< / code > challenge before sending the the oauth header . all requests to all domains will be signed for this instance . < / p > <p / > <p > this assumes you ve already generated an <code > accesstoken< / code > and <code > secrettoken< / code > for the site you re targeting . for more information on how to achieve this see the <a href = https : // github . com / scribejava / scribejava / wiki / getting - started > scribe documentation< / a > . < / p >
< / p > oauth2 sign all requests . note that this currently does <strong > not< / strong > wait for a <code > www - authenticate< / code > challenge before sending the the oauth header . all requests to all domains will be signed for this instance . < / p > <p / > <p > this assumes you ve already generated an <code > accesstoken< / code > for the site you re targeting . for more information on how to achieve this see the <a href = https : // github . com / scribejava / scribejava / wiki / getting - started > scribe documentation< / a > . < / p >
helper method to get the content - type string from the response ( no charset ) .
an alternative way to create a headers object from the constructor .
this is usually the entry - point of the api if you need to specify parameters or a body in the request . for example : <p / > <pre > given () . param ( x y ) . when () . get ( / something ) . then () . statuscode ( 200 ) . body ( x . y notnullvalue () ) ; < / pre > note that this method is the same as { @link #with () } but with another syntax .
reset all static configurations to their default values .
perform a get request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a get request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a post request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a post request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a put request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a delete request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a delete request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a head request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a head request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a patch request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a patch request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a options request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a options request to a <code > path< / code > . normally the path doesn t have to be fully - qualified e . g . you don t need to specify the path as <tt > http : // localhost : 8080 / path< / tt > . in this case it s enough to use <tt > / path< / tt > .
perform a request to a <code > uri< / code > .
perform a request to a <code > url< / code > .
perform a custom http request to a <code > uri< / code > .
perform a custom http request to a <code > url< / code > .
authenticate using the given principal . used as : <pre > restassured . authentication = principal ( myprincipal ) ; < / pre > or in a { @link mockmvcrequestspecbuilder } : <pre > mockmvcrequestspecification req = new mockmvcrequestspecbuilder () . setauth ( principal ( myprincipal )) . .. < / pre >
authenticate using the given principal . used as : <pre > restassured . authentication = principal ( myprincipal ) ; < / pre > or in a { @link mockmvcrequestspecbuilder } : <pre > mockmvcrequestspecification req = new mockmvcrequestspecbuilder () . setauth ( principal ( myprincipal )) . .. < / pre >
authenticate using the given principal and credentials . used as : <pre > restassured . authentication = principalwithcredentials ( myprincipal mycredentials ) ; < / pre > or in a { @link mockmvcrequestspecbuilder } : <pre > mockmvcrequestspecification req = new mockmvcrequestspecbuilder () . setauth ( principalwithcredentials ( myprincipal mycredentials )) . .. < / pre >
authenticate using the supplied authentication instance ( <code > org . springframework . security . core . authentication< / code > from spring security ) . used as : <pre > restassured . authentication = authentication ( myauth ) ; < / pre > or in a { @link mockmvcrequestspecbuilder } : <pre > mockmvcrequestspecification req = new mockmvcrequestspecbuilder () . setauth ( authentication ( myauth )) . .. < / pre >
authenticate using a { @link requestpostprocessor } . this is mainly useful when you have added the <code > spring - security - test< / code > artifact to classpath . this allows you to do for example : <pre > restassured . authentication = with ( user ( username ) . password ( password )) ; < / pre > where <code > user< / code > is statically imported from <code > org . springframework . security . test . web . servlet . request . securitymockmvcrequestpostprocessors< / code > .
enable logging of both the request and the response if rest assureds test validation fails with the specified log detail . <p / > <p > this is just a shortcut for : < / p > <pre > restassured . config = new restassuredmockmvcconfig () . logconfig ( logconfig () . enableloggingofrequestandresponseifvalidationfails ( logdetail )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id playerid : my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( userid equaltopath ( playerid )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id href : http : // localhost : 8080 / my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( href endswithpath ( userid )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id baseuri : http : // localhost : 8080 href : http : // localhost : 8080 / my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( href startswithpath ( baseuri )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id href : http : // localhost : 8080 / my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( href containspath ( userid )) ; < / pre >
set the content type of the response
set the content type of the response
set a specific header
build the actual response
verifies whether value of cookie satisfies specified matcher .
verifies whether comment of cookie satisfies specified matcher .
verifies whether expiry date of cookie satisfies specified matcher .
verifies whether domain of cookie satisfies specified matcher .
verifies whether path of cookie satisfies specified matcher .
verifies whether secured property of cookie satisfies specified matcher .
verifies whether http - only property of cookie satisfies specified matcher .
verifies whether version of cookie satisfies specified matcher .
verifies whether max age of cookie satisfies specified matcher .
expect that a response header matches the supplied header name and hamcrest matcher .
expect that a response header matches the supplied name and value .
expect that a response cookie matches the supplied cookie name and hamcrest matcher . <p > e . g . <tt > cookiename1 = cookievalue1< / tt > < / p >
expect that a detailed response cookie matches the supplied cookie name and hamcrest matcher ( see { @link detailedcookiematcher } . <p > e . g . expect that the response of the get request to / something contain cookie <tt > cookiename1 = cookievalue1< / tt > <pre > expectcookie ( cookiename1 detailedcookie () . value ( cookievalue1 ) . secured ( true )) ; < / pre > < / p > <p / > <p > you can also expect several cookies : <pre > expectcookie ( cookiename1 detailedcookie () . value ( cookievalue1 ) . secured ( true )) . expectcookie ( cookiename2 detailedcookie () . value ( cookievalue2 ) . secured ( false )) ; < / pre > < / p >
expect that a response cookie matches the supplied name and value .
validate that the response time matches the supplied <code > matcher< / code > and time unit .
set the root path of the response body so that you don t need to write the entire path for each expectation . the same as { @link #rootpath ( string ) } but also provides a way to defined arguments .
append the given path to the root path with arguments supplied of the response body so that you don t need to write the entire path for each expectation . this is mainly useful when you have parts of the path defined in variables . e . g . instead of writing : <p / > <pre > string namepath = name ; expect () . root ( x . y ) . body ( age is ( .. )) . body ( gender is ( .. )) . body ( namepath + first is ( .. )) . body ( namepath + last is ( .. )) . when () . get ( .. ) ; < / pre > <p / > you can use a append root and do : <pre > string namepath = name ; expect () . root ( x . y ) . body ( age is ( .. )) . body ( gender is ( .. )) . appendroot ( %s withargs ( namepath )) . body ( first is ( .. )) . body ( last is ( .. )) . when () . get ( .. ) ; < / pre >
expect that the json or xml response content conforms to one or more hamcrest matchers . <br > <h3 > json example< / h3 > <p / > assume that a get request to / lotto returns a json response containing : <pre > { lotto : { lottoid : 5 winning - numbers : [ 2 45 34 23 7 5 3 ] winners : [ { winnerid : 23 numbers : [ 2 45 34 23 3 5 ] } { winnerid : 54 numbers : [ 52 3 12 11 18 22 ] } ] }} < / pre > <p / > you can verify that the lottoid is equal to 5 like this : <pre > responsespecbuilder builder = new responsespecbuilder () ; builder . expectbody ( lotto . lottoid equalto ( 5 )) ; < / pre >
same as { @link #expectbody ( string org . hamcrest . matcher ) } expect that you can pass arguments to the path . this is useful in situations where you have e . g . pre - defined variables that constitutes the path : <pre > string somesubpath = else ; int index = 1 ; expect () . body ( something . %s [ %d ] withargs ( somesubpath index ) equalto ( some value )) . .. < / pre > <p / > or if you have complex root paths and don t wish to duplicate the path for small variations : <pre > expect () . root ( filters . filterconfig [ %d ] . filterconfiggroups . find { it . name == gold } . includes ) . body ( withargs ( 0 ) hasitem ( first )) . body ( withargs ( 1 ) hasitem ( second )) . .. < / pre > <p / > the path and arguments follows the standard <a href = http : // download . oracle . com / javase / 1 5 . 0 / docs / api / java / util / formatter . html#syntax > formatting syntax< / a > of java . <p > note that <code > withargs< / code > can be statically imported from the <code > io . restassured . restassured< / code > class . < / p >
merge this builder with settings from another specification . note that the supplied specification can overwrite data in the current specification . the following settings are overwritten : <ul > <li > content type< / li > <li > root path< / <li > status code< / li > <li > status line< / li > < / ul > the following settings are merged : <ul > <li > response body expectations< / li > <li > cookies< / li > <li > headers< / li > < / ul >
enabled logging with the specified log detail . set a { @link logconfig } to configure the print stream and pretty printing options .
register a content - type to be parsed using a predefined parser . e . g . let s say you want parse content - type <tt > application / vnd . uoml + xml< / tt > with the xml parser to be able to verify the response using the xml dot notations : <pre > expect () . body ( document . child equalsto ( something )) .. < / pre > since <tt > application / vnd . uoml + xml< / tt > is not registered to be processed by the xml parser by default you need to explicitly tell rest assured to use this parser before making the request : <pre > expect () . parser ( application / vnd . uoml + xml parser . xml ) . when () . .. ; < / pre > <p / > you can also specify by default by using : <pre > restassured . registerparser ( application / vnd . uoml + xml parser . xml ) ; < / pre >
creates a hamcrest matcher that validates that a json document conforms to the json schema provided to this method .
creates a hamcrest matcher that validates that a json document conforms to the json schema provided to this method .
creates a hamcrest matcher that validates that a json document conforms to the json schema provided to this method .
creates a hamcrest matcher that validates that a json document conforms to the json schema provided to this method .
compose this { @link responseawarematcher } with another { @link responseawarematcher } .
compose this { @link responseawarematcher } with another { @link responseawarematcher } .
compose this { @link responseawarematcher } with another { @link responseawarematcher } .
get a single entity with the supplied name . if there are several entities match the <code > entityname< / code > then the last one is returned .
get a single entity value with the supplied name . if there are several headers match the <code > headername< / code > then the last one is returned .
get all entities with the supplied name . if there s only one entity matching the <code > entityname< / code > then a list with only that entity is returned .
get all entity values of the entity with supplied name . if there s only one header matching the <code > entity name< / code > then a list with only that header value is returned .
specify the hostname for of the proxy . will use port { @value #default_port } and scheme { @value #default_scheme } .
specify preemptive basic authentication for the proxy . will use hostname { @value #default_host } port { @value #default_port } and scheme { @value #default_scheme } .
specify the hostname of the proxy .
specify ( preemptive ) basic authentication for the proxy
specifies if jsonpath should use floats and doubles or bigdecimals to represent json numbers .
creates an json path configuration that uses the specified parser type as default .
creates an json path configuration that uses the specified object de - serializer as default .
specify a custom gson object mapper factory .
specify a custom jackson 1 . 0 object mapper factory .
specify a custom jackson 1 . 0 object mapper factory .
checks if the <code > potentialuri< / code > is a uri .
specify a new default stream to the print to .
enable logging of both the request and the response if rest assureds test validation fails with the specified log detail
todo extract content - type from headers and apply charset if needed!
get the httprequest class that represents this request type .
create a new { @link mockmvcfactory } with the supplied controllers or mock mvc configureres
define headers that should be overwritten instead of merged adding headers or using request specifications . note that by default all headers are merged except the { @value #accept_header_name } and { @value #content_type_header_name } headers . for example if the header with name <code > header1< / code > is <i > not< / i > marked as overwritable ( default ) and you do the following : <pre > given () . header ( header1 value1 ) . header ( header1 value2 ) . .. < / pre > <p / > then <code > header1< / code > will be sent twice in the request : <pre > header1 : value1 header1 : value2 < / pre > <p / > if you configure <code > header1< / code > to be overwritable by doing : <pre > given () . config ( restassured . config () . headerconfig ( headerconfig () . overwriteheaderswithname ( header1 )) . header ( header1 value1 ) . header ( header1 value2 ) . ... < / pre > then <code > header1< / code > will only be sent once : <pre > header1 : value2 < / pre >
specify the default control name to use if not defined explicitly in multi - part request . <p > default is { @value #default_control_name } < / p >
specify the default filename to use if not defined explicitly in multi - part request . <p > default is { @value #default_file_name } < / p >
specify the default subtype to use if not defined explicitly in when making the multi - part request . this will control how the content - type will be constructed for multipart requests when using rest assured when no content - type header has been explicitly defined . for example if subtype is set to mixed then the content - type header will be multipart / mixed if not specified explicitly . <p > default is { @value #default_subtype } < / p >
specify an explicit default multipart boundary to use when sending multi - part data .
specify a default charset to use for multi - parts ( default is us - ascii ) . this affects the encoding of the multipart body ( such as the control name ) but <i > not< / i > the actual <i > content< / i > ( such as the a json or string document ) . <p > <b > note : < / b > this setting is <i > only< / i > taken into account if { @link httpclientconfig#httpmultipartmode ( httpmultipartmode ) } is set to something other than { @link httpmultipartmode#strict } ( which is the default ) . so if you want this setting to apply you also need to explicitly change the multipart mode for example :
specify a default charset to use for multi - parts ( default is us - ascii ) . this affects the encoding of the multipart body ( such as the control name ) but <i > not< / i > the actual <i > content< / i > ( such as the a json or string document ) . <p > <b > note : < / b > this setting is <i > only< / i > taken into account if { @link httpclientconfig#httpmultipartmode ( httpmultipartmode ) } is set to something other than { @link httpmultipartmode#strict } ( which is the default ) . so if you want this setting to apply you also need to explicitly change the multipart mode for example :
specify an object request content that will automatically be serialized to json or xml and sent with the request using a specific object mapper . this works for the post patch and put methods only . trying to do this for the other http methods will cause an exception to be thrown . <p > note that { @link #setbody ( object objectmapper ) } are the same except for the syntactic difference . < / p >
specify an object request content that will automatically be serialized to json or xml and sent with the request using a specific object mapper type . this works for the post patch and put methods only . trying to do this for the other http methods will cause an exception to be thrown . <p > example of use : <pre > message message = new message () ; message . setmessage ( my beautiful message ) ;
set a session attribute .
add request attribute
add a header to be sent with the request
specify a file to upload to the server using multi - part form data uploading with a specific control name . it will use the content - type <tt > application / octet - stream< / tt > . if this is not what you want please use an overloaded method .
specify a byte - array to upload to the server using multi - part form data . it will use the content - type <tt > application / octet - stream< / tt > . if this is not what you want please use an overloaded method .
specify a string to send to the server using multi - part form data . it will use the content - type <tt > text / plain< / tt > . if this is not what you want please use an overloaded method .
specify a string to send to the server using multi - part form data with a specific mime - type .
set the session id name and value for this request . it ll override the default session id name from the configuration ( by default this is { @value sessionconfig#default_session_id_name } ) . you can configure the default session id name by using : <pre > restassuredmockmvc . config = newconfig () . sessionconfig ( new sessionconfig () . sessionidname ( &lt ; sessionidname&gt ; )) ; < / pre > and then you can use the { @link mockmvcrequestspecbuilder#setsessionid ( string ) } method to set the session id value without specifying the name for each request .
initialize with a { @link webapplicationcontext } that will be used to create the { @link mockmvc } instance . <p / > note that this will override the any { @link mockmvc } instances configured by other setters .
add a result handler
enabled logging with the specified log detail . set a { @link logconfig } to configure the print stream and pretty printing options .
set a http client parameter .
replaces the currently configured parameters with the ones supplied by <code > httpclientparams< / code > . this method is the same as { @link #setparams ( java . util . map ) } .
add the given parameters to an already configured number of parameters .
set the http client factory that rest assured should use when making request . for each request rest assured will invoke the factory to get the a the httpclient instance .
specify the http multipart mode when sending multi - part data .
get the result of an object path expression as a boolean .
get the result of an object path expression as an int .
get the result of an object path expression as a byte .
get the result of an object path expression as a short .
get the result of an object path expression as a float .
get the result of an object path expression as a double .
get the result of an object path expression as a long .
get the result of an object path expression as a list .
get the result of an object path expression as a map .
get the result of a object path expression as a java object . e . g . given the following object document : <pre > { store : { book : [ { category : reference author : nigel rees title : sayings of the century price : 8 . 95 } { category : fiction author : evelyn waugh title : sword of honour price : 12 . 99 } { category : fiction author : herman melville title : moby dick isbn : 0 - 553 - 21311 - 3 price : 8 . 99 } { category : fiction author : j . r . r . tolkien title : the lord of the rings isbn : 0 - 395 - 19395 - 8 price : 22 . 99 } ] bicycle : { color : red price : 19 . 95 } } } < / pre > and a java object like this : <p / > <pre > public class book { private string category ; private string author ; private string title ; private string isbn ; private float price ;
get the result of a object path expression as a java object with generic type . e . g . given the following object document : <pre > { store : { book : [ { category : reference author : nigel rees title : sayings of the century price : 8 . 95 } { category : fiction author : evelyn waugh title : sword of honour price : 12 . 99 } { category : fiction author : herman melville title : moby dick isbn : 0 - 553 - 21311 - 3 price : 8 . 99 } { category : fiction author : j . r . r . tolkien title : the lord of the rings isbn : 0 - 395 - 19395 - 8 price : 22 . 99 } ] bicycle : { color : red price : 19 . 95 } } } < / pre > and you want to get a book as a <code > map&lt ; string object&gt ; < / code > : <p / > then <pre > map&lt ; string object&gt ; book = from ( object ) . getobject ( store . book [ 2 ] new typeref&lt ; map&lt ; string object&gt ; &gt ; () {} ) ; < / pre > <p / > maps the second book to a book instance .
add a parameter for the expression . example : <pre > string name = system . console () . readline () ; list&lt ; map&gt ; books = with ( object ) . param ( name name ) . get ( store . book . findall { book - > book . author == name } ) ; < / pre >
get and print the json as a prettified string . <p > note that the content is not guaranteed to be looking exactly like the it does at the source . this is because once you peek the content has been downloaded and transformed into another data structure ( used by jsonpath ) and the json is rendered from this data structure . < / p >
specify features that will be used when parsing xml .
specify properties that will be used when parsing xml .
set a value of a feature flag .
set a value of a property .
specify declared namespaces that will be used when parsing xml . will also set { @link #namespaceaware ( boolean ) } to <code > true< / code > of namespaces are not empty . <p > note that you cannot use this to add namespaces for the { @link org . hamcrest . xml . hasxpath } matcher . this has to be done by providing a { @link javax . xml . namespace . namespacecontext } to the matcher instance . < / p >
declares a namespace and also sets { @link #namespaceaware ( boolean ) } to <code > true< / code > . <p / > <p > note that you cannot use this to add namespaces for the { @link org . hamcrest . xml . hasxpath } matcher . this has to be done by providing a { @link javax . xml . namespace . namespacecontext } to the matcher instance . < / p >
disables external dtd loading . <p > this is a shortcut for doing : <br > <pre > setfeature ( http : // apache . org / xml / features / nonvalidating / load - external - dtd false ) ; < / pre > < / p >
configure if xmlpath should validate documents as they are parsed ( default is { @value #default_validating } ) . note that this is only applicable when { @link xmlpath . compatibilitymode } is equal to { @link xmlpath . compatibilitymode#xml } .
configure whether or not rest assured should be aware of namespaces when parsing xml ( default is { @value #default_namespace_aware } ) . note that this is only applicable when { @link xmlpath . compatibilitymode } is equal to { @link xmlpath . compatibilitymode#xml } .
configure if xmlpath should provide support for doctype declarations ( default is { @value #default_allow_doc_type_declaration } ) . note that this is only applicable when { @link xmlpath . compatibilitymode } is equal to { @link xmlpath . compatibilitymode#xml } .
specify the default charset to use for the specific content - type if it s not specified in the content - type header explicitly
specify the default charset to use for the specific content - type if it s not specified in the content - type header explicitly
specify the default charset to use for the specific content - type if it s not specified in the content - type header explicitly
specify the default charset of the content in the response that s assumed if no charset is explicitly specified in the response .
specify the default charset of the content in the response that s assumed if no charset is explicitly specified in the response .
specify the content decoders that will be presented to the server when making a request ( using the <code > accept - encoding< / code > header ) . if the server supports any of these encodings then rest assured will automatically perform decoding of the response accordingly . <p > by default { @link contentdecoder#gzip } and { @link contentdecoder#deflate } are used . < / p >
get the result of an xml path expression . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a list . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a map . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get an xml document as a java object .
get the result of an xml path expression as an int . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a boolean . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a char . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a byte . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a short . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a float . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a double . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a long . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a string . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
get the result of an xml path expression as a uuid . for syntax details please refer to <a href = http : // www . groovy - lang . org / processing - xml . html#_manipulating_xml > this< / a > url .
add a parameter for the expression . example : <pre > string type = system . console () . readline () ; list&lt ; map&gt ; books = with ( object ) . param ( type type ) . get ( shopping . category . findall { it . @type == type } ) ; < / pre >
peeks into the xml / html that xmlpath will parse by printing it to the console . you can continue working with xmlpath afterwards . this is mainly for debug purposes . if you want to return a prettified version of the content see { @link #prettify () } . if you want to return a prettified version of the content and also print it to the console use { @link #prettyprint () } . <p / > <p > note that the content is not guaranteed to be looking exactly like the it does at the source . this is because once you peek the content has been downloaded and transformed into another data structure ( used by xmlpath ) and the xml is rendered from this data structure . < / p >
peeks into the xml / html that xmlpath will parse by printing it to the console in a prettified manner . you can continue working with xmlpath afterwards . this is mainly for debug purposes . if you want to return a prettified version of the content see { @link #prettify () } . if you want to return a prettified version of the content and also print it to the console use { @link #prettyprint () } . <p / > <p > note that the content is not guaranteed to be looking exactly like the it does at the source . this is because once you peek the content has been downloaded and transformed into another data structure ( used by xmlpath ) and the xml is rendered from this data structure . < / p >
specify an object request content that will automatically be serialized to json or xml and sent with the request using a specific object mapper . this works for the post patch and put methods only . trying to do this for the other http methods will cause an exception to be thrown .
specify an object request content that will automatically be serialized to json or xml and sent with the request using a specific object mapper type . this works for the post patch and put methods only . trying to do this for the other http methods will cause an exception to be thrown . <p > example of use : <pre > message message = new message () ; message . setmessage ( my beautiful message ) ;
add a cookie to be sent with the request .
add a parameter to be sent with the request .
add a multi - value parameter to be sent with the request .
add a query parameter to be sent with the request . this method is the same as { @link #addparam ( string java . util . collection ) } for all http methods except post where this method can be used to differentiate between form and query params .
add a query parameter to be sent with the request . this method is the same as { @link #addparam ( string object ... ) } ) } for all http methods except post where this method can be used to differentiate between form and query params .
add a form parameter to be sent with the request . this method is the same as { @link #addparam ( string java . util . collection ) } for all http methods except put where this method can be used to differentiate between form and query params .
add a form parameter to be sent with the request . this method is the same as { @link #addparam ( string object ... ) } ) } for all http methods except put where this method can be used to differentiate between form and query params .
specify a path parameter . path parameters are used to improve readability of the request path . e . g . instead of writing : <pre > expect () . statuscode ( 200 ) . when () . get ( / item / + myitem . getitemnumber () + / buy / + 2 ) ; < / pre > you can write : <pre > given () . pathparam ( itemnumber myitem . getitemnumber () ) . pathparam ( amount 2 ) . expect () . statuscode ( 200 ) . when () . get ( / item / { itemnumber } / buy / { amount } ) ; < / pre > <p / > which improves readability and allows the path to be reusable in many tests . another alternative is to use : <pre > expect () . statuscode ( 200 ) . when () . get ( / item / { itemnumber } / buy / { amount } myitem . getitemnumber () 2 ) ; < / pre >
specify multiple path parameter name - value pairs . path parameters are used to improve readability of the request path . e . g . instead of writing : <pre > expect () . statuscode ( 200 ) . when () . get ( / item / + myitem . getitemnumber () + / buy / + 2 ) ; < / pre > you can write : <pre > given () . pathparam ( itemnumber myitem . getitemnumber () amount 2 ) . expect () . statuscode ( 200 ) . when () . get ( / item / { itemnumber } / buy / { amount } ) ; < / pre > <p / > which improves readability and allows the path to be reusable in many tests . another alternative is to use : <pre > expect () . statuscode ( 200 ) . when () . get ( / item / { itemnumber } / buy / { amount } myitem . getitemnumber () 2 ) ; < / pre >
specify a keystore . <pre > restassured . keystore ( / truststore_javanet . jks test1234 ) ; < / pre > or <pre > given () . keystore ( / truststore_javanet . jks test1234 ) . .. < / pre > < / p >
the following documentation is taken from <a href = http builder > https : // github . com / jgritman / httpbuilder / wiki / ssl< / a > : <p > <h1 > ssl configuration< / h1 > <p / > ssl should for the most part just work . there are a few situations where it is not completely intuitive . you can follow the example below or see httpclient s sslsocketfactory documentation for more information . <p / > <h1 > sslpeerunverifiedexception< / h1 > <p / > if you can t connect to an ssl website it is likely because the certificate chain is not trusted . this is an apache httpclient issue but explained here for convenience . to correct the untrusted certificate you need to import a certificate into an ssl truststore . <p / > first export a certificate from the website using your browser . for example if you go to https : // dev . java . net in firefox you will probably get a warning in your browser . choose add exception get certificate view details tab . choose a certificate in the chain and export it as a pem file . you can view the details of the exported certificate like so : <pre > $ keytool - printcert - file equifaxsecureglobalebusinessca - 1 . crt owner : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us issuer : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us serial number : 1 valid from : mon jun 21 00 : 00 : 00 edt 1999 until : sun jun 21 00 : 00 : 00 edt 2020 certificate fingerprints : md5 : 8f : 5d : 77 : 06 : 27 : c4 : 98 : 3c : 5b : 93 : 78 : e7 : d7 : 7d : 9b : cc sha1 : 7e : 78 : 4a : 10 : 1c : 82 : 65 : cc : 2d : e1 : f1 : 6d : 47 : b4 : 40 : ca : d9 : 0a : 19 : 45 signature algorithm name : md5withrsa version : 3 .... < / pre > now import that into a java keystore file : <pre > $ keytool - importcert - alias equifax - ca - file equifaxsecureglobalebusinessca - 1 . crt - keystore truststore_javanet . jks - storepass test1234 owner : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us issuer : cn = equifax secure global ebusiness ca - 1 o = equifax secure inc . c = us serial number : 1 valid from : mon jun 21 00 : 00 : 00 edt 1999 until : sun jun 21 00 : 00 : 00 edt 2020 certificate fingerprints : md5 : 8f : 5d : 77 : 06 : 27 : c4 : 98 : 3c : 5b : 93 : 78 : e7 : d7 : 7d : 9b : cc sha1 : 7e : 78 : 4a : 10 : 1c : 82 : 65 : cc : 2d : e1 : f1 : 6d : 47 : b4 : 40 : ca : d9 : 0a : 19 : 45 signature algorithm name : md5withrsa version : 3 ... trust this certificate? [ no ] : yes certificate was added to keystore < / pre > now you want to use this truststore in your client : <pre > restassured . truststore ( / truststore_javanet . jks test1234 ) ; < / pre > or <pre > given () . truststore ( / truststore_javanet . jks test1234 ) . .. < / pre > < / p >
add a header to be sent with the request e . g :
specify an inputstream to upload to the server using multi - part form data . it will use the content - type <tt > application / octet - stream< / tt > . if this is not what you want please use an overloaded method .
specify a string to send to the server using multi - part form data . it will use the content - type <tt > text / plain< / tt > . if this is not what you want please use an overloaded method .
set the session id name and value for this request . it ll override the default session id name from the configuration ( by default this is { @value sessionconfig#default_session_id_name } ) . you can configure the default session id name by using : <pre > restassured . config = newconfig () . sessionconfig ( new sessionconfig () . sessionidname ( &lt ; sessionidname&gt ; )) ; < / pre > and then you can use the { @link requestspecbuilder#setsessionid ( string ) } method to set the session id value without specifying the name for each request .
merge this builder with settings from another specification . note that the supplied specification can overwrite data in the current specification . the following settings are overwritten : <ul > <li > port< / li > <li > authentication scheme< / <li > content type< / li > <li > request body< / li > < / ul > the following settings are merged : <ul > <li > parameters< / li > <li > cookies< / li > <li > headers< / li > <li > filters< / li > < / ul >
enabled logging with the specified log detail . set a { @link logconfig } to configure the print stream and pretty printing options .
instruct rest assured to connect to a proxy on the specified port on localhost with a specific scheme .
set form parameter update strategy to the given value .
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id playerid : my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( userid equaltopath ( playerid )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id href : http : // localhost : 8080 / my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( href endswithpath ( userid )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id baseuri : http : // localhost : 8080 href : http : // localhost : 8080 / my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( href startswithpath ( baseuri )) ; < / pre >
creates a { @link responseawarematcher } that extracts the given path from the response and wraps it in a { @link org . hamcrest . matchers#equalto ( object ) } matcher . this is useful if you have a resource that e . g . returns the given json : <pre > { userid : my - id href : http : // localhost : 8080 / my - id } < / pre > you can then test it like this : <pre > get ( / x ) . then () . body ( href containspath ( userid )) ; < / pre >
create a new logging filter without using the new operator . will make the dsl look nicer .
use a keystore located on the file - system . see { @link #keystore ( string string ) } for more details .
uses the user default keystore stored in &lt ; user . home&gt ; / . keystore
the certificate type will use { @link java . security . keystore#getdefaulttype () } by default .
use relaxed http validation . this means that you ll trust all hosts regardless if the ssl certificate is invalid . by using this method you don t need to specify a keystore ( see { @link #keystore ( string string ) } or trust store ( see { @link #truststore ( java . security . keystore ) } .
specify a { @link org . apache . http . conn . ssl . sslsocketfactory } . this will override settings from trust store as well as keystore and password .
get a single cookie with the supplied name . if there are several cookies match the <code > cookiename< / code > then the first one is returned .
get a single cookie <i > value< / i > with the supplied name . if there are several cookies matching the <code > cookiename< / code > then the first one is returned .
an alternative way to create a cookies object from the constructor .
creates a provider which looks up objects in jndi using the given name . example usage :
there may be multiple child injectors blacklisting a certain key so only remove the source that s relevant .
indexes bindings by type .
returns the binding for {
gets a binding implementation . first it check to see if the parent has a binding . if the parent has a binding and the binding is scoped it will use that binding . otherwise this checks for an explicit binding . if no explicit binding is found it looks for a just - in - time binding .
returns a just - in - time binding for { @code key } creating it if necessary .
returns true if the key type is membersinjector ( but not a subclass of membersinjector ) .
creates a synthetic binding to {
converts a constant string binding to the required type .
iterates through the binding s dependencies to clean up any stray bindings that were leftover from a failed jit binding . this is required because the bindings are eagerly & optimistically added to allow circular dependency support so dependencies may pass where they should have failed .
cleans up any state that may have been cached when constructing the jit binding .
safely gets the dependencies of possibly not initialized bindings .
creates a binding for an injectable type with the given scope . looks for a scope on the type if none is specified .
converts a binding for a {
creates a binding for a type annotated with
creates a binding for a type annotated with
attempts to create a just - in - time binding for {
returns a new just - in - time binding created by resolving { @code key } . the strategies used to create just - in - time bindings are :
returns parameter injectors or {
looks up thread local context and { @link internalcontext#enter () enters } it or creates a new context if necessary .
returns an array of parameter values .
creates the label for a node . this is a string of html that defines a table with a heading at the top and ( in the case of {
returns a new multibinder that collects instances of the key s type in a { @link set } that is itself bound with the annotation ( if any ) of the key .
returns a new multibinder that collects instances of {
see the factory configuration examples at {
see the factory configuration examples at {
see the factory configuration examples at {
the injector is a special case because we allow both parent and child injectors to both have a binding for that key .
the logger is a special case because it knows the injection point of the injected member . it s the only binding that does this .
this metohd is necessary to create a dependency<t > with proper generic type information
returns a new injection point for the specified constructor . if the declaring type of { @code constructor } is parameterized ( such as { @code list<t > } ) prefer the overload that includes a type literal .
returns a new injection point for the specified constructor of { @code type } .
returns a new injection point for the injectable constructor of { @code type } .
returns a new injection point for the specified method of { @code type } . this is useful for extensions that need to build dependency graphs from arbitrary methods .
returns all static method and field injection points on { @code type } .
returns all instance method and field injection points on { @code type } .
returns true if the binding annotation is in the wrong place .
returns an ordered immutable set of injection points for the given type . members in superclasses come before members in subclasses . within a class fields come before methods . overridden methods are filtered out . the order of fields / methods within a class is consistent but undefined .
returns true if the method is eligible to be injected . this is different than { @link #isvalidmethod } because ineligibility will not drop a method from being injected if a superclass was eligible & valid . bridge & synthetic methods are excluded from eligibility for two reasons :
returns true if a overrides b . assumes signatures of a and b are the same and a s declaring class is a subclass of b s declaring class .
sets the actual members injector .
returns the looked up members injector . the result is not valid until this lookup has been initialized which usually happens when the injector is created . the members injector will throw an {
returns a { @link checkedprovider } which always provides { @code instance } .
returns a { @link checkedprovider } which always provides { @code instance } .
returns a { @link checkedprovider } which always throws exceptions .
returns a { @link checkedprovider } which always throws exceptions .
returns the type from super class s type parameter in {
gets the type of this type s provider .
gets type literal for the given {
returns an immutable list of the resolved types .
returns the generic form of { @code supertype } . for example if this is { @code arraylist<string > } this returns { @code iterable<string > } given the input { @code iterable . class } .
returns the resolved generic type of { @code field } .
returns the resolved generic parameter types of { @code methodorconstructor } .
returns the resolved generic exception types thrown by { @code constructor } .
returns the resolved generic return type of { @code method } .
returns a key that doesn t hold any references to parent classes . this is necessary for anonymous keys so ensure we don t hold a ref to the containing module ( or class ) forever .
returns an type that s appropriate for use in a key .
returns true if {
returns a type that is functionally equal but not necessarily equal according to {
returns the declaring class of {
introspects the injector and collects all instances of bound { @code list<servletdefinition > } into a master list .
installs default converters for primitives enums and class literals .
attempts to canonicalize null references to the system class loader . may return null if for some reason the system loader is unavailable .
returns a fastclass proxy for invoking the given member or { @code null } if access rules disallow it .
returns a fastclass proxy for invoking the given member or { @code null } if access rules disallow it .
returns true if the types classloader has the same version of cglib that bytecodegen has . this only returns false in strange osgi situations but it prevents us from using fastclass for non public members .
returns true if the member can be called by a fast class generated in a different classloader .
creates a { @link providermethod } .
returns the guice {
replace annotation instances with annotation types this is only appropriate for testing if a key is bound and not for injecting .
returns the unique binding annotation from the specified list or { @code null } if there are none .
registers an instance for member injection when that step is performed .
prepares member injectors for all injected instances . this prompts guice to do static analysis on the injected instances .
performs creation - time injections on all objects that require it . whenever fulfilling an injection depends on another object that requires injection we inject it first . if the two instances are codependent ( directly or transitively ) ordering of injection is arbitrary .
returns an instance of t constructed using this constructor with the supplied arguments .
introspects the injector and collects all instances of bound { @code list<filterdefinition > } into a master list .
used to create an proxy that dispatches either to the guice - servlet pipeline or the regular pipeline based on uri - path match . this proxy also provides minimal forwarding support .
transitively resolves aliases . given aliases ( x to y ) and ( y to z ) it will return mappings ( x to z ) and ( y to z ) .
returns true if this scope is a singleton that should be loaded eagerly in {
scopes an internal factory .
replaces annotation scopes with instance scopes using the injector s annotation - to - instance map . if the scope annotation has no corresponding instance an error will be added and unscoped will be retuned .
normalizes a path by unescaping all safe percent encoded characters .
percent - decodes a us - ascii string into a unicode string . the specified encoding is used to determine what characters are represented by any consecutive sequences of the form %<i > xx< / i > . this is the lenient kind of decoding that will simply ignore and copy as - is any %xx sequence that is invalid ( for example %hh ) .
we tolerate duplicate bindings if one exposes the other or if the two bindings are considered duplicates ( see { @link bindings#areduplicates ( bindingimpl bindingimpl ) } .
generates an annotation for the annotation class . requires that the annotation is all optionals .
implements {
implements {
implements {
returns true if the given annotation is retained at runtime .
returns the scope annotation on {
returns the scoping annotation or null if there isn t one .
adds an error if there is a misplaced annotations on {
gets a key for the given type member and annotations .
returns the binding annotation on {
if the annotation is an instance of {
if the annotation is the class {
returns the name the binding should use . this is based on the annotation . if the annotation has an instance and is not a marker annotation we ask the annotation for its tostring . if it was a marker annotation or just an annotation type we use the annotation s name . otherwise the name is the empty string .
sets the actual provider .
returns the looked up provider . the result is not valid until this lookup has been initialized which usually happens when the injector is created . the provider will throw an {
returns {
returns a new mapbinder that collects entries of {
returns a new mapbinder that collects entries of {
returns a new mapbinder that collects entries of {
adds a binding for t . multiple calls to this are safe and will be collapsed as duplicate bindings .
returns a new complete constructor injector with injection listeners registered .
returns true if the given class has a scope annotation .
returns a new mapbinder that collects entries of {
provider map <k v > is safely a map<k javax . inject . provider<v >>>
given a key<t > will return a key<provider<t >>
since it s an easy way to group a type and an optional annotation type or instance .
adds a binding to the map for the given key .
returns some metadata if the method is annotated { @code @finder } or null .
returns {
prepends the given { @code source } to the stack of binding sources for the errors reported in this exception .
construct an instance . returns {
provisions a new t .
sets the binding to a copy with the specified annotation on the bound key
sets the binding to a copy with the specified annotation on the bound key
when serialized we eagerly convert sources to strings . this hurts our formatting but it guarantees that the receiving end will be able to read the message .
returns a module which creates bindings for provider methods from the given module .
the collection is immutable .
returns true if the configurationexception is due to an error of typeliteral not being fully specified .
finds a constructor suitable for the method . if the implementation contained any constructors marked with {
matching logic for constructors annotated with assistedinject . this returns true if and only if all
calculates all dependencies required by the implementation and constructor .
return all non - assisted dependencies .
returns true if all dependencies are suitable for the optimized version of assistedinject . the optimized version caches the binding & uses a threadlocal provider so can only be applied if the assisted bindings are immediately provided . this looks for hints that the values may be lazily retrieved by looking for injections of injector or a provider for the assisted values .
returns true if the dependency is for {
at injector - creation time we initialize the invocation handler . at this time we make sure all factory methods will be able to build the target types .
creates a child injector that binds the args and returns the binding for the method s result .
when a factory method is invoked we create a child injector that binds all parameters then use that to get an instance of the return type .
returns true if {
throws a configurationexception with an nullpointerexceptions as the cause if the given reference is {
throws a configurationexception with a formatted {
returns an instance that uses {
within guice s core allow for better missing binding messages
todo ( lukes ) : inline into callers
todo ( lukes ) : inline in callers . there are some callers outside of guice so this is difficult
implementation of newsetbinder .
adds a new entry to the set and returns the key for it .
iterates over the remaining filter definitions . returns the first applicable filter or null if none apply .
returns true if the inject annotation is on the constructor .
returns an injection point that can be used to clean up the constructor store .
returns a set of dependencies that can be iterated over to clean up stray jit bindings .
/ * if [ aop ]
/ * end [ aop ]
returns the instance methods and fields of { @code instance } that will be injected to fulfill this request .
gets the system option indicated by the specified key ; runs as a privileged action .
gets the system option indicated by the specified key ; runs as a privileged action .
returns a name for a guice source object . this will typically be either a {
returns a new parameterized type applying { @code typearguments } to { @code rawtype } . the returned type does not have an owner type .
returns a new parameterized type applying { @code typearguments } to { @code rawtype } and enclosed by { @code ownertype } .
returns a type modelling a { @link map } whose keys are of type { @code keytype } and whose values are of type { @code valuetype } .
returns a type modelling a { @link javax . inject . provider } that provides elements of type { @code elementtype } .
returns a module which creates bindings methods in the module that match the scanner .
returns the annotation that is claimed by the scanner or null if there is none .
creates a constant binding to {
creates a constant binding to {
creates an injector for the given set of modules in a given development stage .
creates an injector for the given set of modules in a given development stage .
returns the position of { @link com . google . inject . module#configure configure ( binder ) } method call in the { @link #getstacktrace stack trace } for modules that their classes returned by { @link #getmoduleclassnames } . for example if the stack trace looks like the following :
returns the sequence of method calls that ends at one of {
get the line number associated with the given member .
initialize the specified lookups either immediately or when the injector is created .
wraps the given callable in a contextual callable that continues the http request in another thread . this acts as a way of transporting request context data from the request processing thread to to worker threads .
wraps the given callable in a contextual callable that transfers the request to another thread . this acts as a way of transporting request context data from the current thread to a future thread .
scopes the given callable inside a request scope . this is not the same as the http request scope but is used if no http request scope is in progress . in this way keys can be scoped as @requestscoped and exist in non - http requests ( for example : rpc requests ) as well as in http request threads .
validates the key and object ensuring the value matches the key type and canonicalizing null objects to the null sentinel .
returns a new complete members injector with injection listeners registered .
creates a new members injector and attaches both injection listeners and method aspects .
returns the injectors for the specified injection points .
visiblefortesting
gets a key for an injection type and an annotation strategy .
gets a key for an injection type .
gets a key for an injection type and an annotation type .
gets a key for an injection type and an annotation .
gets a key for an injection type and an annotation type .
gets a key for an injection type and an annotation .
gets a key for an injection type .
gets a key for an injection type and an annotation type .
gets a key for an injection type and an annotation .
returns a new key of the specified type with the same annotation as this key .
returns a new key of the specified type with the same annotation as this key .
gets the strategy for an annotation .
gets the strategy for an annotation type .
records the elements executed by {
records the elements executed by {
records the elements executed by {
removes stacktrace elements related to aop internal mechanics from the throwable s stack trace and any causes it may have .
returns a new {
creates a new {
returns a string describing where this dependency was bound . if the binding was just - in - time there is no valid binding source so this describes the class in question .
/ * if [ aop ]
/ * end [ aop ]
prepends the list of sources to the given {
calls {
returns the formatted message for an exception with the specified messages .
creates a new message without a cause .
creates a new message with the given cause .
creates a new message with the given cause and a binding source stack .
formats an object in a user friendly way .
returns the cause throwable if there is exactly one cause in {
returns the class names of modules in this module source . the first element ( index 0 ) is filled by this object {
returns the full call stack that ends just before the module {
creates an injector defined by { @code modules } and immediately uses it to create an instance of { @code type } . the modules can be of any type and must contain { @code @provides } methods .
returns true if the classname should be skipped .
returns the class names as strings
returns the calling line of code . the selected line is the nearest to the top of the stack that is not skipped .
returns the non - skipped module class name .
registers all the bindings of an injector with the platform mbean server . consider using the name of your root {
registers all the bindings of an injector with the given mbean server . consider using the name of your root {
run with no arguments for usage instructions .
returns encoded in - memory version of {
decodes in - memory stack trace elements to regular {
sets the new current dependency & adds it to the state .
adds to the state without setting the dependency .
returns the current dependency chain ( all the state stored in the dependencystack ) .
returns an initializable for an instance that requires no initialization .
utility that delegates to the actual service method of the servlet wrapped with a contextual request ( i . e . with correctly computed path info ) .
provisions a new instance . subclasses should override this to catch exceptions & rethrow as errorsexceptions .
dispatch events .
add event processor .
get the result of a future task
launder the throwable
register processor to process command that has the command code of cmdcode .
register the default processor to process command with no specific processor registered .
get the specific processor with command code of cmdcode if registered otherwise the default processor is returned .
try get from cache
decode the protocol code
get all connections of all poolkey .
warning! this is weakly consistent implementation to prevent lock the whole { @link concurrenthashmap } .
in case of cache pollution and connection leak to do schedule scan
if no task cached create one and initialize the connections .
if no task cached create one and initialize the connections . if task cached check whether the number of connections adequate if not then heal it .
get the mapping instance of { @link connectionpool } with the specified poolkey or create one if there is none mapping in conntasks .
remove task and remove all connections
execute heal connection tasks if the actual number of connections in pool is less than expected
do create connections
initialize executor
shutdown . <p > notice : <br > <li > rpc client can not be used any more after shutdown . <li > if you need you should destroy it and instantiate another one .
one way invocation using a string address address format example - 127 . 0 . 0 . 1 : 12200?key1 = value1&key2 = value2 <br > <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the string address to find a available connection if none then create one . < / li > <ul > <li > you can use { @link rpcconfigs#connect_timeout_key } to specify connection timeout time unit is milliseconds e . g [ 127 . 0 . 0 . 1 : 12200?_connecttimeout = 3000 ] <li > you can use { @link rpcconfigs#connection_num_key } to specify connection number for each ip and port e . g [ 127 . 0 . 0 . 1 : 12200?_connectionnum = 30 ] <li > you can use { @link rpcconfigs#connection_warmup_key } to specify whether need warmup all connections for the first time you call this method e . g [ 127 . 0 . 0 . 1 : 12200?_connectionwarmup = false ] < / ul > <li > you should use { @link #closeconnection ( string addr ) } to close it if you want . < / ol >
one way invocation using a { @link connection } <br > <p > notice : <br > <b > do not modify the request object concurrently when this method is called . < / b >
oneway invocation with a { @link invokecontext } common api notice please see { @link #oneway ( connection object ) }
synchronous invocation using a string address address format example - 127 . 0 . 0 . 1 : 12200?key1 = value1&key2 = value2 <br > <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the string address to find a available connection if none then create one . < / li > <ul > <li > you can use { @link rpcconfigs#connect_timeout_key } to specify connection timeout time unit is milliseconds e . g [ 127 . 0 . 0 . 1 : 12200?_connecttimeout = 3000 ] <li > you can use { @link rpcconfigs#connection_num_key } to specify connection number for each ip and port e . g [ 127 . 0 . 0 . 1 : 12200?_connectionnum = 30 ] <li > you can use { @link rpcconfigs#connection_warmup_key } to specify whether need warmup all connections for the first time you call this method e . g [ 127 . 0 . 0 . 1 : 12200?_connectionwarmup = false ] < / ul > <li > you should use { @link #closeconnection ( string addr ) } to close it if you want . < / ol >
synchronous invocation with a { @link invokecontext } common api notice please see { @link #invokesync ( string object int ) }
synchronous invocation using a parsed { @link url } <br > <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the parsed { @link url } to find a available connection if none then create one . < / li > <ul > <li > you can use { @link url#setconnecttimeout } to specify connection timeout time unit is milliseconds . <li > you can use { @link url#setconnnum } to specify connection number for each ip and port . <li > you can use { @link url#setconnwarmup } to specify whether need warmup all connections for the first time you call this method . < / ul > <li > you should use { @link #closeconnection ( url url ) } to close it if you want . < / ol >
synchronous invocation with a { @link invokecontext } common api notice please see { @link #invokesync ( url object int ) }
synchronous invocation using a { @link connection } <br > <p > notice : <br > <b > do not modify the request object concurrently when this method is called . < / b >
synchronous invocation with a { @link invokecontext } common api notice please see { @link #invokesync ( connection object int ) }
future invocation using a { @link connection } <br > you can get result use the returned { @link rpcresponsefuture } . <p > notice : <br > <b > do not modify the request object concurrently when this method is called . < / b >
callback invocation with a { @link invokecontext } common api notice please see { @link #invokewithcallback ( url object invokecallback int ) }
callback invocation using a { @link connection } <br > you can specify an implementation of { @link invokecallback } to get the result . <p > notice : <br > <b > do not modify the request object concurrently when this method is called . < / b >
callback invocation with a { @link invokecontext } common api notice please see { @link #invokewithcallback ( connection object invokecallback int ) }
create a stand alone connection using ip and port . <br > <p > notice : <br > <li > each time you call this method will create a new connection . <li > bolt will not control this connection . <li > you should use { @link #closestandaloneconnection } to close it .
create a stand alone connection using address address format example - 127 . 0 . 0 . 1 : 12200 <br > <p > notice : <br > <ol > <li > each time you can this method will create a new connection . <li > bolt will not control this connection . <li > you should use { @link #closestandaloneconnection } to close it . < / ol >
get a connection using address address format example - 127 . 0 . 0 . 1 : 12200?key1 = value1&key2 = value2 <br > <p > notice : <br > <ol > <li > get a connection if none then create . < / li > <ul > <li > you can use {
get a connection using a { @link url } . <br > <p > notice : <ol > <li > get a connection if none then create . <li > bolt will control this connection in { @link com . alipay . remoting . connectionpool } <li > you should use { @link #closeconnection ( url url ) } to close it . < / ol >
check connection the address format example - 127 . 0 . 0 . 1 : 12200?key1 = value1&key2 = value2
close all connections of a address
enable heart beat for a certain connection . if this address not connected then do nothing . <p > notice : this method takes no effect on a stand alone connection .
enable heart beat for a certain connection . if this { @link url } not connected then do nothing . <p > notice : this method takes no effect on a stand alone connection .
disable heart beat for a certain connection . if this addr not connected then do nothing . <p > notice : this method takes no effect on a stand alone connection .
disable heart beat for a certain connection . if this { @link url } not connected then do nothing . <p > notice : this method takes no effect on a stand alone connection .
initialization .
do something when closing .
close the connection .
set attribute if key absent .
this method has been modified to check the size of decoded msgs which is represented by the local variable { @code recyclablearraylist out } . if has decoded more than one msg then construct an array list to submit all decoded msgs to the pipeline .
called once data should be decoded from the given { @link bytebuf } . this method will call { @link #decode ( channelhandlercontext bytebuf list ) } as long as decoding should take place .
help register single - interest user processor .
help register multi - interest user processor .
send response using remoting context if necessary . <br > if request type is oneway no need to send any response nor exception .
dispatch request command to user processor
deserialize request command
pre process remoting context initial some useful infos and pass to biz
print some log when request timeout and discarded in io thread .
print some debug log when receive request
process the remoting command with its own executor or with the defaultexecutor if its own if null .
synchronous invocation
invocation with callback .
oneway invocation .
create an instance of { @link protocolswitch } according to byte value
create an instance of { @link protocolswitch } according to switch index
from bit set to byte
from byte to bit set
get connection and set init invokecontext if invokecontext not { @code null }
add reconnect task
stop reconnect thread
oneway rpc invocation . <br > notice! do not modify the request object concurrently when this method is called .
oneway rpc invocation . <br > notice! do not modify the request object concurrently when this method is called .
synchronous rpc invocation . <br > notice! do not modify the request object concurrently when this method is called .
synchronous rpc invocation . <br > notice! do not modify the request object concurrently when this method is called .
rpc invocation with future returned . <br > notice! do not modify the request object concurrently when this method is called .
rpc invocation with callback . <br > notice! do not modify the request object concurrently when this method is called .
rpc invocation with callback . <br > notice! do not modify the request object concurrently when this method is called .
convert application request object to remoting request command .
filter connections to monitor
monitor connections and close connections with status is off
close the connection of the fresh select connections
/ * handle the request ( s ) .
/ * return error command if necessary .
~~~ public helper methods to retrieve system property
deserialize according to mask . <ol > <li > if mask < = { @link rpcdeserializelevel#deserialize_clazz } only deserialize clazz - only one part . < / li > <li > if mask < = { @link rpcdeserializelevel#deserialize_header } deserialize clazz and header - two parts . < / li > <li > if mask < = { @link rpcdeserializelevel#deserialize_all } deserialize clazz header and content - all three parts . < / li > < / ol >
getter method for property <tt > customserializer< / tt > .
setter method for property <tt > listener< / tt > .
print info log
whether this request already timeout
get user processor for class name .
get one connection randomly
getter method for property <tt > customserializer< / tt > .
get
get and use default if not found
get property value according to property key
compute crc32 code for byte [] .
analyze the response command and generate the response object .
convert remoting response command to application response object .
convert remoting response command to throwable if it is a throwable otherwise return null .
detail your error msg with the error msg returned from response command
create server exception using error msg and fill the stack trace using the stack trace of throwable .
print trace log
create the right event loop according to current platform and system property fallback to nio when epoll not enabled .
use {
start!
parse the remote address of the channel .
parse the local address of the channel .
parse the remote host ip of the channel .
parse the remote hostname of the channel .
parse the local host ip of the channel .
parse the remote host port of the channel .
parse the local host port of the channel .
parse the socket address omit the leading / if present .
parse the host ip of socket address .
<ol > <li > if an address starts with a / skip it . <li > if an address contains a / substring it . < / ol >
add a connection
removeandtryclose a connection
get a connection
register custom serializer for class name .
get the custom serializer for class name .
register custom serializer for command code .
get the custom serializer for command code .
start schedule task
notice : only { @link globalswitch#server_manage_connection_switch } switch on will close all connections .
one way invocation with a { @link invokecontext } common api notice please see { @link #oneway ( string object ) }
one way invocation using a parsed { @link url } <br > <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the parsed { @link url } to find a available client connection if none then throw exception< / li > < / ol >
one way invocation with a { @link invokecontext } common api notice please see { @link #oneway ( url object ) }
future invocation using a string address address format example - 127 . 0 . 0 . 1 : 12200?key1 = value1&key2 = value2 <br > you can get result use the returned { @link rpcresponsefuture } . <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the string address to find a available client connection if none then throw exception< / li > <li > unlike rpc client address arguments takes no effect here for rpc server will not create connection . < / li > < / ol >
future invocation with a { @link invokecontext } common api notice please see { @link #invokewithfuture ( string object int ) }
future invocation using a parsed { @link url } <br > you can get result use the returned { @link rpcresponsefuture } . <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the parsed { @link url } to find a available client connection if none then throw exception< / li > < / ol >
future invocation with a { @link invokecontext } common api notice please see { @link #invokewithfuture ( url object int ) }
future invocation with a { @link invokecontext } common api notice please see { @link #invokewithfuture ( connection object int ) }
callback invocation using a string address address format example - 127 . 0 . 0 . 1 : 12200?key1 = value1&key2 = value2 <br > you can specify an implementation of { @link invokecallback } to get the result . <p > notice : <br > <ol > <li > <b > do not modify the request object concurrently when this method is called . < / b > < / li > <li > when do invocation use the string address to find a available client connection if none then throw exception< / li > <li > unlike rpc client address arguments takes no effect here for rpc server will not create connection . < / li > < / ol >
check whether a client address connected
check whether a { @link url } connected
init netty write buffer water mark
check if the provided bytebbuffer contains a valid utf8 encoded string . <p > using the algorithm flexible and economical utf - 8 decoder by bjrn hhrmann ( http : // bjoern . hoehrmann . de / utf - 8 / decoder / dfa / )
get a frame with a specific opcode
returns whether the whole outqueue has been flushed
set the close code for this close frame
validate the payload to valid utf8
update the payload to represent the close code and the reason
check if the requested protocol is part of this draft
translate the buffer depending when it has an extended payload length ( 126 or 127 )
check if the frame size exceeds the allowed limit
check if the max packet size is smaller than the real packet size
generate a final key from a input string
process the frame if it is a continuous frame or the fin bit is not set
process the frame if it is a binary frame
log the runtime exception to the specific websocketimpl
process the frame if it is a text frame
process the frame if it is the last frame
process the frame if it is not the last frame
process the frame if it is a closing frame
check the current size of the buffer and throw an exception if the size is bigger than the max allowed frame size
method to generate a full bytebuffer out of all the fragmented frame payload
get the current size of the resulting bytebuffer in the bytebuffer list
implements the handshake protocol between two peers required for the establishment of the ssl / tls connection . during the handshake encryption configuration information - such as the list of available cipher suites - will be exchanged and if the handshake is successful will lead to an established ssl / tls session . <p > <p / > a typical handshake will usually contain the following steps : <p > <ul > <li > 1 . wrap : clienthello< / li > <li > 2 . unwrap : serverhello / cert / serverhellodone< / li > <li > 3 . wrap : clientkeyexchange< / li > <li > 4 . wrap : changecipherspec< / li > <li > 5 . wrap : finished< / li > <li > 6 . unwrap : changecipherspec< / li > <li > 7 . unwrap : finished< / li > < / ul > <p / > handshake is also used during the end of the session in order to properly close the connection between the two peers . a proper connection close will typically include the one peer sending a close message to another and then wait for the other s close message to close the transport link . the other peer from his perspective would read a close message from his peer and then enter the handshake procedure to send his own close message as well .
compares <code > sessionproposedcapacity<code > with buffer s capacity . if buffer s capacity is smaller returns a buffer with the proposed capacity . if it s equal or larger returns a buffer with capacity twice the size of the initial one .
handles { @link sslengineresult . status#buffer_underflow } . will check if the buffer is already filled and if there is no space problem will return the same buffer so the client tries to read again . if the buffer is already filled will try to enlarge the buffer either to session s proposed size or to a larger capacity . a buffer underflow can happen only after an unwrap so the buffer will always be a peernetdata buffer .
checking the handshake for the role as server
checking the handshake for the role as client
method to decode the provided bytebuffer
returns whether the handshake phase has is completed . in case of a broken handshake this will be never the case .
close the connection if the received handshake was not correct
close the connection if there was a server error by a runtimeexception
generate a simple response for the corresponding endpoint to indicate some error
this will close the connection immediately without a proper close handshake . the code and the message therefore won t be transfered over the wire also they will be forwarded to onclose / onwebsocketclose .
send text data to the other end .
send binary data ( plain bytes ) to the other end .
write a list of bytebuffer ( frames in binary form ) into the outgoing queue
reset everything relevant to allow a reconnect
initiates the websocket connection . this method does not block .
same as <code > connect< / code > but blocks with a timeout until the websocket connected or failed to do so . <br >
extract the specified port
create and send the handshake to the other endpoint
calls subclass implementation of <var > onopen< / var > .
calls subclass implementation of <var > onclose< / var > .
setter for the interval checking for lost connections a value lower or equal 0 results in the check to be deactivated
stop the connection lost timer
start the connection lost timer
this methods allows the reset of the connection lost timer in case of a changed parameter
send a ping to the endpoint or close the connection since the other endpoint did not respond with a ping
cancel any running timer for the connection lost detection
/ * keystore with certificate created like so ( in jks format ) :
this default implementation does not do anything . go ahead and overwrite it .
this default implementation will send a pong in response to the received ping . the pong frame will have the same payload as the ping frame .
/ * keystore with certificate created like so ( in jks format ) :
this method will do whatever necessary to process the sslengine handshake . thats why it s called both from the {
performs the unwrap operation by unwrapping from {
blocks when in blocking mode until at least one byte has been decoded . <br > when not in blocking mode 0 may be returned .
{
closes all connected clients sockets then closes the underlying serversocketchannel effectively killing the server socket selectorthread freeing the port the server was bound to and stops all internal workerthreads .
gets the port number that this server listens on .
runnable implementation /////////////////////////////////////////////////
do an additional read
execute a accept operation
execute a read operation
execute a write operation
setup the selector thread as well as basic server settings
the websocket server can only be started once
clean up everything after a shutdown
this method performs remove operations on the connection and therefore also gives control over whether the operation shall be synchronized <p > {
getter to return the socket used by this specific connection
send a byte array to a specific collection of websocket connections
send a text to a specific collection of websocket connections
private method to cache all the frames to improve memory footprint and conversion time
fills the draftframes with new data for the broadcast
transfer from one bytebuffer to another bytebuffer
/ * keystore with certificate created like so ( in jks format ) :
initialise jpa entity manager factories .
get a newly created entitymanager for the specified persistence unit name .
run a block of code with a newly created entitymanager for the default persistence unit .
run a block of code with a newly created entitymanager for the named persistence unit .
run a block of code with a newly created entitymanager for the named persistence unit .
run a block of code with a newly created entitymanager for the named persistence unit .
run a block of code in a jpa transaction .
run a block of code in a jpa transaction .
run a block of code in a jpa transaction .
converts the varargs to a scala buffer takes care of wrapping varargs into a intermediate list if necessary
wraps arguments passed into a list if necessary .
translates a message .
translates the first defined message .
check if a message key is defined .
get a messages context appropriate for the given candidates .
get a messages context appropriate for the given request .
given a result and a lang return a new result with the lang cookie set to the given lang .
add additional configuration .
add additional configuration .
add additional configuration .
add bindings from guiceable modules .
add bindings from play modules .
add play bindings .
override bindings using guiceable modules .
override bindings using play modules .
override bindings using play bindings .
disable modules by class .
executes this action with the given http context and returns the result .
executes this action with the given http request and returns the result .
retrieves a file relative to the application root path . this method returns an optional using empty if the file was not found .
configure the scope for this binding .
constructs a tuple of a b
constructs a tuple of a b c d e
converts the execution context to an executor preparing it first .
decodes the specified set - cookie http header value into a { @link cookie } .
returns a new instance that also skips { @code moreclassestoskip } .
returns the class names as strings
returns the calling line of code . the selected line is the nearest to the top of the stack that is not skipped .
create a default jpa configuration with the given name and unit name .
create a default jpa configuration with the given names and unit names .
create a default jpa configuration from a map of names to unit names .
produces a flow of escaped bytestring from a series of string elements . calls out to comet . flow internally .
produces a flow of bytestring using json . stringify from a flow of jsonnode . calls out to comet . flow internally .
obtain a logger instance .
obtain a logger instance .
log a message with the trace level .
log a message with the trace level .
log a message with the trace level .
log a message with the debug level .
log a message with the debug level .
log a message with the debug level .
log a message with the info level .
log a message with the info level .
log a message with the info level .
log a message with the warn level .
log a message with the warn level .
log a message with the warn level .
log a message with the error level .
log a message with the error level .
log a message with the error level .
adds validator as a singleton .
need to do so .
#clients - show - action
#range - request
returns an accessible method ( that is one that can be invoked via reflection ) that implements the specified method . if no such method can be found return { @code null } .
returns an accessible method ( that is one that can be invoked via reflection ) by scanning through the superclasses . if no such method can be found return { @code null } .
finds an accessible method that matches the given name and has compatible parameters . compatible parameters mean that every method parameter is assignable from the given parameters . in other words it finds a method with the given name that will take the parameters given .
invoked when a client error occurs that is an error in the 4xx series .
invoked when a client makes a bad request .
invoked when a client makes a request that was forbidden .
invoked when a handler or resource is not found .
invoked when a server error occurs .
responsible for logging server errors .
convert the given exception to an exception that play can report more information about .
invoked in dev mode when a server error occurs . note that this method is where the url set by play . editor is used .
invoked in prod mode when a server error occurs .
create a builddochandler that serves documentation from the given files which could either be directories or jar files . the basedir array must be the same length as the files array and the corresponding entry in there for jar files is used as a base directory to use resources from in the jar .
create an builddochandler that serves documentation from a given directory by wrapping a filesystemrepository .
create an builddochandler that serves the manual from a given directory by wrapping a filesystemrepository and the api docs from a given jar file by wrapping a jarrepository
create an builddochandler that serves the manual from a given directory by wrapping a filesystemrepository and the api docs from a given jar file by wrapping a jarrepository .
create an builddochandler that serves documentation from a given jar file by wrapping a jarrepository .
###insert : import static net . logstash . logback . marker . markers . append ;
#logging - log - info - with - async - request - context
consumes the data .
create an entity from the given content .
create an entity from the given string .
convert the given source of bytestrings to a chunked entity .
#bind
#bind
generates a simple result .
generates a simple result .
generates a simple result with json content and utf8 encoding .
generates a simple result with json content .
generates a simple result with byte - array content .
generates a chunked result .
generates a result with file contents .
generates a result .
generates a result .
generates a result with path contents .
generates a result with path contents .
generates a result .
generates a 200 ok result .
generates a 200 ok result .
generates a 200 ok result .
generates a 200 ok result .
generates a 200 ok result .
generates a 200 ok result .
generates a 200 ok result .
generates a 201 created result .
generates a 201 created result .
generates a 201 created result .
generates a 201 created result .
generates a 201 created result .
generates a 201 created result .
generates a 201 created result .
generates a 400 bad request result .
generates a 400 bad request result .
generates a 400 bad request result .
generates a 400 bad request result .
generates a 400 bad request result .
generates a 400 bad request result .
generates a 400 bad request result .
generates a 401 unauthorized result .
generates a 401 unauthorized result .
generates a 401 unauthorized result .
generates a 401 unauthorized result .
generates a 401 unauthorized result .
generates a 401 unauthorized result .
generates a 401 unauthorized result .
generates a 402 payment required result .
generates a 402 payment required result .
generates a 402 payment required result .
generates a 402 payment required result .
generates a 402 payment required result .
generates a 402 payment required result .
generates a 402 payment required result .
generates a 403 forbidden result .
generates a 403 forbidden result .
generates a 403 forbidden result .
generates a 403 forbidden result .
generates a 403 forbidden result .
generates a 403 forbidden result .
generates a 403 forbidden result .
generates a 404 not found result .
generates a 404 not found result .
generates a 404 not found result .
generates a 404 not found result .
generates a 404 not found result .
generates a 404 not found result .
generates a 404 not found result .
generates a 406 not acceptable result .
generates a 406 not acceptable result .
generates a 406 not acceptable result .
generates a 406 not acceptable result .
generates a 406 not acceptable result .
generates a 406 not acceptable result .
generates a 406 not acceptable result .
generates a 415 unsupported media type result .
generates a 415 unsupported media type result .
generates a 415 unsupported media type result .
generates a 415 unsupported media type result .
generates a 415 unsupported media type result .
generates a 415 unsupported media type result .
generates a 415 unsupported media type result .
generates a 428 precondition required result .
generates a 428 precondition required result .
generates a 428 precondition required result .
generates a 428 precondition required result .
generates a 428 precondition required result .
generates a 428 precondition required result .
generates a 428 precondition required result .
generates a 429 too many requests result .
generates a 429 too many requests result .
generates a 429 too many requests result .
generates a 429 too many requests result .
generates a 429 too many requests result .
generates a 429 too many requests result .
generates a 429 too many requests result .
generates a 431 request header fields too large result .
generates a 431 request header fields too large result .
generates a 431 request header fields too large result .
generates a 431 request header fields too large result .
generates a 431 request header fields too large result .
generates a 431 request header fields too large result .
generates a 431 request header fields too large result .
generates a 500 internal server error result .
generates a 500 internal server error result .
generates a 500 internal server error result .
generates a 500 internal server error result .
generates a 500 internal server error result .
generates a 500 internal server error result .
generates a 500 internal server error result .
generates a 511 network authentication required result .
generates a 511 network authentication required result .
generates a 511 network authentication required result .
generates a 511 network authentication required result .
generates a 511 network authentication required result .
generates a 511 network authentication required result .
generates a 511 network authentication required result .
generates a 301 moved permanently result .
generates a 301 moved permanently result .
generates a 302 found result .
generates a 302 found result .
generates a 303 see other result .
generates a 303 see other result .
generates a 303 see other result .
generates a 307 temporary redirect result .
generates a 307 temporary redirect result .
generates a 308 permanent redirect result .
generates a 308 permanent redirect result .
#bind
designed to be lightweight operation
select a preferred language given the list of candidates .
append a unique identifier to the url .
returns a new call with the given fragment .
transform this call to an absolute url .
transform this call to an websocket url .
create a scala function wrapper for connectionrunnable .
create a scala function wrapper for connectioncallable .
#show - page - action
create a server for the given router .
create a server for the given router .
create a server for the router returned by the given block .
#javascript - router - resource
converts an object to jsonnode .
converts a jsonnode to a java value
parses a string representing a json and return it as a jsonnode .
parses a inputstream representing a json and return it as a jsonnode .
signs the given string using the given key . <br >
generates a javascript reverse router .
generates a javascript reverse router .
generates a javascript reverse router .
returns a new array whose entries do not contain container annotations anymore but the indirectly present annotation ( s ) a container annotation was wrapping instead . an annotation is considered a container annotation if its indirectly present annotation ( s ) are annotated with { @link repeatable } . annotations inside the given array which don t meet the above definition of a container annotations will be returned untouched .
if the return type of an existing { @code value () } method of the passed annotation is an { @code annotation [] } array and the annotations inside that { @code annotation [] } array are annotated with the { @link repeatable } annotation the annotations of that array will be returned . if the passed annotation does not have a { @code value () } method or the above criteria are not met an empty list will be returned instead .
create a path to targetpath that s relative to the given startpath .
create a canonical path that does not contain parent directories current directories or superfluous directory separators .
#hello - world - hello - correct - action
converts a set of constraints to human - readable values . does not guarantee the order of the returned constraints .
converts a set of constraints to human - readable values in guaranteed order . only constraints that have an annotation that intersect with the { @code orderedannotations } parameter will be considered . the order of the returned constraints corresponds to the order of the { @code orderedannotations parameter } .
converts a constraint to a human - readable value .
#jpa - withtransaction - function
#jpa - withtransaction - consumer
creates a completionstage that returns either the input stage or a futures .
an alias for futures ( stage delay unit ) that uses a java . time . duration .
create a completionstage which after a delay will be redeemed with the result of a given supplier . the supplier will be called after the delay .
create a completionstage which after a delay will be redeemed with the result of a given supplier . the supplier will be called after the delay .
checks if an array of classes can be assigned to another array of classes .
parses a cron expression .
compute the number of milliseconds between the next valid date and the one after .
creates ws client manually from configuration internally creating a new instance of asynchttpclient and managing its own thread pool .
#inject
construct a builder to use for loading the given context .
identify some bindings that should be used as overrides when loading an application using this context . the default implementation of this method provides bindings that most applications should include .
generates a 501 not_implemented simple result .
puts a new value into the current session .
puts a new value into the flash scope .
#pass - arg - action - index
qualify this binding key with the given instance of an annotation .
qualify this binding key with the given annotation .
bind this binding key to the given implementation class .
bind this binding key to the given provider instance .
bind this binding key to the given instance .
bind this binding key to another binding key .
bind this binding key to the given provider class .
returns a configured {
create a lang value from a code ( such as fr or en - us ) .
retrieve lang availables from the application configuration .
guess the preferred lang in the langs set passed as argument . the first lang that matches an available lang wins otherwise returns the first lang available in this application .
create an evolutions reader that reads evolution files from a classloader .
create an evolutions reader that reads evolution files from a classloader .
create an evolutions reader based on a simple map of database names to evolutions .
create an evolutions reader for the default database from a list of evolutions .
apply evolutions for the given database .
apply evolutions for the given database .
cleanup evolutions for the given database .
set the initial configuration loader . overrides the default or any previously configured values .
set the module loader . overrides the default or any previously configured values .
override the module loader with the given guiceable modules .
override the module loader with the given guice modules .
override the module loader with the given play modules .
override the module loader with the given play bindings .
implementation of self creation for guicebuilder .
encodes the specified cookie into a cookie header value .
encodes the specified cookies into a single cookie header value .
encodes the specified cookies into a single cookie header value .
get the default entitymanager for this thread .
get the entitymanager stack .
pushes or pops the entitymanager stack depending on the value of the em argument . if em is null then the current entitymanager is popped . if em is non - null then em is pushed onto the stack and becomes the current entitymanager .
#person - class
#xml - hello
#xml - hello - bodyparser
bypass the given flow using the given splitter function .
using the given splitter flow allow messages to bypass a flow .
create a flow that is handled by an actor .
binds request data to this form - that is handles form submission .
binds request data to this form - that is handles form submission .
binds request data to this form - that is handles form submission .
binds request data to this form - that is handles form submission .
binds json data to this form - that is handles form submission .
binds json data to this form - that is handles form submission .
when dealing with @validatewith or @validatepayloadwith annotations and message parameter is not used in the annotation extract the message from validator s geterrormessagekey () method
binds data to this form - that is handles form submission .
binds data to this form - that is handles form submission .
binds data to this form - that is handles form submission .
convert the error arguments .
populates this form with an existing value used for edit forms .
retrieve all global errors - errors without a key .
returns the form errors serialized as json using the given lang .
gets the concrete value only if the submission was a success . if the form is invalid because of validation errors this method will throw an exception . if you want to retrieve the value even when the form is invalid use { @link #value () } instead .
retrieves a field .
a copy of this form with the given lang set which is used for formatting when retrieving a field ( via {
sets the locale of the current request ( if there is one ) into spring s localecontextholder .
gets the concrete value only if the submission was a success . if the form is invalid because of validation errors or you try to access a file field this method will return null . if you want to retrieve the value even when the form is invalid use { @link #value ( string ) } instead . if you want to retrieve a file field use { @link #file ( string ) } instead .
gets the concrete value only if the submission was a success . if the form is invalid because of validation errors or you try to access a non - file field this method will return null . if you want to retrieve the value even when the form is invalid use { @link #value ( string ) } instead . if you want to retrieve a non - file field use { @link #get ( string ) } instead .
gets the concrete value
fills the form with existing data .
-- tools
parses this string as instance of the given class .
parses this string as instance of a specific field
computes the display string for any value .
computes the display string for any value for a specific field .
computes the display string for any value for a specific type .
converter for string - > optional and optional - > string
registers a simple formatter .
registers an annotation - based formatter .
encodes the specified cookie into a set - cookie header value .
batch encodes cookies into set - cookie header values .
batch encodes cookies into set - cookie header values .
batch encodes cookies into set - cookie header values .
decodes the specified set - cookie http header value into a { @link cookie } .
returns the stream as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the stream as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the path as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the path as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the path as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the path as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the file as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the file as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the file as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the stream as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
returns the stream as a result considering range header . if the header is present and it is satisfiable then a result containing just the requested part will be returned . if the header is not present or is unsatisfiable then a regular result will be returned .
select all nodes that are selected by this xpath expression . if multiple nodes match multiple nodes will be returned . nodes will be returned in document - order
converts a java list to scala seq .
converts a java array to scala seq .
converts a java varargs to scala varargs .
acceptor for json websockets .
helper to create handlers for websockets .
returns whether a { @link member } is accessible .
xxx default access superclass workaround .
compares the relative fitness of two constructors in terms of how well they match a set of runtime parameter types such that a list ordered by the results of the comparison would return the best match first ( least ) .
compares the relative fitness of two methods in terms of how well they match a set of runtime parameter types such that a list ordered by the results of the comparison would return the best match first ( least ) .
compares the relative fitness of two executables in terms of how well they match a set of runtime parameter types such that a list ordered by the results of the comparison would return the best match first ( least ) .
gets the number of steps required to promote a primitive number to another type .
returns the sum of the object transformation cost for each class in the source argument list .
gets the number of steps required needed to turn the source class into the destination class . this represents the number of steps in the object hierarchy graph .
#explicit - messages - api
get the message at the given key .
get the message at the first defined key .
create a pooled database with the given configuration .
create a pooled database with the given configuration .
create a pooled database named default with the given configuration .
create an in - memory h2 database .
create an in - memory h2 database .
create an in - memory h2 database .
create an in - memory h2 database .
create an in - memory h2 database with name default and with extra configuration provided by the given entries .
create an in - memory h2 database with name default and with extra configuration provided by the given entries .
helper method to create a new <code > beanmap< / code > . for finer control over the generated instance use a new instance of <code > beanmap . generator< / code > instead of this static method .
todo : optimize
create a new parallelsorter object for a set of arrays . you may sort the arrays multiple times via the same parallelsorter object .
sort the arrays using the quicksort algorithm .
sort the arrays using an in - place merge sort .
todo : support constructor indices ( <init > )
todo
helper method to create an interface mixin . for finer control over the generated instance use a new instance of <code > mixin< / code > instead of this static method . todo
helper method to create an interface mixin . for finer control over the generated instance use a new instance of <code > mixin< / code > instead of this static method . todo
helper method to create a bean mixin . for finer control over the generated instance use a new instance of <code > mixin< / code > instead of this static method . todo
}
for internal use by {
return the <code > methodproxy< / code > used when intercepting the method matching the given signature .
invoke the original method on a different object of the same type .
invoke the original ( super ) method on the specified object .
casts from one primitive numeric type to another
pushes the specified argument of the current method onto the stack .
zero - based ( see load_this )
package - protected for emitutils try to fix
if the argument is a primitive class replaces the primitive value on the top of the stack with the wrapped ( object ) equivalent . for example char - > character . if the class is void a null is pushed onto the stack instead .
if the argument is a primitive class replaces the object on the top of the stack with the unwrapped ( primitive ) equivalent . for example character - > char .
allocates and fills an object [] array with the arguments to the current method . primitive values are inserted as their boxed ( object ) equivalents .
pushes a zero onto the stack if the argument is a primitive class or a null otherwise .
unboxes the object on the top of the stack . if the object is null the unboxed primitive value becomes zero .
process an array on the stack . assumes the top item on the stack is an array of the specified type . for each element in the array puts the element on the stack and triggers the callback .
branches to the specified label if the top two items on the stack are not equal . the items must both be of the specified class . equality is determined by comparing primitive values directly and by invoking the <code > equals< / code > method for objects . arrays are recursively processed in the same manner .
if both objects on the top of the stack are non - null does nothing . if one is null or both are null both are popped off and execution branches to the respective label .
/ * generates : } catch ( runtimeexception e ) { throw e ; } catch ( error e ) { throw e ; } catch ( <declaredexception > e ) { throw e ; } catch ( throwable e ) { throw new <wrapper > ( e ) ; }
finds all bridge methods that are being called with invokespecial & returns them .
set the class which the generated class will extend . as a convenience if the supplied superclass is actually an interface <code > setinterfaces< / code > will be called with the appropriate argument instead . a non - interface argument must not be declared as final and must have an accessible constructor .
set the array of callbacks to use . ignored if you use {
set the array of callback types to use . this may be used instead of {
generate a new class if necessary and uses the specified callbacks ( if any ) to create a new object instance . uses the constructor of the superclass matching the <code > argumenttypes< / code > parameter with the given arguments .
finds all of the methods that will be extended by an enhancer - generated class using the specified superclass and interfaces . this can be useful in building a list of callback objects . the methods are added to the end of the given list . due to the subclassing nature of the classes generated by enhancer the methods are guaranteed to be non - static non - final and non - private . each method signature will only occur once even if it occurs in multiple classes .
filter the list of constructors from the superclass . the constructors which remain will be included in the generated class . the default implementation is to filter out all private constructors but subclasses may extend enhancer to override this behavior .
determine if a class was generated using <code > enhancer< / code > .
instantiates a proxy instance and assigns callback values . implementation detail : java . lang . reflect instances are not cached so this method should not be used on a hot path . this method is used when { @link #setusecache ( boolean ) } is set to { @code false } .
helper method to create an intercepted object . for finer control over the generated instance use a new instance of <code > enhancer< / code > instead of this static method .
helper method to create an intercepted object . for finer control over the generated instance use a new instance of <code > enhancer< / code > instead of this static method .
helper method to create an intercepted object . for finer control over the generated instance use a new instance of <code > enhancer< / code > instead of this static method .
set the class which the generated class will extend . the class must not be declared as final and must have a non - private no - argument constructor .
to avoid jvm hashcode implementation incompatibilities
add a method signature to the interface . the method modifiers are ignored since interface methods are by definition abstract and public .
add all the public methods in the specified class . methods from superclasses are included except for methods declared in the base object class ( e . g . <code > getclass< / code > <code > equals< / code > <code > hashcode< / code > ) .
if bit 31 is set then this method results in an infinite loop .
override the default naming policy .
set the strategy to use to create the bytecode from this generator . by default an instance of {
loads entry to the cache . if entry is missing put {
used by methodinterceptorgenerated generated code
resolves subpath in safer way . for some reason if child starts with a separator it gets resolved as a full path ignoring the base . this method acts different .
reads path content .
sets request host name .
sets the destination ( method host port ... ) at once .
generic request builder usually used when method is a variable . otherwise use one of the other static request builder methods .
builds a connect request .
builds a get request .
builds a post request .
builds a put request .
builds a patch request .
builds a delete request .
builds a head request .
builds a trace request .
builds an options request .
sets request path . query string is allowed . adds a slash if path doesn t start with one . query will be stripped out from the path . previous query is discarded .
sets cookies to the request .
adds query parameter .
adds many query parameters at once . although it accepts objects each value will be converted to string .
adds all parameters from the provided map .
sets query from provided query string . previous query values are discarded .
generates query string . all values are url encoded .
returns full url path . simply concatenates {
returns just host url without path and query .
enables basic authentication by adding required header .
sets host header from current host and port .
opens a new {
assignees provided {
continues using the same keep - alive connection . don t use any variant of <code > open () < / code > when continuing the communication! first it checks if connection header exist in the response and if it is equal to keep - alive value . then it checks the keep - alive headers max parameter . if its value is positive then the existing { @link jodd . http . httpconnection } from the request will be reused . if max value is 1 connection will be sent with connection : close header indicating its the last request . when new connection is created the same { @link jodd . http . httpconnectionprovider } that was used for creating initial connection is used for opening the new connection .
{
prepares the request buffer .
syntax sugar .
creates new { @link session } with or without custom { @link properties } .
copies properties from given set . if { @link session } is already created exception will be thrown .
sets property for the { @link session } . if { @link session } is already created an exception will be thrown .
add new error message to the {
removes the range between start and end from the handler list that begins with the given element .
returns the number of elements of the handler list that begins with the given element .
puts the jvms exception_table corresponding to the handler list that begins with the given element . <i > this includes the exception_table_length field . < / i >
collects all interceptors .
collects all filters .
collects all action results .
collects all action runtime configurations .
resolves nested property name to the very last indexed property . if forced <code > null< / code > or non - existing properties will be created .
---------------------------------------------------------------- simple property
sets a value of simple property .
---------------------------------------------------------------- indexed property
get non - nested property value : either simple or indexed property . if forced missing bean will be created if possible .
sets indexed or regular properties ( no nested! ) .
---------------------------------------------------------------- set
returns value of bean s property .
---------------------------------------------------------------- has
---------------------------------------------------------------- type
extract the first name of this reference .
returns buffered writer . buffer will be created if not already used .
resets the builder so it can be used again . not everything is reset : object references and column alias type is not .
saves object reference .
returns object reference .
lookups for object reference and throws an exception if reference doesn t exist .
returns entity descriptor for provided table reference .
finds entity descriptor of a table that contains provided column reference .
returns table alias for provided table reference .
registers table reference for provided entity .
adds query parameter .
lookups for entity name and throws exception if entity name not found .
lookups for table reference and throws an exception if table reference not found .
defines parameter with name and its value .
registers a hint .
detects circular dependencies and pushes value as current type context .
---------------------------------------------------------------- inject
injects request attributes .
inject request parameters .
inject uploaded files from multipart request parameters .
---------------------------------------------------------------- outject
converts property name to column name .
converts column name to property name .
applies column naming strategy to given column name hint . returns full column name .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
stores value in database . value is casted to sql type .
once when value is read from result set prepare it to match destination type .
returns all action wrappers . returns a copy in new set .
resolves single wrapper . creates new wrapper instance if not already registered . does not expand the wrappers .
resolves wrappers . unregistered wrappers will be registered . returned array may be different size than size of provided array due to {
replaces all {
creates new wrapper .
concatenates a filename to a base path using normal command line style rules . <p > the effect is equivalent to resultant directory after changing directory to the first argument followed by changing directory to the second argument . <p > the first argument is the base path the second is the path to concatenate . the returned path is always normalized via { @link #normalize ( string ) } thus <code > .. < / code > is handled . <p > if <code > pathtoadd< / code > is absolute ( has an absolute prefix ) then it will be normalized and returned . otherwise the paths will be joined normalized and returned . <p > the output will be the same on both unix and windows except for the separator character . <pre > { @code / foo / + bar -- > / foo / bar / foo + bar -- > / foo / bar / foo + / bar -- > / bar / foo + c : / bar -- > c : / bar / foo + c : bar -- > c : bar ( * ) / foo / a / + .. / bar -- > foo / bar / foo / + .. / .. / bar -- > null / foo / + / bar -- > / bar / foo / .. + / bar -- > / bar / foo + bar / c . txt -- > / foo / bar / c . txt / foo / c . txt + bar -- > / foo / c . txt / bar ( ! ) } < / pre > ( * ) note that the windows relative drive prefix is unreliable when used with this method . ( ! ) note that the first parameter must be a path . if it ends with a name then the name will be built into the concatenated path . if this might be a problem use { @link #getfullpath ( string ) } on the base path argument .
converts all separators to the system separator .
returns the index of the last directory separator character . <p > this method will handle a file in either unix or windows format . the position of the last forward or backslash is returned . <p > the output will be the same irrespective of the machine that the code is running on .
does the work of getting the path .
splits filename into a array of four strings containing prefix path basename and extension . path will contain ending separator .
resolve <code > ~< / code > in the path .
calculates relative path of target path on base path .
---------------------------------------------------------------- visitor
registers additional madvoc components after the registration of default components .
registers madvoc component <i > instance< / i > . use with caution as injection of components registered after this will fail .
configures the action configurations .
configures a component . while the signature is the same as for {
initializes and starts web application .
configure defaults .
registers default madvoc components .
specify excluded jars .
specify included jars .
sets included set of names that will be considered during configuration .
sets excluded names that narrows included set of packages .
returns <code > true< / code > if some jar file has to be accepted .
scans classes inside single jar archive . archive is scanned as a zip file .
scans single classpath directory .
prepares resource and class names . for classes it strips . class from the end and converts all ( back ) slashes to dots . for resources it replaces all backslashes to slashes .
if entry name is {
returns type signature bytes used for searching in class file .
scans urls . if ( #ignoreexceptions } is set exceptions per one url will be ignored and loops continues .
scans provided paths .
starts with the scanner .
returns string characters in most performing way . if possible the inner <code > char [] < / code > will be returned . if not <code > tochararray () < / code > will be called . returns <code > null< / code > when argument is <code > null< / code > .
{
builds new transaction instance .
lookups the scope instance of given scope annotation . if instance does not exist it will be created cached and returned .
performs search for the scope class and returns it s instance .
finds a given scope and consumes it .
parses { @link message } and extracts all data for the received message .
process part of the received message . all parts are simply added to the { @link receivedemail } i . e . hierarchy is not saved .
process the { @link multipart } .
adds string content as either { @link emailattachment } or as { @link emailmessage } .
returns the content - id of this { @link part } . returns { @code null } if none present .
returns { @code true } if the { @link part } is inline .
adds received attachment .
adds received attachment .
creates { @link emailattachmentbuilder } from { @link part } and sets content id inline and name .
encodes a raw byte array into a base64 <code > char [] < / code > .
decodes a base64 encoded char array .
encodes a raw byte array into a base64 <code > char [] < / code > .
---------------------------------------------------------------- string
generates new csrf token and puts it in the session . returns generated token value .
removes expired tokens if token set is full .
checks if {
checks token value . c
creates <code > beancopy< / code > with given <code > map< / code > as a source .
defines source detects a map .
performs the copying .
copies single property to the destination . exceptions are ignored so copying continues if destination does not have some of the sources properties .
parses content using lagarto and {
resolves and registers table references .
resolves and registers scope from a scope type .
creates new instance of given type . in the first try it tries to use constructor with a {
registers new scope . it is not necessary to manually register scopes since they become registered on first scope resolving . however it is possible to pre - register some scopes or to <i > replace< / i > one scope type with another . replacing may be important for testing purposes when using container - depended scopes .
lookups for {
lookups for first founded {
lookups for existing {
creates {
creates {
registers a bean using provided class that is annotated .
registers a bean using provided class that is annotated .
registers or defines a bean .
registers bean definition by putting it in the beans map . if bean does not have petite name explicitly defined alternative bean names will be registered .
removes all petite beans of provided type . bean name is not resolved from a type! instead all beans are iterated and only beans with equal types are removed .
removes bean and returns definition of removed bean . all resolvers references are deleted too . returns bean definition of removed bean or <code > null< / code > .
resolves bean names for give type .
registers constructor injection point .
registers property injection point .
registers set injection point .
registers method injection point .
registers init method .
registers destroy method .
registers instance method provider .
registers static method provider .
iterates all beans . iteration occurs over the {
iterates all beans that are of given type .
defines many parameters at once .
defines many parameters at once from {
returns the value in the current classloader copy of this variable . if the variable has no value for the current classloader it is first initialized to the value returned by an invocation of the initialvalue () method .
sets the current classloaders s copy of this variable to the specified value . most subclasses will have no need to override this method relying solely on the initialvalue () method to set the values of classloader - locals .
{
{
{
{
measure action invocation time .
prints out the message . user can override this method and modify the way the message is printed .
prints out the message . user can override this method and modify the way the message is printed .
resolves java version from current version .
pushes int value in an optimal way .
validates argument index .
builds advice field name .
builds advice method name .
---------------------------------------------------------------- load
loads all method arguments before invokespecial call .
loads all method arguments before invokestatic call .
loads all method arguments before invokevirtual call .
loads one argument . index is 1 - based . no conversion occurs .
stores one argument . index is 1 - based . no conversion occurs .
returns <code > true< / code > if opcode is xstore .
visits return opcodes .
prepares return value .
creates unique key for method signatures map .
visits non - array element value for annotation . returns <code > true< / code > if value is successfully processed .
creates new array .
stores element on stack into an array .
---------------------------------------------------------------- detect advice macros
lookups the decorator for given decorator path . returns {
resolves decorator path based on request and action path . if decorator is not found returns <code > null< / code > . by default applies decorator on all * . html pages .
todo : should this always return lowercase or always uppercase?
todo : should this always return lowercase or always uppercase?
extracts encoding from a given content type .
correctly resolves file name from the message part . thanx to : flavio pompermaier
check whether flags is a empty flags
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
returns <code > true< / code > if a request is multi - part request .
decodes the authorization header and retrieves the user s name from it . returns <code > null< / code > if the header is not present .
returns bearer token .
sends correct headers to require basic authentication for the given realm .
prepares response for file download with provided mime type .
prepares response for various provided data .
returns all cookies from client that matches provided name .
reads http request body using the request reader . once body is read it cannot be read again!
reads http request body using the request stream . once body is read it cannot be read again!
returns correct context path as by servlet definition . different application servers return all variants : null / . <p > the context path always comes first in a request uri . the path starts with a / character but does not end with a / character . for servlets in the default ( root ) context this method returns .
returns correct context path as by servlet definition . different application servers return all variants : null / . <p > the context path always comes first in a request uri . the path starts with a / character but does not end with a / character . for servlets in the default ( root ) context this method returns .
stores context path in server context and request scope .
stores context path in page context and request scope .
returns non - <code > null< / code > attribute value . scopes are examined in the following order : request session application .
returns value of property / attribute . the following value sets are looked up : <ul > <li > page context attributes< / li > <li > request attributes< / li > <li > request parameters ( multi - part request detected ) < / li > <li > session attributes< / li > <li > context attributes< / li > < / ul >
returns value of property / attribute . the following value sets are looked up : <ul > <li > request attributes< / li > <li > request parameters ( multi - part request detected ) < / li > <li > session attributes< / li > <li > context attributes< / li > < / ul >
sets scope attribute .
removes scope attribute .
returns <code > true< / code > if current url is absolute <code > false< / code > otherwise .
strips a servlet session id from <code > url< / code > . the session id is encoded as a url path parameter beginning with jsessionid = . we thus remove anything we find between ; jsessionid = ( inclusive ) and either eos or a subsequent ; ( exclusive ) .
returns http request parameter as string or string [] .
checks if some parameter is in get parameters .
prepares parameters for further processing .
returns {
copies all request parameters to attributes .
invokes tag body .
renders tag body to char array .
renders tag body to string .
sets scope attribute .
removes scope attribute .
invokes init methods .
calls destroy methods on given beandata . destroy methods are called without any order .
creates a new instance .
injects all parameters .
rewrites action path .
---------------------------------------------------------------- configure
---------------------------------------------------------------- valid
adds new header value . if existing value exist it will be removed so the store the new key value .
---------------------------------------------------------------- configure
---------------------------------------------------------------- valid
puts key - value pair into the map with respect of appending duplicate properties
adds base property .
counts profile properties . note : this method is not that easy on execution .
adds profile property .
returns profile property .
lookup props value through profiles and base properties . returns {
resolves all macros in this props set . called on property lookup .
extracts props to target map . this is all - in - one method that does many things at once .
cycically extract a word of key material .
hash a password using the openbsd bcrypt scheme .
check that a plaintext password matches a previously hashed one .
reads data header from the input stream . when there is no more headers ( i . e . end of stream reached ) returns <code > null< / code >
copies bytes from this stream to some output until boundary is reached . returns number of copied bytes . it will throw an exception for any irregular behaviour .
copies max or less number of bytes to output stream . useful for determining if uploaded file is larger then expected .
parses action class and method and creates {
parses java action method annotation and returns its action runtime .
resolves action config .
detects if alias is defined in annotation and registers it if so .
reads class or method annotation for action interceptors .
reads class or method annotation for action filters .
reads action path for package . if annotation is not set on package - level class package will be used for package action path part .
reads action path from class . if the class is annotated with {
reads action path from the action method .
reads method s alias value .
reads method s http method or {
creates new instance of action runtime configuration . initialize caches .
{
{
todo move to bufferresponsewrapper ?
converts value to <code > boolean< / code > .
converts value to <code > boolean< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > boolean< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > integer< / code > .
converts value to <code > integer< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > int< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > long< / code > .
converts value to <code > long< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > long< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > float< / code > .
converts value to <code > float< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > float< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > double< / code > .
converts value to <code > double< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > double< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > short< / code > .
converts value to <code > short< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > short< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > character< / code > .
converts value to <code > character< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > char< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > byte< / code > .
converts value to <code > byte< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > byte< / code > . returns default value when conversion result is <code > null< / code > .
converts value to <code > long [] < / code > .
converts value to <code > string [] < / code > .
converts value to <code > class< / code > .
converts value to <code > biginteger< / code > .
converts value to <code > biginteger< / code > . returns default value when conversion result is <code > null< / code >
converts value to <code > bigdecimal< / code > .
converts value to <code > bigdecimal< / code > . returns default value when conversion result is <code > null< / code >
---------------------------------------------------------------- configure
configures {
registers a class consumer that registers only those annotated with {
applies advice on given target class and returns proxy instance .
injects target into proxy .
visits an annotation of the field .
resolves real name from json name .
resolves json name from real name .
returns all includes for given type . returns an empty array when no includes are defined .
lookups type data and creates one if missing .
finds type data of first annotated superclass or interface .
returns different name of a property if set by annotation .
returns real property name for given json property .
scans class for annotations and returns {
---------------------------------------------------------------- process
returns the content of file upload item .
read the bootstrapmethods bootstrap_methods array binary content and add them as entries of the symboltable .
sets the major version and the name of the class to which this symbol table belongs . also adds the class name to the constant pool .
puts this symbol table s constant_pool array in the given bytevector preceded by the constant_pool_count value .
puts this symbol table s bootstrapmethods attribute in the given bytevector . this includes the 6 attribute header bytes and the num_bootstrap_methods value .
puts the given entry in the { @link #entries } hash set . this method does <i > not< / i > check whether { @link #entries } already contains a similar entry or not . { @link #entries } is resized if necessary to avoid hash collisions ( multiple entries needing to be stored at the same { @link #entries } array index ) as much as possible with reasonable memory usage .
adds the given entry in the { @link #entries } hash set . this method does <i > not< / i > check whether { @link #entries } already contains a similar entry or not and does <i > not< / i > resize { @link #entries } if necessary .
adds a constant_fieldref_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a constant_methodref_info or constant_interfacemethodref_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a constant_fieldref_info constant_methodref_info or constant_interfacemethodref_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_fieldref_info constant_methodref_info or constant_interfacemethodref_info to the constant pool of this symbol table .
adds a constant_integer_info or constant_float_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_integer_info or constant_float_info to the constant pool of this symbol table .
adds a constant_long_info or constant_double_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_long_info or constant_double_info to the constant pool of this symbol table .
adds a constant_nameandtype_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_nameandtype_info to the constant pool of this symbol table .
adds a constant_utf8_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_string_info to the constant pool of this symbol table .
adds a constant_methodhandle_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_methodhandle_info to the constant pool of this symbol table .
adds a constant_dynamic_info to the constant pool of this symbol table . also adds the related bootstrap method to the bootstrapmethods of this symbol table . does nothing if the constant pool already contains a similar item .
adds a constant_invokedynamic_info to the constant pool of this symbol table . also adds the related bootstrap method to the bootstrapmethods of this symbol table . does nothing if the constant pool already contains a similar item .
adds a constant_dynamic or a constant_invokedynamic_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_dynamic_info or constant_invokedynamic_info to the constant pool of this symbol table .
adds a constant_class_info constant_string_info constant_methodtype_info constant_module_info or constant_package_info to the constant pool of this symbol table . does nothing if the constant pool already contains a similar item .
adds a new constant_class_info constant_string_info constant_methodtype_info constant_module_info or constant_package_info to the constant pool of this symbol table .
adds a bootstrap method to the bootstrapmethods attribute of this symbol table . does nothing if the bootstrapmethods already contains a similar bootstrap method .
adds a bootstrap method to the bootstrapmethods attribute of this symbol table . does nothing if the bootstrapmethods already contains a similar bootstrap method ( more precisely reverts the content of { @link #bootstrapmethods } to remove the last duplicate bootstrap method ) .
adds a merged type in the type table of this symbol table . does nothing if the type table already contains a similar type .
adds the given type symbol to { @link #typetable } .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
calculates hash value of the input string .
returns <code > true< / code > if two names are the same .
clears the map .
---------------------------------------------------------------- set / add
---------------------------------------------------------------- remove
returns the first value from the map associated with the name . returns <code > null< / code > if name does not exist or if associated value is <code > null< / code > .
returns first entry for given name . returns <code > null< / code > if entry does not exist .
returns all values associated with the name .
returns iterator of all entries .
returns all the entries of this map . case sensitivity does not influence the returned list it always contains all of the values .
grows the buffer .
appends single {
appends another fast buffer to this one .
appends character sequence to buffer .
copies target method annotations .
finally builds proxy methods if applied to current method .
starts creation of first chain delegate .
continues the creation of the very first method in calling chain that simply delegates invocation to the first proxy method . this method mirrors the target method .
creates proxy methods over target method for each matched proxy new proxy method is created by taking advice bytecode and replaces usages of {
parses input dot - separated string that represents a path .
push element to the path .
alternative way for registering joy listeners . sometimes servlet container does not allow adding new listener from already added listener . this method therefore registers the listener <i > before< / i > container actually called the callback methods .
creates {
configures servlet context .
---------------------------------------------------------------- integer
---------------------------------------------------------------- boolean
---------------------------------------------------------------- byte
---------------------------------------------------------------- doublw
---------------------------------------------------------------- float
---------------------------------------------------------------- string
---------------------------------------------------------------- long
reads method name and appends it . creates object for next call and returns that value . if next object is unsupported it will return null ;
inspects fields and returns map of {
returns all fields of this collection . returns empty array if no fields exist . initialized lazy .
{
{
applies proxetta on bean class before bean registration .
converter jtx transaction mode to db transaction mode .
{
{
reads property value and {
invoked on serializable properties that have passed all the rules . property type is <code > null< / code > for metadata class name property .
reads property using property descriptor .
returns <code > true< / code > if first argument contains provided element . it works for strings collections maps and arrays . s
creates eml string from given { @link email } .
creates eml string from given { @link receivedemail } .
appends another fast buffer to this one .
rehashes the contents of this map into a new <code > inthashmap< / code > instance with a larger capacity . this method is called automatically when the number of keys in this map exceeds its capacity and load factor .
associates the specified value with the specified key in this map . if the map previously contained a mapping for this key the old value is replaced .
copies all of the mappings from the specified map to this one . these mappings replace any mappings that this map had for any of the keys currently in the specified map .
removes all mappings from this map .
appends another fast buffer to this one .
creates {
appends string content to buffer .
appends {
appends other buffer to this one .
writes content to the writer .
writes content to the output stream .
writes content to the output stream using progress listener to track the sending progress .
---------------------------------------------------------------- private
returns the string value with the specified key .
returns the integer value with the specified key .
returns the long value with the specified key .
returns the double value with the specified key .
returns the float value with the specified key .
returns the {
returns the {
returns the binary value with the specified key . <p > json itself has no notion of a binary . this extension complies to the rfc - 7493 . the byte array is base64 encoded binary .
returns the value with the specified key as an object .
like {
like {
like {
like {
like {
like {
like {
like {
like {
like {
puts an enum into the json object with the specified key . <p > json has no concept of encoding enums so the enum will be converted to a string using the {
puts an {
puts a string into the json object with the specified key .
puts a {
puts a {
returns array of all { @link folder } s as { @code string } s . you can use these names in { @link #usefolder ( string ) } method .
opens new folder and closes previously opened folder .
just returns a folder w / o opening .
receives all emails that matches given { @link emailfilter } . messages are not modified . however servers may set seen flag anyway so we force messages to remain unseen .
receives all emails that matches given { @link emailfilter } and mark them as seen ( ie read ) .
receives all emails that matches given { @link emailfilter } and mark all messages as seen and deleted .
the main email receiving method .
updates the email flags on the server .
closes folder if opened and expunge deleted messages .
lookup for named parameter .
returns the size of batch parameter . returns <code > 0< / code > if parameter does not exist .
---------------------------------------------------------------- parser
creates alias .
creates alias from target object and target method name . if classname contains a $ sign everything will be stripped after it ( to get the real name if action class is proxified ) .
validates action . profiles are reset after the invocation .
adds action violation .
returns <code > true< / code > if tag name is a void tag .
defines mime type by providing real mime type or just extension!
defines download file name and mime type from the name extension .
defines class input stream as a target .
defines class name as a target . class will not be loaded by classloader!
defines class as a target .
returns new suffix or <code > null< / code > if suffix is not in use .
reads the target and creates destination class .
returns byte array of created class .
defines class .
creates new instance of created class . assumes default no - arg constructor .
writes created class content to output folder for debugging purposes .
sets the from address by providing personal name and address .
appends to address .
appends to address by personal name and email address .
appends reply - to address .
appends reply - to address .
appends reply - to addresses .
appends cc address .
appends cc address .
appends cc addresses .
sets message subject with specified encoding to override default platform encoding . if the subject contains non us - ascii characters it will be encoded using the specified charset . if the subject contains only us - ascii characters no encoding is done and it is used as - is . the application must ensure that the subject does not contain any line breaks . see { @link javax . mail . internet . mimemessage#setsubject ( string string ) } .
adds a { @link emailmessage } .
adds plain message text .
adds html message .
sets header value .
sets headers .
sets headers .
adds { @link emailattachment } s .
adds { @link emailattachment } s .
adds { @link emailattachment } . content id will be set to { @code null } .
attaches the embedded attachment : content id will be set if missing from attachment s file name .
embed { @link emailattachment } to last message . no header is changed .
---------------------------------------------------------------- helper
returns system property . if key is not available returns the default value .
returns system property as boolean .
returns system property as an int .
returns system property as a long .
invokes parsing on {
invokes parsing on {
appends single {
appends {
appends another fast buffer to this one .
returns <code > true< / code > if type name equals param type .
returns method parameters once when method is parsed . if method has no parameters an empty array is returned .
serializes key and a value .
lookups value as an alias and if not found as a default alias .
returns resolved alias result value or passed on if alias doesn t exist .
resolves result path .
resolves result path as a string when parts are not important and when only full string matters . additional alias resolving on full path is done .
locates last dot after the last slash or just slash .
locates last index of dot after the optional last slash .
locates first dot after the last slash .
removes last camelword
returns matched name or <code > null< / code > if name is not matched . <p > matches if attribute name matches the required field name . if the match is positive injection is performed on the field . <p > parameter name matches field name if param name starts with field name and has either . or [ after the field name . <p > returns real property name once when name is matched .
encodes the {
decodes the string to the {
resolves table name from a type . if type is annotated table name will be read from annotation value . if this value is empty or if type is not annotated table name will be set to wildcard pattern * ( to match all tables ) .
resolves schema name from a type . uses default schema name if not specified .
returns <code > true< / code > if class is annotated with <code > dbtable< / code > annotation .
resolves column descriptor from property . if property is annotated value will be read from annotation . if property is not annotated then property will be ignored if entity is annotated . otherwise column name is generated from the property name .
resolves mapped types from {
---------------------------------------------------------------- privates
initialize the cipher using the key and the tweak value .
implementation of the e ( k t p ) function . the k and t values should be set previously using the init () method . this version is the 64 bit implementation of threefish .
implementation of the mix function .
implementation of the d ( k t c ) function . the k and t values should be set previously using the init () method . this version is the 64 bit implementation of threefish .
implementation of the un - mix function .
creates the subkeys .
initializes cipher in a simple way .
encrypts a block .
converts segment of byte array into long array .
converts char digit into integer value . accepts numeric chars ( 0 - 9 ) as well as letter ( a - z ) .
filter initialization .
builds {
parses email address . returns {
convenient shortcut of {
convenient shortcut of {
builds all regexp patterns .
---------------------------------------------------------------- utilities
given a string extract the first matched comment token as defined in 2822 trimmed ; return null on all errors or non - findings . <p > note for future improvement : if comment_pattern could handle nested comments then this should be able to as well but if this method were to be used to find the cfws personal name ( see boolean option ) then such a nested comment would probably not be the one you were looking for?
if the string starts and ends with start and end char remove them otherwise return the string as it was passed in .
wraps action class and returns <code > methref< / code > object ( proxified target ) so user can choose the method .
returns path value .
compresses a file into zlib archive .
compresses a file into gzip archive .
decompress gzip archive .
zips a file or a folder . if adding a folder all its content will be added .
lists zip content .
extracts zip file content to the target directory .
adds single entry to zip output stream .
adds byte content into the zip as a file .
returns field descriptor .
returns {
returns property descriptor . declared flag is matched on both read and write methods .
returns the default ctor or <code > null< / code > if not found .
returns the constructor identified by arguments or <code > null< / code > if not found .
sets bundle name for provided servlet request .
saves locale to http session .
returns current locale from session . s
creates new {
returns an array of param keys that belongs to provided bean . optionally resolves the value of returned parameters .
-----------------------------------------------------------------------------------------------
returns the size of a runtime [ in ] visible [ type ] annotations attribute containing this annotation and all its <i > predecessors< / i > ( see { @link #previousannotation } . also adds the attribute name to the constant pool of the class ( if not null ) .
puts a runtime [ in ] visible [ type ] annotations attribute containing this annotations and all its <i > predecessors< / i > ( see { @link #previousannotation } in the given bytevector . annotations are put in the same order they have been visited .
returns the size of a runtime [ in ] visibleparameterannotations attribute containing all the annotation lists from the given annotationwriter sub - array . also adds the attribute name to the constant pool of the class .
puts a runtime [ in ] visibleparameterannotations attribute containing all the annotation lists from the given annotationwriter sub - array in the given bytevector .
enables profiles to iterate .
gets a long from a byte buffer in little endian byte order .
returns the murmurhash3_x64_128 hash .
reads the given input stream and returns its content as a byte array .
returns the internal names of the implemented interfaces ( see { @link type#getinternalname () } ) .
makes the given visitor visit the jvms classfile structure passed to the constructor of this { @link classreader } .
reads the module modulepackages and modulemainclass attributes and visit them .
reads a jvms field_info structure and makes the given visitor visit it .
reads a jvms method_info structure and makes the given visitor visit it .
reads a jvms code attribute and makes the given visitor visit it .
returns the label corresponding to the given bytecode offset . the default implementation of this method creates a label for the given offset if it has not been already created .
creates a label without the { @link label#flag_debug_only } flag set for the given bytecode offset . the label is created with a call to { @link #readlabel } and its { @link label#flag_debug_only } flag is cleared .
creates a label with the { @link label#flag_debug_only } flag set if there is no already existing label for the given bytecode offset ( otherwise does nothing ) . the label is created with a call to { @link #readlabel } .
parses a runtime [ in ] visibletypeannotations attribute to find the offset of each type_annotation entry it contains to find the corresponding labels and to visit the try catch block annotations .
returns the bytecode offset corresponding to the specified jvms type_annotation structure or - 1 if there is no such type_annotation of if it does not have a bytecode offset .
parses the header of a jvms type_annotation structure to extract its target_type target_info and target_path ( the result is stored in the given context ) and returns the start offset of the rest of the type_annotation structure .
reads a runtime [ in ] visibleparameterannotations attribute and makes the given visitor visit it .
reads the element values of a jvms annotation structure and makes the given visitor visit them . this method can also be used to read the values of the jvms array_value field of an annotation s element_value .
reads a jvms element_value structure and makes the given visitor visit it .
computes the implicit frame of the method currently being parsed ( as defined in the given { @link context } ) and stores it in the given context .
reads a jvms stack_map_frame structure and stores the result in the given { @link context } object . this method can also be used to read a full_frame structure excluding its frame_type field ( this is used to parse the legacy stackmap attributes ) .
reads a jvms verification_type_info structure and stores it at the given index in the given array .
returns the offset in { @link #b } of the first classfile s attributes array field entry .
reads the bootstrapmethods attribute to compute the offset of each bootstrap method .
reads a non standard jvms attribute structure in { @link #b } .
reads a signed int value in { @link #b } . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
reads a signed long value in { @link #b } . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
dontcheck ( abbreviationaswordinname ) : can t be renamed ( for backward binary compatibility ) .
reads a constant_utf8 constant pool entry in { @link #b } .
reads an utf8 string in { @link #b } .
reads a constant_dynamic constant pool entry in { @link #b } .
reads a numeric or string constant pool entry in { @link #b } . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
{
{
sets content type . if charset is missing current value is reset . if passed value is <code > null< / code > content type will be reset as never set .
returns content type and optionally charset . returns <code > null< / code > when mime type is not set .
{
{
inspects all declared constructors of a target type .
finds constructor description that matches given argument types .
returns instance map from http request .
creates instance map and stores it in the request .
returns request from current thread .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
converts array value to array .
converts primitive array to target array .
initializes decora filter . loads manager and parser from init parameters .
registers file consumer
specifies the search path . if provided path contains {
specifies the search path . throws an exception if uri is invalid .
specifies the search path . throws an exception if url is invalid .
defines include patterns .
defines exclude patterns .
determine if file is accepted based on include and exclude rules . called on each file entry ( file or directory ) and returns <code > true< / code > if file passes search criteria . file is matched using {
resolves file path depending on {
adds existing search path to the file list . non existing files are ignored . if path is a folder it will be scanned for all files .
reset the search so it can be run again with very same parameters ( and sorting options ) .
finds the next file . returns founded file that matches search configuration or <code > null< / code > if no more files can be found .
finds all files and returns list of founded files .
initializes file walking . separates input files and folders .
returns file walking iterator .
{
{
resolves bean s auto - wire flag from the annotation . returns default auto - wire if annotation doesn t exist .
resolves bean s scope type from the annotation . returns <code > null< / code > if annotation doesn t exist .
resolves bean s name from bean annotation or type name . may be used for resolving bean name of base type during registration of bean subclass .
returns <code > true< / code > if bean has name defined by petite annotation .
returns a writer .
returns a servlet output stream .
returns the { @link type } corresponding to the given class .
returns the { @link type } corresponding to the given internal name .
returns the method { @link type } corresponding to the given argument and return types .
returns the { @link type } values corresponding to the argument types of the given method descriptor .
returns the { @link type } corresponding to the return type of the given method descriptor .
returns the { @link type } corresponding to the given field or method descriptor .
returns the binary name of the class corresponding to this type . this method must not be used on method types .
returns the descriptor corresponding to the given constructor .
returns the descriptor corresponding to the given argument and return types .
returns the descriptor corresponding to the given method .
appends the descriptor corresponding to this type to the given string buffer .
returns the size of values of this type . this method must not be used for method types .
computes the size of the arguments and of the return value of a method .
returns a jvm instruction opcode adapted to this { @link type } . this method must not be used for method types .
modify the transaction associated with the target object such that the only possible outcome of the transaction is to roll back the transaction .
performs either commit or rollback on all transaction resources .
commits all attached resources . on successful commit resource will be closed and detached from this transaction . on exception resource remains attached to transaction . <p > all resources will be committed even if commit fails on some in that process . if there was at least one failed commit its exception will be re - thrown after finishing committing all resources and transaction will be marked as rollback only .
rollbacks all attached resources . resource will be closed . and detached from this transaction . if exception occurs it will be rethrown at the end .
requests a resource . if resource is not found it will be created and new transaction will be started on it .
lookups for open resource . returns <code > null< / code > if resource not found . only open resources can be found .
stores name to temporary stack . used when name s value may or may not be serialized ( e . g . it may be excluded ) in that case we do not need to write the name .
writes stored name to json string . cleans storage .
writes object s property name : string and a colon .
write a quoted and escaped value to the output .
writes unicode representation of a character .
appends char sequence to the buffer . used for numbers nulls booleans etc .
sets parsing error log level as a name .
---------------------------------------------------------------- util methods
returns <code > true< / code > if provided tag matches decorator tag .
starts defining region by setting the start index and reset region length to zero .
returns <code > true< / code > if region of this decora tag is inside of region of provided decora tag .
returns true if attribute is containing some value .
registers pseudo function .
lookups pseudo function for given pseudo function name .
accepts node within selected results . invoked after results are matched .
creates destination subclass header from current target class . destination name is created from targets by adding a suffix and optionally a number . destination extends the target .
creates proxified methods and constructors . destination proxy will have all constructors as a target class using {
copies all destination type annotations to the target .
creates static initialization block that simply calls all advice static init methods in correct order .
creates init method that simply calls all advice constructor methods in correct order . this created init method is called from each destination s constructor .
checks for all public super methods that are not overridden .
check if proxy should be applied on method and return proxy method builder if so . otherwise returns <code > null< / code > .
matches pointcuts on method . if no pointcut found returns <code > null< / code > .
finds index of given element in inclusive index range . returns negative value if element is not found .
finds very first index of given element in inclusive index range . returns negative value if element is not found .
finds very last index of given element in inclusive index range . returns negative value if element is not found .
---------------------------------------------------------------- internal
returns chalked string .
-----------------------------------------------------------------------------------------------
returns the content of the class file that was built by this classwriter .
returns the equivalent of the given class file with the asm specific instructions replaced with standard ones . this is done with a classreader - &gt ; classwriter round trip .
returns the prototypes of the attributes used by this class its fields and its methods .
adds a handle to the constant pool of the class being build . does nothing if the constant pool already contains a similar item . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
adds a dynamic constant reference to the constant pool of the class being build . does nothing if the constant pool already contains a similar item . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
adds an invokedynamic reference to the constant pool of the class being build . does nothing if the constant pool already contains a similar item . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
adds a field reference to the constant pool of the class being build . does nothing if the constant pool already contains a similar item . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
adds a method reference to the constant pool of the class being build . does nothing if the constant pool already contains a similar item . <i > this method is intended for { @link attribute } sub classes and is normally not needed by class generators or adapters . < / i >
returns the common super type of the two given types . the default implementation of this method <i > loads< / i > the two given classes and uses the java . lang . class methods to find the common super class . it can be overridden to compute this common super type in other ways in particular without actually loading any class or to take into account the class that is currently being generated by this classwriter which can of course not be loaded since it is under construction .
registers default set of sql types .
registers sql type for provided type .
retrieves sql type for provided type . all subclasses and interfaces are examined for matching sql type .
returns sql type instance . instances are stored for better performances .
creates socks4 proxy .
creates socks5 proxy .
creates http proxy .
returns total number of transactions associated with current thread .
returns total number of transactions of the specified status associated with current thread .
returns <code > true< / code > if provided transaction is associated with current thread .
removes transaction association with current thread . transaction should be properly handled ( committed or rolledback ) before removing from current thread . also removes thread list from this thread .
returns last transaction associated with current thread or <code > null< / code > when thread has no associated transactions created by this transaction manager .
associate transaction to current thread .
creates new {
requests transaction with specified {
returns <code > true< / code > if scope is specified and it is different then of existing transaction .
check if propagation of a transaction is possible due to source and destination transaction modes .
propagation : required <pre > {
propagation : requires_new <pre > {
propagation : supports <pre > {
propagation : mandatory <pre > {
propagation : not_supported <pre > {
propagation : never <pre > {
registers new {
lookups resource manager for provided type . throws an exception if provider doesn t exists .
closes transaction manager . all registered {
creates proxy object .
appends method name to existing path .
static factory of next target . it handles special cases of maps sets and lists . in case target can not be proxified ( like for java classes ) it returns <code > null< / code > .
----------------------------------------------------------------------- apache commons codec - base64
puts the text to the left and pads with spaces until the size is reached .
formats byte size to human readable bytecount . https : // stackoverflow . com / questions / 3758606 / how - to - convert - byte - size - into - human - readable - format - in - java / 3758880#3758880
converts object into pretty string . all arrays are iterated .
changes camelcase string to lower case words separated by provided separator character . the following translations are applied : <ul > <li > every upper case letter in the camelcase name is translated into two characters a separator and the lower case equivalent of the target character with three exceptions . <ol > <li > for contiguous sequences of upper case letters characters after the first character are replaced only by their lower case equivalent and are not preceded by a separator ( <code > thefoo< / code > to <code > the_foo< / code > ) . <li > an upper case character in the first position of the camelcase name is not preceded by a separator character and is translated only to its lower case equivalent . ( <code > foo< / code > to <code > foo< / code > and not <code > _foo< / code > ) <li > an upper case character in the camelcase name that is already preceded by a separator character is translated only to its lower case equivalent and is not preceded by an additional separator . ( <code > user_name< / code > to <code > user_name< / code > and not <code > user__name< / code > . < / ol > <li > if the camelcase name starts with a separator then that separator is not included in the translated name unless the camelcase name is just one character in length i . e . it is the separator character . this applies only to the first character of the camelcase name . < / ul >
converts separated string value to camelcase .
formats provided string as paragraph .
converts all tabs on a line to spaces according to the provided tab width . this is not a simple tab to spaces replacement since the resulting indentation remains the same .
escapes a string using java rules .
unescapes a string using java rules .
shortcut for checking the annotation on annotated element and returning either the values or {
---------------------------------------------------------------- core
returns petite bean instance . bean name will be resolved from provided type .
returns petite bean instance named as one of the provided names . returns {
returns petite bean instance . petite container will find the bean in corresponding scope and all its dependencies either by constructor or property injection . when using constructor injection cyclic dependencies can not be prevented but at least they are detected .
resolves and initializes bean definition . may be called multiple times .
wires bean injects parameters and invokes init methods . such a loooong name : )
wires provided bean with the container and optionally invokes init methods . bean is <b > not< / b > registered withing container .
invokes the method of some bean with the container when its parameters requires to be injected into . the bean is <b > not< / b > registered within container .
creates and wires a bean within the container and optionally invokes init methods . however bean is <b > not< / b > registered .
invokes provider to get a bean .
adds object instance to the container as singleton bean .
sets petite bean property .
returns petite bean property value .
shutdowns container . after container is down it can t be used anymore .
---------------------------------------------------------------- properties
{ @inheritdoc }
---------------------------------------------------------------- lifecycle
converts jodd logging level to jdk .
{
{
resolves method parameters from a method or constructor . returns an empty array when target does not contain any parameter . no caching is involved in this process i . e . class bytecode is examined every time this method is called .
performs smart form population .
returns the property value with replaced macros .
starts with dom building . creates root {
finishes the tree building . closes unclosed tags .
creates new element with correct configuration .
visits tags .
removes last child node if contains just empty text .
finds matching parent open tag or <code > null< / code > if not found .
fixes all unclosed tags up to matching parent . missing end tags will be added just before parent tag is closed making the whole inner content as its tag body . <p > tags that can be closed implicitly are checked and closed . <p > there is optional check for detecting orphan tags inside the table or lists . if set tags can be closed beyond the border of the table and the list and it is reported as orphan tag . <p > this is just a generic solutions closest to the rules .
---------------------------------------------------------------- tree
---------------------------------------------------------------- error
returns argument index from the history . <b > must< / b > pop value from the stack after the execution .
---------------------------------------------------------------- visitors
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
visits replacement code for {
returns the query string .
saves the parameter value <code > obj< / code > for the specified <code > position< / code > for use in logging output .
returns correct action class name . detects proxetta classes .
calculates to .
iterates collection .
iterates arrays .
joins entity array using provided string hints .
replaces all occurrences of a certain pattern in a string with a replacement string . this is the fastest replace function known to author .
replaces all occurrences of a character in a string .
replaces all occurrences of a characters in a string .
replaces the very first occurrence of a substring with supplied string .
replaces the very first occurrence of a character in a string .
replaces the very last occurrence of a substring with supplied string .
replaces the very last occurrence of a character in a string .
removes all substring occurrences from the string .
removes a single character from string .
determines if string array contains empty strings .
determines if string array contains just blank strings .
returns <code > true< / code > if string contains only white spaces .
returns <code > true< / code > if string contains only digits .
converts an array object to array of strings where every element of input array is converted to a string . if input is not an array the result will still be an array with one element .
internal method for changing the first character case .
makes a title - cased string from given input .
returns a new string that is a substring of this string . the substring begins at the specified <code > fromindex< / code > and extends to the character at index <code > toindex - 1< / code > . however index values can be negative and then the real index will be calculated from the strings end . this allows to specify e . g . <code > substring ( 1 - 1 ) < / code > to cut one character from both ends of the string . if <code > fromindex< / code > is negative and <code > toindex< / code > is 0 it will return last characters of the string . also this method will never throw an exception if index is out of range .
returns <code > true< / code > if substring exist at given offset in a string .
splits a string in several parts ( tokens ) that are separated by delimiter . delimiter is <b > always< / b > surrounded by two strings! if there is no content between two delimiters empty string will be returned for that token . therefore the length of the returned array will always be : #delimiters + 1 . <p > method is much much faster then regexp <code > string . split () < / code > and a bit faster then <code > stringtokenizer< / code > .
splits a string in several parts ( tokens ) that are separated by delimiter characters . delimiter may contains any number of character and it is always surrounded by two strings .
compress multiple occurrences of given char into one appearance .
finds the first occurrence of a character in the given source but within limited range ( start end ] .
finds the first occurrence of a character in the given source but within limited range ( start end ] .
finds first index of a substring in the given source string with ignored case .
finds last index of a substring in the given source string with ignored case .
finds last index of a substring in the given source string with ignored case .
finds last index of a substring in the given source string in specified range [ end start ] see { @link #indexof ( string string int int ) } for details about the speed .
finds last index of a character in the given source string in specified range [ end start ]
tests if this string starts with the specified prefix with ignored case and with the specified prefix beginning a specified index .
returns if string ends with provided character .
count substring occurrences in a source string ignoring case .
finds the very last index of a substring from the specified array . it returns an int [ 2 ] where int [ 0 ] represents the substring index and int [ 1 ] represents position where substring was found . returns <code > null< / code > if noting found .
compares two string arrays .
replaces many substring at once . order of string array is important .
replaces many substring at once . order of string array is important .
compares string with at least one from the provided array . if at least one equal string is found returns its index . otherwise <code > - 1< / code > is returned .
compares string with at least one from the provided array ignoring case . if at least one equal string is found it returns its index . otherwise <code > - 1< / code > is returned .
checks if string starts with at least one string from the provided array . if at least one string is matched it returns its index . otherwise <code > - 1< / code > is returned .
checks if string starts with at least one string from the provided array . if at least one string is matched it returns its index . otherwise <code > - 1< / code > is returned .
checks if string ends with at least one string from the provided array . if at least one string is matched it returns its index . otherwise <code > - 1< / code > is returned .
checks if string ends with at least one string from the provided array . if at least one string is matched it returns its index . otherwise <code > - 1< / code > is returned .
returns first index of a whitespace character starting from specified index offset .
strips leading char if string starts with one .
strips trailing char if string ends with one .
strips leading and trailing char from given string .
strips everything up to the first appearance of given char . character is included in the returned string .
strips everything from the first appearance of given char . character is not included in the returned string .
trims array of strings . <code > null< / code > array elements are ignored .
trims array of strings where empty strings are set to <code > null< / code > . <code > null< / code > elements of the array are ignored .
trims string and sets to <code > null< / code > if trimmed string is empty .
crops all elements of string array .
trim whitespaces from the left .
trim whitespaces from the right .
returns indexes of the first region without escaping character .
returns indexes of the first string region . region is defined by its left and right boundary . return value is an array of the following indexes : <ul > <li > start of left boundary index< / li > <li > region start index i . e . end of left boundary< / li > <li > region end index i . e . start of right boundary< / li > <li > end of right boundary index< / li > < / ul > <p > escape character may be used to prefix boundaries so they can be ignored . double escaped region will be found and first index of the result will be decreased to include one escape character . if region is not founded <code > null< / code > is returned .
joins an collection of objects into one string with separator .
joins an array of objects into one string with separator .
converts string charset . if charset names are the same the same string is returned .
safely compares provided char with char on given location .
surrounds the string with provided prefix and suffix if such missing from string .
inserts prefix if doesn t exist .
appends suffix if doesn t exist .
cuts the string from beginning to the first index of provided substring .
cuts the string from the first index of provided substring to the end .
cuts prefix if exists .
cuts sufix if exists .
removes surrounding prefix and suffixes .
cuts a string between two other strings . if either of left and right is missing nothing will be cut and <code > null< / code > is returned . if indexes of left or right strings are wrong empty string is returned .
returns <code > true< / code > if character at provided index position is escaped by escape character .
inserts a string on provided offset .
creates a new string that contains the provided string a number of times .
reverse a string .
returns max common prefix of two strings .
finds common prefix for several strings . returns an empty string if arguments do not have a common prefix .
shorten string to given length .
converts all of the characters in the string to upper case based on the locale .
removes starting and ending single or double quotes .
converts bytes to hex string .
executes function on a string if not {
returns string bytes using jodds default encoding .
detects quote character or return 0 .
redirects to the given location . provided path is parsed action is used as a value context .
appends another fast buffer to this one .
visits a primitive value of the annotation .
visits an enumeration value of the annotation .
visits a nested annotation value of the annotation .
lookups {
registers just type and entity names . enough for most usages .
registers entity . {
registers entity . existing entity will be removed if exist so no exception will be thrown .
removes entity and returns removed descriptor .
creates {
creates new entity instances .
defines the interface of the resulting class .
{
injects target into wrapper .
lookups for annotated properties . caches all annotated properties on the first action class scan .
detects database and configure dboom engine .
detects database and returns {
closes this output stream causing any buffered data to be flushed and any further output data to throw an ioexception .
writes the specified byte to our output stream .
writes <code > len< / code > bytes from the specified byte array starting at the specified offset to our output stream .
writes byte array to gzip output stream . creates new <code > gzipoutputstream< / code > if not created yet . also sets the content - encoding header .
filters requests to remove url - based session identifiers .
detects if session id exist in the url . it works more reliable than <code > servletrequest . isrequestedsessionidfromurl () < / code > .
returns encoded attachment name .
returns byte content of the attachment .
saves attachment to a file .
saves attachment to the output stream .
{
{
invoked on invokevirtual invokespecial invokestatic invokeinterface or invokedynamic .
appends argument to the existing description .
prepends argument to the existing description .
changes return type .
cleans unnecessary whitespaces .
registers default set of converters .
registers a converter for specified type . user must register converter for all super - classes as well .
retrieves converter for provided type . only registered types are matched therefore subclasses must be also registered .
converts an object to destination type . if type is registered it s {
special case of {
selects nodes using css3 selector query .
selected nodes using pre - parsed css selectors . take in consideration collection type for results grouping order .
process selectors and keep adding results .
selects nodes using css3 selector query and returns the very first one .
selects nodes using {
selects nodes using {
---------------------------------------------------------------- internal
walks over the child notes maintaining the tree order and not using recursion .
finds nodes in the tree that matches single selector .
selects single node for single selector and appends it to the results .
filter nodes .
unpacks the compressed character translation table .
refills the input buffer .
resumes scanning until the next regular expression is matched the end of input is encountered or an i / o - error occurs .
performs the pagination with given { @link jodd . joy . page . pagerequest } .
pages given page .
removes the first select from the sql query .
removes the first part of the sql up to the relevant from . tries to detect sub - queries in the select part .
removes everything from last order by .
decodes html text . assumes that all character references are properly closed with semi - colon .
detects the longest character reference name on given position in char array .
---------------------------------------------------------------- define
appends order by keyword .
builds page sql using limit keyword after the select .
builds count sql using count ( * ) .
resolves list of all columns and properties .
finds column descriptor by column name . case is ignored .
finds column descriptor by property name .
returns property name for specified column name .
returns column name for specified property name ..
returns id value for given entity instance .
sets id value for given entity .
returns unique key for this entity . returned key is built from entity class and id value .
appends a string .
specifies the new index .
returns char at given position . this method is <b > not< / b > fast as it calculates the right string array element and the offset!
expands internal string array by multiplying its size by 2 .
calculates string length .
returns scoped proxy bean if injection scopes are mixed on some injection point . may return <code > null< / code > if mixing scopes is not detected .
creates mixed scope message .
creates scoped proxy bean for given bean definition .
prepares step value . if step is 0 it will be set to + 1 or - 1 depending on start and end value . <p > if autodirection flag is <code > true< / code > then it is assumed that step is positive and that direction ( step sign ) should be detected from start and end value . <p > if checkdirection flag is <code > true< / code > than it checks loop direction ( step sign ) based on start and end value . throws an exception if direction is invalid . if autodirection is set direction checking is skipped .
loops body .
initializes dir watcher by reading all files from watched folder .
accepts if a file is going to be watched .
enables usage of provided watch file .
starts the watcher .
triggers listeners on file change .
adds an enumeration to this composite .
returns <code > true< / code > if composite has more elements .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
returns the size of the field_info jvms structure generated by this fieldwriter . also adds the names of the attributes of this field in the constant pool .
puts the content of the field_info jvms structure generated by this fieldwriter into the given bytevector .
matches conditional comment expression with current mode . returns <code > true< / code > it conditional comment expression is positive otherwise returns <code > false< / code > .
appends another fast buffer to this one .
creates a common target over a value with known scope data .
creates a common target over a method param .
creates a common target over a method param .
writes value to this target . depending on a flag writing the value can be completely silent when no exception is thrown and with top performances . otherwise an exception is thrown on a failure .
decorates page content with decorator template and outputs the result .
parses decorator file and collects {
parses target page and extracts decora regions for replacements .
writes decorated content .
writes region to output but extracts all inner regions .
returns <code > true< / code > if text content is blank .
starts http tunnel . method ends when the tunnel is stopped .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
executes a process and returns the process output and exit code .
returns email store .
returns <code > true< / code > if path matches the query .
creates and returns a servletoutputstream to write the content associated with this response .
invokes validation on inner context . always returns <code > true< / code > since inner context violations will be appended to provided validator .
{
{
---------------------------------------------------------------- process
counts actual real hints .
appends alias .
simply appends column name with optional table reference and alias .
adds a rule . duplicates are not allowed and will be ignored .
matches value against the set of rules using provided white / black list mode .
applies rules on given flag . flag is only changed if at least one rule matched . otherwise the same value is returned . this way you can chain several rules and have the rule engine change the flag only when a rule is matched .
process includes rules .
process excludes rules .
matches value against single rule . by default performs <code > equals< / code > on value against the rule .
returns pseudo - class name from simple class name .
adds an object to sorted list . object is inserted at correct place found using binary search . if the same item exist it will be put to the end of the range . <p > this method breaks original list contract since objects are not added at the list end but in sorted manner .
add all of the elements in the given collection to this list .
conducts a binary search to find the index where object should be inserted .
converts jodd logging level to jdk .
---------------------------------------------------------------- match
registers action configuration for given annotation . new {
binds action annotation and the action config . this can overwrite the default annotation configuration of an annotation .
registers action configuration for given type .
lookup for the action configuration . typically the input argument is either the action type or annotation type .
fetch some action config and consumes it .
returns {
setups the system email properties .
validates provided context and value withing this constraint content .
returns <code > true< / code > if provided element is one of the table - related elements .
returns <code > true< / code > if given node is a table element .
returns <code > true< / code > if parent node is one of the table elements .
finds the last table in stack of open elements .
finds foster elements . returns <code > true< / code > if there was no change in dom tree of the parent element . otherwise returns <code > false< / code > meaning that parent will scan its childs again .
performs the fix for elements .
prune only expired objects <code > linkedhashmap< / code > will take care of lru if needed .
registers new session destroy callback if not already registered .
returns instance map from http session .
returns request from current thread .
work data initialization .
saves used static initialization blocks ( clinit ) of advices .
saves used constructors of advices .
{
{
process links . returns bundle link if this is the first resource of the same type . otherwise returns <code > null< / code > indicating that collection is going on and the original link should be removed .
called on end of parsing .
replaces bundle marker with calculated bundle id . used for <code > resource_only< / code > strategy .
convert java properties to jodd props format .
convert java properties to jodd props format .
loads properties .
adds accumulated value to key and current section .
extracts profiles from the key name and adds key - value to them .
core key - value addition .
compares value of two same instances .
converts bytecode - like description to java class name that can be loaded with a classloader . uses less - known feature of class loaders for loading array classes .
converts type reference to java - name .
returns java - like signature of a bytecode - like description . only first description is parsed .
converts type to byteccode type ref .
converts <code > integer< / code > object to an <code > int< / code > .
converts <code > long< / code > object to a <code > long< / code > .
converts <code > float< / code > object to a <code > float< / code > .
converts <code > double< / code > object to a <code > double< / code > .
converts <code > byte< / code > object to a <code > byte< / code > .
converts <code > short< / code > object to a <code > short< / code > .
converts <code > boolean< / code > object to a <code > boolean< / code > .
converts <code > character< / code > object to a <code > char< / code > .
registers additional consumers .
consumes all registered consumers . the are executed sequentially in order of registration . if {
creates new collection of target component type . default implementation uses reflection to create an collection of target type . override it for better performances .
creates a collection with single element .
converts non - collection value to collection .
converts collection value to target collection . each element is converted to target component type .
converts primitive array to target collection .
{
adds a source line number corresponding to this label .
makes the given visitor visit this label and its source line numbers if applicable .
puts a reference to this label in the bytecode of a method . if the bytecode offset of the label is known the relative bytecode offset between the label and the instruction referencing it is computed and written directly . otherwise a null relative offset is written and a new forward reference is declared for this label .
adds a forward reference to this label . this method must be called only for a true forward reference i . e . only if this label is not resolved yet . for backward references the relative bytecode offset of the reference can be and must be computed and stored directly .
sets the bytecode offset of this label to the given value and resolves the forward references to this label if any . this method must be called when this label is added to the bytecode of the method i . e . when its bytecode offset becomes known . this method fills in the blanks that where left in the bytecode by each forward reference previously added to this label .
finds the basic blocks that belong to the subroutine starting with the basic block corresponding to this label and marks these blocks as belonging to this subroutine . this method follows the control flow graph to find all the blocks that are reachable from the current basic block without following any jsr target .
finds the basic blocks that end a subroutine starting with the basic block corresponding to this label and for each one of them adds an outgoing edge to the basic block following the given subroutine call . in other words completes the control flow graph by adding the edges corresponding to the return from this subroutine when called from the given caller basic block .
adds the successors of this label in the method s control flow graph ( except those corresponding to a jsr target and those already in a list of labels ) to the given list of blocks to process and returns the new list .
compare digits at certain position in two strings . the longest run of digits wins . that aside the greatest value wins .
fixes accent char .
safe {
puts a byte into this byte vector . the byte vector is automatically enlarged if necessary .
puts two bytes into this byte vector . the byte vector is automatically enlarged if necessary .
puts a short into this byte vector . the byte vector is automatically enlarged if necessary .
puts a byte and a short into this byte vector . the byte vector is automatically enlarged if necessary .
puts two bytes and a short into this byte vector . the byte vector is automatically enlarged if necessary .
puts an int into this byte vector . the byte vector is automatically enlarged if necessary .
puts one byte and two shorts into this byte vector . the byte vector is automatically enlarged if necessary .
puts a long into this byte vector . the byte vector is automatically enlarged if necessary .
puts an array of bytes into this byte vector . the byte vector is automatically enlarged if necessary .
enlarges this byte vector so that it can receive size more bytes .
tries to authenticate user via http session . returns the token if user is authenticated . returned token may be rotated .
tries to authenticate user via token . returns the token if user is authenticated . returned token may be rotated .
tires to authenticate user via the basic authentication . returns the token if user is authenticated .
{
{
calculates indexedtextname ( collection [ * ] ) if applicable .
finds messages in the provided bundle . if message not found all parent bundles will be examined until the root bundle . at the end if still no success all default bundles will be examined . returns <code > null< / code > if key is not found .
finds message in default bundles only starting from fallback bundlename .
gets the message from the named resource bundle . performs the failback only when bundle name or locale are not specified ( i . e . are <code > null< / code > ) .
finds resource bundle by it s name . missed and founded resource bundles are cached for better performances . returns <code > null< / code > if resource bundle is missing .
returns specified bundle . invoked every time if cache is disabled . input arguments are always valid .
returns array s element at given index .
returns <code > true< / code > if entity is persistent .
sets new id value for entity .
saves or updates entity . if id is not <code > null< / code > entity will be updated . otherwise entity will be inserted into the database .
simply inserts object into the database .
updates single entity .
updates single property in database and in the bean .
updates property in the database by storing the current property value .
finds single entity by its id .
finds single entity by matching property .
finds one entity for given criteria .
finds list of entities matching given criteria .
finds list of entities matching given criteria .
deleted single entity by its id .
delete single object by its id . resets id value .
counts number of all entities .
increases a property .
decreases a property .
finds related entity .
list all entities .
returns <code > true< / code > if parent node tag can be closed implicitly .
returns <code > true< / code > if current end tag ( node name ) closes the parent tag .
returns <code > true< / code > if tag should be closed on eof .
removes all attributes from the request as well as clears entries in this map .
returns a set of attributes from the http request .
saves an attribute in the request .
removes the specified request attribute .
returns current stack trace in form of array of stack trace elements . first stack trace element is removed . since an exception is thrown internally this method is slow .
returns stack trace filtered by class names .
returns stack trace chain filtered by class names .
returns exception chain starting from top up to root cause .
prints stack trace into a string .
prints full exception stack trace from top to root cause into a string .
build a message for the given base message and its cause .
introspects the <code > throwable< / code > to obtain the root cause . <p > this method walks through the exception chain to the last element root of the tree and returns that exception . if no root cause found returns provided throwable .
finds throwing cause in exception stack . returns throwable object if cause class is matched . otherwise returns <code > null< / code > .
rolls up sql exceptions by taking each proceeding exception and making it a child of the previous using the <code > setnextexception< / code > method of sqlexception .
returns <code > non - null< / code > message for a throwable .
wraps exception to {
unwraps invocation and undeclared exceptions to real cause .
shortcut for checking the annotation on annotated element and returning either the values or {
parses class name that matches madvoc - related names .
determines if class should be examined for madvoc annotations . array anonymous primitive interfaces and so on should be ignored . sometimes checking may fail due to e . g . <code > noclassdeffounderror< / code > ; we should continue searching anyway .
builds action runtime configuration on founded action class . action classes are annotated with {
registers new madvoc component .
returns default class loader . by default it is {
returns system class loader .
returns classpath item manifest or <code > null< / code > if not found .
returns base folder for classpath item . if item is a ( jar ) file its parent is returned . if item is a directory its name is returned .
returns default class path from all available <code > urlclassloader< / code > in classloader hierarchy . the following is added to the classpath list : <ul > <li > file urls from <code > urlclassloader< / code > ( other url protocols are ignored ) < / li > <li > inner entries from containing <b > manifest< / b > files ( if exist ) < / li > <li > bootstrap classpath is ignored< / li > < / ul >
retrieves given resource as url . resource is always absolute and may starts with a slash character . <p > resource will be loaded using class loaders in the following order : <ul > <li > {
opens a resource of the specified name for reading .
opens a resource of the specified name for reading . controls caching that is important when the same jar is reloaded using custom classloader .
opens a class of the specified name for reading using class classloader .
opens a class of the specified name for reading using provided class loader .
loads a class using default class loader strategy .
loads a class using default class loader strategy .
adds a new child to the tree .
finds existing chunk or creates a new one if does not exist .
returns {
returns new or existing instance of <code > multipartrequest< / code > .
checks if request if multi - part and parse it . if request is not multi - part it copies all parameters to make usage the same in both cases .
converts object to destination type . invoked before the value is set into destination . throws <code > typeconversionexception< / code > if conversion fails .
converter to collection .
invokes setter but first converts type to match the setter type .
returns the element of an array forced . if value is <code > null< / code > it will be instantiated . if not the last part of indexed bean property array will be expanded to the index if necessary .
sets the array element forced . if index is greater then arrays length array will be expanded to the index . if speed is critical it is better to allocate an array with proper size before using this method .
finds the very first next dot . ignores dots between index brackets . returns <code > - 1< / code > when dot is not found .
extract index string from non - nested property name . if index is found it is stripped from bean property name . if no index is found it returns <code > null< / code > .
creates new instance for current property name through its setter . it uses default constructor!
extracts generic component type of a property . returns <code > object . class< / code > when property does not have component .
converts <b > map< / b > index to key type . if conversion fails original value will be returned .
extracts type of current property .
retrieves the user session from the http session . returns {
stops the user session by removing it from the http session and invalidating the cookie .
starts new user session .
converts local date to date .
converts local date time to calendar .
formats time to http date / time format . note that number of milliseconds is lost .
parses the http date / time format . returns <code > - 1< / code > if given string is invalid .
generates new class .
adds validation checks .
resolve validation context for provided target class .
parses class annotations and adds all checks .
process all annotations of provided properties .
collect annotations for some target .
create new constraint . the following rules are used : <ul > <li > use default constructor if exist . < / li > <li > otherwise use constructor with validationcontext parameter . < / li > < / ul >
copies default properties from annotation to the check .
returns {
{
{
encodes single uri component .
encodes byte array using allowed characters from {
encodes string using default rfcp rules .
encodes the given uri scheme with the given encoding .
encodes the given uri host with the given encoding .
encodes the given uri port with the given encoding .
encodes the given uri path with the given encoding .
encodes the given uri query with the given encoding .
encodes the given uri query parameter with the given encoding .
encodes the given uri fragment with the given encoding .
encodes the given source uri into an encoded string . all various uri components are encoded according to their respective valid character sets . <p > this method does <b > not< / b > attempt to encode = and {
encodes the given http uri into an encoded string . all various uri components are encoded according to their respective valid character sets . <p > this method does <b > not< / b > support fragments ( {
creates url builder with given path that can be optionally encoded . since most of the time path is valid and does not require to be encoded use this method to gain some performance . when encoding flag is turned off provided path is used without processing . <p > the purpose of builder is to help with query parameters . all other uri parts should be set previously or after the url is built .
inspects all properties of target type .
adds a setter and / or getter method to the property . if property is already defined the new updated definition will be created .
creates new {
creates new field - only {
returns all property descriptors . properties are sorted by name .
parses location header to return the next location or returns {
returns list of valid cookies sent from server . if no cookie found returns an empty array . invalid cookies are ignored .
unzips gzip - ed body content removes the content - encoding header and sets the new content - length value .
creates response {
reads response input stream and returns {
closes requests connection if it was open . should be called when using keep - alive connections . otherwise connection will be already closed .
defines allowed referenced scopes that can be injected into the thread - local scoped bean .
---------------------------------------------------------------- lifecycle
prints routes to console .
encrypts complete content block by block .
decrypts the whole content block by block .
converts map to target type .
converts type of all list elements to match the component type .
sets the property value .
change map elements to match key and value types .
reads method name and stores it in local variable . for methods that return <code > string< / code > returns the method name otherwise returns <code > null< / code > .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
compares two column descriptors . identity columns should be the first on the list . each group then will be sorted by column name .
adds default header to all requests .
sends new request as a browser . before sending all browser cookies are added to the request . after sending the cookies are read from the response . moreover status codes 301 and 302 are automatically handled . returns very last response .
opens connection and sends a response .
add default headers to the request . if request already has a header set default header will be ignored .
reads cookies from response and adds to cookies list .
add cookies to the request .
prepares message and sends it . returns message id of sent email .
creates new { @link mimemessage } from an { @link email } .
sets subject in msgtoset from subject in emailwithdata .
sets sent date in msgtoset with sent date from emailwithdata .
sets headers in msgtoset with headers from emailwithdata .
sets from reply - to and recipients .
sets to cc and bcc in msgtoset with to cc and bcc from emailwithdata .
adds message data and attachments .
returns new { @link mimebodypart } with content set as msgmultipart .
sets emailwithdata content into msgtoset .
creates attachment body part . handles regular and inline attachments .
filters out the { @link list } of embedded { @link emailattachment } s for given { @link emailmessage } . this will remove the embedded attachments from the { @link list } and return them in a new { @link list } .
adds { @link list } of { @link emailattachment } s to multipart .
compares value of two same instances .
gets value of data field or <code > null< / code > if field not found .
strips content type information from requests data header .
stores result set .
initializes session . when not specified ( i . e . is <code > null< / code > ) session is fetched from session provider .
performs jdbc initialization of the query . obtains connection parses the sql query string and creates statements . initialization is performed only once when switching to initialized state .
closes all result sets opened by this query . query remains active . returns <code > sqlexception< / code > ( stacked with all exceptions ) or <code > null< / code > .
closes all result sets created by this query . query remains active .
closes all assigned result sets and then closes the query . query becomes closed .
closes the query and all created results sets and detaches itself from the session .
closes single result set that was created by this query . it is not necessary to close result sets explicitly since {
gives the jdbc driver a hint as to the number of rows that should be fetched from the database when more rows are needed . the number of rows specified affects only result sets created using this statement . if the value specified is zero then the hint is ignored . the default value is zero .
sets the limit for the maximum number of rows that any resultset object can contain to the given number . if the limit is exceeded the excess rows are silently dropped . zero means there is no limit .
executes the query . if this method is invoked at least once the query or all created resultsets must be explicitly closed at the end of query usage . this can be done explicitly by calling {
executes update insert or delete queries and optionally closes the query .
executes count queries and optionally closes query afterwards .
{
{
{
returns generated columns .
returns generated key i . e . first generated column as <code > long< / code > .
returns query sql string . for prepared statements returned sql string with quick - and - dirty replaced values .
creates new address by specifying one of the following : <ul > <li > { @code foo@bar . com - only email address . } < / li > <li > { @code jenny doe &lt ; foo@bar . com&gt ; - first part of the string is personal name and the other part is email surrounded with < and > . } < / li > < / ul >
creates new { @link internetaddress } from current data .
converts array of { @link address } to { @link emailaddress } .
convert from array of { @link emailaddress } to array of { @link internetaddress } .
creates a proxy of given target and the aspect .
creates a proxy from given {
parses string template and replaces macros with resolved values .
adapt the specified <code > iterator< / code > to the <code > enumeration< / code > interface .
adapt the specified <code > enumeration< / code > to the <code > iterator< / code > interface .
returns a collection containing all elements of the iterator .
converts iterator to a stream .
wraps an iterator as a stream .
wraps an iterator as a stream .
{
compares two objects starting with first comparator ; if they are equals proceeds to the next comparator and so on .
---------------------------------------------------------------- add content
---------------------------------------------------------------- folder
specifies default wiring mode .
resolves wiring mode by checking if default and <code > null< / code > values .
prints error message if level is enabled .
returns called class .
returns shorten class name .
defines custom {
defines custom {
adds excludes with optional parent including . when parents are included for each exclude query its parent will be included . for example exclude of aaa . bb . ccc would include it s parent : aaa . bb .
excludes type names . you can disable serialization of properties that are of some type . for example you can disable properties of <code > inputstream< / code > . you can use wildcards to describe type names .
excludes types . supports interfaces and subclasses as well .
serializes object into provided appendable .
serializes object into source .
serializes the object but returns the {
create object copy using serialization mechanism .
writes serializable object to a file . existing file will be overwritten .
reads serialized object from the file .
serialize an object to byte array .
de - serialize an object from byte array .
{
resolves {
creates table names for all specified types . since this is usually done once per result set these names are cached . type name will be <code > null< / code > for simple names i . e . for all those types that returns <code > null< / code > when used by {
resolved mapped type names for each type .
creates table names for given types .
reads column value from result set . since this method may be called more then once for the same column it caches column values .
{
caches returned entities . replaces new instances with existing ones .
resolves all providers in the class
converts entity ( type ) name to table name .
converts table name to entity ( type ) name .
applies table naming strategy to given table name hint . returns full table name .
{
{
checks if existing connection is valid and available . it may happens that if connection is not used for a while it becomes inactive although not technically closed .
close all the connections . use with caution : be sure no connections are in use before calling . note that you are not <i > required< / i > to call this when done with a connectionpool since connections are guaranteed to be closed when garbage collected . but this method gives more control regarding when the connections are closed .
renders the view by dispatching to the target jsp .
locates target using path with various extensions appended .
returns <code > true< / code > if target exists .
returns buffered writer if buffering is enabled otherwise returns the original writer .
returns buffered output stream if buffering is enabled otherwise returns the original stream .
returns buffered content as chars no matter if stream or writer is used . returns <code > null< / code > if buffering was not enabled .
writes content to original output stream using either output stream or writer depending on how the content was buffered . it is assumed that provided content is a modified wrapped content .
writes ( unmodified ) buffered content using either output stream or writer . may be used for writing the unmodified response . of course you may {
sets the content type and enables or disables buffering .
prevents setting content - length if buffering enabled .
prevents setting content - length if buffering enabled .
appends string to the buffer .
authenticate user and start user session .
prepares the json payload that carries on the token value .
tries to login user with form data . returns session object otherwise returns <code > null< / code > .
tries to login user with basic authentication .
logout hook .
---------------------------------------------------------------- utils
simple factory for {
converts {
converts { @link file } { @link url } s to file name . accepts only { @link url } s with file protocol . otherwise for other schemes returns { @code null } .
returns a file of either a folder or a containing archive .
creates all directories at once .
creates single directory .
implements the unix touch utility . it creates a new {
copies a { @link file } to another { @link file } .
internal file copy when most of the pre - checking has passed .
copies a {
copies directory with specified copy params .
moves a { @link file } .
moves a file to a directory .
moves a directory .
cleans a directory without deleting it .
reads utf file content as char array .
reads file content as char array .
write characters . append = false
writes characters to { @link file } destination .
detects optional bom and reads utf { @link string } from a { @link file } . if bom is missing utf - 8 is assumed .
detects optional bom and reads utf { @link string } from an { @link inputstream } . if bom is missing utf - 8 is assumed .
reads { @link file } content as { @link string } encoded in provided encoding . for utf encoded files detects optional bom characters .
writes string . append = false
appends string . append = true
writes data using encoding to { @link file } .
write { @link inputstream } in to { @link fileoutputstream } .
reads lines from source { @link file } with specified encoding and returns lines as { @link string } s in array .
read file and returns byte array with contents .
write bytes . append = false
appends bytes . append = true
writes data to { @link file } destination .
---------------------------------------------------------------- equals content
compare the contents of two {
uses { @link file#lastmodified () } for reference .
uses { @link file#lastmodified () } for reference .
smart copy . if source is a directory copy it to destination . otherwise if destination is directory copy source file to it . otherwise try to copy source file to destination file .
smart move . if source is a directory move it to destination . otherwise if destination is directory move source { @link file } to it . otherwise try to move source { @link file } to destination { @link file } .
smart delete of destination file or directory .
check if one { @link file } is an ancestor of second one .
returns parent for the file . the method correctly processes . and .. in { @link file } names . the name remains relative if was relative before . returns { @code null } if the { @link file } has no parent .
checks if file and its ancestors are acceptable by using { @link filefilter#accept ( file ) } .
creates temporary directory .
creates temporary { @link file } .
creates temporary { @link file } . wraps java method and repeats creation several times if something fails .
checks the start of the file for ascii control characters
returns either new { @link fileinputstream } or new { @link unicodeinputstream } .
detect encoding on { @link unicodeinputstream } by using { @link unicodeinputstream#getdetectedencoding () } .
checks if { @link file } exists . throws illegalargumentexception if not .
checks if directory can be created . throws ioexception if it cannot . <p > this actually creates directory ( and its ancestors ) ( as per { @link file#mkdirs () } } ) .
checks that srcdir exists that it is a directory and if srcdir and destdir are not equal .
checks that file copy can occur .
appends another fast buffer to this one .
prints the usage line .
resolves action method for given action class ane method name .
registers action with provided action class and method name .
registration main point . does two things : <ul > <li > {
registers manually created {
---------------------------------------------------------------- look - up
registers new path alias .
iterates to next value at the beginning of the loop .
static constructor that creates a char sequence by making a copy of provided char array .
appends another fast buffer to this one .
looks up for method in target object and invokes it using reflection .
defines class and it s classloader to scan . this is not required in java8 and would not hurt anything if called . however for java9 you should pass <i > any< / i > user - application class so jodd can figure out the real class path to scan .
shortcut for {
configures scanner class finder . works for all three scanners : petite dboom and madvoc . all scanners by default include all jars but exclude all entries .
---------------------------------------------------------------- javascripts
---------------------------------------------------------------- conditional comments
post process final content . required for <code > resource_only< / code > strategy .
wraps checked exceptions in a <code > uncheckedexception< / code > . unchecked exceptions are not wrapped .
wraps checked exceptions in a <code > uncheckedexception< / code > . unchecked exceptions are not wrapped .
finds a character in some range and returns its index . returns <code > - 1< / code > if character is not found .
finds character buffer in some range and returns its index . returns <code > - 1< / code > if character is not found .
matches char buffer with content on given location .
matches char buffer given in uppercase with content at current location that will be converted to upper case to make case - insensitive matching .
creates char sub - sequence from the input .
calculates {
requests for transaction and returns non - null value <b > only< / b > when new transaction is created! when <code > null< / code > is returned transaction may be get by { @link #getcurrenttransaction () } .
commits transaction if created in the same level where this method is invoked . returns <code > true< / code > if transaction was actually committed or <code > false< / code > if transaction was not created on this level .
rollbacks transaction if created in the same scope where this method is invoked . if not current transaction is marked for rollback . returns <code > true< / code > if transaction was actually roll backed .
returns urls for the classloader .
----------------------------------------------------------------------- apache commons codec - base32
appends bcc address .
appends bcc address .
appends one or more bcc addresses .
{
registers default set of {
registers new serializer .
get type serializer from map . first the current map is used . if element is missing default map will be used if exist .
---------------------------------------------------------------- load and extract
extracts uploaded files and parameters from the request data .
returns single value of a parameter . if parameter name is used for more then one parameter only the first one will be returned .
returns all values all of the values the given request parameter has .
returns uploaded file .
returns all uploaded files the given request parameter has .
place this filter into service .
parses template and returns generated sql builder .
finds macros end .
count escapes to the left .
---------------------------------------------------------------- handlers
builds a query string from given query map .
parses query from give query string . values are optionally decoded .
makes nice header names .
extracts media - type from value of content type header .
extracts header parameter . returns <code > null< / code > if parameter not found .
sets prepared statement object using target sql type . here jodd makes conversion and not jdbc driver . see : http : // www . tutorialspoint . com / jdbc / jdbc - data - types . htm
{
{
process action path in two modes : matching mode and extracting mode .
renders node to appendable .
renders node children to appendable .
returns <code > null< / code > for excluded http headers .
{
{
{
{
{
configures madvoc by reading context init parameters .
creates and starts new <code > madvoc< / code > web application . <code > madvoc< / code > instance is stored in servlet context . important : <code > servletcontext< / code > may be <code > null< / code > when web application is run out from container .
stops <em > madvoc< / em > web application .
creates {
loads madvoc parameters . new {
loads madvoc component that will be used for configuring the user actions . if class name is <code > null< / code > default {
defines a class from byte array into the specified class loader . warning : this is a <b > hack< / b > !
resets json parser so it can be reused .
defines how json parser works . in non - lazy mode the whole json is parsed as it is . in the lazy mode not everything is parsed but some things are left lazy . this way we gain performance especially on partial usage of the whole json . however be aware that parser holds the input memory until the returned objects are disposed .
maps a class to given path . for arrays append <code > values< / code > to the path to specify component type ( if not specified by generics ) .
replaces type with mapped type for current path .
defines {
adds a {
parses input json as given type .
parses input json to a list with specified component type .
parses input json to a list with specified key and value types .
parses input json as given type .
parses a json value .
resolves lazy value during the parsing runtime .
skips over complete object . it is not parsed just skipped . it will be parsed later but only if required .
parses a string .
parses string content once when starting quote has been consumed .
grows text array when {
parses 4 characters and returns unicode character .
parses un - quoted string content .
parses json numbers .
parses arrays once when open bracket has been consumed .
parses object once when open bracket has been consumed .
consumes one of the allowed char at current position . if char is different return <code > 0< / code > . if matched returns matched char .
matches char buffer with content on given location .
throws {
{
created empty default constructor .
{
creates simple method wrapper without proxy .
---------------------------------------------------------------- method - info signature
resolves raw type name using the generics information from the class or method information .
resolves reference from given values . returns bean reference of given value or defaults if given name is blank .
takes given parameters references and returns reference set for given method or constructor .
extracts references for given property . returns {
extracts references from method or constructor annotation .
reads annotation value and returns {
builds default method references .
builds default field references .
removes duplicate names from bean references .
converts single string array to an array of bean references .
converts comma - separated string into array of bean references .
runs joy in standalone mode with only backend .
starts new read / write transaction in propagation_required mode .
returns method from an object matched by name . this may be considered as a slow operation since methods are matched one by one . returns only accessible methods . only first method is matched .
finds constructor with given parameter types . first matched ctor is returned .
returns {
returns classes from array of objects . it accepts {
safe version of <code > isassignablefrom< / code > method that returns <code > false< / code > if one of the arguments is <code > null< / code > .
safe version of <code > isinstance< / code > returns <code > false< / code > if any of the arguments is <code > null< / code > .
resolves all interfaces of a type . no duplicates are returned . direct interfaces are prior the interfaces of subclasses in the returned array .
resolves all super classes from top ( direct subclass ) to down . <code > object< / code > class is not included in the list .
returns array of all methods that are accessible from given class upto limit ( usually <code > object . class< / code > ) . abstract methods are ignored .
returns a <code > method< / code > array of the methods to which instances of the specified respond except for those methods defined in the class specified by limit or any of its superclasses . note that limit is usually used to eliminate them methods defined by <code > java . lang . object< / code > . if limit is <code > null< / code > then all methods are returned .
compares method declarations : signature and return types .
compares method signatures : names and parameters .
compares classes usually method or ctor parameters .
suppress access check against a reflection object . securityexception is silently ignored . checks first if the object is already accessible .
returns <code > true< / code > if class member is public and if its declaring class is also public .
creates new instance of given class with given optional arguments .
creates new instances including for common mutable classes that do not have a default constructor . more user - friendly . it examines if class is a map list string character boolean or a number . immutable instances are cached and not created again . arrays are also created with no elements . note that this bunch of <code > if< / code > blocks is faster then using a <code > hashmap< / code > .
returns <code > true< / code > if the first member is accessible from second one .
returns all superclasses .
returns <code > true< / code > if method is a bean property .
returns property name from a getter method . returns <code > null< / code > if method is not a real getter .
returns beans property setter name or <code > null< / code > if method is not a real setter .
returns single component type for given type and implementation . index is used when type consist of many components . if negative index will be calculated from the end of the returned array . returns <code > null< / code > if component type does not exist or if index is out of bounds . <p >
returns all component types of the given type . for example the following types all have the component - type myclass : <ul > <li > myclass [] < / li > <li > list&lt ; myclass&gt ; < / li > <li > foo&lt ; ? extends myclass&gt ; < / li > <li > bar&lt ; ? super myclass&gt ; < / li > <li > &lt ; t extends myclass&gt ; t [] < / li > < / ul >
converts <code > type< / code > to a <code > string< / code > . supports successor interfaces : <ul > <li > <code > java . lang . class< / code > - represents usual class< / li > <li > <code > java . lang . reflect . parameterizedtype< / code > - class with generic parameter ( e . g . <code > list< / code > ) < / li > <li > <code > java . lang . reflect . typevariable< / code > - generic type literal ( e . g . <code > list< / code > <code > t< / code > - type variable ) < / li > <li > <code > java . lang . reflect . wildcardtype< / code > - wildcard type ( <code > list&lt ; ? extends number&gt ; < / code > <code > ? extends number< / code > - wildcard type ) < / li > <li > <code > java . lang . reflect . genericarraytype< / code > - type for generic array ( e . g . <code > t [] < / code > <code > t< / code > - array type ) < / li > < / ul >
reads annotation value . returns <code > null< / code > on error ( e . g . when value name not found ) .
emulates <code > reflection . getcallerclass< / code > using standard api . this implementation uses custom <code > securitymanager< / code > and it is the fastest . other implementations are : <ul > <li > <code > new throwable () . getstacktrace () [ callstackdepth ] < / code > < / li > <li > <code > thread . currentthread () . getstacktrace () [ callstackdepth ] < / code > ( the slowest ) < / li > < / ul > <p > in case when usage of <code > securitymanager< / code > is not allowed this method fails back to the second implementation . <p > note that original <code > reflection . getcallerclass< / code > is way faster then any emulation .
smart variant of {
returns <code > enum< / code > class or <code > null< / code > if class is not an enum .
returns the class of the immediate subclass of the given parent class for the given object instance ; or null if such immediate subclass cannot be uniquely identified for the given object instance .
returns the jar file from which the given class is loaded ; or null if no such jar file can be located .
resolves class file name from class name by replacing dot s with / separator and adding class extension at the end . if array component type is returned .
returns {
returns <code > true< / code > if type is some integer - like type : integer smallint tinyint bit .
puts a thread to sleep without throwing an interruptedexception .
puts a thread to sleep forever .
waits for a object for synchronization purposes .
---------------------------------------------------------------- join
creates new daemon thread factory .
returns the value . value will be computed on first call .
visits a parameter of this method .
visits an annotation of this method .
visits an annotation on a type in the method signature .
visits an annotation of a parameter this method .
visits the current state of the local variables and operand stack elements . this method must ( * ) be called <i > just before< / i > any instruction <b > i< / b > that follows an unconditional branch instruction such as goto or throw that is the target of a jump instruction or that starts an exception handler block . the visited types must describe the values of the local variables and of the operand stack elements <i > just before< / i > <b > i< / b > is executed . <br > <br > ( * ) this is mandatory only for classes whose version is greater than or equal to { @link opcodes#v1_6 } . <br > <br > the frames of a method must be given either in expanded form or in compressed form ( all frames must use the same format i . e . you must not mix expanded and compressed frames within a single method ) :
visits a field instruction . a field instruction is an instruction that loads or stores the value of a field of an object .
visits a method instruction . a method instruction is an instruction that invokes a method .
visits an invokedynamic instruction .
visits a jump instruction . a jump instruction is an instruction that may jump to another instruction .
visits a multianewarray instruction .
visits a try catch block .
visits an annotation on a local variable type .
convert java properties to jodd props format
reads data from input stream into byte array and stores file size .
returns <code > true< / code > if there is {
returns next mapped object .
moves to next element .
joins arrays . component type is resolved from the array argument .
joins arrays using provided component type .
join <code > double< / code > arrays .
resizes an array .
resizes a <code > string< / code > array .
appends an element to array .
removes sub - array .
removes sub - array from <code > boolean< / code > array .
returns subarray .
returns subarray .
returns subarray .
inserts one array into another <code > string< / code > array .
inserts one array into another at given offset .
inserts one array into another at given offset .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
converts to primitive array .
converts to object array .
finds the first occurrence in an array from specified given position and upto given length .
finds the first occurrence of an element in an array .
finds the first occurrence of value in <code > float< / code > array .
finds the first occurrence in <code > float< / code > array from specified given position and upto given length .
finds the first occurrence of value in <code > double< / code > array .
finds the first occurrence in <code > double< / code > array from specified given position and upto given length .
finds the first occurrence in an array .
finds the first occurrence in an array from specified given position .
finds the first occurrence in an array from specified given position and upto given length .
converts an array to string array .
converts an array to string array .
enables xhtml mode .
creates dom tree from provided content .
parses the content using provided lagarto parser .
-----------------------------------------------------------------------------------------------
computes all the stack map frames of the method from scratch .
computes the maximum stack size of the method .
adds a successor to { @link #currentbasicblock } in the control flow graph .
ends the current basic block . this method must be used in the case where the current basic block does not have any successor .
starts the visit of a new stack map frame stored in { @link #currentframe } .
ends the visit of {
compresses and writes {
puts some abstract types of { @link #currentframe } in { @link #stackmaptableentries } using the jvms verification_type_info format used in stackmaptable attributes .
puts the given public api frame element type in { @link #stackmaptableentries } using the jvms verification_type_info format used in stackmaptable attributes .
returns whether the attributes of this method can be copied from the attributes of the given method ( assuming there is no method visitor between the given classreader and this methodwriter ) . this method should only be called just after this methodwriter has been created and before any content is visited . it returns true if the attributes corresponding to the constructor arguments ( at most a signature an exception a deprecated and a synthetic attribute ) are the same as the corresponding attributes in the given method .
returns the size of the method_info jvms structure generated by this methodwriter . also add the names of the attributes of this method in the constant pool .
puts the content of the method_info jvms structure generated by this methodwriter into the given bytevector .
collects the attributes of this method into the given set of attribute prototypes .
{
inject context into target .
parses selector string . returns <code > null< / code > if no selector can be parsed .
parses string of selectors ( separated with <b > < / b > ) . returns list of {
registers pseudo class .
lookups pseudo class for given pseudo class name .
accepts node within selected results . invoked after results are matched .
invokes an action asynchronously by submitting it to the thread pool .
closes silently the closable object . if it is {
copies specified number of characters from { @link reader } to { @link writer } using buffer . { @link reader } and { @link writer } don t have to be wrapped to buffered since copying is already optimized .
copies specified number of bytes from { @link inputstream } to { @link outputstream } using buffer . { @link inputstream } and { @link outputstream } don t have to be wrapped to buffered since copying is already optimized .
reads all available bytes from { @link inputstream } as a byte array . uses { @link inputstream#available () } to determine the size of input stream . this is the fastest method for reading { @link inputstream } to byte array but depends on { @link inputstream } implementation of { @link inputstream#available () } .
copies { @link reader } to { @link outputstream } using buffer and specified encoding .
copies { @link inputstream } to a new { @link fastbytearrayoutputstream } using buffer and specified encoding .
copies { @link reader } to a new { @link fastbytearrayoutputstream } using buffer and specified encoding .
copies { @link inputstream } to a new { @link fastchararraywriter } using buffer and specified encoding .
copies { @link reader } to a new { @link fastchararraywriter } using buffer and specified encoding .
returns new { @link inputstreamreader } using specified { @link inputstream } and encoding .
returns new { @link outputstreamwriter } using specified { @link outputstream } and encoding .
returns all bean property names .
returns an array of bean properties . if bean is a <code > map< / code > all its keys will be returned .
starts visiting properties .
compares property name to the rules .
{
resolve method injection points in given class .
reads filter config parameters and set into destination target .
creates {
outputs bundle file to the response .
configures {
registers a class consumer that registers only those annotated with {
sets the number of random characters that will be appended to the {
creates bundle file in bundlefolder / staplerpath . only file object is created not the file content .
lookups for bundle file .
locates gzipped version of bundle file . if gzip file does not exist it will be created .
registers new bundle that consist of provided list of source paths . returns the real bundle id as provided one is just a temporary bundle id .
creates digest i . e . bundle id from given string . returned digest must be filename safe for all platforms .
creates bundle file by loading resource files content . if bundle file already exist it will not be recreated!
clears all settings and removes all created bundle files from file system .
returns the content with all relative urls fixed .
for a given url ( optionally quoted ) produces css url where relative paths are fixed and prefixed with offsetpath .
creates update query that updates all non - null values of an entity that is matched by id .
creates update query that updates all values of an entity that is matched by id .
creates update query for single column of an entity that is matched by id .
reads property value and updates the db .
creates delete query that deletes entity matched by non - null values .
creates delete query that deletes entity matched by all values .
creates delete query that deletes entity by id .
creates delete query that deletes entity by id .
creates select criteria for the entity matched by non - null values .
creates select criteria for the entity matched by non - null values .
creates select criteria for the entity matched by all values .
creates select criteria for the entity matched by column name
creates select criteria for the entity matched by foreign key . foreign key is created by concatenating foreign table name and column name .
returns all records for given type .
creates select criteria for the entity matched by id .
creates select criteria for the entity matched by id .
creates select count criteria for the entity matched by non - null values .
creates select count all query .
creates select count criteria for the entity matched by all values .
creates update that increases / decreases column by some delta value .
creates table reference name from entity type . always appends an underscore to reference name in order to circumvent sql compatibility issues when entity class name equals to a reserved word .
returns session from jtx transaction manager and started transaction .
resolves method name of method reference . argument is used so {
returns name of method reference . target {
registers actions and applies proxetta on actions that are not already registered . we need to define {
creates an array with single element .
converts non - array value to array . detects various collection types and iterates them to make conversion and to create target array .
converts primitive array to target array .
parses signature for generic information and returns a map where key is generic name and value is raw type . returns an empty map if signature does not define any generics .
resolves all collections for given type .
returns <code > true< / code > if object has been already processed during the serialization . used to prevent circular dependencies . objects are matched by identity .
{
{
serializes the object using {
matches property types that are ignored by default .
closes current session and all allocated resources . all attached queries are closed . if a transaction is still active exception occurs . database connection is returned to the {
opens connection in auto - commit mode if already not opened .
opens a transaction .
closes current transaction .
commit the current transaction writing any unflushed changes to the database . transaction mode is closed .
roll back the current transaction . transaction mode is closed .
replaces action path macros in the path . if one of the provided paths is <code > null< / code > it will not be replaced - so to emphasize the problem .
single point of {
returns {
create properties from the file .
loads properties from the file . properties are appended to the existing properties object .
loads properties from the file . properties are appended to the existing properties object .
writes properties to a file .
writes properties to a file .
writes properties to a file .
writes properties to a file .
creates properties from string .
loads properties from string .
creates new properties object from the original one by copying those properties that have specified first part of the key name . prefix may be optionally stripped during this process .
creates properties from classpath .
loads properties from classpath file ( s ) . properties are specified using wildcards .
returns string property from a map . if key is not found or if value is not a string returns <code > null< / code > . mimics <code > property . getproperty< / code > but on map .
returns string property from a map .
resolves all variables .
returns property with resolved variables .
resolves tx scope from scope pattern .
reads transaction mode from method annotation . annotations are cached for better performances .
registers new tx annotations .
finds tx annotation .
---------------------------------------------------------------- attributes
accepts single node .
matches element to css selector . all non - element types are ignored .
accepts node within current results .
unescapes css string by removing all backslash characters from it .
builds a set of java core packages .
---------------------------------------------------------------- java checks
copies all non - final values to the empty cloned object . cache - related values are not copied .
removes this node from dom tree .
appends child node . don t use this node in the loop since it might be slow due to {
appends several child nodes at once . reindex is done only once after all children are added .
inserts node at given index .
inserts node before provided node .
inserts several child nodes before provided node .
inserts node after provided node .
inserts several child nodes after referent node .
removes child node at given index . returns removed node or <code > null< / code > if index is invalid .
removes all child nodes . each child node will be detached from this parent .
returns attribute at given index or <code > null< / code > if index not found .
returns <code > true< / code > if node contains an attribute .
returns attribute value . returns <code > null< / code > when attribute doesn t exist or when attribute exist but doesn t specify a value .
sets attribute value . value may be <code > null< / code > .
returns <code > true< / code > if attribute containing some word .
finds the first child node with given node name .
returns a child node at given index or <code > null< / code > if child doesn t exist for that index .
returns a child node with given hierarchy . just a shortcut for successive calls of {
returns a child element node at given index . if index is out of bounds <code > null< / code > is returned .
returns first child or <code > null< / code > if no children exist .
returns last child or <code > null< / code > if no children exist .
returns last child <b > element< / b > with given name or <code > null< / code > if no such child node exist .
checks the health of child nodes . useful during complex tree manipulation to check if everything is ok . not optimized for speed should be used just for testing purposes .
reindex children nodes . must be called on every children addition / removal . iterates {
initializes list of child elements .
initializes siblings elements of the same name .
initializes child nodes list when needed . also fix owner document for new node if needed .
changes owner document for given node and all its children .
returns this node s next sibling of <b > any< / b > type or <code > null< / code > if this is the last sibling .
returns this node s next <b > element< / b > .
returns this node s next <b > element< / b > with the same name .
returns this node s previous sibling of <b > any< / b > type or <code > null< / code > if this is the first sibling .
returns this node s previous sibling of <b > element< / b > type or <code > null< / code > if this is the first sibling .
returns this node s previous sibling element with the same name .
returns the text content of this node and its descendants .
appends the text content to an <code > appendable< / code > ( <code > stringbuilder< / code > <code > charbuffer< / code > ... ) . this way we can reuse the <code > appendable< / code > instance during the creation of text content and have better performances .
generates html .
generates inner html .
visits children nodes .
returns css path to this node from document root .
handle decora tags .
handle open and empty id attribute tags .
defines decora tag position inside decorator content . resets current decora tag tracking .
adds a proxy aspect .
creates proxetta with all aspects . the following aspects are created : <ul > <li > transaction proxy - applied on all classes that contains public top - level methods annotated with <code >
---------------------------------------------------------------- benchmark
{
{
returns the corresponding mime type to the given extension . if no mime type was found it returns <code > application / octet - stream< / code > type .
finds all extensions that belong to given mime type ( s ) . if wildcard mode is on provided mime type is wildcard pattern .
{
{
adds root package and its path mapping . duplicate root packages are ignored if mapping path is equals otherwise exception is thrown .
sets root package to package of given class .
finds closest root package for the given action path .
finds mapping for given action class . returns <code > null< / code > if no mapping is found . if there is more then one matching root package the closest one will be returned .
{
{
{
returns json violations string . contains javascript array with elements that contain : <ul > <li > name - violation name< / li > <li > msg - message code i . e . constraint class name< / li > < / ul >
prepares validation messages . key is either validation constraint class name or violation name .
removes later duplicated references in an array . returns new instance of beanreferences if there was changes otherwise returns the same instance .
adds props files or patterns .
creates and loads application props . it first loads system properties ( registered as <code > sys . * < / code > ) and then environment properties ( registered as <code > env . * < / code > ) . finally props files are read from the classpath . all properties are loaded using <p > if props have been already loaded does nothing .
creates new {
iterates all targets .
iterates all targets and for each target iterates all in injection points of given scope .
iterates all targets and for each target iterates all out injection points of given scope .
collects all parameters from target into an array .
joins action and parameters into one single array of targets .
creates action method arguments .
stores session in map and broadcasts event to registered listeners .
removes session from a map and broadcasts event to registered listeners .
returns the string at position {
returns the integer at position {
returns the long at position {
returns the double at position {
returns the float at position {
retruns the jsonobject at position {
returns the jsonarray at position {
returns the byte [] at position {
returns the object value at position {
adds an enum to the json array . <p > json has no concept of encoding enums so the enum will be converted to a string using the {
adds an object to the json array .
appends all of the elements in the specified array to the end of this json array .
removes the value at the specified position in the json array .
dispatches to the template location created from result value and jsp extension . does its forward via a <code > requestdispatcher< / code > . if the dispatch fails a 404 error will be sent back in the http response .
locates the target file from action path and the result value .
called when target not found . by default sends 404 to the response .
redirects to the given location . provided path is parsed action is used as a value context .
---------------------------------------------------------------- input
converts value to a string .
configures an interceptor .
configures an interceptor .
returns action filter instance for further configuration .
returns <code > true< / code > if node matches the pseudoclass within current results .
returns pseudo - function name .
returns action string in form actionclass#actionmethod .
{
{
resolves all properties for given type .
connects to the socks4 proxy and returns proxified socket .
reads a { @link #type } attribute . this method must return a <i > new< / i > { @link attribute } object of type { @link #type } corresponding to the length bytes starting at offset in the given classreader .
returns the byte array form of the content of this attribute . the 6 header bytes ( attribute_name_index and attribute_length ) must <i > not< / i > be added in the returned bytevector .
returns the number of attributes of the attribute list that begins with this attribute .
returns the total size in bytes of all the attributes in the attribute list that begins with this attribute . this size includes the 6 header bytes ( attribute_name_index and attribute_length ) per attribute . also adds the attribute type names to the constant pool .
returns the total size in bytes of all the attributes in the attribute list that begins with this attribute . this size includes the 6 header bytes ( attribute_name_index and attribute_length ) per attribute . also adds the attribute type names to the constant pool .
puts all the attributes of the attribute list that begins with this attribute in the given byte vector . this includes the 6 header bytes ( attribute_name_index and attribute_length ) per attribute .
puts all the attributes of the attribute list that begins with this attribute in the given byte vector . this includes the 6 header bytes ( attribute_name_index and attribute_length ) per attribute .
returns all action results as new set .
registers new action result instance . if action result of the same class is already registered registration will be skipped . if result for the same result type or same target class exist it will be replaced! however default jodd results will <i > never< / i > replace other results . after the registration results are initialized .
lookups for action result and {
lookups for {
creates new {
match if one character equals to any of the given character .
finds index of the first character in given charsequence the matches any from the given set of characters .
finds index of the first character in given array the matches any from the given set of characters .
adds several arguments .
sets environment variable .
runs command and returns process result .
invoke the listener based on type . not very oop but works .
sets this frame to the value of the given frame .
returns the abstract type corresponding to the given public api frame element type .
returns the abstract type corresponding to the given type descriptor .
sets the input frame from the given method description . this method is used to initialize the first frame of a method which is implicit ( i . e . not stored explicitly in the stackmaptable attribute ) .
sets the input frame from the given public api frame description .
returns the abstract type stored at the given local variable index in the output frame .
replaces the abstract type stored at the given local variable index in the output frame .
pushes the given abstract type on the output frame stack .
pushes the abstract type corresponding to the given descriptor on the output frame stack .
pops the given number of abstract types from the output frame stack .
pops as many abstract types from the output frame stack as described by the given descriptor .
adds an abstract type to the list of types on which a constructor is invoked in the basic block .
returns the initialized abstract type corresponding to the given abstract type .
simulates the action of the given instruction on the output stack frame .
merges the type at the given index in the given abstract type array with the given type . returns { @literal true } if the type array has been modified by this operation .
makes the given { @link methodwriter } visit the input frame of this { @link frame } . the visit is done with the { @link methodwriter#visitframestart } { @link methodwriter#visitabstracttype } and { @link methodwriter#visitframeend } methods .
put the given abstract type in the given bytevector using the jvms verification_type_info format used in stackmaptable attributes .
prunes expired elements from the cache . returns the number of removed objects .
schedules prune .
visit the module corresponding to the class .
visits the nest host class of the class . a nest is a set of classes of the same package that share access to their private members . one of these classes called the host lists the other members of the nest which in turn should link to the host of their nest . this method must be called only once and only if the visited class is a non - host member of a nest . a class is implicitly its own nest so it s invalid to call this method with the visited class name as argument .
visits the enclosing class of the class . this method must be called only if the class has an enclosing class .
visits an annotation of the class .
visits a member of the nest . a nest is a set of classes of the same package that share access to their private members . one of these classes called the host lists the other members of the nest which in turn should link to the host of their nest . this method must be called only if the visited class is the host of a nest . a nest host is implicitly a member of its own nest so it s invalid to call this method with the visited class name as argument .
visits information about an inner class . this inner class is not necessarily a member of the class being visited .
visits a field of the class .
---------------------------------------------------------------- provider
returns existing thread session or new one if already not exist . if session doesn t exist it will be created using default connection provider .
closes thread session .
creates execution array that will invoke all filters actions and results in correct order .
invokes action method after starting all interceptors . after method invocation all interceptors will finish in opposite order .
reads request body only once and returns it to user .
calculates the first item index of requested page .
calculates first item index of the page .
parses int value or throws <code > cssellyexception< / code > on failure .
matches expression with the value .
converts char array into byte array by replacing each character with two bytes .
finds index of the first character in given array the differs from the given set of characters .
renders node name .
renders attribute name .
renders attribute .
loads props from the file . assumes utf8 encoding unless the file ends with . properties than it uses iso 8859 - 1 .
loads properties from the file in provided encoding .
loads properties from input stream . stream is not closed at the end .
loads base properties from the provided java properties . null values are ignored .
loads base properties from java map using provided prefix . null values are ignored .
loads system properties with given prefix . if prefix is <code > null< / code > it will not be ignored .
loads environment properties with given prefix . if prefix is <code > null< / code > it will not be used .
loads props and properties from the classpath .
returns value of property using active profiles or default value if not found .
returns double value of given property or {
returns <code > string< / code > value of given profiles . if key is not found under listed profiles base properties will be searched . returns <code > null< / code > if property doesn t exist .
sets value on some profile .
extracts props belonging to active profiles .
extract props of given profiles .
extracts subset of properties that matches given wildcards .
returns inner map from the props with given prefix . keys in returned map will not have the prefix .
adds child map to the props on given prefix .
resolves active profiles from special property . this property can be only a base property! if default active property is not defined nothing happens . otherwise it will replace currently active profiles .
returns all profiles names .
returns all the profiles that define certain prop s key name . key name is given as a wildcard or it can be matched fully .
adds property injection point .
adds set injection point .
adds method injection point .
adds init methods .
adds destroy methods .
returns target class if proxetta applied on given class . if not returns given class as result .
injects some target instance into {
injects target instance into proxy using default target field name .
returns wrapper target type .
prunes expired and if cache is still full the lfu element ( s ) from the cache . on lfu removal access count is normalized to value which had removed object . returns the number of removed objects .
locates property field . field is being searched also in all superclasses of current class .
returns property type . raw types are detected .
returns {
creates a {
returns {
creates a {
resolves key type for given property descriptor .
resolves component type for given property descriptor .
---------------------------------------------------------------- util
creates json result from given object . the object will be serialized to json .
creates a json response from an exception . response body will have information about the exception and response status will be set to 500 .
resolves http method name from method name . if method name or first camel - case word of a method equals to a http method it will be used as that http methods .
checks if two strings are equals or if they {
internal matching recursive function .
matches string to at least one pattern . returns index of matched pattern or <code > - 1< / code > otherwise .
matches path against pattern using * ? and ** wildcards . both path and the pattern are tokenized on path separators ( both \ and / ) . ** represents deep tree wildcard as in ant .
returns <code > true< / code > if class or resource name matches at least one package rule from the list .
resolves loading rules .
resolves resources .
loads class using parent - first or parent - last strategy .
returns a resource using parent - first or parent - last strategy .
waits for gobbler to end .
scans annotation and returns type of madvoc annotations .
inspects {
builds injection point .
inspects {
visits a type .
invoked on each property . properties are getting matched against the rules . if property passes all the rules it will be processed in {
returns urls for the classloader
sets new bean instance .
updates the bean . detects special case of suppliers .
loads property descriptor if property was updated .
returns getter .
returns setter .
initializes the dboom by connecting to the database . database will be detected and dboom will be configured to match it .
adds an iterator to this composite .
returns <code > true< / code > if next element is available .
detects if there was a <code > null< / code > reading and returns <code > null< / code > if it was . result set returns default value ( e . g . 0 ) for many getters therefore it detects if it was a null reading or it is a real value .
detects <code > null< / code > before storing the value into the database .
starts the joy . returns the {
prints a logo .
stops the joy .
creates new connection from current { @link jodd . http . httprequest request } .
creates a socket using socket factory .
creates a ssl socket . enables default secure enabled protocols if specified .
returns default ssl socket factory allowing setting trust managers .
returns socket factory based on proxy type and ssl requirements .
creates random string whose length is the number of characters specified . characters are chosen from the set of characters specified .
creates random string whose length is the number of characters specified . characters are chosen from the provided range .
creates random string whose length is the number of characters specified . characters are chosen from the multiple sets defined by range pairs . all ranges must be in acceding order .
parses eml with provided eml content .
parses eml with provided eml content .
starts eml parsing with provided eml { @link file } .
parses the eml content . if { @link session } is not created default one will be used .
creates new type for json array objects . it returns a collection . later the collection will be converted into the target type .
creates new object or a <code > hashmap< / code > if type is not specified .
injects value into the targets property .
converts type of the given value .
visit an implementation of a service .
{
{
---------------------------------------------------------------- header
creates default implementation of the type cache .
add values to the map .
returns existing value or add default supplied one . use this method instead of {
{
{
inspects types methods and return map of {
returns a method that matches given name and parameter types . returns <code > null< / code > if method is not found .
returns method descriptor for given name . if more then one methods with the same name exists one method will be returned ( not determined which one ) . returns <code > null< / code > if no method exist in this collection by given name .
returns all methods . cached . lazy .
resolves ip address from a hostname .
returns ip address as integer .
checks given string against ip address v4 format .
resolves host name from ip address bytes .
downloads resource as byte array .
downloads resource as string .
downloads resource to a file potentially very efficiently .
wraps the response and parse it using lagarto parser . it first calls {
accepts action path for further parsing . by default only <code > * . htm ( l ) < / code > requests are passed through and those without any extension .
sets the {
{
performs injection .
performs outjection .
creates a socket .
creates a socket with a timeout .
prepares classname for loading respecting the arrays . returns <code > null< / code > if class name is not an array .
detects if provided class name is a primitive type . returns > = 0 number if so .
loads class by name .
loads a class using provided class loader . if class is an array it will be first loaded using the <code > class . forname< / code > ! we must use this since for jdk {
loads array class using component type .
iterate all beans and invokes registered destroy methods .
creates binary search wrapper over an array .
creates binary search wrapper over an array with given comparator .
finds index of given element in inclusive index range . returns negative value if element is not found .
defines excluded property names .
defines included property names .
defines included property names as public properties of given template class . sets to black list mode .
starts the tag with the index of first < . resets all tag data .
---------------------------------------------------------------- match
---------------------------------------------------------------- util
---------------------------------------------------------------- output
registers component using its { @link #resolvebasecomponentname ( class ) base name } . previously defined component will be removed .
registers madvoc component with given name .
registers component instance using its { @link #resolvebasecomponentname ( class ) base name } . previously defined component will be removed .
registers component instance and wires it with internal container . warning : in this moment we can not guarantee that all other components are registered replaced or configuration is update ; therefore do not use injection unless you are absolutely sure it works .
fires the madvoc event . warning : since event handlers may register more handlers we must collect first the list of components that matches the type and then to execute .
returns registered component or {
returns existing component . throws an exception if component is not registered .
returns existing component . throws an exception if component is not registered .
resolves the name of the last base non - abstract subclass for provided component . it iterates all subclasses up to the <code > object< / cde > and declares the last non - abstract class as base component . component name will be resolved from the founded base component .
prepares the query after initialization . besides default work it checks if sql generator is used and if so generator hints and query parameters will be used for this query . note regarding hints : since hints can be added manually generators hints will be ignored if there exists some manually set hints .
resolves column db sql type and populates it in column descriptor if missing .
pre - process sql before using it . if string starts with a non - ascii char or it has no spaces it will be loaded from the query map .
prepares a row ( array of rows mapped object ) using hints . returns either single object or objects array .
factory for result sets mapper .
finds generated key column of given type .
populates entity with generated column values from executed query .
acquires interceptor from petite container .
clears the current parameter values immediately . <p > in general parameter values remain in force for repeated use of a statement . setting a parameter value automatically clears its previous value . however in some cases it is useful to immediately release the resources used by the current parameter values ; this can be done by calling the method <code > clearparameters< / code > .
---------------------------------------------------------------- null
---------------------------------------------------------------- int
---------------------------------------------------------------- integer
---------------------------------------------------------------- boolean
---------------------------------------------------------------- long
---------------------------------------------------------------- byte
---------------------------------------------------------------- double
---------------------------------------------------------------- double
---------------------------------------------------------------- float
---------------------------------------------------------------- short
---------------------------------------------------------------- string
---------------------------------------------------------------- date
---------------------------------------------------------------- time
---------------------------------------------------------------- timestamp
---------------------------------------------------------------- big decimal
---------------------------------------------------------------- big integer
---------------------------------------------------------------- url
---------------------------------------------------------------- blob
---------------------------------------------------------------- clob
---------------------------------------------------------------- array
---------------------------------------------------------------- ref
---------------------------------------------------------------- ascii streams
sets bean parameters from bean . non - existing bean properties are ignored .
sets properties from the map .
sets the value of the designated parameter with the given object . this method is like the method <code > setobject< / code > above except that it assumes a scale of zero .
sets the value of the designated parameter with the given object . this method is like the method <code > setobject< / code > above except that it assumes a scale of zero .
sets the value of the designated parameter with the given object . this method is like the method <code > setobject< / code > above except that it assumes a scale of zero .
sets object parameter in an advanced way . <p > first it checks if object is <code > null< / code > and invokes <code > setnull< / code > if so . if object is not <code > null< / code > it tries to resolve {
sets an array of objects parameters in given order .
sets sql parameters from two arrays : names and values .
sets batch parameters with given array of values .
sets batch parameters with given array of values .
appends chunk to previous one and maintains the double - linked list of the previous chunk . current surrounding connections of this chunk will be cut - off .
lookups for entity name and throws exception if entity name not found .
lookups for entity name and throws an exception if entity type is invalid .
finds a table that contains given column .
resolves table name or alias that will be used in the query .
defines parameter with name and its value .
resolves object to a class .
returns <code > true< / code > if a value is considered empty i . e . not existing .
appends missing space if the output doesn t end with whitespace .
---------------------------------------------------------------- valid
---------------------------------------------------------------- get / free
get an enumeration of the parameter names for uploaded files
get a { @link fileupload } array for the given input field name .
compares value of two same instances .
include page which path is relative to the current http request .
include named resource .
include named resource .
include page which path relative to the root of the servletcontext .
include page which path relative to the root of the servletcontext .
forward to page path relative to the root of the servletcontext .
forward to page path relative to the root of the servletcontext .
performs redirection ( 302 ) to specified url .
performs permanent redirection ( 301 ) to specified url .
returns full url : uri + query string including the context path .
returns url without context path convenient for request dispatcher .
returns <code > true< / code > if current page is included .
returns the base ( top - level ) uri .
get current request uri .
returns method parameter names .
builds {
creates new <code > pathmacro< / code > instance .
creates and initializes petite container . it will be auto - magically configured by scanning the classpath .
stops petite container .
---------------------------------------------------------------- print
sets this currentframe to the input stack map frame of the next current instruction i . e . the instruction just after the given one . it is assumed that the value of this object when this method is called is the stack map frame status just before the given instruction is executed .
defines filter for subject field .
defines filter for message id .
defines filter for from field .
defines filter for to field .
defines filter for cc field .
defines filter for bcc field .
defines filter for many flags at once .
defines filter for single flag .
defines filter for received date .
defines filter for sent date .
defines filter on a message body . all parts of the message that are of mime type text / * are searched .
defines filter for { @link header } .
defines filter for message size .
defines and group of filters .
defines or group of filters .
appends single filter as not .
concatenates last search term with new one .
sets { @link andterm } as searchterm .
sets { @link orterm } searchterm .
encode an array of binary bytes into a base32 string .
decode a base32 string into an array of binary bytes .
converts non - array value to array . detects various types and collections iterates them to make conversion and to create target array .
if browser supports gzip sets the content - encoding response header and invoke resource with a wrapped response that collects all the output . extracts the output and write it into a gzipped byte array . finally write that array to the client s output stream . <p > if browser does not support gzip invokes resource normally .
filter initialization .
determine if request is eligible for gzipping .
adds new {
validate object using context from the annotations .
performs validation of provided validation context and appends violations .
enables single profile .
enables list of profiles .
determine if any of checks profiles is among enabled profiles .
parses request body into the target type .
converts to milliseconds .
adds a jd to current instance .
subtracts a jd from current instance .
sets integer and fractional part with normalization . normalization means that if double is out of range values will be correctly fixed .
returns span between two days . returned value may be positive ( when this date is after the provided one ) or negative ( when comparing to future date ) .
---------------------------------------------------------------- fg codes
colors with red - green - blue value in the range 0 to 6 .
---------------------------------------------------------------- bg codes
colors with red - green - blue value in the range 0 to 6 .
---------------------------------------------------------------- bgcolors
initializes parser .
parses content and callback provided {
emits a comment . also checks for conditional comments!
prepares error message and reports it to the visitor .
---------------------------------------------------------------- util
returns a salted pbkdf2 hash of the password .
computes the pbkdf2 hash of a password .
converts a string of hexadecimal characters into a byte array .
resolves provider definition defined in a bean .
sets file name .
sets the { @link datasource } . common { @link datasource } s include { @link bytearraydatasource } and { @link filedatasource } .
creates new { @link bytearraydatasource } and then calls { @link #content ( datasource ) } .
creates new { @link bytearraydatasource } and then calls { @link #content ( datasource ) } .
creates { @link emailattachment } .
creates { @link emailattachment } .
set content id if it is missing .
resolves content type from all data .
makes the given visitor visit the signature of this { @link signaturereader } . this signature is the one specified in the constructor ( see { @link #signaturereader } ) . this method is intended to be called on a { @link signaturereader } that was created using a <i > classsignature< / i > ( such as the <code > signature< / code > parameter of the { @link org . objectweb . asm . classvisitor#visit } method ) or a <i > methodsignature< / i > ( such as the <code > signature< / code > parameter of the { @link org . objectweb . asm . classvisitor#visitmethod } method ) .
parses a javatypesignature and makes the given visitor visit it .
returns the size of the module modulepackages and modulemainclass attributes generated by this modulewriter . also add the names of these attributes in the constant pool .
puts the module modulepackages and modulemainclass attributes generated by this modulewriter in the given bytevector .
decodes url elements . this method may be used for all parts of url except for the query parts since it does not decode the + character .
decodes query name or value .
initializes database . first creates connection pool . and transaction manager . then jodds dbentitymanager is configured . it is also configured automagically by scanning the class path for entities .
checks if connection provider can return a connection .
---------------------------------------------------------------- print
returns method signature for some method . if signature is not found returns <code > null< / code > . founded signatures means that those method can be proxyfied .
---------------------------------------------------------------- visits
stores method signature for target method .
stores signatures for all super public methods not already overridden by target class . all this methods will be accepted for proxyfication .
creates method signature from method name .
parse fields as csv string
converts csv line to string array .
resolves constructor injection point from type . looks for single annotated constructor . if no annotated constructors found the total number of constructors will be checked . if there is only one constructor that one will be used as injection point . if more constructors exist the default one will be used as injection point . otherwise exception is thrown .
creates advice s class reader .
returns class reader for advice .
parse advice class to gather some advice data . should be called before any advice use . must be called only * once * per advice .
symmetrically encrypts the string .
symmetrically decrypts the string .
sets {
returns logger for given name . repeated calls to this method with the same argument should return the very same instance of the logger .
sets the cookie name and checks for validity .
invokes action registered to provided action path provides action chaining by invoking the next action request . returns <code > null< / code > if action path is consumed and has been invoked by this controller ; otherwise the action path string is returned ( it might be different than original one provided in arguments ) . on first invoke initializes the action runtime before further proceeding .
invokes a result after the action invocation . <p > results may be objects that specify which action result will be used to render the result . <p > result value may consist of two parts : type and value . result type is optional and if exists it is separated by semi - colon from the value . if type is not specified then the default result type if still not defined . result type defines which { @link actionresult } should be used for rendering the value . <p > result value is first checked against aliased values . then it is resolved and then passed to the founded { @link actionresult } .
creates new action object from {
creates new action request .
acquires filter from petite container .
returns <code > true< / code > if bean is destroyable .
checks if bean data is destroyable ( has destroy methods ) and registers it for later {
removes destroyable bean from the list and calls it destroy methods . if bean is not destroyable does nothing . bean gets destroyed only once .
shutdowns the scope and calls all collected destroyable beans .
creates { @link mailsession } { @link properties } .
receives the emails as specified by the builder .
duplicate the underlying { @link bytebuffer } s and wrap them for thread local access .
launch the clustered service container and await a shutdown signal .
allocate a per { @link io . aeron . driver . publicationimage } indicator .
run loop for the rate reporter
return a reusable parametrised { @link fragmenthandler } that calls into a { @link ratereporter } .
generic error handler that just prints message to stdout .
print the rates to stdout
map an existing file as a read only buffer .
close the merge and stop any active replay . will remove the replay destination from the subscription . will not remove the live destination if it has been added .
process the operation of the merge . do not call the processing of fragments on the subscription .
poll the { @link image } used for the merging replay and live stream . the { @link replaymerge#dowork () } method will be called before the poll so that processing of the merge can be done .
get the current position to which the publication has advanced for this stream .
non - blocking publish of a partial buffer containing a message .
non - blocking publish of a message composed of two parts e . g . a header and encapsulated payload .
non - blocking publish of a partial buffer containing a message .
non - blocking publish of a message composed of two parts e . g . a header and encapsulated payload .
non - blocking publish by gathering buffer vectors into a message .
try to claim a range in the publication log into which a message can be written with zero copy semantics . once the message has been written then { @link bufferclaim#commit () } should be called thus making it available . <p > <b > note : < / b > this method can only be used for message lengths less than mtu length minus header . if the claim is held after the publication is closed or the client dies then it will be unblocked to reach end - of - stream ( eos ) . <pre > { @code final bufferclaim bufferclaim = new bufferclaim () ;
append a padding record log of a given length to make up the log to a position .
set channel field in ascii
notify the archive that this control session is closed so it can promptly release resources then close the local resources associated with the client .
connect to an aeron archive by providing a { @link context } . this will create a control session . <p > before connecting { @link context#conclude () } will be called . if an exception occurs then { @link context#close () } will be called .
begin an attempt at creating a connection which can be completed by calling { @link asyncconnect#poll () } until it returns the client before complete it will return null .
poll the response stream once for an error . if another message is present then it will be skipped over so only call when not expecting another response .
check if an error has been returned for the control session and throw a { @link archiveexception } if { @link context#errorhandler ( errorhandler ) } is not set . <p > to check for an error response without raising an exception then try { @link #pollforerrorresponse () } .
add a { @link publication } and set it up to be recorded . if this is not the first i . e . { @link publication#isoriginal () } is true then an { @link archiveexception } will be thrown and the recording not initiated . <p > this is a sessionid specific recording .
add an { @link exclusivepublication } and set it up to be recorded . <p > this is a sessionid specific recording .
start recording a channel and stream pairing . <p > channels that include sessionid parameters are considered different than channels without sessionids . if a publication matches both a sessionid specific channel recording and a non - sessionid specific recording it will be recorded twice .
stop recording for a channel and stream pairing . <p > channels that include sessionid parameters are considered different than channels without sessionids . stopping a recording on a channel without a sessionid parameter will not stop the recording of any sessionid specific recordings that use the same channel and streamid .
stop recording a sessionid specific recording that pertains to the given { @link publication } .
stop recording for a subscriptionid that has been returned from { @link #startrecording ( string int sourcelocation ) } or { @link #extendrecording ( long string int sourcelocation ) } .
start a replay for a length in bytes of a recording from a position . if the position is { @link #null_position } then the stream will be replayed from the start . <p > the lower 32 - bits of the returned value contains the { @link image#sessionid () } of the received replay . all 64 - bits are required to uniquely identify the replay when calling { @link #stopreplay ( long ) } . the lower 32 - bits can be obtained by casting the { @code long } value to an { @code int } .
stop a replay session .
replay a length in bytes of a recording from a position and for convenience create a { @link subscription } to receive the replay . if the position is { @link #null_position } then the stream will be replayed from the start .
list all recording descriptors from a recording id with a limit of record count . <p > if the recording id is greater than the largest known id then nothing is returned .
list recording descriptors from a recording id with a limit of record count for a given channelfragment and stream id . <p > if the recording id is greater than the largest known id then nothing is returned .
list a recording descriptor for a single recording id . <p > if the recording id is greater than the largest known id then nothing is returned .
get the position recorded for an active recording . if no active recording then return { @link #null_position } .
find the last recording that matches the given criteria .
truncate a stopped recording to a given position that is less than the stopped position . the provided position must be on a fragment boundary . truncating a recording to the start position effectively deletes the recording .
list active recording subscriptions in the archive . these are the result of requesting one of { @link #startrecording ( string int sourcelocation ) } or a { @link #extendrecording ( long string int sourcelocation ) } . the returned subscription id can be used for passing to { @link #stoprecording ( long ) } .
dump the contents of a segment file to a { @link printstream } .
print the information for an available image to stdout .
this handler is called when image is unavailable
return a reusable parameterized { @link fragmenthandler } that prints to stdout for the first stream ( stream )
return the controllable idle strategy { @link statusindicator } .
return the read - only status indicator for the given send channel uri .
return the read - only status indicator for the given receive channel uri .
set this limit for this buffer as the position at which the next append operation will occur .
append a source buffer to the end of the internal buffer resizing the internal buffer as required .
poll for control response events .
map a new loss report in the aeron directory for a given length .
the implementation of { @link controlledfragmenthandler } that reassembles and forwards whole messages .
take a snapshot of all the counters and group them by streams .
print a snapshot of the stream positions to a { @link printstream } . <p > each stream will be printed on its own line .
generate a new randomized delay value in the units of { @code maxbackofft }} .
{
{
reset the poller to dispatch the descriptors returned from a query .
read a { @link lossreport } contained in the buffer . this can be done concurrently .
return an initialised default data frame header .
fill the key buffer .
fill the label buffer .
poll the { @link image } s under the subscription for available message fragments . <p > each fragment read will be a whole message if it is under mtu length . if larger than mtu then it will come as a series of fragments ordered within a session . <p > to assemble messages that span multiple fragments then use { @link fragmentassembler } .
poll in a controlled manner the { @link image } s under the subscription for available message fragments . control is applied to fragments in the stream . if more fragments can be read on another stream they will even if break or abort is returned from the fragment handler . <p > each fragment read will be a whole message if it is under mtu length . if larger than mtu then it will come as a series of fragments ordered within a session . <p > to assemble messages that span multiple fragments then use { @link controlledfragmentassembler } .
poll the { @link image } s under the subscription for available message fragments in blocks . <p > this method is useful for operations like bulk archiving and messaging indexing .
poll the { @link image } s under the subscription for available message fragments in blocks . <p > this method is useful for operations like bulk archiving a stream to file .
return the { @link image } associated with the given sessionid .
iterate over the { @link image } s for this subscription .
launch a new { @link archivingmediadriver } with provided contexts .
///////////////////////////////////////////////////////////
on catalog load we verify entries are in coherent state and attempt to recover entries data where untimely termination of recording has resulted in an unaccounted for stopposition / stoptimestamp . this operation may be expensive for large catalogs .
claim length of a the term buffer for writing in the message with zero copy semantics .
append an unfragmented message to the the term buffer .
append an unfragmented message to the the term buffer .
append a fragmented message to the the term buffer . the message will be split up into fragments of mtu length minus header .
connect to an archive on its control interface providing the response stream details .
try connect to an archive on its control interface providing the response stream details . only one attempt will be made to offer the request .
close this control session with the archive .
start recording streams for a given channel and stream id pairing .
stop an active recording .
stop an active recording by the { @link subscription#registrationid () } it was registered with .
replay a recording from a given position .
stop an existing replay session .
list a range of recording descriptors .
list a range of recording descriptors which match a channel uri fragment and stream id .
list a recording descriptor for a given recording id .
extend an existing non - active recorded stream for a the same channel and stream id .
get the recorded position of an active recording .
truncate a stopped recording to a given position that is less than the stopped position . the provided position must be on a fragment boundary . truncating a recording to the start position effectively deletes the recording .
get the stop position of a recording .
find the last recording that matches the given criteria .
list registered subscriptions in the archive which have been used to record streams .
parse channel uri and create a { @link udpchannel } .
return a string which is a canonical form of the channel suitable for use as a file or directory name and also as a method of hashing etc . <p > a canonical form : <ul > <li > begins with the string udp - < / li > <li > has all addresses converted to hexadecimal< / li > <li > uses - as all field separators< / li > < / ul > <p > the general format is : udp - interface - localport - remoteaddress - remoteport
does this channel have a tag match to another channel including endpoints .
get the endpoint address from the uri .
used for debugging to get a human readable description of the channel .
{
{
{
called from the { @link lossdetector } when gap is detected by the { @link driverconductor } thread .
add a destination to this image so it can merge streams .
called from the { @link driverconductor } .
insert frame into term buffer .
to be called from the { @link receiver } to see if a image should be retained .
called from the { @link receiver } to send any pending status messages .
called from the { @link receiver } thread to processing any pending loss of packets .
called from the { @link receiver } thread to check for initiating an rtt measurement .
called from the { @link receiver } upon receiving an rtt measurement that is a reply .
{
map a { @link countersreader } over the provided { @link file } for the cnc file .
find the control toggle counter or return null if not found .
put a key and value pair in the map of params .
get the channel tag if it exists that refers to an another channel .
get the entity tag if it exists that refers to an entity such as subscription or publication .
initialise a channel for restarting a publication at a given position .
parse a { @link charsequence } which contains an aeron uri .
add a sessionid to a given channel .
get the value of the tag from a given parameter value .
claim length of a the term buffer for writing in the message with zero copy semantics .
pad a length of the term buffer with a padding record .
append an unfragmented message to the the term buffer .
append a fragmented message to the the term buffer . the message will be split up into fragments of mtu length minus header .
update the publishers limit for flow control as part of the conductor duty cycle .
search for a list of network interfaces that match the specified address and subnet prefix . the results will be ordered by the length of the subnet prefix ( { @link interfaceaddress#getnetworkprefixlength () } ) . if no results match then the collection will be empty .
allocate a direct { @link bytebuffer } that is padded at the end with at least alignment bytes .
allocate a counter for tracking a position on a stream of messages .
return the label name for a counter type identifier .
scan the term buffer for availability of new message fragments from a given offset up to a maxlength of bytes .
clear out all the values thus setting back to the initial state .
validates that the collection of set parameters are valid together .
set the prefix for taking an addition action such as spying on an outgoing publication with aeron - spy .
set the media for this channel . valid values are udp and ipc .
set the control mode for multi - destination - cast . set to manual for allowing control from the publication api .
set the time to live ( ttl ) for a multicast datagram . valid values are 0 - 255 for the number of hops the datagram can progress along .
set the maximum transmission unit ( mtu ) including aeron header for a datagram payload . if this is greater than the network mtu for udp then the packet will be fragmented and can amplify the impact of loss .
set the length of buffer used for each term of the log . valid values are powers of 2 in the 64k - 1g range .
set the offset within a term at which a publication will start . this when combined with the term id can establish a starting position .
set the time a network publication will linger in nanoseconds after being drained . this time is so that tail loss can be recovered .
initialise a channel for restarting a publication at a given position .
build a channel uri string for the given parameters .
throw a { @link aeronexception } with a message for a send error .
create the underlying channel for reading and writing .
close transport canceling any pending read operations and closing channel
is the received frame valid . this method will do some basic checks on the header and can be overridden in a subclass for further validation .
receive a datagram from the media layer .
called on reception of a nak to start retransmits handling .
called to indicate a retransmission is received that may obviate the need to send one ourselves . <p > note : currently only called from unit tests . would be used for retransmitting from receivers for nak suppression .
called to process any outstanding timeouts .
reset the poller to dispatch the descriptors returned from a query .
the implementation of { @link controlledfragmenthandler } that reassembles and forwards whole messages .
string representation of the channel status .
allocate an indicator for tracking the status of a channel endpoint .
the implementation of { @link fragmenthandler } that reassembles and forwards whole messages .
reset the values .
ensure the vector is valid for the buffer .
validate an array of vectors to make up a message and compute the total length .
how far ahead a producer can get from a consumer position .
get the { @link idlestrategy } that should be applied to { @link org . agrona . concurrent . agent } s .
get the supplier of { @link sendchannelendpoint } s which can be used for debugging monitoring or modifying the behaviour when sending to the channel .
get the supplier of { @link receivechannelendpoint } s which can be used for debugging monitoring or modifying the behaviour when receiving from the channel .
get the supplier of { @link flowcontrol } s which can be used for changing behavior of flow control for unicast publications .
get the supplier of { @link flowcontrol } s which can be used for changing behavior of flow control for multicast publications .
get the supplier of { @link congestioncontrol } implementations which can be used for receivers .
validate that the mtu is an appropriate length . mtu lengths must be a multiple of { @link framedescriptor#frame_alignment } .
get the { @link terminationvalidator } implementations which can be used for validating a termination request sent to the driver to ensure the client has the right to terminate a driver .
validate that the socket buffer lengths are sufficient for the media driver configuration .
validate that page size is valid and alignment is valid .
validate the range of session ids based on a high and low value provided which accounts for the values wrapping .
validate that the timeouts for unblocking publications from a client are valid .
set the error code for the command .
get the { @link set } of { @link clustereventcode } s that are enabled for the logger .
get the { @link set } of { @link archiveeventcode } s that are enabled for the logger .
get the { @link set } of { @link drivereventcode } s that are enabled for the logger .
reset the state of a cluster member so it can be canvassed and reestablished .
parse the details for a cluster members from a string . <p > <code > member - id client - facing : port member - facing : port log : port transfer : port archive : port|1 ... < / code >
encode member details from a cluster members array to a string .
add the publications for sending status messages to the other members of the cluster .
close the publications associated with members of the cluster .
add an exclusive { @link publication } for communicating to a member on the member status channel .
populate map of { @link clustermember } s which can be looked up by id .
check if the cluster leader has an active quorum of cluster followers .
calculate the position reached by a quorum of cluster members .
reset the log position of all the members to the provided value .
has the members of the cluster the voted reached the provided position in their log .
become a candidate by voting for yourself and resetting the other votes to { @link aeron#null_value } .
has the candidate got unanimous support of the cluster?
has sufficient votes being counted for a majority for all members observed during { @link election . state#canvass } ?
has sufficient votes being counted for a majority?
determine which member of a cluster this is and check endpoints .
check the member with the memberendpoints
are two cluster members using the same endpoints?
has the member achieved a unanimous view to be a suitable candidate in an election .
has the member achieved a quorum view to be a suitable candidate in an election .
the result is positive if lhs has the more recent log zero if logs are equal and negative if rhs has the more recent log .
the result is positive if lhs has the more recent log zero if logs are equal and negative if rhs has the more recent log .
is the string of member endpoints not duplicated in the members .
find the index at which a member id is present .
find a { @link clustermember } with a given id .
add a new member to an array of { @link clustermember } s .
remove a member from an array if found otherwise return the array unmodified .
find the highest member id in an array of members .
create a string of member facing endpoints by id in format { @code id = endpoint id = endpoint ... } .
{
attempt to unblock the current term at the current offset . <ol > <li > current position length is &gt ; 0 then return< / li > <li > current position length is 0 scan forward by frame alignment until one of the following : <ol > <li > reach a non - 0 length unblock up to indicated position ( check original frame length for non - 0 ) < / li > <li > reach end of term and tail position &gt ; = end of term unblock up to end of term ( check original frame length for non - 0 ) < / li > <li > reach tail position &lt ; end of term do not unblock< / li > < / ol > < / li > < / ol >
map the cnc file if it exists .
is a media driver active in the given directory?
is a media driver active in the current aeron directory?
is a media driver active in the current mapped cnc buffer? if the driver is mid start then it will wait for up to the drivertimeoutms by checking for the cncversion being set .
request a driver to run its termination hook .
read the error log to a given { @link printstream }
read the error log to a given { @link printstream }
get the length of a frame from the header as a volatile read .
write the length header for a frame in a memory ordered fashion .
write the type field for a frame .
write the flags field for a frame .
write the term offset field for a frame .
write the term id field for a frame .
called from the { @link sender } to add information to the control packet dispatcher .
send contents of a { @link bytebuffer } to connected address . this is used on the sender side for performance over send ( bytebuffer socketaddress ) .
find the active counter id for a stream based on the recording id .
find the active counter id for a stream based on the session id .
get the recording id for a given counter id .
get the { @link image#sourceidentity () } for the recording .
is the recording counter still active .
utility for parsing socket addresses from a { @link charsequence } . supports hostname : port ipv4address : port and [ ipv6address ] : port
{
scan for gaps from the scanoffset up to a limit offset . each gap will be reported to the { @link gaphandler } .
launch a new { @link clusteredmediadriver } with provided contexts .
identifier for the receiver to distinguish them for flowcontrol strategies .
identifier for the receiver to distinguish them for flowcontrol strategies .
retrieve the application specific feedback ( if present ) from the status message .
set the application specific feedback for the status message .
reload the log from disk .
find the last recording id used for a leader ship term . if not found then { @link recordingpos#null_recording_id } .
find the last leadership term in the recording log .
get the term { @link entry } for a given leadership term id .
create a recovery plan for the cluster that when the steps are replayed will bring the cluster back to the latest stable state .
create a recovery plan that has only snapshots . used for dynamicjoin snapshot load .
append a log entry for a leadership term .
append a log entry for a snapshot .
commit the position reached in a leadership term before a clean shutdown .
tombstone an entry in the log so it is no longer valid .
connect to the cluster providing { @link context } for configuration .
begin an attempt at creating a connection which can be completed by calling { @link asyncconnect#poll () } until it returns the client before complete it will return null .
close session and release associated resources .
non - blocking publish of a partial buffer containing a message plus session header to a cluster . <p > this version of the method will set the timestamp value in the header to zero .
non - blocking publish by gathering buffer vectors into a message . the first vector will be replaced by the cluster ingress header so must be left unused .
send a keep alive message to the cluster to keep this session open . <p > <b > note : < / b > keepalives can fail during a leadership transition . the consumer should continue to call { @link #pollegress () } to ensure a connection to the new leader is established .
to be called when a new leader event is delivered . this method needs to be called when using the { @link egressadapter } or { @link egresspoller } rather than { @link #pollegress () } method .
attempt to unblock a log buffer at given position
get the channel field as ascii
set the channel field as ascii
check that term length is valid and alignment is valid .
check that page size is valid and alignment is valid .
compare and set the value of the current active term count .
compute the current position in absolute number of bytes .
compute the total length of a log file given the term length .
store the default frame header to the log meta data buffer .
apply the default header for a message in a term .
rotate the log and update the tail counter for the new term .
set the initial value for the termid in the upper bits of the tail counter .
read the termoffset from a packed raw tail value .
set the raw value of the tail for the given partition .
set the raw value of the tail for the given partition .
get the raw value of the tail for the current active partition .
compare and set the raw value of the tail for the given partition .
launch an { @link archive } with that communicates with an out of process { @link io . aeron . driver . mediadriver } and await a shutdown signal .
fill the token buffer .
allocate a counter to represent the snapshot services should load on start .
find the active counter id for recovery state .
get the position at which the snapshot was taken . { @link aeron#null_value } if no snapshot for recovery .
has the recovery process got a log to replay?
get the recording id of the snapshot for a service .
convert header flags to an array of chars to be human readable .
create a new entry for recording loss on a given stream . <p > if not space is remaining in the error report then null is returned .
non - blocking publish of a partial buffer containing a message plus session header to a cluster . <p > this version of the method will set the timestamp value in the header to { @link aeron#null_value } .
set the channel field in ascii
try to gap fill the current term at a given offset if the gap contains no data . <p > note : the gap offset plus gap length must end on a { @link framedescriptor#frame_alignment } boundary .
reads data from a term in a log buffer and updates a passed { @link position } so progress is not lost in the event of an exception .
write a header to the term buffer in { @link byteorder#little_endian } format using the minimum instructions .
non - blocking publish of a partial buffer containing a message to a cluster .
wrap a region of an underlying log buffer so can can represent a claimed space for use by a publisher .
put bytes into the claimed buffer space for a message . to write multiple parts then use { @link #buffer () } and { @link #offset () } .
commit the message to the log buffer so that is it available to subscribers .
abort a claim of the message space to the log buffer so that the log can progress by ignoring this claim .
start media driver as a stand - alone process .
launch an isolated mediadriver embedded in the current process with a provided configuration ctx and a generated aerondirectoryname ( overwrites configured { @link context#aerondirectoryname () } ) that can be retrieved by calling aerondirectoryname . <p > if the aerondirectoryname is set as a system property or via context to something different than { @link commoncontext#aeron_dir_prop_default } then this set value will be used .
shutdown the media driver by stopping all threads and freeing resources .
poll for new messages in a stream . if new messages are found beyond the last consumed position then they will be delivered to the { @link fragmenthandler } up to a limited number of fragments as specified . <p > use a { @link fragmentassembler } to assemble messages which span multiple fragments .
poll for new messages in a stream . if new messages are found beyond the last consumed position then they will be delivered to the { @link controlledfragmenthandler } up to a limited number of fragments as specified . <p > use a { @link controlledfragmentassembler } to assemble messages which span multiple fragments .
peek for new messages in a stream by scanning forward from an initial position . if new messages are found then they will be delivered to the { @link controlledfragmenthandler } up to a limited position . <p > use a { @link controlledfragmentassembler } to assemble messages which span multiple fragments . scans must also start at the beginning of a message so that the assembler is reset .
poll for new messages in a stream . if new messages are found beyond the last consumed position then they will be delivered to the { @link blockhandler } up to a limited number of bytes . <p > a scan will terminate if a padding frame is encountered . if first frame in a scan is padding then a block for the padding is notified . if the padding comes after the first frame in a scan then the scan terminates at the offset the padding frame begins . padding frames are delivered singularly in a block . <p > padding frames may be for a greater range than the limit offset but only the header needs to be valid so relevant length of the frame is { @link io . aeron . protocol . dataheaderflyweight#header_length } .
poll for new messages in a stream . if new messages are found beyond the last consumed position then they will be delivered to the { @link rawblockhandler } up to a limited number of bytes . <p > this method is useful for operations like bulk archiving a stream to file . <p > a scan will terminate if a padding frame is encountered . if first frame in a scan is padding then a block for the padding is notified . if the padding comes after the first frame in a scan then the scan terminates at the offset the padding frame begins . padding frames are delivered singularly in a block . <p > padding frames may be for a greater range than the limit offset but only the header needs to be valid so relevant length of the frame is { @link io . aeron . protocol . dataheaderflyweight#header_length } .
get the current position to which the image has advanced on reading this message .
set channel field in ascii
create new { @link rawlog } in the publications directory for the supplied triplet .
create new { @link rawlog } in the rebuilt publication images directory for the supplied triplet .
allocate a counter to represent the heartbeat of a clustered service .
find the active counter id for heartbeat of a given service id .
take a snapshot of all the backlog information and group by stream .
print a snapshot of the stream backlog with some explanation to a { @link printstream } . <p > each stream will be printed in its own section .
scan for gaps and handle received data . <p > the handler keeps track from scan to scan what is a gap and what must have been repaired .
non - blocking publish of a partial buffer containing a message .
non - blocking publish of a message composed of two parts e . g . a header and encapsulated payload .
try to claim a range in the publication log into which a message can be written with zero copy semantics . once the message has been written then { @link bufferclaim#commit () } should be called thus making it available . <p > <b > note : < / b > this method can only be used for message lengths less than mtu length minus header . if the claim is held for more than the aeron . publication . unblock . timeout system property then the driver will assume the publication thread is dead and will unblock the claim thus allowing other threads to make progress or to reach end - of - stream ( eos ) . <pre > { @code final bufferclaim bufferclaim = new bufferclaim () ; // can be stored and reused to avoid allocation
scan a term buffer for a block of message fragments from an offset up to a limitoffset . <p > a scan will terminate if a padding frame is encountered . if first frame in a scan is padding then a block for the padding is notified . if the padding comes after the first frame in a scan then the scan terminates at the offset the padding frame begins . padding frames are delivered singularly in a block . <p > padding frames may be for a greater range than the limit offset but only the header needs to be valid so relevant length of the frame is { @link io . aeron . protocol . dataheaderflyweight#header_length } .
launch an { @link consensusmodule } with that communicates with an out of process { @link io . aeron . archive . archive } and { @link io . aeron . driver . mediadriver } then awaits shutdown signal .
allocate a counter for tracking the last heartbeat of an entity .
create an aeron instance and connect to the media driver . <p > threads required for interacting with the media driver are created and managed within the aeron instance . <p > if an exception occurs while trying to establish a connection then the { @link context#close () } method will be called on the passed context .
print out the values from { @link #countersreader () } which can be useful for debugging .
add a new { @link subscription } for subscribing to messages from publishers . <p > this method will override the default handlers from the { @link aeron . context } i . e . { @link aeron . context#availableimagehandler ( availableimagehandler ) } and { @link aeron . context#unavailableimagehandler ( unavailableimagehandler ) } . null values are valid and will result in no action being taken .
allocate a counter on the media driver and return a { @link counter } for it . <p > the counter should be freed by calling { @link counter#close () } .
this is called automatically by { @link aeron#connect ( aeron . context ) } and its overloads . there is no need to call it from a client application . it is responsible for providing default values for options that are not individually changed through field setters .
clean up all resources that the client uses to communicate with the media driver .
dispatch a descriptor message to a consumer by reading the fields in the correct order .
insert a packet of frames into the log at the appropriate termoffset as indicated by the term termoffset header . <p > if the packet has already been inserted then this is a noop .
construct a capacitybytearrayoutputstream configured such that its initial slab size is determined by { @link #initialslabsizeheuristic } with targetcapacity == maxcapacityhint
the new slab is guaranteed to be at least minimumsize
writes the complete contents of this buffer to the specified output stream argument . the output stream s write method <code > out . write ( slab 0 slab . length ) < / code > ) will be called once per slab .
when re - using an instance with reset it will adjust slab size based on previous data size . the intent is to reuse the same instance for the same type of data ( for example the same column ) . the assumption is that the size in the buffer will be consistent .
replace the byte stored at position index in this stream with value
adds the data from the specified statistics to this builder
min [ i ] > = min [ i + 1 ] && max [ i ] > = max [ i + 1 ]
called to initialize the column reader from a part of a page .
same functionality as method of the same name that takes a bytebuffer instead of a byte [] .
called to initialize the column reader from a part of a page .
set the subset of columns to read ( projection pushdown ) . specified as an avro schema the requested projection is converted into a parquet schema for parquet column projection . <p > this is useful if the full schema is large and you only want to read a few columns since it saves time by not reading unused columns . <p > if a requested projection is set then the avro schema used for reading must be compatible with the projection . for instance if a column is not included in the projection then it must either not be included or be optional in the read schema . use {
override the avro schema to use for reading . if not set the avro schema used for writing is used . <p > differences between the read and write schemas are resolved using <a href = http : // avro . apache . org / docs / current / spec . html#schema + resolution > avro s schema resolution rules< / a > .
uses an instance of the specified {
todo : making the assumption that getconverter ( i ) is only called once is that valid?
calculates the row ranges containing the indexes of the rows might match the specified filter .
call this method when setting up your hadoop job if reading into a thrift object that is not encoded into the parquet - serialized thrift metadata ( for example writing with apache thrift but reading back into twitter scrooge version of the same thrift definition or a different but compatible apache thrift class ) .
1 anonymous element array_element
an optional group containing multiple elements
2 elements : key value
expands a string with braces ( {} ) into all of its possible permutations . we call anything inside of {} braces a one - of group .
/ * creates a new rowranges object with the single range [ 0 rowcount - 1 ] .
/ * creates a new rowranges object with the following ranges . [ firstrowindex [ 0 ] lastrowindex [ 0 ]] [ firstrowindex [ 1 ] lastrowindex [ 1 ]] ... [ firstrowindex [ n ] lastrowindex [ n ]] ( see offsetindex . getfirstrowindex and offsetindex . getlastrowindex for details . )
/ * calculates the union of the two specified rowranges object . the union of two range is calculated if there are no elements between them . otherwise the two disjunct ranges are stored separately . for example : [ 113 241 ]  [ 221 340 ] = [ 113 330 ] [ 113 230 ]  [ 231 340 ] = [ 113 340 ] while [ 113 230 ]  [ 232 340 ] = [ 113 230 ] [ 232 340 ]
/ * calculates the intersection of the two specified rowranges object . two ranges intersect if they have common elements otherwise the result is empty . for example : [ 113 241 ]  [ 221 340 ] = [ 221 241 ] while [ 113 230 ]  [ 231 340 ] = <empty >
/ * adds a range to the end of the list of ranges . it maintains the disjunct ascending order ( * ) of the ranges by trying to union the specified range to the last ranges in the list . the specified range shall be larger ( * ) than the last one or might be overlapped with some of the last ones . ( * ) [ a b ] < [ c d ] if b < c
stores a positive long into an int ( assuming it fits )
parse a string into a { @link globnodesequence }
for pretty printing which character had the error
if we are currently writing a bit - packed - run update the bit - packed - header and consider this run to be over
reads one record from in and writes it to out exceptions are not recoverable as record might be halfway written
given a filterpredicate return a filter that wraps it . this method also logs the filter being used and rewrites the predicate to not include the not () operator .
given either a filterpredicate or the class of an unboundrecordfilter or neither ( but not both ) return a filter that wraps whichever was provided . <p > either filterpredicate or unboundrecordfilterclass must be null or an exception is thrown . <p > if both are null the no op filter will be returned .
for files provided check if there s a summary file . if a summary file is found it is used otherwise the file footer is used .
for files provided check if there s a summary file . if a summary file is found it is used otherwise the file footer is used .
read all the footers of the files provided ( not using summary files )
read the footers of all the files under that path ( recursively ) not using summary files .
read the footers of all the files under that path ( recursively ) not using summary files . rowgroups are not skipped
this always returns the row groups
read the footers of all the files under that path ( recursively ) using summary files if possible
specifically reads a given summary file
reads the meta data block in the footer of the file
reads the meta data in the footer of the file . skipping row groups ( or not ) based on the provided filter
reads the meta data block in the footer of the file
reads the meta data block in the footer of the file using provided input stream
open a { @link inputfile file } .
open a { @link inputfile file } with { @link parquetreadoptions options } .
reads all the columns requested from the row group at the current file position .
reads all the columns requested from the row group at the current file position . it may skip specific pages based on the column indexes according to the actual filter . as the rows are not aligned among the pages of the different columns row synchronization might be required . see the documentation of the class synchronizingcolumnreader for details .
returns a { @link dictionarypagereadstore } for the row group that would be returned by calling { @link #readnextrowgroup () } or skipped by calling { @link #skipnextrowgroup () } .
reads and decompresses a dictionary page for the given column chunk .
add a new writer and its memory allocation to the memory manager .
remove the given writer from the memory manager .
update the allocated size of each writer based on the current allocations and pool size .
register callback and deduplicate it if any .
start the file
start a block
start a column inside a block
writes a dictionary page page
writes a single page
writes a single page
writes a single page
writes a column chunk at once
end a column ( once all rep def and data have been written )
ends a block once all column chunks have been written
copy from a fs input stream to an output stream . thread - safe
ends a file once all blocks have been written . closes the file .
given a list of metadata files merge them into a single parquetmetadata requires that the schemas be compatible and the extrametadata be exactly equal .
given a list of metadata files merge them into a single metadata file . requires that the schemas be compatible and the extrametadata be exactly equal . this is useful when merging 2 directories of parquet files into a single directory as long as both directories were written with compatible schemas and equal extrametadata .
writes a _metadata and _common_metadata file
writes _common_metadata file and optionally a _metadata file depending on the {
will return the result of merging tomerge into mergedmetadata
will return the result of merging tomerge into mergedschema
will return the result of merging tomerge into mergedschema
reads the value into the binding .
returns whether null is allowed by the schema .
merges { @link schema } instances if they are compatible . <p > schemas are incompatible if : <ul > <li > the { @link schema . type } does not match . < / li > <li > for record schemas the record name does not match< / li > <li > for enum schemas the enum name does not match< / li > < / ul > <p > map value array element and record field types types will use unions if necessary and union schemas are merged recursively .
merges two { @link schema } instances if they are compatible . <p > two schemas are incompatible if : <ul > <li > the { @link schema . type } does not match . < / li > <li > for record schemas the record name does not match< / li > <li > for enum schemas the enum name does not match< / li > < / ul > <p > map value and array element types will use unions if necessary and union schemas are merged recursively .
merges two { @link schema } instances or returns { @code null } . <p > the two schemas are merged if they are the same type . records are merged if the two records have the same name or have no names but have a significant number of shared fields . <p > @see { @link #mergeorunion } to return a union when a merge is not possible .
creates a union of two { @link schema } instances . <p > if either { @code schema } is a union this will attempt to merge the other schema with the types contained in that union before adding more types to the union that is produced . <p > if both schemas are not unions no merge is attempted .
merges two { @link schema } instances or returns { @code null } . <p > the two schemas are merged if they are the same type . records are merged if the two records have the same name or have no names but have a significant number of shared fields . <p > @see { @link #mergeorunion } to return a union when a merge is not possible .
returns a union { @link schema } of null and the given { @code schema } . <p > a null schema is always the first type in the union so that a null default value can be set .
creates a new field with the same name schema doc and default value as the incoming schema . <p > fields cannot be used in more than one record ( not immutable? ) .
returns the first non - null object that is passed in .
{
{
returns a the value as the first matching schema type or null .
reads thriftmetadata from the parquet file footer .
creates thriftmetadata from a thrift - generated class .
generates a map of key values to store in the footer
writes the current null value
writes the current value
writes the current value
finalizes the column chunk . possibly adding extra pages if needed ( dictionary ... ) is called right after writepage
writes the current data to a new page in the page store
visible for testing
visible for testing
{
{
{
{
{
{
{
returns the { @link type } specific comparator for properly comparing values . the natural ordering of the values might not proper in certain cases ( e . g . { @code uint_32 } requires unsigned comparison of { @code int } values while the natural ordering is signed . )
eagerly loads all the data into memory
the value buffer is allocated so that the size of it is multiple of mini block because when writing data is flushed on a mini block basis
mini block has a size of 8 * n unpack 8 value each time
will merge the metadata as if it was coming from a single file . ( for all part files written together this will always work ) if there are conflicting values an exception will be thrown
helper method to convert the old representation of logical types ( originaltype ) to new logical type .
{
getbytes will trigger flushing block buffer do not write after getbytes () is called without calling reset ()
precondition - style validation that throws { @link illegalargumentexception } .
precondition - style validation that throws { @link illegalstateexception } .
reads one record from in and writes it to out . exceptions encountered during reading are treated as skippable exceptions { @link fieldignoredhandler } will be notified when registered .
in thrift enum values are written as ints this method checks if the enum index is defined .
attempts to validate and construct a { @link messagetype } from a read projection schema
called in { @link org . apache . hadoop . mapreduce . inputformat#getsplits ( org . apache . hadoop . mapreduce . jobcontext ) } in the front end
called in { @link org . apache . hadoop . mapreduce . inputformat#getsplits ( org . apache . hadoop . mapreduce . jobcontext ) } in the front end
sets min and max values re - uses the byte [] passed in . any changes made to byte [] will be reflected in min and max values as well .
iterate through values in each mini block and calculate the bitwidths of max values .
returns builder for creating an and filter .
{
/ * creates a column index store which lazily reads column / offset indexes for the columns in paths . ( paths are the set of columns used for the projection )
returns builder for creating an and filter .
if the given throwable is an instance of e throw it as an e .
returns the typed statistics object based on the passed type parameter
creates an empty { @code statistics } instance for the specified type to be used for reading / writing the new min / max statistics used in the v2 format .
returns a builder to create new statistics object . used to read the statistics from the parquet file .
method to merge this statistics object with the object passed as parameter . merging keeps the smallest of min values largest of max values and combines the number of null counts .
given a schema check to see if it is a union of a null type and a regular schema and then return the non - null sub - schema . otherwise return the given schema .
implements the rules for interpreting existing data from the logical type spec for the list annotation . this is used to produce the expected schema . <p > the avroarrayconverter will decide whether the repeated type is the array element type by testing whether the element schema and repeated type are the same . this ensures that the list rules are followed when there is no schema and that a schema can be provided to override the default behavior .
creates jobcontext from a jobconf and jobid using the correct constructor for based on hadoop version . <code > jobid< / code > could be null .
creates taskattemptcontext from a jobconf and jobid using the correct constructor for based on hadoop version .
invoke getconfiguration () method on jobcontext . works with both hadoop 1 and 2 .
invokes a method and rethrows any exception as runtime exceptions .
appends a display string for of the members of this group to sb
{
produces the list of fields resulting from merging tomerge into the fields of this
init counters in hadoop s mapred api which is used by cascading and hive .
fills specified buffer with compressed data . returns actual number of bytes of compressed data . a return value of 0 indicates that needsinput () should be called in order to determine if more input data is required .
closes a ( potentially null ) closeable swallowing any ioexceptions thrown by c . close () . the exception will be logged .
returns a non - null filter which is a wrapper around either a filterpredicate an unboundrecordfilter or a no - op filter .
{
{
/ * this is to support multi - level / recursive directory listing until mapreduce - 1577 is fixed .
the footers for the files
groups together all the data blocks for the same hdfs block
keeps records if their value is equal to the provided value . nulls are treated the same way the java programming language does . <p > for example : eq ( column null ) will keep all records whose value is null . eq ( column 7 ) will keep all records whose value is 7 and will drop records whose value is null
keeps records if their value is not equal to the provided value . nulls are treated the same way the java programming language does . <p > for example : noteq ( column null ) will keep all records whose value is not null . noteq ( column 7 ) will keep all records whose value is not 7 including records whose value is null .
keeps records if their value is less than ( but not equal to ) the provided value . the provided value cannot be null as less than null has no meaning . records with null values will be dropped . <p > for example : lt ( column 7 ) will keep all records whose value is less than ( but not equal to ) 7 and not null .
keeps records if their value is less than or equal to the provided value . the provided value cannot be null as less than null has no meaning . records with null values will be dropped . <p > for example : lteq ( column 7 ) will keep all records whose value is less than or equal to 7 and not null .
keeps records if their value is greater than ( but not equal to ) the provided value . the provided value cannot be null as less than null has no meaning . records with null values will be dropped . <p > for example : gt ( column 7 ) will keep all records whose value is greater than ( but not equal to ) 7 and not null .
keeps records if their value is greater than or equal to the provided value . the provided value cannot be null as less than null has no meaning . records with null values will be dropped . <p > for example : gteq ( column 7 ) will keep all records whose value is greater than or equal to 7 and not null .
keeps records that pass the provided { @link userdefinedpredicate } <p > the provided class must have a default constructor . to use an instance of a userdefinedpredicate instead see userdefined below .
keeps records that pass the provided { @link userdefinedpredicate } <p > the provided instance of userdefinedpredicate must be serializable .
prints a debug message
prints a debug message
prints an info message
prints an info message
prints a warn message
prints a warn message
prints an error message
prints an error message
returns builder for creating an and filter .
writes protocol buffer to parquet file .
validates mapping between protobuffer fields and parquet fields .
returns message descriptor as json string
create a codec factory that will provide compressors and decompressors that will work natively with bytebuffers backed by direct memory .
a . 2 . b [ 3 ] [ key ] * optional ( union with null ) should be ignored * unions should match by position number or short name ( e . g . 2 user ) * fields should match by name * arrays are dereferenced by position [ n ] = &gt ; schema is the element schema * maps are dereferenced by key = &gt ; schema is the value schema
given a thrift definition protocols events it checks all the required fields and create default value if a required field is missing
check each element of the set make sure all the element contain required fields
reads the meta data from the stream
close the file
set the schema being written to the job conf
set up the mapping in both directions
asserts that foundcolumn was declared as a type that is compatible with the type for this column found in the schema of the parquet file .
join an iterable of strings into a single string with a delimiter . for example join ( arrays . aslist ( foo bar x ) | ) would return foo||bar|x
join an iterator of strings into a single string with a delimiter . for example join ( arrays . aslist ( foo bar x ) | ) would return foo||bar|x
join an array of strings into a single string with a delimiter . for example join ( new string [] { foo bar x } | ) would return foo||bar|x
expands a string according to { @link #expandglob ( string ) } and then constructs a { @link wildcardpath } for each expanded result which can be used to match strings as described in { @link wildcardpath } .
cast value to a an int or throw an exception if there is an overflow .
internal method visible for testing purposes
internal method visible for testing purposes
todo : all the catching of exceptions below -- see parquet - 383
compatibility api
compatibility api
creates a parquet schema from an arrow one and returns the mapping
creates an arrow schema from an parquet one and returns the mapping
maps a parquet and arrow schema for now does not validate primitive type compatibility
visible for testing
visible for testing
visible for testing
returns whether to use signed order min and max with a type . it is safe to use signed min and max when the type is a string type and contains only ascii characters ( where the sign bit was 0 ) . this checks whether the type is a string type and uses { @code usesignedstringminmax } to determine if only ascii characters were written .
visible for testing
visible for testing
visible for testing
visible for testing
visible for testing
visible for testing
statistics are no longer saved in page headers
writes a <code > long< / code > to the underlying output stream as eight bytes low byte first . in no exception is thrown the counter <code > written< / code > is incremented by <code > 8< / code > .
skips forwards until the filter finds the first match . returns false if none found .
writes an object to a configuration .
reads an object ( that was written using { @link #writeobjecttoconfasbase64 } ) from a configuration
adds the specified parameters to this builder . used by the writers to building up { @link offsetindex } objects to be written to the parquet file .
adds the specified parameters to this builder . used by the metadata converter to building up { @link offsetindex } objects read from the parquet file .
builds the offset index . used by the writers to building up { @link offsetindex } objects to be written to the parquet file .
removes the mapping for the specified key from this cache if present .
associates the specified value with the specified key in this cache . the value is only inserted if it is not null and it is considered current . if the cache previously contained a mapping for the key the old value is replaced only if the new value is newer than the old one .
returns the value to which the specified key is mapped or null if 1 ) the value is not current or 2 ) this cache contains no mapping for the key .
calls an appropriate write method based on the value . value must not be null .
set and compile a glob pattern
output content to the console or a file .
returns a qualified { @link path } for the { @code filename } .
returns a { @link uri } for the { @code filename } that is a qualified path or a resource uri .
opens an existing file or resource .
returns a { @link classloader } for a set of jars and directories .
returns a { @link classloader } for a set of jars .
returns a { @link classloader } for a set of directories .
{
{
factory method for record filter which applies the supplied predicate to the specified column . note that if searching for a repeated sub - attribute it will only ever match against the first instance of it in the object .
/ * returns the filtered offset index containing only the pages which are overlapping with rowranges .
struct is assumed to contain valid structoruniontype metadata when used with this method . this method may throw if structoruniontype is unknown .
struct is not required to have known structoruniontype which is useful for converting a structtype from an ( older ) file schema to a messagetype
returns whether the given type is the element type of a list or is a synthetic group with one field that is the element type . this is determined by checking whether the type can be a synthetic group and by checking whether a potential synthetic group matches the expected thriftfield . <p > this method never guesses because the expected thriftfield is known .
to preserve the difference between empty list and null when optional
creates a 3 - level list structure annotated with list with elements of the given elementtype . the repeated level is inserted automatically and the elementtype s repetition should be the correct repetition of the elements required for non - null and optional for nullable .
{
{
{
if there is a conflicting value when reading from multiple files an exception will be thrown
gets a parquetinputsplit corresponding to a split given by hive
{
see the general contract of the <code > skipbytes< / code > method of <code > datainput< / code > . <p > bytes for this operation are read from the contained input stream .
bytes for this operation are read from the contained input stream .
bytes for this operation are read from the contained input stream .
builds a { @code parquetinputsplit } from a mapreduce { @link filesplit } .
builds a { @code parquetinputsplit } from a mapred { @link org . apache . hadoop . mapred . filesplit } .
{
{
returns a builder to construct a required { @link primitivetype } .
returns a builder to construct an optional { @link primitivetype } .
returns a builder to construct a repeated { @link primitivetype } .
returns a builder to construct a required { @link grouptype } .
returns a builder to construct an optional { @link grouptype } .
returns a builder to construct a repeated { @link grouptype } .
( not an actual iterable )
decides if the statistics from a file created by createdby ( the created_by field from parquet format ) should be ignored because they are potentially corrupt .
todo : have those wrappers for a converter
this was taken from avro s reflectdata
returns whether the given type is the element type of a list or is a synthetic group with one field that is the element type . this is determined by checking whether the type can be a synthetic group and by checking whether a potential synthetic group matches the expected schema . <p > unlike { @link avroschemaconverter#iselementtype ( type string ) } this method never guesses because the expected schema is known .
{
{
{
{
{
{
{
{
{
{
{
{
{
{
determine the file column names based on the position within the requested columns and use that as the requested schema .
{
{
{
get all input files .
check input files basically . parquetfilereader will throw exception when reading an illegal parquet file .
get all parquet files under partition directory .
{
returns builder for creating a paged query .
visible for testing
visible for testing
visible for testing
visible for testing
visible for testing
to consume a list of elements
initialize the mrwork variable in order to get all the partition and start to update the jobconf
{
/ * iterates over list of fields . *
filters a parquet schema based on a pig schema for projection
filters a parquet schema based on a pig schema for projection
create a { @link schema } for the given type . if the type is null the schema will be a nullable string . if isnullable is true the returned schema will be nullable .
a { @link thriftrecordconverter } builds an object by working with { @link tprotocol } . the default implementation creates standard apache thrift { @link tbase } objects ; to support alternatives such as <a href = http : // github . com / twitter / scrooge > twiter s scrooge< / a > a custom converter can be specified ( for example scroogerecordconverter from parquet - scrooge ) .
a { @link thriftrecordconverter } builds an object by working with { @link tprotocol } . the default implementation creates standard apache thrift { @link tbase } objects ; to support alternatives such as <a href = http : // github . com / twitter / scrooge > twiter s scrooge< / a > a custom converter can be specified ( for example scroogerecordconverter from parquet - scrooge ) .
the input tuple contains a bag of string representations of tuplesummarydata
the input tuple contains a bag of tuples to sum up
{
}
reads a struct from the underlying protocol and passes the field events to the fieldconsumer
reads the content of a struct ( fields ) from the underlying protocol and passes the events to c
reads the set content ( elements ) from the underlying protocol and passes the events to the set event consumer
reads the map content ( key values ) from the underlying protocol and passes the events to the map event consumer
reads a key - value pair
reads the list content ( elements ) from the underlying protocol and passes the events to the list event consumer
writes an int using the requested number of bits . accepts only values less than 2^bitwidth
reads an int in little endian at the given position
write a little endian int to out using the the number of bytes required by bit width @param out an output stream @param v an int value @param bitwidth bit width for padding @throws ioexception if there is an exception while writing
uses a trick mentioned in https : // developers . google . com / protocol - buffers / docs / encoding to read zigzag encoded data
uses a trick mentioned in https : // developers . google . com / protocol - buffers / docs / encoding to read zigzag encoded data todo : the implementation is compatible with readzigzagvarint . is there a need for different functions?
fills specified buffer with uncompressed data . returns actual number of bytes of uncompressed data . a return value of 0 indicates that { @link #needsinput () } should be called in order to determine if more input data is required .
sets input data for decompression . this should be called if and only if { @link #needsinput () } returns <code > true< / code > indicating that more input data is required . ( both native and non - native versions of various decompressors require that the data passed in via <code > b [] < / code > remain unmodified until the caller is explicitly notified -- via { @link #needsinput () } -- that the buffer may be safely modified . with this requirement an extra buffer - copy can be avoided . )
set the avro schema to use for writing . the schema is translated into a parquet schema so that the records can be written in parquet format . it is also stored in the parquet metadata so that records can be reconstructed as avro objects at read time without specifying a read schema .
{
wraps a { @link fsdatainputstream } in a { @link seekableinputstream } implementation for parquet readers .
theoretically they could just copy / paste the output into the topics bulk edit field in the kafka config
should be called only by mapr streams producer . it creates a topic using kafkaproducer .
create a stringredactor based on the json found in a file . the file format looks like this : { version : 1 rules : [ { description : this is the first rule trigger : triggerstring 1 search : regex 1 replace : replace 1 } { description : this is the second rule trigger : triggerstring 2 search : regex 2 replace : replace 2 } ] }
create a stringredactor based on the json found in the given string . the format is identical to that described in createfromjsonfile () .
create pipelinebean which means instantiating all stages for the pipeline .
creates additional pipelinestagebeans for additional runners . stages will share stage definition and thus class loader with the first given runner . that includes stages with private class loader as well .
create new instance of stagebean .
create interceptors for given stage .
create a default interceptor for given interceptordefinition . this method might return null as the underlying interface for default creation allows it as well - in such case no interceptor is needed .
parse json representation of avro schema to avro s schema java object
return date in milliseconds @param days number of days since unix epoch @return milliseconds representation for date
return number of days since the unix epoch .
retrieves avro schema from given header . throws an exception if the header is missing or is empty .
returns a { @link bigdecimal } from the given bytes and scale . the bytes must adhere to the format that avro stores decimals in . <br > avro stores decimal values as two s complement big - endian for the integral portion then the decimal place separately ( via the scale ) .
migrating to service for data format library .
buffer size .
copy blobstore resources to data directory
reset the listener to use with the next statement . all column information is cleared .
updates gauge for the registered thread with the given details . note that the value of the threadname argument must match the one used to register .
creates and registers a gauge with the given thread name . the same name must be used to report health .
store configuration from control hub in persistent manner inside data directory . this configuration will be loaded on data collector start and will override any configuration from sdc . properties .
get the available information about the user <p / > for this loginmodule the credential can be null which will result in a binding ldap authentication scenario <p / > roles are also an optional concept if required
attempts to get the users credentials from the users context <p / > note : this is not an user authenticated operation
attempts to get the users roles <p / > note : this is not an user authenticated operation
given a filter ( user / role filter ) replace attributes using given information from config . this will create complete filter which will look like & ( objectclass = inetorgperson ) ( uid = { user } ))
since ldap uses a context bind for valid authentication checking we override login () <p / > if credentials are not available from the users context or if we are forcing the binding check then we try a binding authentication check otherwise if we have the users encoded password then we can try authentication via that mechanic
password supplied authentication check
binding authentication check this method of authentication works only if the user branch of the dit ( ldap tree ) has an aci ( access control instruction ) that allow the access to any user or at least for the user that logs in .
<p > move a series of config values from old names to new names ( one to one correspondence ) . config values will be preserved . < / p >
<p > move a series of config values from old names to new names ( one to one correspondence ) . config values will be preserved . < / p >
<p > returns a { @link config } object from the supplied list with the supplied name if it exists . if a non - null config is returned the supplied list of { @code configs } will be modified such that it no longer contains the returned value . < / p >
re - login a principal . this method assumes that {
upgrade whole pipeline at once and return updated variant .
upgrade detached stage ( stage not associated directly with the pipeline ) .
upgrade whole stage configuration including all services if needed . convenience method that will lookup stage definition from the library .
upgrade whole stage configuration including all services if needed .
internal method that will upgrade service configuration if needed .
internal method that will upgrade only stage configuration - not the associated services - and only if needed .
sets the file offsets to use for the next read . to work correctly the last return offsets should be used or an empty <code > map< / code > if there is none . <p / > if a reader is already live the corresponding set offset is ignored as we cache all the contextual information of live readers .
should be replaced by null .
checks if a class should be included as a system class .
visible for testing ( todo - import guava and make sure it doesn t conflict with spark s rootclassloader )
adds the given element to this queue . if the queue is currently full the element at the head of the queue is evicted to make room .
adds the given element to this queue . if the queue is currently full the element at the head of the queue is evicted to make room and returns the evicted element .
internal method to ensure that we return and not cache the default value if needed
preview only returns data associated with batches however errors are reported outside of batch context for multi - threaded pipelines . thus we emulate the behavior by simply adding into the current batch all so - far reported errors .
returns a protobuf descriptor instance from the provided descriptor file .
loads a protobuf file descriptor set into an ubermap of file descriptors .
populates a map of protobuf extensions and map with the default values for each message field from a map of file descriptors .
generates a protobuf descriptor instance from a filedescriptor set .
converts a protobuf message to an sdc record field .
creates an sdc record field from the provided protobuf message and descriptor .
serializes a record to a protobuf message using the specified descriptor .
serializes a field path in a record to a protobuf message using the specified descriptor .
helper method to upgrade both http stages to the jerseyconfigbean
check network connection to the kudu master .
convert from kudu type to sdc field type
create a field and assign a value off of rowresult .
intercept given records with all the interceptors .
returns the text of the line .
configuration
resolve stage aliases ( e . g . when a stage is renamed ) .
resolve all stage library relevant aliases - this includes :
add any missing configs to the stage configuration .
validate given stage configuration .
{
{
waits for the jersey client to complete an asynchronous request checks the response code and continues to parse the response if it is deemed ok .
parses the http response text from a request into sdc records
populates http response headers to the configured location
writes http response headers to the sdc record at the configured field path .
writes http response headers to the sdc record header with the configured optional prefix .
commit metadata content to a file to disk .
{
helper method to apply jersey client configuration properties .
{
returns the url of the next page to fetch when paging is enabled . otherwise returns the previously configured url .
sets the startat el variable in scope for the resource and request body . if the source offset is null ( origin was reset ) then the initial value from the user provided configuration is used .
helper method to construct an http request and fetch a response .
determines whether or not we should continue making additional http requests in the current produce () call or whether to return the current batch .
parses the response of a completed request into records and adds them to the batch . if more records are available in the response than we can add to the batch the response is not closed and parsing will continue on the next batch .
used only for head requests . sets up a record for output based on headers only with an empty body .
increments the current source offset s startat portion by the specified amount . this is the number of records parsed when paging by_offset or 1 if incrementing by_page .
cleanup the {
returns the most recently requested page number or page offset requested .
parses a paginated result from the configured field .
adds the http response headers to the record header .
resolves any expressions in the header value entries of the request .
verifies that the response was a successful one and has data and continues to parse the response .
return true if and only if given property is defined with non empty non default value
change package name for dataparserexception .
change package name for datageneratorexception .
tries to create a { @link credentialsprovider } for the appropriate type of credentials supplied .
reads a json credentials file for a service account from and returns any errors .
run pipeline preview
we use this to trim the output in case of overruns
finds package names associated with a class loader which which are not jvm level packages . anything inside java home are specifically excluded as well as some os specific install locations ( macos ) .
traverses sorted list of packages and removes logical duplicates . for example if the set contains akka . akka . io . and akka . util . only akka . will remain . note that if the set contains only akka . io . and akka . util . both will remain . otherwise all of the org . apache . would devolve to org .
new data .
{
finds the first main line in the chunk from the specified index position onwards
it there is an incomplete multiline from a previous chunk it starts from it .
get {
close the current thread s connection
inputstream
inputstream
inputstream
readablebytechannel
add backslash to escape the | character within quoted sections of the input string . this prevents the | from being processed as part of a regex .
returns a flow control setting such that a subscriber will block if it has buffered more messages than can be processed in a single batch times the number of record processors . since the flow control settings are per subscriber we should divide by the number of subscribers to avoid buffering too much data in each subscriber .
creates a channel provider shared by each subscriber . it is basically the default channelprovider with the exception that it can be configured with a custom endpoint for example when running against the pubsub emulator .
generate hive type info representation inside the metadata record .
generate { @link hivetypeinfo } from the metadata record <br > . ( reverse of { @link #generatehivetypeinfofieldformetadatarecord ( hivetypeinfo ) } )
generate column definition for create table / add columns
queues the batch for the consumer and waits until the consumer successfully commits the batch . while waiting processes any control messages from the consumer . throws an exception when the consumer has indicated it encountered an error .
compiles the expression into a pattern
digests the original expression into a pure named regex
loads dictionary from an input stream
adds a dictionary entry via a reader object
stops the aggregatordataprovider instance .
atomically rolls the datawindow of all aggregators associated with the aggregatordataprovider .
returns the current aggregatordata for an aggregator . <p / > this method is also used by the group - by element aggregators .
serialize the given java object into json string .
deserialize the given json string to java object .
deserialize the given file to java object .
{
{
writes a single record to the destination .
resolve expression from record
/ * extract information from the list fields of form :
opposite operation of extractinnermapfromthelist . it takes linkedhashmap and generate a field that contains the list . this is to send metadata record to hms target . this function is called to for partition type list and partition value list .
get qualified table name ( defined as dbname . tablename )
extract column information from the column list in / columns field . <br >
extract column information from the partition list in / partitions field . <br >
extract column information from the partition list in / partitions field . <br >
returns true if this is a table metadata request ( new or changed table ) .
returns true if this is a table metadata request ( new or changed table ) .
get table name from the metadata record .
get database name from the metadata record .
get internal field from the metadata record .
get location from the metadata record .
get the customlocation flag from the metadata record . this flag marks whether or not the hive database object is stored into a custom path on the hadoop filesystem . in both cases the path is stored in the location field of the metadata record .
get avro schema from metadata record .
get dataformat from metadata record .
fill in metadata to record . this is for new partition creation . use the {
fill in metadata to record . this is for new schema creation .
evaluate precision or scale in context of record and given field path .
convert a record to linkedhashmap . this is for comparing the structure of incoming record with cache . since avro does not support char short and date types it needs to convert the type to corresponding supported types and change the value in record .
generate avro schema from column name and type information . typeinfo in 1st parameter needs to contain precision and scale information in the value ( hivetypeinfo ) . the 2nd parameter qualifiedname will be the name of avro schema .
checks whether the number of partition columns and names match w . r . t hive .
build a partition path for the external table .
returns the hdfs paths where the avro schema is stored after serializing . path is appended with current time so as to have an ordering .
gets cached { @link com . streamsets . pipeline . stage . lib . hive . cache . hmscachesupport . hmscacheinfo } from cache . <br > first call getifpresent to obtain data from local cache . if not exists load from hms
set parameters and primary keys in query .
<p > some databases drivers allow us to figure out which record in a particular batch failed . < / p > <p > in the case that we have a list of update counts we can mark just the record as erroneous . otherwise we must send the entire batch to error . < / p >
returns all sdc configuration
builds the read context cache {
initialize the gauge with needed information
generate a batch ( looping through as many tables as needed ) until a batch can be generated and then commit offset .
after a batch is generate perform needed operations generate and commit batch evict entries from {
initialize the {
wait if needed before a new query is issued . ( does not wait if the result set is already cached )
get or load {
sets the file offsets to use for the next read . to work correctly the last return offsets should be used or an empty <code > map< / code > if there is none . <p / > if a reader is already live the corresponding set offset is ignored as we cache all the contextual information of live readers .
parse date in rfc 5424 format . uses an lru cache to speed up parsing for multiple messages that occur in the same second .
parse the rfc3164 date format . this is trickier than it sounds because this format does not specify a year so we get weird edge cases at year boundaries . this implementation tries to do what i mean .
<p > puts the current thread to sleep for the specified number of milliseconds . < / p > <p > if the thread was interrupted before the sleep method is called the sleep method wont sleep . < / p > @param milliseconds number of milliseconds to sleep .
no escaping is supported no array content printing either .
serializes the <code > livefile< / code > as a string .
deserializes a string representation of a <code > livefile< / code > . <p / >
refreshes the <code > livefile< / code > if the file was renamed the path will have the new name .
{
{
this is used by destination which performs crud operations . records sent from mongooplog origin have / o field that contains a map of key - value for insert and delete operation but update record has / o2 field which contains _id and / o / $set field which contains a map of key - value to update . this method looks into the right field path for update so that users don t need a separate field - column mapping for update .
for all pushsource callbacks we have to make sure that we get back to a security context of sdc container module otherwise we won t be able to update state files with new offsets and other stuff .
parses an httpsourceoffset from a string e . g . from lastsourceoffset in {
validates the parameters for this config bean .
checks whether the record contains solr fields in solrfieldsmap or not .
filter auto - generated fields from the list passed as argument .
check that the list of mappings in { @code mappings } covers all the fields in { @code solrfields } .
handles an error that occurred when processing a record . the error can either be logged or thrown in an exception .
handles an error that occurred when processing a record . the error can either be logged or thrown in an exception .
send exception ex to errorrecordhandler in order to let the handler process it .
generate dependency from a jar file name .
generate dependency from a url .
maintains a singleton instance of the couchbaseconnector object per pipeline
disconnects from couchbase and releases all resources
validates connection configurations that don t require runtime exception handling
{
convert from code in string type to label
verify that the config definition s dependency actually maps to a valid config definition
returns true if child creates a dependency with any member ( s ) of dependencyancestors . also adds the stringified cycle to the cycles list
visible for testing
visible for testing
visible for testing
visible for testing
the user - id portion of vault s app - auth should be machine specific and at least somewhat obfuscated to make it more difficult to derive . we use the sha256 hash of the mac address of the first interface found by inetaddress . getlocalhost () .
reads a secret from the local cache if it hasn t expired and returns the value for the specified key . if the secret isn t cached or has expired it requests it from vault again .
evaluates the sdc . operation . type header for a record and returns the equivalent couchbase write operation type .
executes a document write operation .
executes a sub - document write operation .
applies standard options to sub - document mutations
influenced by javax . security . auth . subject . #doas
influenced by javax . security . auth . subject . #doas
because the path is going to be used only once ( because only one record is used ) .
h2 wants an alter table command per column
create a frame out of the { @link bytebuf } and return it .
extract the sub - region of the specified buffer . <p > if you are sure that the frame and its content are not accessed after the current {
login constructor . the constructor starts the thread used to periodically re - login to the kerberos ticket granting server .
re - login a principal . this method assumes that {
checks whether any of the {
consumes messages off the queue . returns null when the producer has indicated it is complete and throws an exception when the consumer producer has indicated it is in error .
commit the offset . required after take has returned a non - null value .
send a control message indicating the consumer has encountered an error .
/ * t0 = [ sorted_intersection ] t1 = [ sorted_intersection ] + [ sorted_rest_of_string1 ] t2 = [ sorted_intersection ] + [ sorted_rest_of_string2 ]
private methods
create a new instance of a stage that does not directly live in the pipeline canvas .
create a new instance of a stage that does not directly live in the pipeline canvas .
stuff a function into the namespace / name dual level map structure
inject config values to given stage .
processor . context
processor . context
processor . context
processor . context
processor . context
returns if the {
returns if the { @link hmscache } has the corresponding { @link hmscachesupport . hmscacheinfo } and qualified table name . this method is safe to call from multiple threads - it will block and serialize multiple readers . it guarantees that each value will be loaded at most once to limit load on hs2 as much as possible .
puts / updates the { @link hmscache } with { @link hmscachesupport . hmscacheinfo } for corresponding { @link hmscachetype } and qualified table name .
returns pipeline &amp ; stage configuration definitions this will fetch defintions based on the hidestage filter
parse given configuration declaration of lineage plugin and return appropriate definition .
format column names based on whether they are case - sensitive
unescapes strings and returns them .
find pipeline configuration by name and revision
add a new pipeline fragment configuration to the store
returns all pipeline configuration info
import pipeline fragment configuration & rules
and the hdfstarget ( in the pipeline runnable thread ) calls flushall
returns the temp file path to write records to
close all generators ( and underlying streams / files )
produce events that were cached during the batch processing .
get the numeric operation code from record header . the default code is used if the operation code is not found in the header .
get the numeric operation code from record header . the default code is used if the operation code is not found in the header . this can be overwritten in inherited classes .
iterate the columnstofield map and check if the record has all the necessary columns . the returned sortedmap contains columnname - param mapping which is only contained in this record . for example if a table in destination db has a column a but record doesn t have a field named a the column a is not included in the returning sortedmap .
this function simply returns field path in record for the corresponding column name . this is needed because records generated by cdc origins store data in different location for different operation . subclasses will override this function and implement special handling .
sorts the vertices in the topological order using { @link #tiecomparator } if needed to break ties . throws { @link illegalstateexception } if there is a cycle detected .
read next event from buffer with respect to maximum timeout .
visible for testing ( can t annotate as can t depend on guava )
copied from https : // raw . githubusercontent . com / kamranzafar / jtar / master / src / test / java / org / kamranzafar / jtar / jtartest . java
get exclusive runner for use .
return a runner that haven t been used at least for the configured number of milliseconds .
return given runner back to the pool .
destroy only the pool itself - not the individual pipe runners .
throw an exception if the runner was already destroyed .
checks for existence of the requested stream and adds any configuration issues to the list .
get the last shard id in the given stream in preview mode kinesis source uses the last shard id to get records from kinesis
process all records in queue . all records have same operation to same table . generate a query and set parameters from each record . insert and delete can be multi - row operation but update is single - row operation . if maxstatement
handle sqlexception in a smart way detecting if the exception is data oriented or not .
generates a hash for the fields present in a record and their mappings . a specific implementation of the hash function is not guaranteed .
/ * creates login url with request url as parameter for a callback redirection on a successful login .
/ * removes the token from request url redirects to the modified url returns the token as a header
/ * terminates the request with an http unauthorized response or redirects to login for page requests
todo this is a great place for generic validator
true if f1 is newer than f2 .
/ * returns the { @code dataparser } of the file could be local file and hdfs file
returns the absolute path from the root to the last base directory meaning the path until the last / before the first *
attempts to retrieve pid from internal jvm classes . this method is not guaranteed to work as jvm is free to change their implementation at will . hence the return value should be only used for troubleshooting or debug and not for main functionality .
basically throw out map list map list and null values fields .
return ugi object that should be used for any remote operation .
returns fresh bean with same usagetimers just reset to zero accumulated time to be used as the new live stats
returns a snapshot for persistency
ensure that given directory exists .
/ * name format is vault s [ path ]
formats the error message of a { @link java . sql . sqlexception } for human consumption .
wrapper for { @link connection#getcatalog () } to solve problems with rdbms for which catalog and schema are the same thing . for these rdbms it returns the schema name when it is not - null and not - empty ; otherwise it returns the value of java . sql . connection . getcatalog () . for other rdbms it returns always the value of java . sql . connection . getcatalog () .
wrapper for { @link java . sql . databasemetadata#getcolumns ( string string string string ) } that detects the format of the supplied tablename .
wrapper for { @link java . sql . databasemetadata#gettables ( string string string string [] ) }
wrapper for { @link java . sql . databasemetadata#gettables ( string string string string [] ) }
wrapper for { @link java . sql . databasemetadata#getprimarykeys ( string string string ) }
wrapper for { @link java . sql . databasemetadata#getimportedkeys ( string string string ) }
write records to potentially different schemas and tables using el expressions and handle errors .
write records to the evaluated tables and handle errors .
write records to a jdbc destination using the recordwriter specified by key and handle errors
generates the no - more - data event
using partition name and value that were obtained from record compare them with cached partition .
obtain a list of partition values from record .
generate a record for new partition . it creates a new record and fill in metadata .
add header information to send to hdfs
processes the given value into the corresponding group - by element of the aggregator .
returns if and only if both stage classes have defined the same version .
bootstrapping the driver which starts a spark job on mesos
this function is called while thread is waiting at countdownlatch . await in stop () . it cancels tasks change pipeline state and call countdown () so that the waiting thread can proceed to terminate .
helper to apply authentication properties to jersey client .
returns true if the request contains potentially sensitive information such as a vault : read el .
evaluates any el expressions in the headers section of the stage configuration .
determines the http method to use for the next request . it may include an el expression to evaluate .
add each object of typed null to simplebindings so that script languages can use constants such as null_integer null_long without importing other files .
receive record and fieldpath from scripting processor . it resolves type of the field and if value is null it returns one of the null_xxx objects defined in this class . if field value is not null it returns the value stored in the field .
receive a scriptoject and find out if the scriptobect is one of the null_ ** object defined in this class . if so create a new field with the type and null value then return the field . if the scriptobject is not one of the typed null object it returns a new field with string converted from the value .
this method returns an {
parses and returns an avro schema loaded from the schema registry using the provided schema id if available or the latest version of a schema for the specified subject .
registers a parsed schema with the schema registry under the specified subject .
loads and parses a schema for the specified subject from the schema registry
looks up schema id for the specified subject from the schema registry
loads and parses a schema for the specified schema id from the schema registry
writes the magic byte and schema id to an output stream replicating the functionality of the confluent kafka avro serializer
checks for a magic byte in the data and if present extracts the schemaid
helper method to extract default values from a schema . this is normally done in datageneratorformat validation however we have to do it at runtime for schema registry .
convenience method to parse all available records in given payload . this method assumes that the stage already depends on dataformatparserservice service and loads the service instance from stage . context .
generate small report into log .
remove initial / replace all other slashes with dots
validates the parameters for this config bean .
waits for the jersey client to complete an asynchronous request checks the response code and continues to parse the response if it is deemed ok .
delete record have / olddata
generate list of error records from the error sink . what precise records will be returned depends on the error record policy configuration .
actual comparison with the same semantics as compareto () method .
initialize the schema generator
returns the outward flowing edge vertices .
returns the inward flowing edge vertices .
add a directed edge from vertex1 to vertex2 adding those vertices graph ( if needed )
serialize the map of table to offset to a string
deserialize string offset to map of table to offset
queue a report using the report . queue method . this will post a request with the report description to the omniture api and return a report id that can be used to retrieve the report once it s ready .
posts a request to the omniture api to get a report back . reports may take a while to generate so this will loop on the report . get request and ignore any errors indicating that the report is not yet ready .
this tell us sdc is check pointing
or if the file is corrupted we want to update the right offsets to the main offset file .
ex : partition offset empty empty map in the offset cannot deserialize
create {
delete a blob for gcs
copy a blob for gcs to a destination bucket and a path ( and delete the source blob if needed )
handle error blob
archive the blob
prepares and gets the reader if available before a read .
updates reader and offsets after a read .
helper method to set dpmbaseurl for the first http dpm authentication .
add a default header .
parse the given string into date object .
select the accept header s value from the given accepts array : if json exists in the given array use it ; otherwise use all of them ( joining into a string )
select the content - type header s value from the given array : if json exists in the given array use it ; otherwise use the first one of the array .
escape the given string to be used as url query value .
serialize the given java object into string according the given content - type ( only json is supported for now ) .
deserialize response body to java object according to the content - type .
get an existing client or create a new client to handle http request .
connect to the database
get metadata for the table
create a bulkinserter
create new event record according for this stage context and event context .
build a schema with type record . this will be the top level schema and contains fields
this is called when jdbc target didn t find sdc . operation . code in record header but found oracle . cdc . operation . since oracle . cdc . operation contains oracle specific operation code we need to convert to sdc operation code .
add jars containing the following classes to the job s classpath .
add jars whose names contain the given patterns to the job s classpath .
{
{
we don t checkpoint on shutdown_requested because we currently always checkpoint each batch in { @link #processrecords } .
{
returns true if the first order by field matches fieldname
returns true if any of the nested conditions contains fieldname
{
{
if passed a valid fileoffsetstring it will return what is the offset lag in the file .
visible due to jvm requirements only
if whitelist is * set is null else whitelist has the whitelisted values
visible for testing
visible for testing
this api is being used by clusterkafkasource
arranges the urls in the following order : <ul > <li > stage lib jars< / li > <li > protolib jars< / li > <li > non protolib jars< / li > < / ul >
executes a query request and returns the results . a timeout is required to avoid waiting for an indeterminate amount of time . if the query fails to complete within the timeout it is aborted .
returns the sdc record { @link field } type mapped from a bigquery { @link com . google . cloud . bigquery . field } type .
converts a list of bigquery fields to sdc record fields . the provided parameters must have matching lengths .
repeated fields are simply fields that may appear more than once . in sdc we will represent them as a list field . for example a repeated field of type record would be a { @link field . type#list } of { @link field . type#list_map } and a repeated field of type string would be a { @link field . type#list } of { @link field . type#string } .
get the table description from the showtableresponse
if it is not
get the class for the column type
the avro type field )
get the table s schema as a json object
get the table s extended column properties
get the java type for a type name
initialize and validate configuration options
returns the topic given the record .
search the provided pattern and get the c standard date / time formatting rules and convert them to the java equivalent .
try to get the java date / time formatting associated with the c standard provided .
/ * max error retries > = 0 are set in clientconfig for s3client < 0 will use default ( 3 )
transition to services
evaluates a given field path expression against a given record and returns all field paths that satisfy the expression upon evaluation . analagous in function to { @link fieldregexutil#getmatchingfieldpaths ( string set ) } and even identical in behavior to it when the given { @code fieldexpression } does not contain any el expressions .
evaluates a field expression against a specific field in a record to see if it matches
this method must be used after completing the write to output stream which was obtained by calling the { @link #getoutputstream () } method .
returns an input stream for the requested file .
returns an output stream for the requested file .
this method must be used to commit contents written to the output stream which is obtained by calling the { @link #getoutputstream () } method . this method closes the argument output stream .
check if the datastore exists and contains data . this method will check for the presence of the set of files that can be used to read data from the store .
get an operation code from record . first look for sdc . operation . code from record header . if not set look for __$operation in record . it is a specific field that ms sql cdc origin set .
parse string representation of permissions into hdfs fspermission class .
validate that all required libraries are available and loaded .
validate service dependencies .
creates a simple aggregator .
returns the unit type of an aggregator value . typically long or double .
creates an aggregatordata .
creates a group - by agregator .
starts the aggregators instance .
stops the aggregators instance .
atomically rolls the datawindow of all aggregators associated with the aggregators instance .
evaluate precision or scale in context of record and given field path .
returns an instance of loginmanager and increases its reference count .
decrease the reference count for this instance and release resources if it reaches 0 .
/ * should only be used in tests .
convert a limited file glob into a simple regex .
decodes one or more { @link netflowv5message } from a packet . for this method the data ( bytebuf ) is assumed to be complete ( i . e . it will contain all the data ) which is the case for udp .
lists objects from amazons3 in lexicographical order
lists objects from amazons3 in chronological order [ lexicographical order if 2 files have same timestamp ] which are later than or equal to the timestamp of the previous offset object
/ * ------------------------------------------------------------
/ * ------------------------------------------------------------
since stages are allowed to produce events during destroy () phase we handle the destroy event as simplified runbatch . we go over all the stagepipes and if it s on data path we destroy it immediately if it s on event path we run it one more time . since the stages are sorted we know that destroyed stage will never be needed again . non stage pipes are always processed to generate required structures in pipebatch .
stops execution of the pipeline after the current batch completes
this method should be called periodically from a scheduler if the pipeline should not allow runners to be idle for more then idletime .
create special batch by salvaging memory structures when pipelines gets into un - recoverable error .
convert a record into a fully - bound statement .
{
{
set multiple configs at once .
{
create a map of keycolumn - value to lookup in cache .
no trespassing ...
checks whether any tables have had partitioning turned off or not and updates the partition map appropriately
basically acquires more tables for the current thread to work on . the maximum a thread can hold is upper bounded to the value the thread number was allocated in {
<p > examines the first item ( head ) im the shared partition queue and adds a new partition if appropriate< / p > <p > a new partition will be created if the number of partitions for the head item s table is still less than the maximum and that table itself is partitionable< / p >
return the next table to work on for the current thread ( will not return null ) deque the current element from head of the queue and put it back at the tail to queue .
each {
used by the main thread {
/ * captures valid lines in currentline and corresponding fields in fieldsfromlogline . captures stack traces if any in the argument stacktrace
returns the reader line length the stringbuilder has up to maxobjectlen chars
returns fresh usagetimer just reset to zero accumulated time
enable control hub on this data collector .
disable control hub on this data collector - with explicit login .
disable control hub on this data collector - using existing auth token .
normalize control hub url - primarily drop training slash .
login user and retrieve authentication token .
logout given token .
update token file with the sdc access token .
update dpm . properties file with new configuration .
create record and add it to {
when pullmap is called the caller should have consumed the opening tag for the record
/ * terminates the request with an http unauthorized response
generate schema for given field and optionally wrap it in union with null if configured .
generates complex schema for given field that will include optional union with null and potentially default value as well . particularly useful to generate nested structures .
generate simple schema for given field - it will never contain union nor a default value . particularly useful for generating schema . field as this will not convert simple string to { type : string defaultvalue : something } which is hard to undo .
resolve parameters of decimal type .
returns default value for given field or null if no default value should be used .
creates a gauge if it is already not . this is done only once for the stage
this method is a simple wrapper that lets us find the nosuchfileexception if that was the cause .
gets the group index of a named capture group at the specified index . if only one instance of the named group exists use index 0 .
gets the names of all capture groups
determines if the character at the specified position of a string is escaped
determines if the character at the specified position of a string is escaped with a backslash
determines if the character at the specified position of a string is quote - escaped ( between \\ q and \\ e )
determines if a string s character is within a regex character class
determines if the parenthesis at the specified position of a string is for a non - capturing group which is one of the flag specifiers ( e . g . ( ?s ) or ( ?m ) or ( ? : pattern ) . if the parenthesis is followed by ? it must be a non - capturing group unless it s a named group ( which begins with ?< ) . make sure not to confuse it with the lookbehind construct ( ?< = or ?<! ) .
counts the open - parentheses to the left of a string position excluding escaped parentheses
parses info on named capture groups from a pattern
replaces strings matching a pattern with another string . if the string to be replaced is escaped with a slash it is skipped .
replaces referenced group names with the reference to the corresponding group index ( e . g . <b > <code > \ k&lt ; named > < / code > < / b > } to <b > <code > \ k2< / code > < / b > } ; <b > <code > $ { named } < / code > < / b > to <b > <code > $2< / code > < / b > } ) . this assumes the group names have already been parsed from the pattern .
builds a { @code java . util . regex . pattern } from a given regular expression pattern ( which may contain named groups ) and flags
process a get request for the specified resource .
--------------------------------------------------------- private methods
refresh the schema for the table if the last update of this table was before the given scn . returns true if it was updated else returns false .
this method needs to get sql like string with all required schemas and tables .
an element is expired if the transaction started before the current window being processed and if no records have actually been sent to the pipeline . if a record has been sent then a commit was seen so it is not expired .
offset will be negative if we are in truncate mode .
returns true if still in truncate mode false otherwise
----------------------------------------------- private members ---------------------------------------------------
detached stage apis
max array size will be limit + 1 ( because the magic byte is being added )
contextextensions
we need to support strings as some information that user might need to deal with is inherently stored in string variables - for example header values or csv files .
parses a collectd packet part .
parses the value part of the packet where metrics are located
adapted from https : // stackoverflow . com / a / 7932774 / 375670
it takes a record structure in <string hivetypeinfo > format . generate a schema and return in string .
our own implementation of jdbctype . valueof () that won t throw an exception in case of unknown type .
returns qualified table name ( schema . table name )
returns quoted qualified table name ( schema . table name ) based on quotechar
evaluate els in initial offsets as needed and populate the final string representation of initial offsets in {
lists all tables matching the {
access the database obtain a list of primary key columns and store them in primarykeycolumns . if table has no primary keys primarykeycolumns stays empty .
access database and obtain the metadata for the table . store columnname and / columnname to the columnstofields map as a default column - to - field mapping . store columnname and ? to columnstoparameters map as a default column - to - value mapping . they will be updated later in createcustomfieldmappings () .
use field to column mapping option obtained from configuration and update columnstofields and columnstoparameters .
spec requires a string name for a data type rather than just an enum .
table this writer will write to .
set primary key values to query . this is called only for update and delete operations . if primary key value is missing in record it throws onrecorderrorexception .
this is an error that is not due to bad input record and should throw a stageexception once we format the error .
get the numeric operation code from record header . the default code is used if the operation code is not found in the header .
split records according to tuples ( schemaname tablename )
process method for push source that will give control of the execution to the origin .
called by pipelinerunner when push origin started a new batch to prepare context for it .
finish batch from the origin s perspective .
flatten the entire record to one giant map
create new instance of detached stage runtime .
executes an action for given record .
records from mysql binlog origin have a bit unique structure .
return a fieldpath for the corresponding column name . the columntofield map contains column - to - field mapping so simply get fieldpath for the column name if operation is insert or update . we replace / data to / olddata for delete operation because that s where records store primary key info .
build query using the lastoffset which is of the form ( <column1 > = <value1 > :: <column2 > = <value2 > :: <column3 > = <value3 > )
builds parts of the query in the where clause for the the partitition column .
splits the offset in the form of ( <column1 > = <value1 > :: <column2 > = <value2 > :: <column3 > = <value3 > ) into a map of columns and values
joins the map of column to values to a string offset in the form of ( <column1 > = <value1 > :: <column2 > = <value2 > :: <column3 > = <value3 > )
this is the inverse of { @link #getsourcekeyoffsetsrepresentation ( map ) } .
validates whether offset names match in the stored offset with respect to table configuration
return inputstream from which a new generated resource bundle can be retrieved .
return inputstream from which a new generated resource bundle can be retrieved .
instead of providing support bundle directly to user upload it to streamsets backend services .
instead of providing support bundle directly to user upload it to streamsets backend services .
try to upload bundle as part of internal sdc error ( for example failing pipeline ) .
this method will read from the input stream until the whole buffer is loaded up with actual bytes or end of stream has been reached . hence it will return buffer . length of all executions except the last two - one to the last call will return less then buffer . length ( reminder of the data ) and returns - 1 on any subsequent calls .
orchestrate what definitions should be used for this bundle .
from https : // stackoverflow . com / a / 31928740 / 33905
this is used by destination which performs crud operations . records sent from mysqlbinlog origin have / data field that contains a map of key - value for insert and update operation but / olddata field for delete operation . this method looks into / olddata for delete operation so that users don t need a separate field - column mapping for delete .
if there is a recordel then an arg could eval to empty string . this method returns args that are not null or empty .
return operation based on the operation code . if the code has a number that kudu destination doesn t support it throws unsupportedoperationexception .
convert the bytes to a human readable format upto 2 decimal places the maximum unit is tb so anything exceeding 1024 tb will be shown with tb unit .
scans the directory of for the next file .
scans the directory for number of files yet to be processed .
return true if this dependency and given set of versions is whitelisted .
compare expected versions with given versions to see if they are the same or not .
validates the parameters for this config bean .
returns true if given snapshot output is usable - e . g . if it make sense to persist .
bootstrapping the driver which starts a spark job on cluster
{
{
we have special type of a configdef called runtime . this config is never displayed in ui and instead it s values are supplied at runtime . this method is the runtime method that propagates them .
{
{
{
validate ominture report description .
/ * escapes special characters with a preceding slash
called by jdbctarget
called by jdbcteeprocessor
remove implicit field mapping
extracts named groups from the raw data
if a null value is passed to this method it s replaced with a dummy due to the fact the payload for each message is wrapped in an optional .
creates an instance of sdc and adds to pool
what is this?! spark could end up scheduling transformers to run on machines that may actually not have received the data due to : - non - local reads : spark locality is time - bound so if local executor where the data is located is not available spark will tell another one to pick up the task . - shuffle in the transformer : after a shuffle it is possible the next task passing the data to the next batch could end up on a different executor .
set the lookup reuslt in the result field
returns info about remote pipelines that have changed since the last sending of events
creates a future ack result from the given parameter . it is expected that the caller will eventually wait for the future ack result that is returned .
get an operation code from record . first look for sdc . operation . code from record header . if not set look for __$operation in record . it is a specific field that ms sql cdc origin set .
kept for backward compatibility with runtime stats to be removed in future
remove metric object ( regardless of it s type )
records from mongodb oplog origin have a bit unique structure .
return a fieldpath for the corresponding column name . the columntofield map contains column - to - field mapping so simply get fieldpath for the column name if operation is insert or delete . we replace / o with / o2 to get _id field and change / o to / o / $set to get updating column & value fields .
generate the header attributes
validate the record is a whole file record
return the temporary parquet file path and validate the path
delete temporary parquet file
return the avro file input stream
return the avro file reader
convert avro record to parquet
{
visible for testing only
visible for testing only
checks that the encryption input is a supported type otherwise sends the record to error .
checks that the encryption input is a supported type otherwise sends the record to stageexception .
checks that the decryption input is a valid type otherwise sends the record to error .
checks that the decryption input is a valid type otherwise sends the record to stageexception .
does data type conversions in preparation for encryption .
returns a decrypted { @link field } with its original type preserved when type information has been preserved in the aad .
processes a batch from the specified file and offset up to a maximum batch size . if the file is fully processed it must return - 1 otherwise it must return the offset to continue from next invocation .
initialize the gauge with needed information
handle exception
find cycles in the {
changes the pattern that this matcher uses to find matches with
implements a non - terminal append - and - replace step .
finds all named groups that exist in the input string . this resets the matcher and attempts to match the input against the pre - specified pattern .
replaces every subsequence of the input sequence that matches the pattern with the given replacement string .
no trespassing ...
this method is used during deserializer and sqpath ( single quote escaped path ) is passed to determine the last field name .
this method escapes backslash double quotes and single quotes ( keeping replacement of to \\\\\ as is so as to maintain backward compatibility any serialization / deserialization )
this method un escapes backslash double quotes and single quotes ( keeping replacement of \\\\\ to as is so as to maintain backward compatibility any serialization / deserialization )
this method un escapes backslash and un escapes extra escapes before double quotes and single quotes ( appended by {
there is a problem with some older stages that originally were not using our data parser library as the upgrade on those stages does not create all the properties that were introduced by the data parser library . for example file tail origin doesn t support avro so the upgrade procedure doesn t use create the avro specific properties . this is normally not a problem as post - upgrade sdc will create all missing properties with default values . however this particular upgrade will fail if the property avroschema is missing .
get global variable value .
**************************************************
create pipeline start event .
create pipeline stop event .
infinite recursion
since salesforce doesn t like scientific notation in queries
runtime supports only numeric types and string at the moment
add a new partition to the given table with optional custom location .
execute alter table set table properties
returns {
returns {
returns location for given database .
returns {
execute given query .
execute given query and process it s result set .
{
run batch with given consumer for each pipe .
execute given consumer for each pipe rethrowing usual exceptions as runtimeexception .
retrieve offsetcommittrigger pipe .
return true if at least one stage is configured with stop_pipeline for onrecorderror policy .
accept given consumer and proper log context of any exception .
evaluate and obtain the row id if the expression is present or return null .
convert the root field to a java map object implicitly mapping each field to the column ( only non nested objects )
convert the sdc field to an object for row content
port .
aggregates errors that occur during the processing of a batch .
aggregates errors that occur during the processing of a batch .
writes sub - document lookup values to the record
writes full document lookup values to the record
writes n1ql query result rows to the record
take an numeric operation code and check if the number is valid operation code . the operation code must be numeric : 1 ( insert ) 2 ( update ) 3 ( delete ) etc
as the record is just the metadata along with file ref .
initialize the gauge with needed information
check if given gtid + seqno pair is contained in this incomplete transactions .
runs a supplier within the context of a specified classloader .
runs a supplier within the context of a specified classloader .
runs a supplier within the context of a specified classloader and in priviledged mode .
runs a supplier within the context of a specified classloader and in priviledged mode .
internal version of the wrapping function that will simply propagate all exceptions up .
headerimpl setter methods
to be removed
to be removed
logs in . if kerberos is enabled it logs in against the kdc otherwise is a nop .
logs out . if keberos is enabled it logs out from the kdc otherwise is a nop .
this method should be called only once and before any stages are loaded .
replace variables to internal sdc directories so that users don t have to be entering fqdn .
make sure that the active code have proper rights to access the file inside protected directory .
generate hive type info representation inside the metadata record .
generate { @link jdbctypeinfo } from the metadata record <br > . ( reverse of { @link #generatejdbctypeinfofieldformetadatarecord ( jdbctypeinfo ) } )
generate column definition for create table / add columns
obtaining a reference on the dummy source which is used to feed a pipeline<br / > direction : stage - > container
bootstrapping the driver which starts a emr job on cluster
returns directory path for given record and date .
this method should be called every time we finish writing into a file and consider it done .
produce events that were cached during the batch processing .
rename all _tmp_ files under directory path ( dirpathtemplate ) return the number of _tmp_ files
this method must always be called after the closelock () method on the writer has been called .
return true if this record should be written into a new file regardless whether we have a file for the record currently opened or not .
/ * when we start with a file ( empty or not ) the file offset is zero . if the file is a rolled file the file will be eof immediately triggering a close of the reader and setting the offset to long . max_value ( this happens in the multidirectoryreader class ) . this is the signal that in the next read a directory scan should be triggered to get the next rolled file or the live file if we were scanning the last rolled file . if the file you are starting is the live file we don t get an eof as we expect data to be appended . we just return null chunks while there is no data . if the file is rolled we ll detect that and then do what is described in the previous paragraph .
set the path separator to use for pattern parsing . <p > default is / as in ant .
tokenize the given path pattern into parts based on this matcher s settings . <p > performs caching based on {
copy the given {
test whether or not a string matches against a pattern .
sets the file offsets to use for the next read . to work correctly the last return offsets should be used or an empty <code > map< / code > if there is none . <p / > if a reader is already live the corresponding set offset is ignored as we cache all the contextual information of live readers .
returns the current file offsets . the returned offsets should be set before the next read .
remaining time till timeout return zero if already in timeout
reads the next { @link livefilechunk } from the directories waiting the specified time for one .
determines the offset lag for each active file being read .
create and initialize new delegate .
create new instance of the delegator from given stage library .
create actual instance of delegator .
private static final configuration jaasconfig = new org . apache . solr . client . solrj . impl . krb5httpclientconfigurer . solrjaasconfiguration () ;
<p > scheduler is not used since a dedicated thread will be running to update the token . even if the thycotic server is not being used the thread will hit for every refresh interval to get a new access token . so instead <tt > volatile< / tt > variables are used to store the token . so only when the token expires thycotic server will be called to fetch the new token . < / p > <p > there are 2 expire checks to make sure that not more than one thread updates the token in case of expiration
get metric value for given rule evaluation .
return calculated metric - from all the runners that are available for given pipeline return the biggest difference between given metric and system . currenttimemillis () . the semantic is that the runner metric stores start time of certain events ( batch start time stage start time ) and we need to find out what is the longer running time for one of those metrics .
starts as a standalone file server and waits for enter .
serves file from homedir and its subdirectories ( only ) . uses only uri ignores all headers and http parameters .
decodes the sent headers and loads the data into key / value pairs
decodes the multipart body data and put it into key / value pairs .
decodes parameters in percent - encoded uri - format ( e . g . name = jack%20daniels&pass = single%20malt ) and adds them to given map .
find byte index separating header from body . it must be the last byte of the first two sequential new lines .
find the byte positions where multipart boundaries start . this reads a large block at a time and uses a temporary buffer to optimize ( memory mapped ) file access .
deduce body length in bytes . either from content - length header or read bytes .
retrieves the content of a sent file and saves it to a temporary file . the full path to the saved file is returned .
creates an sslsocketfactory for https . pass a loaded keystore and an array of loaded keymanagers . these objects must properly loaded / initialized by the caller .
creates an sslsocketfactory for https . pass a loaded keystore and a loaded keymanagerfactory . these objects must properly loaded / initialized by the caller .
creates an sslsocketfactory for https . pass a keystore resource with your certificate and passphrase
get mime type from file name extension if possible
this is the master method that delegates requests to handlers and makes sure there is a response to every request . you are not supposed to call or override this method in any circumstances . but no one will stop you if you do . i m a javadoc not code police .
override this to customize the server . <p / > <p / > ( by default this returns a 404 not found plain text error response . )
stop the server .
default routings they are over writable .
sends given response to the socket .
sends the body to the specified outputstream . the pending parameter limits the maximum amounts of bytes sent unless it is - 1 in which case everything is sent .
create a response with unknown length ( using http 1 . 1 chunking ) .
create a response with known length .
create a text response with known length .
create a text response with known length .
else decide whether or not to use gzip .
facade ---------------------------
translates the specified byte array into base64 string . <p > android has android . util . base64 sun has sun . misc . base64encoder java 8 hast java . util . base64 i have this from stackoverflow : http : // stackoverflow . com / a / 4265472 < / p >
-------------------------------- serialization ---------------------------
-------------------------------- encoding --------------------------------
------------------------------------------------------------------------
sets a cookie .
internally used by the webserver to add all queued cookies into the response s http headers .
end :: findbyusername []
/ * ( non - javadoc )
/ * ( non - javadoc )
decode the value using base64 .
encode the value using base64 .
<p > sets a case insensitive pattern used to extract the domain name from the { @link httpservletrequest#getservername () } . the pattern should provide a single grouping that defines what the value is that should be matched . user s should be careful not to output malicious characters like new lines to prevent from things like <a href = https : // www . owasp . org / index . php / http_response_splitting > http response splitting< / a > . < / p >
set the name of database table used to store sessions .
/ * ( non - javadoc )
tag :: cookie - serializer []
customized { @link objectmapper } to add mix - in for class that doesn t have default constructors
tag :: dofilterinternal []
end :: dofilterinternal []
/ * ( non - javadoc )
configure a { @link websessionmanager } using a provided { @link reactivesessionrepository } .
/ * ( non - javadoc )
allows customization of whether a remember - me login has been requested . the default is to return {
derives a string name for the given principal .
registers the springsessionrepositoryfilter .
get the {
tries to determine the principal s name from the given session .
this {
gets the session .
gets the {
make any runtime changes necessary to effect the changes indicated by the given { @code operation } . e <p > it constructs a mailsessionservice that provides mail session and registers it to naming service . < / p >
extracts the raw jndi_name value from the given model node and depending on the value and the value of any use_java_context child node converts the raw name into a compliant jndi name .
this method returns the class names of the parameters of the given method in canonical form . in case of a method without parameters it will return an empty array .
this is only allowed at various points of the transaction lifecycle .
exceptions from synchronizations that are registered with this tsr are not trapped for before completion . this is because an error in a sync here should result in the transaction rolling back .
called by <code > txserverinterceptorinitializer< / code > at orb initialization time .
returns the transaction associated with the transaction propagation context that arrived in the current iiop request .
reads and trims the text for the given attribute and returns it or { @code defaultvalue } if there is no value for the attribute
{
add pojo module if we have any bean factories .
return a list of all the entries contained here .
determine if management console can display the second level cache entries
process the model to figure out the name of the services the server config service has to depend on
validates the credential . unfortunately there is not much we can do here by default . <p / > this method can be overridden to provide some real validation logic
returns true if the passed <code > mdbclass< / code > meets the requirements set by the ejb3 spec about bean implementation classes . the passed <code > mdbclass< / code > must not be an interface and must be public and not final and not abstract . if it passes these requirements then this method returns true . else it returns false .
<p > this method needs to be called once to initialize the static fields orb and rootpoa . < / p >
<p > this method needs to be called for each newly created or re - read naming context to set its poa . < / p >
======================================= namingcontextoperation methods ================================== //
======================================= namingcontextextoperations methods ================================== //
<p > cleanup bindings i . e . ping every object and remove bindings to non - existent objects . < / p >
<p > obtains the oid of the specified corba object . < / p >
<p > determines if the supplied object is non_existent < / p >
<p > overrides readobject in serializable . < / p >
<p > overrides writeobject in serializable . < / p >
ensures that the current thread doesn t hold any read locks . if the thread holds any read locks this method throws a {
decrements the read lock count held by the thread
increments the read lock count held by the thread
makes all { @link beandeploymentarchiveimpl } s in the given module accessible to all bdas in this module
makes all { @link beandeploymentarchiveimpl } s in the given modules accessible to all bdas in this module
adds a service to all bean deployment archives in the module
<p > sets the jacc contextid using a privileged action and returns the previousid from the { @code policycontext } . < / p >
functionalservice#destroyer implementation
{
makes sure that the timer is only run once after being restored .
returns the { @link java . lang . reflect . method } represented by the { @link org . jboss . as . ejb3 . timerservice . persistence . timeoutmethod } <p > note : this method uses the { @link thread#getcontextclassloader () } to load the relevant classes while getting the { @link java . lang . reflect . method } < / p >
{
authenticate the user with the given credential against the configured elytron security domain .
loads the persistence provider adapter
loads the persistence provider adapter
if set to auto will behave like not having set the property
returns the {
{ @link org . jboss . as . weld . deployment . processors . welddeploymentprocessor } assembles a basic accessibility graph based on the deployment structure . here we complete the graph by examining classloader visibility . this allows additional accessibility edges caused e . g . by the class - path declaration in the manifest file to be recognized .
adds additional edges to the accessibility graph that allow static cdi - enabled modules to inject beans from top - level deployment units
{
builds universal jse meta data model that is as agnostic .
sets config name and config file .
builds security meta data .
returns servlet name to url pattern mappings .
returns servlet name to servlet class mappings .
checks if this ejb injection has been resolved yet and if not resolves it .
{
fixme use capabilities & requirements
{
handle the core - environment element and children
handle the process - id child elements
create ee container entity manager factory
org . hibernate . jpa . event . spi . jpa . extendedbeanmanager is added to hibernate 5 . 1 as an extension for delaying registration of entity listeners until the cdi afterdeploymentvalidation event is triggered . this allows entity listener classes to reference the ( origin ) persistence unit ( wfly - 2387 ) .
returns the address of the specified operation
sets the address of the specified operation .
returns the attribute value of the specified operation
indicates whether or not this operation expects to include default values .
creates a composite operation using the specified operation steps .
creates an add operation using the specified address and parameters
creates an indexed add operation using the specified address and index
creates a read - attribute operation using the specified address and name .
creates a write - attribute operation using the specified address name and value .
creates an undefine - attribute operation using the specified address and name .
lookup the value from the naming context .
add an objectfactory to handle requests for a specific url scheme .
remove an objectfactory from the map of registered ones . to make sure that not anybody can remove an objectfactory both the scheme as well as the actual object factory itself need to be supplied . so you can only remove the factory if you have the factory object .
returns a list with all { @link validationprovider } validation providers .
retrieves the providers from the given loader using the service loader mechanism .
{
{
<p > gets the canonical request uri - that is the request uri minus the context path . < / p >
todo : should this be part of the messaging subsystem
modifies web meta data to configure webservice stack transport and properties .
configures transport servlet class for every found webservice endpoint .
modifies context root .
returns stack specific transport class name .
{
returns the last date of the month represented by the passed <code > cal< / code >
removes activation config properties which aren t recognized by the resource adapter <code > activation< / code > from the passed <code > activationconfigprops< / code > and returns only those properties which are valid .
returns the { @link org . jboss . jca . core . spi . rar . endpoint } corresponding to the passed <code > resourceadaptername< / code >
create a jboss security context with the given security domain name
set the { @code securitycontext } on the { @code securitycontextassociation }
get the current { @code securitycontext }
clears current {
sets the run as identity
removes the run as identity
todo move to undertowdeploymentservice and use all registered servlets from deployment instead of just one found by metadata
try to obtain the security domain configured in jboss - app . xml at the ear level if available
containedimpl implementation ----------------------------------
install a binder service to bind the { @code obj } using the binding { @code name } .
install a binder service to bind the value of the { @code service } using the binding { @code name } .
overrides the default impl to use a special definition of the add op that includes additional parameter {
inject a value into an object property
compare the type of a class with the actual value
find a method
find a field
{
process a deployment for standard ra deployment files . will parse the xml file and attach a configuration discovered during processing .
escape any occurrence of / . and \
build options for non - interactive vaulttool usage scenario .
containedimpl implementation ----------------------------------
{
obtain debug information from the servlet request object
{ @inheritdoc }
collect a jdr report when run outside the application server .
collect a jdr report .
register a resource adapter deployment
unregister a resource adapter deployment
{
<p > jaspic 1 . 1 specification : if there is an { @code authconfigprovider } for the { @code httpservlet } layer and application context then @ { @code login } must throw a { @code servletexception } which may convey that the exception was caused by an incompatibility between the { @code login } method and the configured authentication mechanism . if there is no such provider then the container must proceed with the regular { @code login } processing . < / p >
<p > jaspic 1 . 1 specification : if there is an {
<p > overrides the parent method to return the cached authenticated account ( that is the account that was set in the session as a result of a sam setting the { @code javax . servlet . http . registersession } property ) when the regular account is null . this allows a sam to retrieve the cached account principal by calling { @code getuserprincipal () } on { @code httpservletrequest } . < / p >
<p > builds the jaspic application context . < / p >
<p > builds the { @code messageinfo } instance for the { @code cleansubject () } call . < / p >
<p > retrieves the authenticated subject from the underlying security context . < / p >
reads a { @code name } attribute on an element .
reads a { @code value } attribute on an element .
reads the required attributes from an xml configuration . <p > the reader must be on an element with attributes . < / p >
add dependencies for modules required for jpa deployments
add the <code > puservicename< / code > as a dependency on each of the passed <code > components< / code >
register the transformers for the 1 . 3 . 0 version .
returns an <code > stubstrategy< / code > for a method given descriptions of the method parameters exceptions and return value . parameter and return value descriptions are marshaller abbreviated names .
marshals the sequence of method parameters into an output stream .
unmarshals from an input stream an exception thrown by the method .
checks if a given <code > throwable< / code > instance corresponds to an exception declared by this <code > stubstrategy< / code > s method .
converts the return value of a local invocation into the expected type . a conversion is needed if the return value is a remote interface ( in this case <code > portableremoteobject . narrow () < / code > must be called ) .
{
{
returns all interfaces implemented by a bean that are eligible to be view interfaces
returns all interfaces implemented by a bean that are eligible to be view interfaces
save the specified entitymanager in the local threads active transaction . the transactionsynchronizationregistry will clear the reference to the entitymanager when the transaction completes .
todo use a custom attribute marshaller
generate the jar processing order .
create a jboss security context with the given security domain name
set the { @code securitycontext } on the { @code securitycontextassociation }
{
adds a key / value parameter pair to the call
appends resource parts to the resource to call <p > < / p > if you want to call / foo = bar / baz = boo / do this : <pre > . resource ( foo bar baz boo ) < / pre >
use either the active transaction or the current thread as the lock owner
releases the passed { @link statefulsessioncomponentinstance } i . e . marks it as no longer in use . after releasing the instance this method releases the lock held by this thread on the stateful component instance .
releases the lock held by this thread on the stateful component instance .
adds the contents of the { @link inputstream } to the path in the zip .
adds the content of the { @link inputstream } to the zip in a location that mirrors where { @link virtualfile file } is located .
adds content to the zipfile at path
adds content to the zipfile at path
adds content to the zipfile in a file named logname
<p > creates a thread with the specified { @code runnable } and name . < / p >
/ * private boolean isjsfspecover1_1 ( moduleidentifier jsfmodule moduledependency jsfapi ) throws deploymentunitprocessingexception { try { return ( jsfapi . getmoduleloader () . loadmodule ( jsfmodule ) . getclassloader () . getresource ( / javax / faces / component / actionsource2 . class ) ! = null ) ; } catch ( moduleloadexception e ) { throw new deploymentunitprocessingexception ( e ) ; } }
a cdi viewhandler .
gets endpoint container lazily .
invokes ws endpoint .
translates sei method to component view method .
compares two methods if they are identical .
create single instance of management statistics resource per managementadaptor version .
{
get {
<p > interception of register work call to get transaction being imported to wildfly transacton client . <p > for importing a transaction wildfly transaction client eventually calls {
<p > start work gets imported transaction and assign it to current thread . <p > this method mimics behavior of narayana s {
<p > suspending transaction and canceling the work . <p > suspend transaction has to be called on the wildfly transaction manager and the we delegate work cancellation to {
<p > calling {
@see org . jboss . webservices . integration . tomcat . abstractsecuritymetadataaccessorejb#getsecuritydomain ( deployment )
@see org . jboss . webservices . integration . tomcat . securitymetadataaccessorejb#issecurewsdlaccess ( endpoint )
@see org . jboss . webservices . integration . tomcat . securitymetadataaccessorejb#gettransportguarantee ( endpoint )
gets ejb security meta data if associated with ejb endpoint .
returns security domain value . this method checks domain is the same for every ejb 3 endpoint .
this method ensures both passed domains contain the same value .
{
{
set my unqualified idl name . this also sets the names of the associated operations .
get the absolute jndi name as a string .
create a new instance of the jndiname by breaking the provided string format into a jndiname parts .
process a deployment for iron - jacamar . xml files . will parse the xml file and attach metadata discovered during processing .
increments the counter and registers a listener to decrement the counter upon exchange complete event .
return the actual jmscontext used by this injection .
check whether there is an active transaction .
lookup the transactionsynchronizationregistry and cache it .
lookup the connectionfactory and cache it .
get the last component of a name .
determine if a name is empty or if ot contains only one component which is the empty string .
create a name - not - found exception .
return a general naming exception with a root cause .
return a general naming exception with a root cause and a remaining name field .
return a cannot - proceed exception .
return a naming enumeration over a collection .
rebind val to name in ctx and make sure that all intermediate contexts exist
unbinds a name from ctx and removes parents if they are empty
hook to allow subclasses to handle read - attribute requests for attributes other than { @link commonattributes#started } . implementations must not call any of the { @link org . jboss . as . controller . operationcontext#completestep ( operationcontext . resulthandler ) context . completestep variants } . <p > this default implementation just throws the exception returned by { @link #unsupportedattribute ( string ) } . < / p >
hook to allow subclasses to handle operations other than { @code read - attribute } { @code start } and { @code stop } . implementations must not call any of the { @link org . jboss . as . controller . operationcontext#completestep ( operationcontext . resulthandler ) context . completestep variants } . <p > this default implementation just throws the exception returned by { @link #unsupportedoperation ( string ) } . < / p >
gets the runtime activemq control object that can help service this request .
parses connection attributes for version 5 . 0
parse a single connection - definition tag
parse a single connection - definition tag
parse a { @link xapool } object
wraps an existing object instance in a componentinstance and run the post construct interceptor chain on it .
construct the component instance . upon return the object instance should have injections and lifecycle invocations completed already .
construct the component instance . upon return the object instance should have injections and lifecycle invocations completed already .
{
merges two descriptors either of the parameters will be null . <p / > this method will never return null ;
lookup seam integration resource loader .
resolves runtime name of model resource .
check the deployment annotation index for all classes with the @managedbean annotation . for each class with the annotation collect all the required information to create a managed bean instance and attach it to the context .
returns true if the passed <code > managedbeanclass< / code > meets the requirements set by the managed bean spec about bean implementation classes . the passed <code > managedbeanclass< / code > must not be an interface and must not be final or abstract . if it passes these requirements then this method returns true . else it returns false .
registers attributes common across listener types
{
{
get a singleton instance representing one of the primitive types .
upon calling this method the ejb will be set to a shutdown state and no further invocations will be allowed . it will then wait for all active invocation to finish and then return .
create ee container entity manager factory
creates url pattern list from passed string .
gets servlets meta data from jboss web meta data . if not found it creates new servlets meta data and associates them with jboss web meta data .
gets servlet mappings meta data from jboss web meta data . if not found it creates new servlet mappings meta data and associates them with jboss web meta data .
gets security constraints meta data from jboss web meta data . if not found it creates new security constraints meta data and associates them with jboss web meta data .
gets login config meta data from jboss web meta data . if not found it creates new login config meta data and associates them with jboss web meta data .
gets context parameters meta data from jboss web meta data . if not found it creates new context parameters meta data and associates them with jboss web meta data .
gets web resource collections meta data from security constraint meta data . if not found it creates new web resource collections meta data and associates them with security constraint meta data .
gets init parameters meta data from servlet meta data . if not found it creates new init parameters meta data and associates them with servlet meta data .
creates new security constraint meta data and associates them with security constraints meta data .
creates new web resource collection meta data and associates them with web resource collections meta data .
creates new servlet meta data and associates them with servlets meta data .
creates new servlet mapping meta data and associates them with servlet mappings meta data .
creates new authentication constraint and associates it with security constraint meta data .
creates new user constraint meta data and associates it with security constraint meta data .
creates new parameter meta data and associates it with parameters meta data .
creates new parameter with specified key and value .
process a deployment for standard ra deployment files . will parse the xml file and attach a configuration discovered during processing .
{
parses the <code > interceptor - binding< / code > element and returns the corresponding { @link interceptorbindingmetadata }
register our listeners on sfsb that will be created
<p > make a deep copy of an { @code iop : taggedcomponent } . < / p >
<p > return a top - level { @code iop :: taggedcomponent } to be stuffed into an ior containing a structure { @code ssliop :: ssl } tagged as { @code tag_ssl_sec_trans } . < / p > <p > should be called with non - null metadata in which case we probably don t want to include security info in the ior . < / p >
<p > return a top - level { @code iop : taggedcomponent } to be stuffed into an ior containing a { @code org . omg . csiiop } . { @code compoundsecmechlist } tagged as { @code tag_csi_sec_mech_list } . only one such component can exist inside an ior . < / p > <p > should be called with non - null metadata in which case we probably don t want to include security info in the ior . < / p >
<p > create a { @code org . omg . csiiop . compoundsecmechanisms } which is a sequence of { @code compoundsecmech } . here we only support one security mechanism . < / p >
<p > create the secure attribute service ( sas ) context included in a { @code compoundsecmech } definition . < / p >
<p > create the client authentication service ( as ) context included in a { @code compoundsecmech } definition . < / p >
<p > create a transport mechanism { @code taggedcomponent } to be stuffed into a { @code compoundsecmech } . < / p > <p > if no { @code transportconfig } metadata is specified or ssl port is negative or the specified metadata indicates that transport config is not supported then a { @code tag_null_tag } ( empty ) { @code taggedcomponent } will be returned . < / p > <p > otherwise a { @code org . omg . csiiop . tls_sec_trans } tagged as { @code tag_tls_sec_trans } will be returned indicating support for tls / ssl as a csiv2 transport mechanism . < / p > <p > multiple { @code transportaddress } may be included in the ssl info ( host / port pairs ) but we only include one . < / p >
<p > create a { @code transportaddress [] } with a single { @code transportaddress } . < / p >
<p > create the bitmask of what the target requires . < / p >
<p > create the bitmask of what the target supports . < / p >
<p > create an asn . 1 der encoded representation for the gssup oid mechanism . < / p >
<p / > generate an exported name as specified in [ rfc 2743 ] section 3 . 2 copied below : <p / > 3 . 2 : mechanism - independent exported name object format <p / > this section specifies a mechanism - independent level of encapsulating representation for names exported via the gss_export_name () call including an object identifier representing the exporting mechanism . the format of names encapsulated via this representation shall be defined within individual mechanism drafts . the object identifier value to indicate names of this type is defined in section 4 . 7 of this document . <p / > no name type oid is included in this mechanism - independent level of format definition since ( depending on individual mechanism specifications ) the enclosed name may be implicitly typed or may be explicitly typed using a means other than oid encoding . <p / > the bytes within mech_oid_len and name_len elements are represented most significant byte first ( equivalently in ip network byte order ) . <p / > length name description <p / > 2 tok_id token identifier for exported name objects this must be hex 04 01 . 2 mech_oid_len length of the mechanism oid mech_oid_len mech_oid mechanism oid in der 4 name_len length of name name_len name exported name ; format defined in applicable mechanism draft . <p / > a concrete example of the contents of an exported name object derived from the kerberos version 5 mechanism is as follows : <p / > 04 01 00 0b 06 09 2a 86 48 86 f7 12 01 02 02 hx xx xx xl pp qq ... zz <p / > ...
<p > asn . 1 - encode an { @code initialcontexttoken } as defined in rfc 2743 section 3 . 1 mechanism - independent token format pp . 81 - 82 . the encoded token contains the asn . 1 tag 0x60 followed by a token length ( which is itself stored in a variable - length format and takes 1 to 5 bytes ) the gssup mechanism identifier and a mechanism - specific token which in this case is a cdr encapsulation of the gssup { @code initialcontexttoken } in the { @code authtoken } parameter . < / p >
<p > decodes an asn . 1 - encoded { @code initialcontexttoken } . see { @code encodeinitialcontexttoken } for a description of the encoded token format . < / p >
<p > decodes a gss exported name that has been encoded with the gssup mechanism oid . see { @code creategssexportedname } for a description of the encoding format . < / p >
<p > helper method to be called from a client request interceptor . the { @code ri } parameter refers to the current request . this method returns the first { @code compoundsecmech } found in the target ior such that <ul > <li > all { @code compoundsecmech } requirements are satisfied by the options in the { @code clientsupports } parameter and< / li > <li > every requirement in the { @code clientrequires } parameter is satisfied by the { @code compoundsecmech } . < / li > < / ul > the method returns null if the target ior contains no { @code compoundsecmech } s or if no matching { @code compoundsecmech } is found . < / p > <p > since this method is intended to be called from a client request interceptor it converts unexpected exceptions into { @code marshal } exceptions . < / p >
{
resolves ejb - ref and ejb - local - ref elements
processes the injection targets of a resource binding
stops the container executed in weldstartservice to shutdown the runtime before namingservice is closed .
extracts the raw jndiname value from the given model node and depending on the value and the value of any use_java_context child node converts the raw name into a compliant jndi name .
{
return null if the resolved attribute is not defined
finds an ejb - jar . xml ( at web - inf of a . war or meta - inf of a . jar ) parses the file and creates metadata out of it . the metadata is then attached to the deployment unit .
creates and returns a { @link xmlstreamreader } for the passed { @link virtualfile ejb - jar . xml }
{
determine the url - pattern type
jacc url pattern qualified url pattern names .
associate the extended persistence context with the current jta transaction ( if one is found )
return whether the definition targets an existing pooled connection factory or use a jca - based connectionfactory .
return whether the definition targets an existing external pooled connection factory .
the jms connection factory can specify another server to deploy its destinations by passing a property server = &lt ; name of the server > . otherwise default is used by default .
/ * when finding the default persistence unit the first persistence unit encountered is returned .
if no persistence unit name is specified return name of default persistence unit
process a deployment for a connector . will install a { @code jbossservice } for this resourceadapter .
a simple implementation of the { @link org . jboss . weld . resources . spi . annotationdiscovery#containsannotation ( class class ) } contract . this implementation uses reflection .
starts the service . registers server activity sets transaction listener on local transaction context and creates and installs deployment controller service .
stops the service . unregisters service activity and clears transaction listener .
notifies local transaction context that server is suspended and only completes suspension if there are no active invocations nor transactions .
notifies local transaction context that server is resumed and restarts deployment controller .
indicates if a invocation should be accepted : which will happen only if server is not suspended or if the invocation involves a still active transaction .
notifies handler that an active invocation is complete .
notifies handler that a new transaction has been created .
completes suspension : stop deployment controller .
releases the service returns <code > true< / code > if the service is removed as a result or false otherwise
bind the entry into the injected context .
unbind the entry from the injected context .
determines a servicename from a capability name . only supported for use by services installed by this subsystem ; will not function reliably until the subsystem has begun adding runtime services .
create the resource roots for a . war deployment
{
{
used by transactionscopedentitymanager to detach entities loaded by a query in a non - jta invocation .
used by transactionscopedentitymanager to detach entities loaded by a query in a non - jta invocation .
localirobject implementation ---------------------------------
{
{
processes the session bean for remote and local views and updates the { @link sessionbeancomponentdescription } accordingly
{
returns the toplevel deployment module classloader and all subdeployment classloaders
determine if class file transformer is needed for the specified persistence unit
determine if two phase persistence unit start is allowed
determine if the default data - source should be used
return true if detaching of managed entities should be deferred until the entity manager is closed . note : only applies to transaction scoped entity managers used without an active jta transaction .
allow the mixed synchronization checking to be skipped for backward compatibility with wildfly 10 . 1 . 0
allow an unsynchronized persistence context that is joined to the transaction be treated the same as a synchronized persistence context with respect to the checking for mixed unsync / sync types .
populate the <code > strictmaxpoolmodel< / code > from the <code > operation< / code >
returns the corba object reference associated with a remote object by using the javax . rmi . corba package . <p / > use reflection to avoid hard dependencies on javax . rmi . corba package . this method effective does the following : <blockquote > <pre > java . lang . object stub ; try { stub = portableremoteobject . tostub ( remoteobj ) ; } catch ( exception e ) { throw new configurationexception ( object not exported or not found ) ; } if ( ! ( stub instanceof javax . rmi . corba . stub )) { return null ; // jrmp impl or jrmp stub } try { (( javax . rmi . corba . stub ) stub ) . connect ( orb ) ; // try to connect iiop stub } catch ( remoteexception e ) { // ignore already connected error } return ( javax . rmi . corba . stub ) stub ;
get orb using given server and port number and properties from environment .
this method returns a new orb instance for the given applet without creating a static dependency on java . applet .
initializes reflection method handles for rmi - iiop .
set the active naming store
initialize the naming components required by {
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
process all parameter defaulvalue objects . flag all parameters with missing and invalid converters .
create a list of paramconverters and paramconverterproviders present in the application .
create list of objects that represents resource method parameters with a defaultvalue annontation assigned to it .
take steps to properly identify the parameter s data type
extract a defaultvalue annotation from the list of parameter annotations
confirm the method can handle the default value without throwing and exception .
{
{
at injection time of a xpc register the xpc ( step 1 of 2 ) finishregistrationofpersistencecontext is step 2
called by postconstruct interceptor
converts a tx status index to a string
/ * check that none of the attrs are defined or log a warning .
called before call to persistenceprovider . createcontainerentitymanagerfactory ( persistenceunit map )
called after call to persistenceprovider . createcontainerentitymanagerfactory ( persistenceunit map )
start cache
add cache dependencies
stop cache
{
read the properties from the timer - sql and extract the database dialects .
check the connection metadata and driver name to guess which database dialect to use .
use the given name and check for different database types to have a unified identifier for the dialect
checks whether the database transaction configuration is appropriate and create the timer table if necessary .
convert the stored date - string from database back to date
set the node name for persistence if the state is in_timeout or retry_timeout to show which node is current active for the timer .
mark this deployment and the top level deployment as being a weld deployment .
returns true if the {
unmarshals the sequence of method parameters from an input stream .
marshals into an output stream the return value of the method .
marshals into an output stream an exception thrown by the method .
localirobject implementation ---------------------------------
containedimpl implementation ----------------------------------
{
do lazy lookup .
--- //
called from sfsbprecreateinterceptor before bean creation
called from sfsbprecreateinterceptor after bean creation
return for just the current entity manager invocation
push the passed sfsb context handle onto the invocation call stack
pops the current sfsb invocation off the invocation call stack
gets the current sfsb invocation off the invocation call stack
add dependencies for modules required for weld deployments if managed weld configurations are attached to the deployment
parse the faces config files looking for managed bean classes . the parser is quite simplistic as the only information we need is the managed - bean - class element
wfly - 6617 according to jsf 2 . 2 spec it should be possible to inject beans using
return the idl type name for the given class . here we use the mapping for parameter types and return values .
check if this class is valid for rmi / iiop mapping . this method will either throw an exception or return true .
insert a java primitive into an any . the primitive is assumed to be wrapped in one of the primitive wrapper classes .
map java name to idl name as per sections 1 . 3 . 2 . 3 1 . 3 . 2 . 4 and 1 . 3 . 2 . 2 . this only works for a single name component without a qualifying dot .
return the ir global id of the given class or interface . this is described in section 1 . 3 . 5 . 7 . the returned string is in the rmi hashed format like rmi : java . util . hashtable : c03324c0ea357270 : 13bb0f25214ae4b8 .
determine if the argument is a reserved idl keyword .
determine if a <code > char< / code > is a legal idl identifier character .
return the class hash code as specified in the common object request broker : architecture and specification ( 01 - 02 - 33 ) section 10 . 6 . 2 .
calculate the signature of a class according to the java vm specification section 4 . 3 . 2 .
calculate the signature of a method according to the java vm specification section 4 . 3 . 3 .
handle mappings for primitive types as per section 1 . 3 . 3 .
process a deployment for standard ra deployment files . will parse the xml file and attach a configuration discovered during processing .
get the permission with the given name .
binds the java : comp / usertransaction service and the java : comp / transactionsynchronizationregistry
{
creates a new injectiontarget for a given class . if the interceptionsupport flag is set to true the resulting instance will support interception ( support provided by weld ) . if an injectiontarget is created for a component where interception support is implemented through component s view ( ejbs managed beans ) the flag must be set to false .
{
get or create a transactional entity manager . only call while a transaction is active in the current thread .
return true if non - tx invocations should defer detaching of entities until entity manager is closed . note that this is an extension for compatibility with jboss application server 5 . 0 / 6 . 0 ( see as7 - 2781 )
returns <tt > true< / tt > if this map maps one or more keys to the specified value . note : this method requires a full internal traversal of the hash table and so is much slower than method <tt > containskey< / tt > .
maps the specified key to the specified value in this table . neither the key nor the value can be null .
copies all of the mappings from the specified map to this one . these mappings replace any mappings that this map had for any of the keys currently in the specified map .
utility for converting camel case based activemq formats to wildfly standards .
consider the uninstalls . <p / > this method is here to be able to override the behavior after installs failed . e . g . perhaps only running uninstalls from the index . <p / > by default we run all uninstalls in the case at least one install failed .
analyze the given class and return the analysis . public static classanalysis getclassanalysis ( class cls ) throws rmiiiopviolationexception { if ( cls == null ) throw new illegalargumentexception ( cannot analyze null class . ) ; if ( cls == java . lang . string . class || cls == java . lang . object . class || cls == java . lang . class . class || cls == java . io . serializable . class || cls == java . io . externalizable . class || cls == java . rmi . remote . class ) throw new illegalargumentexception ( cannot analyze special class : + cls . getname () ) ; <p / > if ( cls . isprimitive () ) return primitiveanalysis . getprimitiveanalysis ( cls ) ; <p / > <p / > if ( cls . isinterface () && java . rmi . remote . class . isassignablefrom ( cls )) return interfaceanalysis . getinterfaceanalysis ( cls ) ; // todo throw new runtimeexception ( classanalysis . getclassanalysis () todo ) ; }
returns either the loaded entity or the most recent version of the entity that has been persisted in this transaction .
gets the timer map loading from the persistent store if necessary . should be called under lock
gets the directory for a given timed object making sure it exists .
process a deployment for jbossservice configuration . will install a { @code jbossservice } for each configured service .
creates and returns a { @link sanitizer } instance that only operates on files that end with a { @code . properties } suffix .
{
returns true if the passed <code > exceptionclass< / code > is an application exception . else returns false .
add a listener to the coordinator with a given target name and event scope . this information is used when an event is fired to determine whether or not to fire this listener .
remove a listener . will remove it from all target mappings . once this method returns the listener will no longer receive any events .
fire a naming event . an event will be created with the provided information and sent to each listener that matches the target and scope information .
returns a consumer that closes its input .
{
{
create a { @link subject } with the principal and password credential obtained from the authentication configuration that matches the target { @link uri } .
get a reference to the current { @link servicecontainer } .
add the specified credential to the subject s private credentials set .
--- //
--- //
{
create an object factory . if the object parameter is a reference it will attempt to create an { @link javax . naming . spi . objectfactory } from the reference . if the parameter is not a reference or the reference does not create an { @link javax . naming . spi . objectfactory } it will return { @code this } as the { @link javax . naming . spi . objectfactory } to use .
create an object instance .
calls to hibernate orm 5 . 3 getflushmode () will not be changed as the desc will not match ( desc == () ljavax . persistence . flushmodetype ; )
sets up the transaction management interceptor for all methods of the passed view .
first checks if <code > name< / code > is a primitive type . if yes then returns the corresponding { @link class } for that primitive . if it s not a primitive then the { @link class#forname ( string boolean classloader ) } method is invoked passing it the <code > name< / code > false and the <code > cl< / code > classloader
transform a hibernate hql query into something that can be displayed / used for management operations
substitute sub - strings inside of a string .
{
performs the actual work of stopping the service . should be called by {
the xmldataimporter requires a connector to connect to the artemis broker .
adds ear prefix to configured adapter name if it is specified in relative form
returns the parent of the given deployment unit if such a parent exists . if the given deployment unit is the parent deployment unit it is returned .
get the service name for this view .
creates view configuration . allows for extensibility in ee sub components .
create the injection source
localirobject implementation ---------------------------------
get the view interceptors for a method . these interceptors are run sequentially on the server side of an invocation . the interceptor factories are used every time a new view instance is constructed called with a new factory context each time . the factory may return the same interceptor instance or a new interceptor instance as appropriate .
adds an interceptor factory to all methods of a view
adds a view interceptor to the given method
get the client interceptors for a method . these interceptors are run sequentially on the client side of an invocation . the interceptor factories are used every time a new client proxy instance is constructed called with a new factory context each time . the factory may return the same interceptor instance or a new interceptor instance as appropriate .
adds a client interceptor factory to all methods of a view
adds a client interceptor to the given method
attaches arbitrary private data to this view instance
returns the <code > moduleclassloaderlocator . combinedclassloader< / code > instance with consideration of security manager enabled
throws a xmlstreamexception for the unexpected element that was encountered during the parse
/ * determines whether resource removal happens in this step or a subsequent step
the regular and pooled cf
gets list of jaxws ejbs meta data .
gets list of jaxws pojos meta data .
returns endpoint name .
returns endpoint class name .
returns servlet meta data for requested servlet name .
returns required attachment value from deployment unit .
returns optional attachment value from deployment unit or null if not bound .
gets the jbosswebmetadata from the warmetadata attached to the provided deployment unit if any .
return a named port - component from the jboss - webservices . xml
returns an ejbendpoint based upon fully qualified classname .
returns context root associated with webservice deployment .
{
{
<p > obtains the subsystem configuration properties from the specified { @code modelnode } using default values for undefined properties . if the property has a iiop equivalent it is translated into its iiop counterpart before being added to the returned { @code properties } object . < / p >
<p > sets up the orb initializers according to what has been configured in the subsystem . < / p >
<p > sets up the ssl domain socket factories if ssl support has been enabled . < / p >
{
{
{
if the class name is found in additionalclasses then return it .
loads a resource from the module class loader
loads resources from the module class loader
lists all children of a particular path taking overlays into account
add dependencies for modules required for ra deployments
current session bean invocation is ending close any transactional entity managers created without a jta transaction .
return the transactional entity manager for the specified scoped persistence unit name
closing of transaction scoped jmscontext is executed through synchronization listener . this method registers listener which takes care of closing jmscontext .
{
process web annotations .
process a single index .
returns true if the update operation succeeds in modifying the runtime false otherwise .
{
{
{
to workaround activemq s bindingregistry limitation in {
/ * checks if the method s throws clause includes java . rmi . remoteexception or a superclass of it .
checks whether all the fields in the class are declared as public .
localirobject implementation ---------------------------------
containeroperations implementation ----------------------------
interfacedefoperations implementation -------------------------
idltypeoperations implementation ------------------------------
containedimpl implementation ----------------------------------
decode a uri string ( according to rfc 2396 ) .
decode a uri string ( according to rfc 2396 ) . <p / > three - character sequences %xy where xy is the two - digit hexadecimal representation of the lower 8 - bits of a character are decoded into the character itself . <p / > the string is subsequently converted using the specified encoding
encode a string for inclusion in a uri ( according to rfc 2396 ) . <p / > unsafe characters are escaped by encoding them in three - character sequences %xy where xy is the two - digit hexadecimal representation of the lower 8 - bits of the character . <p / > the question mark ? character is also escaped as required by rfc 2255 . <p / > the string is first converted to the specified encoding . for ldap ( 2255 ) the encoding must be utf - 8 .
@see org . jboss . webservices . integration . deployers . deployment . deploymentmodelbuilder#newdeploymentmodel ( deploymentunit )
creates new http web service endpoint .
creates new web service deployment .
build an { @link uri } using the information extracted from the specified { @link clientrequestinfo } . the format of the uri built by this method is iiop : // hostname : port .
create an encoded { @link initialcontexttoken } with an username / password pair obtained from an elytron client configuration matched by the specified { @link uri } .
jax - rs annotations are found in the deployment especially if it s an ear one )
{
{ @inheritdoc }
{ @inheritdoc }
sets the next timeout of this timer
{
returns true if this timer is active . else returns false . <p > a timer is considered to be active if its { @link timerstate } is neither of the following : <ul > <li > { @link timerstate#canceled } < / li > <li > { @link timerstate#expired } < / li > <li > has not been suspended< / li > < / ul > <p / > and if the corresponding timer service is still up <p / > < / p >
asserts that the timer is <i > not< / i > in any of the following states : <ul > <li > { @link timerstate#canceled } < / li > <li > { @link timerstate#expired } < / li > < / ul >
sets the state and timer task executing thread of this timer
merges a list of additional jax - rs deployment data with this lot of deployment data .
<p > returns the method roles as a set of { @code principal } instances . all roles specified in the method - permissions or via { @code rolesallowed } for this method are wrapped by a { @code simpleprincipal } . if the method has been added to the exclude - list or annotated with { @code denyall } a nobody_principal is returned . if the method has been added to the unchecked list or annotated with { @code permitall } an anybody_principal is returned . < / p >
localirobject implementation ----------------------------------
containedimpl implementation ----------------------------------
add the ee apis as a dependency to all deployments
<p > adds to the deployment the { @link org . wildfly . extension . undertow . security . jaspi . jaspicauthenticationmechanism } if necessary . the handler will be added if the security domain is configured with jaspi authentication . < / p >
<p > sets the { @link jaccauthorizationmanager } in the specified { @link deploymentinfo } if the webapp security domain has defined a jacc authorization module . < / p >
convert the authentication method name from the format specified in the web . xml to the format used by { @link javax . servlet . http . httpservletrequest } . <p / > if the auth method is not recognised then it is returned as - is .
adds a dependency for the componentconfiguration on the remote transaction service if the ejb exposes at least one remote view
sets up a {
sets up a {
sets up a {
returns true if this component description has any security metadata configured at the ejb level . else returns false . note that this method does * not * consider method level security metadata .
returns a combined map of class and method level container interceptors
style 1 ( 13 . 3 . 7 . 2 . 1 @1 )
style 2 ( 13 . 3 . 7 . 2 . 1 @2 )
style 3 ( 13 . 3 . 7 . 2 . 1 @3 )
returns true if the given transaction specification was expliitly specified at a method level returns false if it was inherited from the default
{
todo we need to handle cases when deployments reference listeners / server / host directly
returns a { @link servicename } for the { @link ejbviewmethodsecurityattributesservice }
returns the abbreviated name of the marshaller for given <code > class< / code > . <p / > <p > abbreviated names of marshallers for basic types follow the usual java convention : <br > <pre > type abbrev name boolean z byte b char c double d float f int i long j short s void v < / pre > <p / > <p > the abbreviated names of marshallers for object types are : <br > <pre > java . lang . string g ( string ) rmi remote interface r + interfacename rmi abstract interface a serializable e ( serializable ) valuetype l + classname externalizable x ( externalizable ) org . omg . corba . object m ( omg ) idl interface n + interfacename java . lang . object o < / pre > <p / > <p > as an example : the abbreviated name of a marshaller for a valuetype class named <code > foo< / code > is the string <code > lfoo < / code > .
returns a <code > cdrstreamreader< / code > given an abbreviated name and a <code > classloader< / code > for valuetype classes .
returns a <code > cdrstreamwriter< / code > given an abbreviated name and a <code > classloader< / code > for valuetype classes .
returns the <code > cdrstreamreader< / code > for a given <code > class< / code > .
returns the <code > cdrstreamwriter< / code > for a given <code > class< / code > .
sets up all resource injections for a class . this takes into account injections that have been specified in the module and component deployment descriptors <p / > note that this does not take superclasses into consideration only injections on the current class
check one and only one of the 2 elements has been defined
note the access to the {
[ as7 - 5850 ] core queues created with activemq api does not create wildfly resources
* define the attributes in the * same order than the xsd * to write them to the xml configuration by simply iterating over the array
get temp bean info .
get temp bean info .
load class .
get component type .
defines a resource that represents an elytron - compatible realm that can be exported by the legacy security subsystem . the constructed { @code securityrealm } wraps a legacy { @code securitydomaincontext } and delegates authentication decisions to that context .
defines a resource that represents an elytron - compatible key store that can be exported by a jsse - enabled domain in the legacy security subsystem .
defines a resource that represents elytron - compatible key managers that can be exported by a jsse - enabled domain in the legacy security subsystem .
defines a resource that represents elytron - compatible trust managers that can be exported by a jsse - enabled domain in the legacy security subsystem .
returns a compoundname given a string in ins syntax .
creates a namecomponent [] from a name structure . used by cnctx to convert the input name arg into a namecomponent [] .
returns the ins stringified form of a namecomponent [] . used by cnctx . getnameinnamespace () cncompoundname . tostring () .
creates a compositename from a namecomponent [] . used by exceptionmapper and cnbindingenumeration to convert a namecomponent [] into a composite name .
converts an ins - syntax string name into a vector in which each element of the vector contains a stringified form of a namecomponent .
return a namecomponent given its stringified form .
returns a string with . \ / escaped . used when stringifying the name into its ins stringified form .
{
unexport this object .
convert a servant to a reference .
the stop () call doesn t do that so it s probably not needed
attempt to authenticate and authorize an username with the specified password evidence .
check whether the types that jca injection knows .
spi contract for this method
unbind the resource and wait until the corresponding binding service is effectively removed .
instantiate bean .
configure bean .
dispatch lifecycle joinpoint .
adds an outbound connection reference used by a remoting receiver in the client context represented by this { @link ejbclientdescriptormetadata }
create a reference to a sub class of {
handles the service reference . the parameters are the same as {
get the current context selector for the current thread .
get mc bean name .
to instances name .
determines a list of classes the given annotation instances are defined on . if an annotation instance is not defined on a class ( e . g . on a member ) this annotation instance is not reflected anyhow in the resulting list .
look for a class description in all available modules .
process annotations and merge any available metadata at the same time .
returns true if the passed <code > sessionbeanclass< / code > meets the requirements set by the ejb3 spec about bean implementation classes . the passed <code > sessionbeanclass< / code > must not be an interface and must be public and not final and not abstract . if it passes these requirements then this method returns true . else it returns false .
{
{
some of this might need to move to the install phase
eliminate duplicate pu definitions from clustering the deployment ( first definition will win ) <p / > jpa 8 . 2 a persistence unit must have a name . only one persistence unit of any given name must be defined within a single ejb - jar file within a single war file within a single application client jar or within an ear . see section 8 . 2 . 2 persistence unit scope .
old as6 names looked like : persistence . unit : unitname = ejb3_ext_propagation . ear / lib / ejb3_ext_propagation . jar#cts - ext - unit
the regular and pooled cf
returns an array of string representations of the parameter types . primitives are returned as their native representations while classes are returned in the internal descriptor form e . g . ljava / lang / integer ;
performs basic validation on a descriptor
process a deployment for kerneldeployment configuration . will install a { @code pojo } for each configured bean .
{
creates web meta data for ejb deployments .
creates web . xml descriptor meta data .
creates jboss - web . xml descriptor meta data . <p / > <pre > &lt ; jboss - web&gt ; &lt ; security - domain&gt ; java : / jaas / custom - security - domain&lt ; / security - domain&gt ; &lt ; context - root&gt ; / custom - context - root&lt ; / context - root&gt ; &lt ; virtual - host&gt ; host1&lt ; / virtual - host&gt ; ... &lt ; virtual - host&gt ; hostn&lt ; / virtual - host&gt ; &lt ; / jboss - web&gt ; < / pre >
creates servlets part of web . xml descriptor . <p / > <pre > &lt ; servlet&gt ; &lt ; servlet - name&gt ; ejbendpointshortname&lt ; / servlet - name&gt ; &lt ; servlet - class&gt ; ejbendpointtargetbeanname&lt ; / servlet - class&gt ; &lt ; / servlet&gt ; < / pre >
creates servlet - mapping part of web . xml descriptor . <p / > <pre > &lt ; servlet - mapping&gt ; &lt ; servlet - name&gt ; ejbendpointshortname&lt ; / servlet - name&gt ; &lt ; url - pattern&gt ; ejbendpointurlpattern&lt ; / url - pattern&gt ; &lt ; / servlet - mapping&gt ; < / pre >
creates security constraints part of web . xml descriptor . <p / > <pre > &lt ; security - constraint&gt ; &lt ; web - resource - collection&gt ; &lt ; web - resource - name&gt ; ejbendpointshortname&lt ; / web - resource - name&gt ; &lt ; url - pattern&gt ; ejbendpointurlpattern&lt ; / url - pattern&gt ; &lt ; http - method&gt ; get&lt ; / http - method&gt ; &lt ; http - method&gt ; post&lt ; / http - method&gt ; &lt ; / web - resource - collection&gt ; &lt ; auth - constraint&gt ; &lt ; role - name&gt ; * &lt ; / role - name&gt ; &lt ; / auth - constraint&gt ; &lt ; user - data - constraint&gt ; &lt ; transport - guarantee&gt ; ejbtransportguarantee&lt ; / transport - guarantee&gt ; &lt ; / user - data - constraint&gt ; &lt ; / security - constraint&gt ; < / pre >
creates login - config part of web . xml descriptor . <p / > <pre > &lt ; login - config&gt ; &lt ; auth - method&gt ; ejbdeploymentauthmethod&lt ; / auth - method&gt ; &lt ; realm - name&gt ; ejbwebserviceendpointservlet realm&lt ; / realm - name&gt ; &lt ; / login - config&gt ; < / pre >
creates security roles part of web . xml descriptor . <p / > <pre > &lt ; security - role&gt ; &lt ; role - name&gt ; role1&lt ; / role - name&gt ; ... &lt ; role - name&gt ; rolen&lt ; / role - name&gt ; &lt ; / security - role&gt ; < / pre >
returns deployment authentication method .
process a deployment for jboss - service . xml files . will parse the xml file and attach a configuration discovered during processing .
handles setting up the ejbcreate and ejbremove methods for stateless session beans and mdb s
makes a dynamic stub class if it does not already exist .
repository implementation -------------------------------------
generate the id of the n - th anonymous object created in this ir .
convert a repository id to an idl scoped name . returns <code > null< / code > if the id cannot be understood .
{
{
{
{
todo : remove this method once wfcore - 3055 and wfcore - 3056 are fixed
{
return a new instance of each persistence provider class
cleared at application undeployment time to remove any persistence providers that were deployed with the application
set at application deployment time to the persistence providers packaged in the application
if a custom cl is in use we want to get the module cl it delegates to
<p > parses the jacorb subsystem configuration according to the xsd version 1 . 0 . < / p >
<p > parses the jacorb subsystem configuration according to the xsd version 1 . 1 or higher . < / p >
<p > parses the { @code orb } section of the jacorb subsystem configuration according to the xsd version 1 . 0 . < / p >
<p > parses the { @code orb } section of the jacorb subsystem configuration according to the xsd version 1 . 1 or higher . < / p >
<p > parses the orb { @code connection } section of the jacorb subsystem configuration . < / p >
<p > parses the orb { @code initializers } section of the jacorb subsystem configuration according to the xsd version 1 . 0 . < / p >
<p > parses the orb { @code initializers } section of the jacorb subsystem configuration according to the xsd version 1 . 1 or higher . < / p >
<p > parses the { @code poa } section of the jacorb subsystem configuration . < / p >
<p > parses the { @code naming } section of the jacorb subsystem configuration . < / p >
<p > parses the { @code interop } section of the jacorb subsystem configuration . < / p >
<p > parses the { @code security } section of the jacorb subsystem configuration according to the xsd version 1 . 0 . < / p >
<p > parses the { @code security } section of the jacorb subsystem configuration according to the xsd version 1 . 1 or higher . < / p >
<p > parses the { @code properties } section of the jacorb subsystem configuration . < / p >
<p > parses a { @code property } element according to the xsd version 1 . 0 and adds the key / value pair to the specified { @code modelnode } . < / p >
<p > parses a { @code property } element according to the xsd version 1 . 1 or higher and adds the name / value pair to the specified { @code modelnode } . < / p >
<p > parses all attributes from the current element and sets them in the specified { @code modelnode } . < / p >
<p > writes the { @code orb } section of the jacorb subsystem configuration using the contents of the provided { @code modelnode } . < / p >
<p > writes the { @code poa } section of the jacorb subsystem configuration using the contents of the provided { @code modelnode } . < / p >
<p > writes the { @code naming } section of the jacorb subsystem configuration using the contents of the provided { @code modelnode } . < / p >
<p > writes the { @code interop } section of the jacorb subsystem configuration using the contents of the provided { @code modelnode } . < / p >
<p > writes the { @code security } section of the jacorb subsystem configuration using the contents of the provided { @code modelnode } . < / p >
<p > writes a { @code property } element for each generic property contained in the specified { @code modelnode } . < / p >
<p > writes the attributes contained in the specified { @code modelnode } to the current element . < / p >
<p > iterates through the specified attribute definitions and checks if any of the attributes can be written to xml by verifying if the attribute has been defined in the supplied node . < / p >
add a contextservice for this module .
resolves persistence - unit - ref
resolves persistence - unit - ref
add dependencies for modules required for manged bean deployments if managed bean configurations are attached to the deployment .
runs the work contained in { @param runnable } as an authenticated identity .
{
{
<p > sets the outgoing sas reply to <code > contexterror< / code > with major status invalid evidence . < / p >
add one pu service per top level deployment that represents
start the persistence unit in one phase
first phase of starting the persistence unit
setup the annotation index map
get the persistence provider adaptor . will load the adapter module if needed .
will save the persistenceprovideradaptor at the top level application deployment unit level for sharing with other persistence units
look up the persistence provider
the sub - deployment phases run in parallel ensure that no deployment / sub - deployment moves past phase . first_module_use until the applications persistence unit services are started .
add to management console ( if managementadapter is supported for provider ) . <p / > full path to management data will be : <p / > / deployment = deployment / subsystem = jpa / hibernate - persistence - unit = fullyappqualifiedpath#persistenceunitname / cache = entityclassname <p / > example of full path : <p / > / deployment = jpa_secondlevelcachetestcase . jar / subsystem = jpa / hibernate - persistence - unit = jpa_secondlevelcachetestcase . jar#mypc / cache = org . jboss . as . test . integration . jpa . hibernate . employee
todo this is a temporary hack into internals until deploymentunit exposes a proper resource - based api
use a plain set and it should work for both versions .
builds universal ejb meta data model that is as agnostic .
builds webservices meta data . this methods sets : <ul > <li > context root< / li > <li > wsdl location resolver< / li > <li > config name< / li > <li > config file< / li > < / ul >
builds jboss agnostic ejb meta data .
validate that an updated address - settings still has resources bound corresponding to expiry - address and dead - letter - address ( if they are defined ) .
refresh the attributes of this participant ( the status attribute should have changed to prepared
returns the application name for the passed deployment . if the passed deployment isn t an . ear or doesn t belong to a . ear then this method returns null . else it returns the application - name set in the application . xml of the . ear or if that s not set will return the . ear deployment unit name ( stripped off the . ear suffix ) .
returns the name ( stripped off the . ear suffix ) of the passed <code > deploymentunit< / code > . returns null if the passed <code > deploymentunit< / code > s name doesn t end with . ear suffix .
localirobject implementation ----------------------------------
containedimpl implementation ----------------------------------
{
<p > parses the optional { @code objectfactory environment } . < / p >
/ * helper methods
checks if the passed exception is an application exception . if yes then throws back the exception as - is . else wraps the exception in a { @link javax . ejb . ejbexception } and throws the ejbexception
binds java : comp / orb
/ * ( non - javadoc )
returns an analysis . if the calling thread is currently doing an analysis of this class an unfinished analysis is returned .
lookup an analysis in the fully done map .
create new work - in - progress .
return the fully qualified idl module name that this analysis should be placed in .
convert an integer to a 16 - digit hex string .
convert a long to a 16 - digit hex string .
check if a method is an accessor .
check if a method is a mutator .
check if a method throws anything checked other than java . rmi . remoteexception and its subclasses .
analyze the fields of the class . this will fill in the <code > fields< / code > and <code > f_flags< / code > arrays .
analyze the interfaces of the class . this will fill in the <code > interfaces< / code > array .
analyze the methods of the class . this will fill in the <code > methods< / code > and <code > m_flags< / code > arrays .
convert an attribute read method name in java format to an attribute name in java format .
convert an attribute write method name in java format to an attribute name in java format .
analyse constants . this will fill in the <code > constants< / code > array .
analyse attributes . this will fill in the <code > attributes< / code > array .
fixup overloaded operation names . as specified in section 1 . 3 . 2 . 6 .
fixup names differing only in case . as specified in section 1 . 3 . 2 . 7 .
return the class hash code as specified in the common object request broker : architecture and specification ( 01 - 02 - 33 ) section 10 . 6 . 2 .
escape non - iso characters for an ir name .
return the ir global id of the given class or interface . this is described in section 1 . 3 . 5 . 7 . the returned string is in the rmi hashed format like rmi : java . util . hashtable : c03324c0ea357270 : 13bb0f25214ae4b8 .
{
{
handle the xts - environment element
handle the enable - client - handler element .
iterating over all attributes got from the reader parameter .
loads the specified jpa persistence provider module
the main method .
localirobject implementation ---------------------------------
containedimpl implementation ----------------------------------
create an add operation that can check that there is no other sibling when the resource is added .
start
adds java ee module as a dependency to any deployment unit which is an ejb deployment
{
{
{
todo attribute . marshallasattribute should return boolean
{
{
receives iiop requests to this servant s <code > ejbobject< / code > s and forwards them to the bean container through the jboss <code > mbean< / code > server .
receives intra - vm invocations on this servant s <code > ejbobject< / code > s and forwards them to the bean container through the jboss <code > mbean< / code > server .
authenticate the user with the given credential against the configured elytron security domain .
centralize this hack
sets up jndi bindings for each of the views exposed by the passed <code > sessionbean< / code >
creates a session using the global request controller .
infer the name of the jms destination based on the queue s address .
{
{
{
{
the <code > endtransaction< / code > method ends a transaction and translates any exceptions into transactionrolledback [ local ] exception or systemexception .
the <code > setrollbackonly< / code > method calls setrollbackonly () on the invocation s transaction and logs any exceptions than may occur .
checks whether this { @link class } is configured to be used .
registers endpoint and its associated ws handlers .
/ * this transformer does the following : - maps <passivation - store / > to <cluster - passivation - store / > - sets appropriate defaults for idle_timeout idle_timeout_unit passivate_events_on_replicate and client_mappings_cache
<p > create the { @code policy } array containing the { @code poa } policies using the values specified in the constructor . when creating a { @code poa } the parent { @code poa } is responsible for generating the relevant policies beforehand . < / p >
generates the code of a given method within a stub class .
generates the bytecodes of a stub class for a given interface .
generates the bytecodes of a stub class for a given interface .
generates the bytecodes of a stub class for a given interface .
creates the { @linkplain jobxmlresolver resolver } for the deployment inheriting any visible resolvers and job xml files from dependencies .
returns the job xml file names which contain the job name .
initializes the state of an instance
get the canonical request uri from the request mapping data requestpath
this method is used by the iiop and iiopname url context factories .
initializes the cos naming service . this method initializes the three instance fields : _nc : the root naming context . _orb : the orb to use for connecting rmi / iiop stubs and for getting the naming context ( _nc ) if one was not specified explicitly via provider_url . _name : the name of the root naming context . <p / > _orb is obtained from java . naming . corba . orb if it has been set . otherwise _orb is created using the host / port from provider_url ( if it contains an iiop or iiopname url ) or from initialization properties specified in env . <p / > _nc is obtained from the ior stored in provider_url if it has been set and does not contain an iiop or iiopname url . it can be a stringified ior corbaloc url corbaname url or a url ( such as file / http / ftp ) to a location containing a stringified ior . if provider_url has not been set in this way it is obtained from the result of orb . resolve_initial_reference ( nameservice ) ; <p / > _name is obtained from the iiop iiopname or corbaname url . it is the empty name by default .
handles iiop and iiopname urls ( ins 98 - 10 - 11 )
initializes using corbaname url ( ins 99 - 12 - 03 )
does the job of calling the cos naming api resolve and performs the exception mapping . if the resolved object is a cos naming context ( sub - context ) then this function returns a new jndi naming context object .
converts the string name into a compositename returns the object resolved by the cos naming api resolve . returns the current context if the name is empty . returns either an org . omg . corba . object or javax . naming . context object .
converts the name name into a namecomponent [] object and returns the object resolved by the cos naming api resolve . returns the current context if the name is empty . returns either an org . omg . corba . object or javax . naming . context object .
performs bind or rebind in the context depending on whether the flag rebind is set . the only objects allowed to be bound are of types org . omg . corba . object org . omg . cosnaming . namingcontext . you can use a state factory to turn other objects ( such as remote ) into these acceptable forms . <p / > uses the cos naming apis bind / rebind or bind_context / rebind_context .
converts the name name into a namecomponent [] object and performs the bind operation . uses callbindorrebind . throws an invalid name exception if the name is empty . we need a name to bind the object even when we work within the current context .
converts the string name into a compositename object and performs the bind operation . uses callbindorrebind . throws an invalid name exception if the name is empty .
calls the unbind api of cos naming and uses the exception mapper class to map the exceptions
converts the name name into a namecomponent [] object and performs the unbind operation . uses callunbind . throws an invalid name exception if the name is empty .
renames an object . since cos naming does not support a rename api this method unbinds the object with the oldname and creates a new binding .
renames an object . since cos naming does not support a rename api this method unbinds the object with the oldname and creates a new binding .
returns a bindingenumeration object which has a list of name class pairs . lists the current context if the name is empty .
calls the destroy on the cos naming server
uses the calldestroy function to destroy the context . destroys the current context if name is empty .
calls the bind_new_context cos naming api to create a new subcontext .
uses the callbindnewcontext convenience function to create a new context . throws an invalid name exception if the name is empty .
is mapped to resolve in the cos naming api .
adds to the environment for the current context . record change but do not reinitialize orb .
record change but do not reinitialize orb
builds transformations common to both stack protocols and transport .
parse security
parse credential tag
{
writes out the <mdb > element and its nested elements
writes out the <entity - bean > element and its nested elements
persist as a passivation - store using relevant attributes
persist as a passivation - store using relevant attributes
{
{
{
{
{
{
removes one security domain from the maps
lookup a context in jndi
creates a { @code securitydomaincontext }
creates a { @code securitydomaincontext } optionally including a { @link jssesecuritydomain }
creates an { @code authenticationmanager }
creates an { @code authorizationmanager }
creates an { @code auditmanager }
creates an { @code identitytrustmanager }
creates an { @code mappingmanager }
use reflection to attempt to set the deep copy subject mode on the { @code authenticationmanager }
returns the corresponding { @link org . jboss . as . ejb3 . timerservice . schedule . value . scheduleexpressiontype } for the passed value
create a modulereference from a target type and factory class .
create a modulereference from a target class name and factory class .
create a modulereference from a target type reference address and factory class .
{
{
creates a jboss diagnostic reporter ( jdr ) report . a jdr report response is printed to <code > system . out< / code > .
connecttimeout added
return the localidltype for the given typecode .
wait for the required service to start up and fail otherwise . this method is necessary when a runtime operation uses a service that might have been created within a composite operation .
method to compute masked password based on class attributes .
initialize the underlying vault .
start the vault with given alias .
add secured attribute to specified vault block . this method can be called only after successful startvaultsession () call .
add secured attribute to specified vault block . this method can be called only after successful startvaultsession () call . after successful storage the secured attribute information will be displayed at standard output . for silent method @see addsecuredattribute
check whether secured attribute is already set for given vault block and attribute name . this method can be called only after successful startvaultsession () call .
this method removes secured attribute stored in { @link securityvault } . after successful remove operation returns true . otherwise false .
retrieves secured attribute from specified vault block with specified attribute name . this method can be called only after successful startvaultsession () call .
display info about stored secured attribute .
display info about vault itself in form of as7 configuration file .
returns vault configuration string in user readable form .
{
convenient method to check notnull of value
resource - adapter dmr resource
makes a note of the resource adapter identifier with which a resource adapter named <code > raname< / code > is registered in the { @link org . jboss . jca . core . spi . rar . resourceadapterrepository } . <p / > subsequent calls to { @link #getregisteredresourceadapteridentifier ( string ) } with the passed <code > raname< / code > return the <code > raidentifier< / code >
insert the constant value into the argument any .
process a deployment for a connector . will install a { @code jbossservice } for this resourceadapter .
determine if this permission implies the other permission .
determine if this permission implies the given { @code actionsbits } on the given { @code name } .
get the actions string . the actions string will be a canonical version of the one passed in at construction .
return a permission which is equal to this one except with its actions reset to { @code actionbits } . if the given { @code actionbits } equals the current bits of this permission then this permission instance is returned ; otherwise a new permission is constructed . any action bits which fall outside of { @link #action_all } are silently ignored .
private
use the short class name as the default for the service name .
callback method of { @link javax . management . mbeanregistration } before the mbean is registered at the jmx agent .
helper for sending out state change notifications
process a deployment for jboss - beans . xml files . will parse the xml file and attach a configuration discovered during processing .
{
<p > returns an { @link javax . persistence . entitymanager } associated with the actual { @link javax . transaction . transaction } if present . < / p >
process a deployment for standard ra deployment files . will parse the xml file and attach a configuration discovered during processing .
if any servlet / filter classes are declared then we probably don t want to scan .
{
returns the corba object for a remote object . if input is not a remote object or if remote object uses jrmp return null . if the rmi - iiop library is not available throw configurationexception .
get value .
get the context service name .
returns a combined map of class and method level interceptors
returns the { @link interceptordescription } for the passed <code > interceptorclassname< / code > if such a class interceptor exists for this component description . else returns null .
add a method interceptor class name .
sets the method level interceptors for a method and marks it as exclude class and default level interceptors . <p / > this is used to set the final interceptor order after it has been modifier by the deployment descriptor
adds an interceptor class method override merging it with existing overrides ( if any )
set the naming mode of this component . may not be { @code null } .
add a dependency to this component . if the same dependency is added multiple times only the first will take effect .
gets the interceptor list for a given method . this should not be called until all interceptors have been added .
gets the around timeout interceptor list for a given method . this should not be called until all interceptors have been added .
adds an interceptor factory to every method on the component .
adds an interceptor factory to every method on the component .
adds an interceptor factory to a given method . the method parameter * must * be retrived from either the { @link org . jboss . as . server . deployment . reflect . deploymentreflectionindex } or from { @link #getdefinedcomponentmethods () } as the methods are stored in an identity hash map
adds an interceptor factory to a given method . the method parameter * must * be retrived from either the { @link org . jboss . as . server . deployment . reflect . deploymentreflectionindex } or from { @link #getdefinedcomponentmethods () } as the methods are stored in an identity hash map
adds a timeout interceptor factory to every method on the component .
get the around - construct interceptors . <p / > this method should only be called after all interceptors have been added
adds an around - construct interceptor
get the post - construct interceptors . <p / > this method should only be called after all interceptors have been added
adds a post construct interceptor
get the pre - destroy interceptors . <p / > this method should only be called after all interceptors have been added
adds a pre destroy interceptor
get the pre - passivate interceptors . <p / > this method should only be called after all interceptors have been added
adds a pre passivate interceptor
get the post - activate interceptors . <p / > this method should only be called after all interceptors have been added
adds a post activate interceptor
set the component create service factory for this component .
{
this method corresponds to the original { @code _getclassloader () } method and returns { @link module } based on original class . this module is then used when defining proxy classes .
without protectiondomain
the entry key is bean . xml url value is ( optional ) jandex index url .
remove jndi alias binder services .
hibernate native applications cannot know when the transactionmanager + transactionsynchronizationregistry services are stopped but jpa container managed applications can and will call settransactionsynchronizationregistry with the new ( global ) transactionsynchronizationregistry to use .
perform the configuration of the transport provider .
get the base service name of a component s jndi namespace .
get the base service name of a module s jndi namespace .
get the service name of a context or { @code null } if there is no service mapping for the context name .
get the service name of an environment entry
get the service name of a namingstore
save the specified entitymanager in the local threads active transaction . the transactionsynchronizationregistry will clear the reference to the entitymanager when the transaction completes .
reads and trims the text for the given attribute and returns it or { @code null }
{
<p > adds a { @code binderservice } to the specified target . the service binds the specified value to jndi under the { @code java : / jboss / contextname } context . < / p >
returns a default cache implementation
localirobject implementation ---------------------------------
idltypeoperations implementation ------------------------------
containedimpl implementation ----------------------------------
create the valuemembers array and return it .
create a valuemembers array for typecode creation only and return it .
add a contextservice for this module .
creates the root subsystem s root address .
reads a element from the stream considering the parameters .
{
{
{
creates a new namingserver and sets the naming context to use the naming server .
{
add dependencies for modules required for jpa deployments
creates the service name used for the job operator registered for the deployment .
add a component to this application .
add a message destination to the application
get all views that have the given type in the application
get all components in the application that have the given name
get all views in the application that have the given name and view type
resolves a message destination name into a jndi name
transformation for wildfly 8 . 1 . 0 . final
transformers for eap 6 . 4 / as7 7 . 5 . 0
transformation for eap 6 . 2 . 0 / as7 7 . 3 . 0
reject the attributes if they are defined or discard them if they are undefined or set to their default value .
rename an attribute
obtain a { @link collection } containing the { @link principal } instances for the user associated with the connection .
push a new { @link principal } and credential pair .
pop the identity previously associated and restore internal state to it s previous value .
{ @inheritdoc }
this is the invocationhandler callback for the context interface that was created by our getobjectinstance () method . we handle the java : jboss / jaas / domain level operations here .
creates a { @code securitydomaincontext } if one cannot be found in jndi for a given security domain
just provide the default implementations
make sure that each version has api impl and injection
if needed convert old jsfversionmarker values to slot values .
{
{
{
{
{
{
configure password from a credential - reference ( as an alternative to the password attribute ) and add it to the ra properties .
process scis .
populate the <code > timerservice< / code > from the <code > operation< / code >
returns the typecode suitable for an idl constant .
returns the typecode idl typecodes for parameter result attribute and value member types . this may provoke a mapping of the class argument . <p / > exception classes map to both values and exceptions . for these this method returns the typecode for the value and you can use the <code > getexceptiontypecode< / code > todo method to get the typecode for the mapping to exception .
add a new idl typecode for a mapped class .
get a reference to the special case mapping for java . lang . object . this is according to java ( tm ) language to idl mapping specification section 1 . 3 . 10 . 2
get a reference to the special case mapping for java . lang . string . this is according to java ( tm ) language to idl mapping specification section 1 . 3 . 5 . 10
get a reference to the special case mapping for java . lang . class . this is according to java ( tm ) language to idl mapping specification section 1 . 3 . 5 . 11 .
ensure that a package exists in the ir . this will create modules in the ir as needed .
add a set of constants to a container ( interface or value class ) .
add a set of attributes to a container ( interface or value class ) .
add a set of operations to a container ( interface or value class ) .
add a set of interfaces to the ir .
add a set of abstract valuetypes to the ir .
map the class and add its iiop mapping to the repository .
add an array .
add an interface .
add a value type .
add an exception type .
based on the the annotation type its either entitymanager or entitymanagerfactory
todo this could be moved to a separate deploymentunitprocessor operating on endpoints ( together with the rest of the config resolution mechanism )
not necessary .
creates the naming store if not provided by the constructor .
destroys the naming store .
{
{
<p > configure the sts token providers . < / p >
<p > configure the saml handlers . < / p >
checks that the current method
transaction sync is not affected by the current invocation as multiple ejb methods may be invoked from aftercompletion
throw an exception when a method cannot be invoked
throw an exception when a method cannot be invoked
try to obtain the security domain configured in jboss - app . xml at the ear level if available
gets all classes that are eligible for injection etc
{
{
{
{
{
{
{
{
{
{
{
{
create a { @link javax . ejb . timer }
creates a calendar based { @link javax . ejb . timer }
returns the { @link javax . ejb . timer } corresponding to the passed { @link javax . ejb . timerhandle }
persists the passed <code > timer< / code > . <p / > <p > if the passed timer is null or is non - persistent ( i . e . { @link javax . ejb . timer#ispersistent () } returns false ) then this method acts as a no - op < / p >
suspends any currently scheduled tasks for {
restores persisted timers corresponding to this timerservice which are eligible for any new timeouts . <p > this includes timers whose { @link timerstate } is <b > neither< / b > of the following : <ul > <li > { @link timerstate#canceled } < / li > <li > { @link timerstate#expired } < / li > < / ul > < / p > <p > all such restored timers will be schedule for their next timeouts . < / p >
registers a timer with a transaction ( if any in progress ) and then moves the timer to an active state so that it becomes eligible for timeouts
returns true if the { @link currentinvocationcontext } represents a lifecycle callback invocation . else returns false . <p > this method internally relies on { @link currentinvocationcontext#get () } to obtain the current invocation context . <ul > <li > if the context is available then it looks for the method that was invoked . the absence of a method indicates a lifecycle callback . < / li > <li > if the context is <i > not< / i > available then this method returns false ( i . e . it doesn t consider the current invocation as a lifecycle callback ) . this is for convenience to allow the invocation of { @link javax . ejb . timerservice } methods in the absence of { @link currentinvocationcontext } < / li > < / ul > <p / > < / p >
creates and schedules a {
cancels any scheduled { @link java . util . concurrent . future } corresponding to the passed <code > timer< / code >
returns an unmodifiable view of timers in the current transaction that are waiting for the transaction to finish
marks the transaction for rollback note : this method will soon be removed once this timer service implementation becomes managed
check if a persistent timer is already executed from a different instance or should be executed . for non - persistent timer it always return <code > true< / code > .
returns true if the passed <code > beanclass< / code > is eligible for implicit no - interface view . else returns false . <p / > ejb3 . 1 spec section 4 . 9 . 8 states the rules for an implicit no - interface view on a bean class . if the implements clause of the bean class is empty then the bean is considered to be exposing a no - interface view . during this implements clause check the { @link java . io . serializable } or { @link java . io . externalizable } or any class from javax . ejb . * packages are excluded .
returns the default local view class of the { @link class beanclass } if one is present . ejb3 . 1 spec section 4 . 9 . 7 specifies the rules for a default local view of a bean . if the bean implements just one interface then that interface is returned as the default local view by this method . if no such interface is found then this method returns null .
returns a filtered list for the passed <code > interfaces< / code > list excluding the { @link java . io . serializable } { @link java . io . externalizable } and any interfaces belonging to <code > javax . ejb< / code > package .
process the acceptor information .
extract extra parameters from the map of parameters .
get the parameters .
process the connector information .
}
the old deployment unit service name . this is still registered as an alias however {{
turn type into class .
convert a value
get types from values .
find method info
find method info
a simple null and length check .
parse the persistence unit definitions based on persistence_2_0 . xsd .
returns the next binding in the list .
get the next batch using _bindingiter . update the more field .
constructs a jndi binding object from the cos naming binding object .
add the specified properties .
add the specified properties .
discover all classes that implements healthcheckprocedure
instantiates <em > unmanaged instances< / em > of healthcheckprocedure and handle manually their cdi creation lifecycle . add them to the {
called when the deployment is undeployed .
returns a corba reference for the given locator
gets a handle for the given ejb locator .
( re ) binds an object to a name in a given corba naming context creating any non - existent intermediate contexts along the way . <p / > this method is synchronized on the class object if multiple services attempt to bind the same context name at once it will fail
{
{
returns the value of the node as an enum value .
returns the optional boolean value of the specified {
returns the optional double value of the specified {
returns the optional float value of the specified {
returns the optional int value of the specified {
returns the optional long value of the specified {
returns the optional string value of the specified {
returns the optional property value of the specified {
returns the optional property list value of the specified {
returns the optional list value of the specified {
returns the optional enum value of the specified {
creates a { @link resourceroot } for the passed { @link virtualfile file } and adds it to the list of { @link resourceroot } s in the { @link deploymentunit deploymentunit }
create a {
create a {
returns an array of { @link principal } representing the roles associated with the identity invoking the ejb . this method will check performs checks against run as identities in order to resolve the correct set of roles to be granted .
ensure inputstream actually skips ahead the required number of bytes
[ as7 - 5808 ] support space - separated roles names for backwards compatibility and comma - separated ones for compatibility with hornetq configuration .
check that not both elements have been defined
sends a request message to the server receives the reply from the server and returns an <code > object< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > boolean< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > byte< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > char< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > short< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns an <code > int< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > long< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > float< / code > result to the caller .
sends a request message to the server receives the reply from the server and returns a <code > double< / code > result to the caller .
create a setting .
adds or retrieves an existing eemoduleclassdescription for the local module . this method should only be used for classes that reside within the current deployment unit usually by annotation scanners that are attaching annotation information . <p / > this
add a component to this module .
maps a top level class loader to all cl s in the deployment
{
{
{
{
{
unbind the entry in the provided location . this will remove the node in the tree and no longer manage it .
lookup the object value of a binding node in the tree .
list all nameclasspair instances at a given location in the tree .
list all the binding instances at a given location in the tree .
add a { @code naminglistener } to the naming event coordinator .
remove a { @code naminglistener } from the naming event coordinator .
get the principal given the authenticated subject . currently the first principal that is not of type { @code group } is considered or the single principal inside the callerprincipal group .
read the <server / > element based on version 1 . 0 of the schema .
add dependencies for modules required for ra deployments
{
adds a new factory .
saves the current invocation context on a chained context handle .
{
adds multiple accessible {
determines if a class from this { @link beandeploymentarchiveimpl } instance can access a class in the { @link beandeploymentarchive } instance represented by the specified <code > beandeploymentarchive< / code > parameter according to the java ee class accessibility requirements .
creates the security realm
we need to create the io subsystem if it does not already exist
create a handler for serving welcome content
returns the name of the resource adapter which will be used as the default ra for mdbs ( unless overridden by the mdbs ) .
get an instance without identity . can be used by finders create - methods and activation
return an instance after invocation . <p / > called in 2 cases : a ) done with finder method b ) just removed
return a list of all the entries contained here .
analyse operations . this will fill in the <code > operations< / code > array .
calculate the map that maps idl operation names to operation analyses . besides mapped operations this map also contains the attribute accessor and mutator operations .
calculate the array containing all type ids of this interface in the format that org . omg . corba . portable . servant . _all_interfaces () is expected to return .
collect metrics from the resources
prepare the ws deployment and return a deploymentunit containing it
triggers the ws deployment aspects which process the deployment and install the endpoint services .
publish the webapp for the ws deployment unit
stops the webapp serving the provided ws deployment
starts the weld container
this is a no - op if {
gets the { @link beanmanager } for a given bean deployment archive id .
adds a {
registers endpoint and its config .
adds an interceptor to invoke the {
{
invokes the timeout method through the {
after a timeout failed the timer need to retried . the method must lock the timer for state check and update but not during calltimeout run .
after running the timer calculate the new state or expire the timer and persist it if changed . the method must lock the timer for state check and updates if overridden .
{
get the declared methods
get the declared fields
set accessibleo
get the constructor
get the method
in domain mode the subsystem are under / profile = xxx . this method fixes the address by prepending the addresses ( that start with / subsystem ) with the current operation parent so that is works both in standalone ( parent = empty_address ) and domain mode ( parent = / profile = xxx )
it s possible that the extension is already present . in that case this method does nothing .
check if the name of the parameter is allowed for the given resourcetype .
for generic acceptor and connectors migrate their factory - class attribute if they are using the default netty ones .
discard from a node and set it to a new node if the attribute is defined . use the {
{
processes the passed { @link org . jboss . metadata . ejb . spec . sessionbeanmetadata } and creates appropriate { @link org . jboss . as . ejb3 . component . session . sessionbeancomponentdescription } out of it . the { @link org . jboss . as . ejb3 . component . session . sessionbeancomponentdescription } is then added to the { @link org . jboss . as . ee . component . eemoduledescription module description } available in the deployment unit of the passed { @link deploymentphasecontext phasecontext }
{
attempt to cancel the corresponding invocation .
attempt to determine whether the invocation should proceed or whether it should be cancelled . this method should only be called once per flag instance .
change the type . it checks for compatibility between the change of type .
do not delete this method it is used in enterprise storage <p > copies content of page into passed in byte array .
do not delete this method it is used in enterprise storage <p > get value of lsn from the passed in offset in byte array .
/ * tries to clone any java object by using 3 techniques : - instanceof ( most verbose but faster performance ) - reflection ( medium performance ) - serialization ( applies for any object type but has a performance overhead )
input the json stream data into the graph . more control over how data is streamed is provided by this method .
input the json stream data into the graph . more control over how data is streamed is provided by this method .
creates an instance of { @link oindexdefinition } for automatic index .
extract field name from <property > [ by key|value ] field format .
tests if current expression is an indexed funciton and that function can also be executed without using the index
estimates how many items of this class will be returned applying this filter
recursive method used to find all classes in a given directory and subdirs .
filters discovered classes to see if they implement a given interface .
returns the declared generic types of a class .
returns the generic class of multi - value objects .
checks if a class is a java type : map collection arrays number ( extensions and primitives ) string boolean ..
execute a method .
this is executed on non - indexed fields .
derives the type of a field in a document .
execute the command .
pushes record to cache . identifier of record used as access key
looks up for record in cache by it s identifier . optionally look up in secondary cache and update primary with found record
execute the remove index .
{
{
{
{
{
creates the database ( if it does not exist ) and initializes batch operations . call this once before starting to create vertices and edges .
creates a new edge between two vertices . if vertices do not exist they will be created
based on the cluster / server map and the query target this method tries to find an optimal strategy to execute the query on the cluster .
given a cluster map and a set of clusters involved in a query tries to calculate the minimum number of nodes that will have to be involved in the query execution with clusters involved for each node .
@param clustermap the cluster map for current sharding configuration @param queryclusters the clusters that are target of the query
tries to calculate which clusters will be impacted by this query
for backward compatibility translate distinct ( foo ) to distinct foo . this method modifies the projection itself .
checks if a projection is a distinct ( expr ) . in new executor the distinct () function is not supported so distinct ( expr ) is translated to distinct expr
returns true if the query is minimal ie . no where condition no skip / limit no unwind no group / order by no let
splits let clauses in global ( executed once ) and local ( executed once per record )
re - writes a list of flat and conditions moving left all the equality operations
creates additional projections for order by
given a list of aliases ( present in the existing projections ) calculates a list of additional projections to add to the existing projections to allow order by calculation . the sorting clause will be modified with new replaced aliases
splits projections in three parts ( pre - aggregate aggregate and final ) to efficiently manage aggregations
if group by is performed on an expression that is not explicitly in the pre - aggregate projections then that expression has to be put in the pre - aggregate ( only here in subsequent steps it s removed )
translates subqueries to let statements
checks if this rid is from one of these clusters
tries to use an index for sorting only . also adds the fetch step to the execution plan
checks if a class is the top of a diamond hierarchy
returns true if all the order clauses are asc false if all are desc null otherwise
checks whether the condition has containsany or similar expressions that require multiple index evaluations
given a flat and block and a set of indexes returns the best index to be used to process it with the complete description on how to use it
finds prefix conditions for a given condition eg . if the condition is on [ a b ] and in the list there is another condition on [ a ] or on [ a b ] then that condition is returned .
returns true if the first argument is a prefix for the second argument eg . if the first argument is [ a ] and the second argument is [ a b ]
given an index and a flat and block returns a descriptor on how to process it with an index ( index index key and additional filters to apply after index fetch
given a full text index and a flat and block returns a descriptor on how to process it with an index ( index index key and additional filters to apply after index fetch
aggregates multiple index conditions that refer to the same key search
creates a new instance of the requested strategy . since strategies are stateless if an existing instance already exists then it s returned .
re - create any object if the class has a public constructor that accepts a string as unique parameter .
serialize the class name size + class name + object content
execute a function .
checks if the user has the permission to access to the requested resource for the requested operation .
checks if a rule was defined for the user .
create a compact string with all the relevant information .
protecte system database from being replicated
initializes all the available server s databases as distributed .
removes the node map entry .
elects a new server as coordinator . the election browse the ordered server list .
assign the lock manager at startup
{
{
{
{
{
commits the micro - transaction if it s a top - level micro - transaction .
rollbacks the micro - transaction if it s a top - level micro - transaction .
updates the record identity after its successful commit .
updates the record cache after unsuccessful micro - transaction commit .
prepares the path for a file creation or replacement . if the file pointed by the path already exists it will be deleted a warning will be emitted to the log in this case . all absent directories along the path will be created .
tries to move a file from the source to the target atomically . if atomic move is not possible falls back to regular move .
splits this pattern into multiple
only idempotent commands that don t involve any other node can be executed locally .
collect up the characters as element s characters may be split across multiple calls . isn t sax lovely ...
converts a string produced by <code > timetostring< / code > or <code > datetostring< / code > back to a time represented as a date object .
tells if the channel is connected .
execute the command and return the odocument object created .
merge short value from two byte buffer . first byte of short will be extracted from first byte buffer and second from second one .
merge int value from two byte buffer . first bytes of int will be extracted from first byte buffer and second from second one . how many bytes will be read from first buffer determines based on <code > buffer . remaining () < / code > value
merge long value from two byte buffer . first bytes of long will be extracted from first byte buffer and second from second one . how many bytes will be read from first buffer determines based on <code > buffer . remaining () < / code > value
split short value into two byte buffer . first byte of short will be written to first byte buffer and second to second one .
split int value into two byte buffer . first byte of int will be written to first byte buffer and second to second one . how many bytes will be written to first buffer determines based on <code > buffer . remaining () < / code > value
split long value into two byte buffer . first byte of long will be written to first byte buffer and second to second one . how many bytes will be written to first buffer determines based on <code > buffer . remaining () < / code > value
execute the create property .
execute the alter class .
indexes a value and save the index . splits the value in single words and index each one . save of the index is responsibility of the caller .
splits passed in key on several words and remove records with keys equals to any item of split result and values equals to passed in value .
delegates to the oqueryexecutor the query execution .
returns only the first record if any .
obtains the value stored under the given entry index in this bucket .
shrink the file content ( filledupto attribute only )
creates the file .
always add the header size because on this type is always needed
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
replaces the file content with the content of the provided file .
execute the command remotely and get the results back .
ends the request and unlock the write lock
parse the urls . multiple urls must be separated by semicolon ( ; )
registers the remote server with port .
acquire a network channel from the pool . don t lock the write stream since the connection usage is exclusive .
{
{
gets the current thread database as a odatabasepojoabstract wrapping it where necessary .
{ @inheritdoc }
builds a orientgraph instance passing a configuration . supported configuration settings are : <table > <tr > <td > <b > name< / b > < / td > <td > <b > description< / b > < / td > <td > <b > default value< / b > < / td > < / tr > <tr > <td > blueprints . orientdb . url< / td > <td > database url< / td > <td > - < / td > < / tr > <tr > <td > blueprints . orientdb . username< / td > <td > user name< / td > <td > admin< / td > < / tr > <tr > <td > blueprints . orientdb . password< / td > <td > user password< / td > <td > admin< / td > < / tr > <tr > <td > blueprints . orientdb . saveoriginalids< / td > <td > saves the original element ids by using the property origid . this could be useful on import of graph to preserve original ids< / td > <td > false< / td > < / tr > <tr > <td > blueprints . orientdb . keepinmemoryreferences< / td > <td > avoid to keep records in memory but only rids< / td > <td > false< / td > < / tr > <tr > <td > blueprints . orientdb . usecustomclassesforedges< / td > <td > use edge s label as orientdb class . if doesn t exist create it under the hood< / td > <td > true< / td > < / tr > <tr > <td > blueprints . orientdb . usecustomclassesforvertex< / td > <td > use vertex s label as orientdb class . if doesn t exist create it under the hood< / td > <td > true< / td > < / tr > <tr > <td > blueprints . orientdb . usevertexfieldsforedgelabels< / td > <td > store the edge relationships in vertex by using the edge s class . this allow to use multiple fields and make faster traversal by edge s label ( class ) < / td > <td > true< / td > < / tr > <tr > <td > blueprints . orientdb . lightweightedges< / td > <td > uses lightweight edges . this avoid to create a physical document per edge . documents are created only when they have properties< / td > <td > true< / td > < / tr > <tr > <td > blueprints . orientdb . autoscaleedgetype< / td > <td > set auto scale of edge type . true means one edge is managed as link 2 or more are managed with a linkbag< / td > <td > false< / td > < / tr > <tr > <td > blueprints . orientdb . edgecontainerembedded2treethreshold< / td > <td > changes the minimum number of edges for edge containers to transform the underlying structure from embedded to tree . use - 1 to disable transformation< / td > <td > - 1< / td > < / tr > <tr > <td > blueprints . orientdb . edgecontainertree2embeddedthreshold< / td > <td > changes the minimum number of edges for edge containers to transform the underlying structure from tree to embedded . use - 1 to disable transformation< / td > <td > - 1< / td > < / tr > < / table >
create a connection .
create a connection .
retrieves the connection by id .
retrieves the connection by address / port .
disconnects and kill the associated network manager .
interrupt the associated network manager .
disconnects a client connections
pushes the distributed configuration to all the connected clients .
for internal use only
closes the transaction and releases all the acquired locks .
handles vertex consistency after an update edge
updates old and new vertices connected to an edge after out / in update on the edge itself
checks if an object is an oidentifiable and an instance of a particular ( schema ) class
{
scans all classes accessible from the context class loader which belong to the given package and subpackages .
generate / updates the schemaclass and properties from given class<? > .
checks if all registered entities has schema generated if not it generates it
updates the metric metadata .
return the element at the current position and move forward the cursor to the next position available .
return the element at the current position and move backward the cursor to the previous position available .
move the iterator to the begin of the range . if no range was specified move to the first record of the cluster .
move the iterator to the end of the range . if no range was specified move to the last record of the cluster .
tell to the iterator that the upper limit must be checked at every cycle . useful when concurrent deletes or additions change the size of the cluster while you re browsing it . default is false .
execute the command and return the odocument object created .
returns the next character from the input stream . handles unicode decoding .
execute the find references .
legacy protocol < 37
protocol 37
convert fields from text to real value . supports : string rid boolean float integer and null .
defines a callback to call in case of error during the asynchronous replication .
registers a stateless implementations the same instance will be shared on all the storages .
detects limit of limit of open files .
@param printsteps print all steps of discovering of memory limit in the log with { @code info } level .
obtains the total size in bytes of the installed physical memory on this machine . note that on some vms it s impossible to obtain the physical memory size in this case the return value will { @code - 1 } .
tests if current expression is an indexed function and that function can be used on this target
execute the command and return the odocument object created .
}
move bytes left or right of an offset .
returns the used buffer as byte [] .
append byte [] to the stream .
fills the stream from current position writing ilength times the ifiller byte
executes all the script and returns last statement execution step so that it can be executed from outside
executes the whole script and returns last statement only if it s a return otherwise it returns null ;
serialize the user pojo to a orecorddocument instance .
returns the declared generic types of a class .
at run - time the evaluation per record must return always true since the recordset are filtered at the beginning unless an operator can work in both modes . in this case sub - class must extend it .
executes the command and return the odocument object created .
{
{
write a oidentifiable instance using this format : <br > - 2 bytes : class id [ - 2 = no record - 3 = rid - 1 = no class id > - 1 = valid ] <br > - 1 byte : record type [ d b f ] <br > - 2 bytes : cluster id <br > - 8 bytes : position in cluster <br > - 4 bytes : record version <br > - x bytes : record content <br >
this method load the record information by the internal cluster segment . it s for compatibility with older database than 0 . 9 . 25 .
added version used for managed network versioning .
returns true if an arrays contains a value otherwise false
returns true if an arrays contains a value otherwise false
this method parses the statement
rebinds filter ( where ) conditions to alias nodes after optimization
assigns default aliases to pattern nodes that do not have an explicit alias
this method works statefully using request and context variables from current match statement . this method will be deprecated in next releases
executes the match statement . this is the preferred execute () method and it has to be used as the default one in the future . this method works in stateless mode
start a depth - first traversal from the starting node adding all viable unscheduled edges and vertices .
sort edges in the order they will be matched
@param request @param ctx @param record
}
compares if 2 field values are the same .
compares two values executing also conversion between types .
add new indexdefinition in current composite .
{
{
{
{
{
{
execute the command .
internal use only this has to be invoked only if the item is aggregate!!!
choosing return type is based on existence of
check whether or not this filter item is chain of fields ( e . g . field1 . field2 . field3 ) . return true if filter item contains only field projections operators if field item contains any other projection operator the method returns false . when filter item does not contains any chain operator it is also field chain consist of one field .
get the collate of this expression based on the fully evaluated field chain starting from the passed object .
returns the plain string representation of this identifier with quoting removed from back - ticks
sets the value of the identifier . it can contain any values this method can manage back - ticks ( internally quote them ) so back - ticks have not to be quoted when passed as a parameter
pseudo - randomly advances and records the given probe value for the given thread .
the transaction is reentrant . if { @code begin () } has been called several times the actual commit happens only after the same amount of { @code commit () } calls
execute the drop cluster .
it returns a odocument starting from a json file .
execute the command and return the odocument object created .
delete the current vertex .
parses the returning keyword if found .
checks if an hash string matches a password based on the algorithm found on hash string .
hashes the input string .
returns true if the algorithm is supported by the current version of java
creates the index .
{
( blueprints extension ) sets the order of results by a field in ascending ( asc ) or descending ( desc ) order based on dir parameter . this is translated on order by in the underlying sql query .
returns the result set of the query as iterable vertices .
returns the result set of the query as iterable edges .
return the partition keys of all the sub - tasks .
computes the timeout according to the transaction size .
{ @inheritdoc }
added version used for managed network versioning .
returns the current graph settings .
removes the edge from the graph . connected vertices aren t removed .
execute the create link .
this check if a file was trimmed or trunked in the current atomic operation .
{
parses the timeout keyword if found .
parses the lock keyword if found .
todo check pgis
execute the alter database .
execute the command and return the odocument object created .
delete the current edge .
combines two queries subset into one . this operation will be valid only if { @link #canbemerged ( oindexsearchresult ) } method will return <code > true< / code > for the same passed in parameter .
execute the command .
obtains the value stored under the given entry index in this bucket .
adds the specified cluster to the class if it doesn t already exist .
remove all records belonging to specified cluster
all operations running at cache initialization stage
all operations running at cache destruction stage
result set with a single result ;
grant a permission to the resource .
revoke a permission to the resource .
{
{
deletes the current record .
add a step that transforms a normal oresult in a specific object that under setproperty () updates the actual oidentifiable
{
{
binds parameters .
convert the item requested .
todo refactor this method to receive the item .
convert the item requested .
parses a string returning the closer type . numbers by default are integer if haven t decimal separator otherwise float . to treat all the number types numbers are postponed with a character that tells the type : b = byte s = short l = long f = float d = double t = date .
parses the field type char returning the closer type . default is string . b = binary if ivalue . length () > = 4 b = byte if ivalue . length () < = 3 s = short l = long f = float d = double a = date t = datetime
parses a string returning the value with the closer type . numbers by default are integer if haven t decimal separator otherwise float . to treat all the number types numbers are postponed with a character that tells the type : b = byte s = short l = long f = float d = double t = date . if starts with # it s a recordid . most of the code is equals to gettype () but has been copied to speed - up it .
increments the popularity of the element if it does not exceed the maximum ( 15 ) . the popularity of all elements will be periodically down sampled when the observed events exceeds a threshold . this process provides a frequency aging to allow expired long term entries to fade away .
increments the specified counter by 1 if it is not already at the maximum value ( 15 ) .
reduces every counter by half of its original value .
returns the table index for the counter at the specified depth .
applies a supplemental hash function to a given hashcode which defends against poor quality hash functions .
creates an index on this property . indexes speed up queries but slow down insert and update operations . for massive inserts we suggest to remove the index make the massive insert and recreate it .
remove the index on property
returns the first index defined for the property .
returns the linked class in lazy mode because while unmarshalling the class could be not loaded yet .
execute the command and return the odocument object created .
add new key value to the list of already registered values . <p > if passed in value is { @link ocompositekey } itself then its values will be copied in current index . but key itself will not be added .
create a new index . <p > may require quite a long time if big amount of data should be indexed .
binds pojo to odocument .
sets the server role between master ( default ) and replica .
adds a server in the configuration . it replaces all the tags &lt ; new_node&gt ; with the new server name<br > note : it must be executed in distributed database lock .
sets the server as owner for the given cluster . the owner server is the first in server list . <br > note : it must be executed in distributed database lock .
removes a server from the list . <br > note : it must be executed in distributed database lock .
set a server offline . it assures the offline server is never on top of the list . <br > note : it must be executed in distributed database lock .
/ * ( non - javadoc )
/ * ( non - javadoc )
remove the current event listener .
creates a distributed database instance if not defined yet .
not synchronized it s called when a message arrives
removes a response manager because in timeout .
{
returns a copy of current database if it s open . the returned instance can be used by another thread without affecting current instance . the database copy is not set in thread local .
this method is internal it can be subject to signature change or be removed do not use .
this method is internal it can be subject to signature change or be removed do not use .
{
notify collection that changes has been saved . converts to non embedded implementation if needed . <p > warning! method is for internal usage .
important! only for internal usage .
silently replace delegate by tree implementation .
manages cross compiler compatibility issues .
execute the create cluster .
closes all the databases .
removes from memory the pool associated to the closed storage . this avoids pool open against closed storages .
iterates on all factories and append all function names .
iterates on all factories and append all collate names .
iterates on all factories and append all command names .
use only for named fields
sets the response s status as http code and reason .
sets the response s headers specifying when using the keep - alive or not .
writes records as response specifying a fetch - plan to serialize nested records . the records are serialized in json format .
writes a record as response . the record is serialized in json format .
sends the complete http response in one call .
sends the complete http response in one call specifying a stream as content .
return the element at the current position and move backward the cursor to the previous position available .
return the element at the current position and move forward the cursor to the next position available .
move the iterator to the begin of the range . if no range was specified move to the first record of the cluster .
tell to the iterator that the upper limit must be checked at every cycle . useful when concurrent deletes or additions change the size of the cluster while you re browsing it . default is false .
open a database specified by name using the username and password if needed
create a new database
@param target @param value @param ctx
avoid to close it but rather release itself to the owner pool .
change uuid to null to prevent its serialization to disk .
distributed requests against the available workers by using one queue per worker . this guarantee the sequence of the operations against the same record cluster .
called inside of { @link com . orientechnologies . orient . core . storage . impl . local . paginated . base . odurablecomponent } to notify that component started to perform operation on data . after that all performance characteristic started to be gathered for this component till method { @link #completecomponentoperation () } will be called . <p > components can be stacked so if components <code > c1< / code > and then <code > c2< / code > call this method than performance data for both components at once started to be gathered .
indicates that the most earliest component in stack of components has completed it s operation so performance data for this component is stopped to be gathered .
read speed of data in pages per second on cache level for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
read speed of data from file system in pages for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
amount of pages read from cache for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
amount of pages are read from file for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
write speed of data in pages per second on cache level for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
amount of pages written to cache for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
percent of cache hits for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
average amount of pages which were read from cache for component with given name during single data operation . <p > if null value is passed or data for component with passed in name does not exist then <code > - 1< / code > will be returned .
takes performance data are split by components from last snapshot and aggregates them with data passed inside method as parameter . result of aggregation of performance data is returned inside of passed in performance data .
takes write cache performance data from last snapshot and aggregates them with data passed inside method as parameter . result of aggregation of performance data is returned inside of passed in performance data and as result of this method call .
takes storage performance data from last snapshot and aggregates them with data passed inside method as parameter . result of aggregation of performance data is returned inside of passed in performance data and as result of this method call .
takes write ahead log data from last snapshot and aggregates them with data passed inside method as parameter . result of aggregation of performance data is returned inside of passed in performance data and as result of this method call .
takes performance data for component from last snapshot and aggregates them with data passed inside method as parameter . result of aggregation of performance data is returned inside of passed in performance data .
converts properties of given class into values of fields of returned document . names of fields equal to names of properties . <p > all data related to separate components are stored in field <code > databycomponent< / code > map which has type { @link otype#embeddedmap } where key of map entry is name of component and value is document which contains the same fields as high level document but with values for single component not whole system . <p > write ahead log performance data are stored inside of <code > waldata< / code > field .
increments counter of page accesses from cache . <p > if you wish to gather statistic for current durable component please call {
stops and records results of timer which counts how much time was spent on operation of flush pages in write cache .
stops and records results of timer which counts how much time was spent on fuzzy checkpoint operation .
stops and records results of timer which counts how much time was spent on read of page from disk cache . <p > if you wish to gather statistic for current durable component please call {
stops and records results of timer which counts how much time was spent on full checkpoint operation .
stops and records results of timer which counts how much time was spent to write page to disk cache . <p > if you wish to gather statistic for current durable component please call {
stops and records results of timer which counts how much time was spent on atomic operation commit .
stops and records results of timer which counts how much time was spent on logging of single write ahead log record .
stops timer and records how much time was spent on flushing of data from write ahead log cache .
makes snapshot of data if time for next snapshot is passed . also clear all data if { @link #cleanupinterval } interval is over .
/ * ( non - javadoc )
returns an already parsed sql executor taking it from the cache if it exists or creating a new one ( parsing and then putting it into the cache ) if it doesn t
@param statement an sql statement
parses an sql statement and returns the corresponding executor
/ * =============== start / stop =================
inits the procedure that listens to pings from other servers eg . that discovers other nodes in the network
init the procedure that sends pings to other servers ie . that notifies that you are alive
inits the procedure that checks if a server is no longer available ie . if he did not ping for a long time
init the procedure that sends pings to other servers ie . that notifies that you are alive
/ * =============== network utilities =================
/ * =============== encryption =================
removes the element from the graph . in case the element is a vertex all the incoming and outgoing edges are automatically removed too .
( blueprints extension ) sets multiple properties in one shot against vertices and edges . this improves performance avoiding to save the graph element at every property set . <br > example : <p > <code > vertex . setproperties ( name jill age 33 city rome born victoria tx ) ; < / code > you can also pass a map of values as first argument . in this case all the map entries will be set as element properties : <p > <code > map<string object > props = new hashmap<string object > () ; props . put ( name jill ) ; props . put ( age 33 ) ; props . put ( city rome ) ; props . put ( born victoria tx ) ; vertex . setproperties ( props ) ; < / code >
sets a property value .
removes a property .
returns a property value .
( blueprints extension ) saves current element to a particular cluster . you don t need to call save () unless you re working against temporary vertices .
( blueprints extension ) fills the element from a byte []
( blueprints extension ) returns the record s identity .
( blueprints extension ) returns the underlying record .
( blueprints extension ) removes the reference to the current graph instance to let working offline . to reattach it use @attach . <p > this methods works only in classic detach / attach mode when dettachment / attachment is done manually by default it is done automatically and currently active graph connection will be used as graph elements owner .
( blueprints extension ) replaces current graph instance with new one on @detach - ed elements . use this method to pass elements between graphs or to switch between tx and notx instances . <p > this methods works only in classic detach / attach mode when detachment / attachment is done manually by default it is done automatically and currently active graph connection will be used as graph elements owner . <p > to set classic detach / attach mode please set custom database parameter <code > classicdetachmode< / code > to <code > true< / code > .
( blueprints extension ) returns the graph instance associated to the current element . on
( blueprints extension ) validates an element property .
check if a class already exists otherwise create it at the fly . if a transaction is running commit changes create the class and begin a new transaction .
( blueprints extension ) sets multiple properties in one shot against vertices and edges without saving the element . this improves performance avoiding to save the graph element at every property set . example : <p > <code > vertex . setproperties ( name jill age 33 city rome born victoria tx ) ; < / code > you can also pass a map of values as first argument . in this case all the map entries will be set as element properties : <p > <code > map<string object > props = new hashmap<string object > () ; props . put ( name jill ) ; props . put ( age 33 ) ; props . put ( city rome ) ; props . put ( born victoria tx ) ; vertex . setproperties ( props ) ; < / code >
@param config global configuration parameter .
wraps courser only if it is not already wrapped .
{
{
{
{
{
{
define custom strategy to use for vertex attribute .
define custom strategy to use for edge attribute .
input the graphml stream data into the graph . in practice usually the provided graph is empty .
input the graphml stream data into the graph . in practice usually the provided graph is empty .
input the graphml stream data into the graph . more control over how data is streamed is provided by this method .
input the graphml stream data into the graph . more control over how data is streamed is provided by this method .
input the graphml stream data into the graph . in practice usually the provided graph is empty .
input the graphml stream data into the graph . in practice usually the provided graph is empty .
{
{
{
called by class iterator .
called by cluster iterator .
bufferizes index changes to be flushed at commit time .
merge the two set try to use the optimum case
returns the actual username if successful null otherwise .
osecurityauthenticator
osecurityauthenticator
if not supported by the authenticator return false .
update current record .
handles vertex consistency after an update edge
parses the returning keyword if found .
see oindexablesqlfunction . searchfromtarget ()
@param target query target @param ctx execution context @param operator operator at the right of the function @param rightvalue value to compare to funciton result
tests if current function is an indexed function and that function can also be executed without using the index
{
{
{
{
{
open a database
open a database
create a new database
create a new database
create a new database if not exists
create a new database if not exists
create proxies that support maximum number of different operations . in case when several different indexes which support different operations ( e . g . indexes of { @code unique } and { @code fulltext } types ) are possible the creates the only one index of each type .
finds the index that fits better as a base index in chain . requirements to the base index : <ul > <li > should be unique or not unique . other types cannot be used to get all documents with required links . < / li > <li > should not be composite hash index . as soon as hash index does not support partial match search . < / li > <li > composite index that ignores null values should not be used . < / li > <li > hash index is better than tree based indexes . < / li > <li > non composite indexes is better that composite . < / li > < / ul >
{
{
make type conversion of keys for specific index .
register statistic information about usage of index in { @link oprofilerstub } .
writes page with given page index to the cache and eventually writes it to the file .
read page content with given index from cache or file .
flushes all buffered pages and truncates file till passed in page index
reads page content from the cache to the <code > bytebuffer< / code > <code > bytebuffer< / code > is not backed by the cache and can be freely changed
writes cache content to the file and performs <code > fsync< / code >
writes cache content to the file and closes it . calls <code > fsync< / code > if needed .
initializes cache and opens underlying file .
{
returns true if the replication is active otherwise false .
returns the new node strategy between dynamic and static . if static the node is registered under the server tag .
returns the execution mode if synchronous .
reads your writes .
returns the list of servers that can manage a list of clusters . the algorithm makes its best to involve the less servers as it can .
returns the clusters where a server is owner . this is used when a cluster must be selected : locality is always the best choice .
returns the set of server names involved on the passed cluster collection .
returns true if the local server has all the requested clusters .
returns true if the local server has the requested cluster .
returns the server list for the requested cluster cluster excluding any tags like <new_nodes > and iexclude if any .
returns an ordered list of master server . the first in the list is the first found in configuration . this is used to determine the cluster leader .
returns the complete list of servers found in configuration .
returns the set of clusters managed by a server .
returns the set of clusters where server is the owner .
returns the owner server for the given cluster excluding the passed node . the owner server is the first in server list .
returns the static owner server for the given cluster .
returns the configured server list for the requested cluster .
returns the server role between master ( default ) and replica .
returns the registered servers .
returns all the configured data centers names if any .
returns the data center write quorum .
returns true if the database is sharded across servers . false if it s completely replicated .
returns the list of servers in a data center .
returns the data center where the server belongs .
returns the global read quorum .
returns the read quorum .
returns the write quorum .
gets the document representing the cluster configuration .
gets the document representing the dc configuration .
returns the read quorum .
internal use only .
( internal )
( internal ) returns the case sensitive edge class names .
( internal )
( internal )
( blueprints extension ) configure the graph instance .
returns an index by name and class
drops an index by name .
creates a new unconnected vertex with no fields in the graph .
( blueprints extension ) creates a new unconnected vertex in the graph setting the initial field values .
( blueprints extension ) creates a new unconnected vertex with no fields of specific class in a cluster in the graph .
( blueprints extension ) creates a temporary vertex setting the initial field values . the vertex is not saved and the transaction is not started .
creates an edge between a source vertex and a destination vertex setting label as edge s label .
returns a vertex by an id .
get all the vertices in graph of a specific vertex class and all sub - classes only if ipolymorphic is true .
get all the vertices in graph filtering by field name and value . example : <code > iterable<vertex > resultset = getvertices ( name jay ) ; < / code >
lookup for a vertex by id using an index . <br > this api relies on unique index ( sbtree / hash ) but is deprecated . <br > example : <code > vertex v = getvertexbykey ( v . name name jay ) ; < / code >
get all the vertices in graph filtering by field name and value . example : <code > iterable<vertex > resultset = getvertices ( person new string [] { name surname } new object [] { sherlock holmes } ) ; < / code >
get all the edges in graph of a specific edges class and all sub - classes only if ipolymorphic is true .
get all the edges in graph filtering by field name and value . example : <code > iterable<edges > resultset = getedges ( name jay ) ; < / code >
returns a edge by an id .
reuses the underlying database avoiding to create and open it every time .
closes the graph . after closing the graph cannot be used .
returns the v persistent class as orientvertextype instance .
returns the persistent class for type itypename as orientvertextype instance .
creates a new vertex persistent class .
creates a new vertex persistent class specifying the super class .
creates a new vertex persistent class specifying the super class .
drop a vertex class .
returns the persistent class for type itypename as orientedgetype instance .
creates a new edge persistent class .
creates a new edge persistent class specifying the super class .
creates a new edge persistent class specifying the super class .
returns a graph element vertex or edge starting from an id .
drops the index against a field name .
creates an automatic indexing structure for indexing provided key for element class .
returns the indexed properties .
returns the indexed properties .
( internal only )
( internal only )
( internal only )
removes listener which is triggered if exception is cast inside background flush data thread .
fires event about exception is thrown in data flush thread
this method is called once new pages are added to the disk inside of {
read information about files are registered inside of write cache / storage file consist of rows of variable length which contains following entries : <ol > <li > internal file id may be positive or negative depends on whether file is removed or not< / li > <li > name of file inside of write cache this name is case sensitive< / li > <li > name of file which is used inside file system it can be different from name of file used inside write cache< / li > < / ol >
given a property name calculates if this property name matches this nested projection item eg . <ul > <li > this is a * so it matches any property name< / li > <li > the field name for this projection item is the same as the input property name< / li > <li > this item has a wildcard and the partial field is a prefix of the input property name< / li > < / ul >
execute the command .
starts performance monitoring only for single thread . after call of this method you can not start system wide monitoring till call of {
starts performance monitoring only for whole system . after call of this method you can not start monitoring on thread level till call of {
stops monitoring of performance statistic for whole system .
registers jmx bean for current manager .
deregisters jmx bean for current manager .
average amount of pages which were read from cache for component with given name during single data operation . if null value is passed or data for component with passed in name does not exist then <code > - 1< / code > will be returned .
percent of cache hits for component name of which is passed as method argument . if null value is passed then value for whole system will be returned . if data for component with passed in name does not exist then <code > - 1< / code > will be returned .
iterates over all live threads and accumulates write performance statics gathered form threads also accumulates statistic from dead threads which were alive when when gathering of performance measurements is started .
iterates over all live threads and accumulates performance statics gathered form threads on system level also accumulates statistic from dead threads which were alive when when gathering of performance measurements is started .
iterates over all live threads and accumulates performance statics gathered form threads for provided component also accumulates statistic from dead threads which were alive when when gathering of performance measurements is started .
removes provided dead threads from { @link #statistics } field and accumulates data from them in { @link #deadthreadsstatistic } .
obtains the value stored under the given entry index in this bucket .
compress content string
returns the property value configured if any .
create a new pojo by its class name . assure to have called the registerentityclasses () declaring the packages that are part of entity classes .
method that detaches all fields contained in the document to the given object .
method that detaches all fields contained in the document to the given object and recursively all object tree . this may throw a { @link stackoverflowerror } with big objects tree . to avoid it set the stack size with - xss java option
saves an object to the database specifying the mode . first checks if the object is new or not . in case it s new a new odocument is created and bound to the object otherwise the odocument is retrieved and updated . the object is introspected using the java reflection to extract the field values . <br > if a multi value ( array collection or map of objects ) is passed then each single object is stored separately .
saves an object in synchronous mode to the database forcing a record cluster where to store it . first checks if the object is new or not . in case it s new a new odocument is created and bound to the object otherwise the odocument is retrieved and updated . the object is introspected using the java reflection to extract the field values . <br > if a multi value ( array collection or map of objects ) is passed then each single object is stored separately . <p > before to use the specified cluster a check is made to know if is allowed and figures in the configured and the record is valid following the constraints declared in the schema .
saves an object to the database forcing a record cluster where to store it . first checks if the object is new or not . in case it s new a new odocument is created and bound to the object otherwise the odocument is retrieved and updated . the object is introspected using the java reflection to extract the field values . <br > if a multi value ( array collection or map of objects ) is passed then each single object is stored separately . <p > before to use the specified cluster a check is made to know if is allowed and figures in the configured and the record is valid following the constraints declared in the schema .
returns the version number of the object . version starts from 0 assigned on creation .
register the static document binary mapping mode in the database context ( only if it s not already set )
returns a wrapped ocommandrequest instance to catch the result - set by converting it before to return to the user application .
converts an array of parameters : if a pojo is used then replace it with its record id .
sets as dirty a pojo . this is useful when you change the object and need to tell to the engine to treat as dirty .
sets as not dirty a pojo . this is useful when you change some other object and need to tell to the engine to treat this one as not dirty .
convert a parameter : if a pojo is used then replace it with its record id .
iterates on all factories and append all index types .
iterates on all factories and append all index engines .
@param storage todo @param indextype index type
not synchronized it s called when a message arrives
@param localnodename @param localresult
waits until the minimum responses are collected or timeout occurs . if waitforlocalnode wait also for local node .
returns the list of node names that didn t provide a response .
returns all the responses in conflict .
returns the biggest response group .
computes the quorum response if possible by returning true and setting the field quorumresponse with the odistributedresponse .
returns the received response objects .
returns an already prepared sql execution plan taking it from the cache if it exists or creating a new one if it doesn t
@param statement an sql statement @param ctx
if the condition involved the current pattern ( match statement eg . $matched . something = foo ) returns the name of involved pattern aliases ( something in this case )
tests if current expression involves an indexed function and that function can be used on this target
formats the library of functions for a language .
acquires a database engine from the pool . once finished using it the instance must be returned in the pool by calling the method #releasedatabaseengine ( string scriptengine ) .
acquires a database engine from the pool . once finished using it the instance must be returned in the pool by calling the method
unbinds variables
returns the next position available .
recalculates real bag size .
removes entry with given key from { @link #newentries } .
it s not key = [ ... ] but a real condition on field names already ordered ( field names will be ignored )
this is for subqueries when a oresult is found <ul > <li > if it s a projection with a single column the value is returned< / li > <li > if it s a document the rid is returned< / li > < / ul >
obtains the value stored under the given index in this bucket .
checks if given a list of = conditions and a set of order by fields
finds a character inside a string specyfing the limits and direction . if ifrom is minor than ito then it moves forward otherwise backward .
jump white spaces .
jump some characters reading from an offset of a string .
like string . startswith () but ignoring case
sets the fetch plan to use .
adds the record to repair int the map of records and cluster . the decision about repairing is taken by the timer task .
cancel the repair against a record because the update succeed .
enqueues the request to repair a cluster . the decision about repairing is taken by the timer task .
execute the command .
calculate the set of dependency aliases for each alias in the pattern .
sort edges in the order they will be matched
assigns default aliases to pattern nodes that do not have an explicit alias
create a pojo by its class name .
scans all classes accessible from the context class loader which belong to the given package and subpackages .
registers provided classes
scans all classes accessible from the context class loader which belong to the given class and all it s attributes - classes .
sets the received handler as default and merges the classes all together .
acquires a connection from the pool . if the pool is empty then the caller thread will wait for it .
returns amount of available connections which you can acquire for given source and user name . source id is consist of source name and source user name .
acquires a connection from the pool specifying options . if the pool is empty then the caller thread will wait for it .
execute the sync cluster .
writes binary dump of this cluster page to the log .
switch to the orientdb classloader before lookups on serviceregistry for implementation of the given class . useful under osgi and generally under applications where jars are loaded by another class loader
@param unlimitedcap the upper limit on reported memory if jvm reports unlimited memory .
checks the orientdb cache memory configuration and emits a warning if configuration is invalid .
tries to fix some common cache / memory configuration problems : <ul > <li > cache size is larger than direct memory size . < / li > <li > memory chunk size is larger than cache size . < / li > <ul / >
creates a vertex from graphson using settings supplied in the constructor .
creates a vertex from graphson using settings supplied in the constructor .
creates an edge from graphson using settings supplied in the constructor .
creates an edge from graphson using settings supplied in the constructor .
creates an edge from graphson using settings supplied in the constructor .
creates graphson for a single graph element .
creates graphson for a single graph element .
reads an individual vertex from json . the vertex must match the accepted graphson format .
reads an individual edge from json . the edge must match the accepted graphson format .
creates a jettison jsonobject from a graph element .
creates a jackson objectnode from a graph element .
executes import with configuration ;
status of the running jobs
{
{
{
returns { @link comparator } instance if applicable one exist or <code > null< / code > otherwise .
returns the cluster map for current deploy . the keys of the map are node names the values contain names of clusters ( data files ) available on the single node .
returns the data center map for current deploy . the keys are data center names the values are node names per data center
@param transactionid
{
returns the secret key algorithm portion of the cipher transformation .
creates an osymmetrickey from an osymmetrickeyconfig interface .
creates an osymmetrickey from a file containing a base64 key .
creates an osymmetrickey from an inputstream containing a base64 key .
creates an osymmetrickey from a java jceks keystore .
creates an osymmetrickey from a java jceks keystore .
this is a convenience method that takes a string argument encodes it as base64 then calls encrypt ( byte [] ) .
this method encrypts an array of bytes .
this method decrypts the base64 - encoded json document using the specified algorithm and cipher transformation .
this method decrypts the base64 - encoded json document using the specified algorithm and cipher transformation .
saves the internal secretkey to the specified outputstream as a base64 string .
saves the internal secretkey as a keystore .
{
{
{
set the inherited context avoiding to copy all the values every time .
adds an item to the unique result set
{
{
{
{
{
object or map . check the type attribute to know it .
null is returned in all other cases and means authentication was unsuccessful .
retrieves the value crossing the map with the dotted notation
makes a deep comparison field by field to check if the passed odocument instance is identical as identity and content to the current one . instead equals () just checks if the rid are the same .
makes a deep comparison field by field to check if the passed odocument instance is identical in the content to the current one . instead equals () just checks if the rid are the same .
returns the remote network address in the format <ip > : <port > .
return the record to use for the operation .
read the current record and increment the counter if the record was found .
deleted records are written in output stream first then created / updated records . all records are sorted by record id . <p > each record in output stream is written using following format : <ol > <li > record s cluster id - 4 bytes< / li > <li > record s cluster position - 8 bytes< / li > <li > delete flag 1 if record is deleted - 1 byte< / li > <li > record version only if record is not deleted - 4 bytes< / li > <li > record type only if record is not deleted - 1 byte< / li > <li > length of binary presentation of record only if record is not deleted - 4 bytes< / li > <li > binary presentation of the record only if record is not deleted - length of content is provided in above entity< / li > < / ol >
obtains from https : // github . com / enderceylan / cs - 314 -- data - structures / blob / master / hw10 - graph . java
obtains from http : // theory . stanford . edu / ~amitp / gameprogramming / heuristics . html
obtains from http : // theory . stanford . edu / ~amitp / gameprogramming / heuristics . html
obtains from http : // theory . stanford . edu / ~amitp / gameprogramming / heuristics . html
obtains from http : // theory . stanford . edu / ~amitp / gameprogramming / heuristics . html
obtains from http : // theory . stanford . edu / ~amitp / gameprogramming / heuristics . html
gets transactional graph with the database from pool if pool is configured . otherwise creates a graph with new db instance . the graph instance inherits the factory s configuration .
gets non transactional graph with the database from pool if pool is configured . otherwise creates a graph with new db instance . the graph instance inherits the factory s configuration .
gives new connection to database . if current factory configured to use pool ( see { @link #setuppool ( int int ) } method ) retrieves connection from pool . otherwise creates new connection each time .
check if the database with path given to the factory exists . <p > this api can be used only in embedded mode and has no need of authentication .
setting up the factory to use database pool instead of creation a new instance of database connection each time .
gets the property value .
closes a transaction .
root productions .
get the next token .
get the specific token .
generate parseexception .
( internal only ) returns the field name used for the relationship .
( internal only )
( internal only )
( internal only )
( blueprints extension ) executes the command predicate against current vertex . use osqlpredicate to execute sql . example : <code > iterable<orientvertex > friendsoffriends = ( iterable<orientvertex > ) luca . execute ( new osqlpredicate ( out () . out ( friend ) . out ( friend ) )) ; < / code >
returns all the property names as set of string . out in and label are not returned as properties even if are part of the underlying document because are considered internal properties .
returns a lazy iterable instance against vertices .
removes the current vertex from the graph . all the incoming and outgoing edges are automatically removed too .
moves current vertex to another class / cluster . all edges are updated automatically .
creates an edge between current vertex and a target vertex setting label as edge s label .
creates an edge between current vertex and a target vertex setting label as edge s label . iclassname is the edge s class used if different by label .
creates an edge between current vertex and a target vertex setting label as edge s label . the fields parameter is an array of fields to set on edge upon creation . fields must be a odd pairs of key / value or a single object as map containing entries as key / value pairs . iclustername is the name of the cluster where to store the new edge .
( blueprints extension ) returns the number of edges connected to the current vertex .
returns the edges connected to the current vertex . if you are interested on just counting the edges use @countedges that it s more efficient for this use case .
( blueprints extension ) returns all the edges from the current vertex to another one .
( blueprints extension ) returns the vertex s label . by default orientdb binds the blueprints label concept to vertex class . to disable this feature execute this at database level <code > alter database custom useclassforvertexlabel = false < / code >
( blueprints extension ) returns the vertex type as orientvertextype object .
used to extract the class name from the vertex s field .
determines if a field is a connections or not .
returns all the possible fields names to look for .
just read collection so import process can continue
execute the command and return the odocument object created .
returns a map of all console method and the object they can be called on .
executes the request on local node . in case of error returns the exception itself
returns the available nodes ( not offline ) and clears the node list by removing the offline nodes .
returns the nodes with the requested status .
installs a database from the network .
executes a backup of the database . during the backup the database will be frozen in read - only mode .
derived classes can override createrole () to return an extended orole implementation .
execute the alter class .
todo : create a regular jsr223 script impl
wait before to retry
returns the argument by position
checks how many parameters have been received .
connects to a remote server .
returns the list of databases on the connected remote server .
returns the server information in form of document .
creates a database in a remote server .
creates a database in a remote server .
checks if a database exists in the remote server .
drops a database from a remote server instance .
freezes the database by locking it in exclusive mode .
releases a frozen database .
gets the cluster status .
execute the create index .
returns a transactional orientgraph implementation from the current database in thread local .
parses the retry number of times
/ * resets the sequence value to it s initialized value .
update the record .
deletes the record .
osecuritycomponent
databasename may be null .
osecuritycomponent
this will authenticate username using the system database .
checks to see if a
osecurityauthenticator
catch the jvm exit and assure to shutdown the orient server .
reinitialise .
reinitialise .
reinitialise .
reinitialise .
reinitialise .
reinitialise .
method to adjust line and column numbers for the start of a token .
{
{
{
write a bucket pointer to specific location .
read bucket pointer from page .
{
starts atomic operation inside of current thread . if atomic operation has been already started current atomic operation instance will be returned . all durable components have to call this method at the beginning of any data modification operation . <p > in current implementation of atomic operation each component which is participated in atomic operation is hold under exclusive lock till atomic operation will not be completed ( committed or rolled back ) . <p > if other thread is going to read data from component it has to acquire read lock inside of atomic operation manager { @link #acquirereadlock ( odurablecomponent ) } otherwise data consistency will be compromised . <p > atomic operation may be delayed if start of atomic operations is prohibited by call of { @link #freezeatomicoperations ( class string ) } method . if mentioned above method is called then execution of current method will be stopped till call of { @link #releaseatomicoperations ( long ) } method or exception will be thrown . concrete behaviour depends on real values of parameters of { @link #freezeatomicoperations ( class string ) } method .
ends the current atomic operation on this manager .
acquires exclusive lock with the given lock name in the given atomic operation .
acquires exclusive lock in the active atomic operation running on the current thread for the {
changes amount of memory which may be used by given cache . this method may consume many resources if amount of memory provided in parameter is much less than current amount of memory .
performs following steps : <ol > <li > if flag { @link oglobalconfiguration#storage_keep_disk_cache_state } is set to <code > true< / code > saves state of all queues of 2q cache into file { @link #cache_state_file } . the only exception is pinned pages they need to pinned again . < / li > <li > closes all files and flushes all data associated to them . < / li > < / ol >
stores state of queues of 2q cache inside of { @link #cache_state_file } file if flag { @link oglobalconfiguration#storage_keep_disk_cache_state } is set to <code > true< / code > . following format is used to store queue state : <ol > <li > max cache size single item ( long ) < / li > <li > file id or - 1 if end of queue is reached ( int ) < / li > <li > page index ( long ) is absent if end of the queue is reached< / li > < / ol >
stores state of single queue to the { @link outputstream } . items are stored from least recently used to most recently used so in case of sequential read of data we will restore the same state of queue . not all queue items are stored only ones which contains pages of selected files . following format is used to store queue state : <ol > <li > file id or - 1 if end of queue is reached ( int ) < / li > <li > page index ( long ) is absent if end of the queue is reached< / li > < / ol >
initialize a server socket for communicating with the client .
initializes connection parameters by the reading xml configuration . if not specified get the parameters defined as global configuration .
start filter out all messages which are logged using {
shutdowns this log manager .
adds item to the container . item should be in open state .
removes item associated with passed in key .
acquires item associated with passed in key in container . it is guarantied that item will not be closed if limit of open items will be exceeded and container will close rarely used items .
checks if containers limit of open files is reached . <p > in such case execution of threads which add or acquire items is stopped and they wait till buffers will be emptied and nubmer of open files will be inside limit .
returns item without acquiring it . state of item is not guarantied in such case .
clears all content .
closes item related to passed in key . item will be closed if it exists and is not acquired .
read content of write buffer and adds / removes lru entries to update internal statistic . method has to be wrapped by lru lock .
read content of all read buffers and reorder elements inside of lru list to update internal statistic . method has to be wrapped by lru lock .
method is used to log operations which change content of the container . such changes should be flushed immediately to update content of lru list .
method is used to log operations which do not change lru list content but affect order of items inside of lru list . such changes may be delayed till buffer will be full .
adds entry to the read buffer with selected index and returns amount of writes to this buffer since creation of this container .
finds closest power of two for given integer value . idea is simple duplicate the most significant bit to the lowest bits for the smallest number of iterations possible and then increment result value by 1 .
{
{
return true if the push request require an unregister
re - create any object if the class has a public constructor that accepts a string as unique parameter .
serialize the class name size + class name + object content
re - create any object if the class has a public constructor that accepts a string as unique parameter .
serialize the class name size + class name + object content
assure that the requested key is converted .
converts all the items
obtain obinaryserializer realization for the otype
distributed requests against the available workers by using one queue per worker . this guarantee the sequence of the operations against the same record cluster .
add handler which will be executed during { @link #shutdown () } call .
adds shutdown handlers in order which will be used during execution of shutdown .
shutdown whole orientdb ecosystem . usually is called during jvm shutdown by jvm shutdown handler . during shutdown all handlers which were registered by the call of { @link #addshutdownhandler ( oshutdownhandler ) } are called together with pre - registered system shoutdown handlers according to their priority .
returns the engine by its name .
obtains an { @link oengine engine } instance with the given { @code enginename } if it is { @link oengine#isrunning () running } .
obtains a { @link oengine#isrunning () running } { @link oengine engine } instance with the given { @code enginename } . if engine is not running starts it .
new execution logic
old execution logic
this function should be called only from readersentry . finalize ()
creates a new readersentry instance for the current thread and its associated atomicinteger to store the state of the reader
acquires the read lock . <p > acquires the read lock if the write lock is not held by another thread and returns immediately . <p > if the write lock is held by another thread then the current thread yields until the write lock is released .
attempts to release the read lock . <p > if the current thread is the holder of this lock then the { @code reentrantreadercount } is decremented . if the { @code reentrantreadercount } is now zero then the lock is released . if the current thread is not the holder of this lock then { @link illegalmonitorstateexception } is thrown .
acquires the write lock . <p > acquires the write lock if neither the read nor write lock are held by another thread and returns immediately setting the write lock {
acquires the read lock only if the write lock is not held by another thread at the time of invocation . <p > acquires the read lock if the write lock is not held by another thread and returns immediately with the value { @code true } . <p > if the write lock is held by another thread then this method will return immediately with the value { @code false } .
acquires the read lock if the write lock is not held by another thread within the given waiting time . <p > acquires the read lock if the write lock is not held by another thread and returns immediately with the value { @code true } . <p > if the write lock is held by another thread then the current thread yields execution until one of two things happens : <ul > <li > the read lock is acquired by the current thread ; or <li > the specified waiting time elapses . < / ul > <p > if the read lock is acquired then the value { @code true } is returned .
acquires the write lock only if it is not held by another thread at the time of invocation . <p > acquires the write lock if the write lock is not held by another thread and returns immediately with the value { @code true } if and only if no other thread is attempting a read lock setting the write lock { @code writerloop } count to one . <p > if the current thread already holds this lock then the { @code reentrantwritercount } count is incremented by one and the method returns { @code true } . <p > if the write lock is held by another thread then this method will return immediately with the value { @code false } .
acquires the write lock if it is not held by another thread within the given waiting time . <p > acquires the write lock if the write lock is not held by another thread and returns immediately with the value { @code true } if and only if no other thread is attempting a read lock setting the write lock { @code reentrantwritercount } to one . if another thread is attempting a read lock this function <b > may yield until the read lock is released< / b > . <p > if the current thread already holds this lock then the { @code reentrantwritercount } is incremented by one and the method returns { @code true } . <p > if the write lock is held by another thread then the current thread yields and lies dormant until one of two things happens : <ul > <li > the write lock is acquired by the current thread ; or <li > the specified waiting time elapses < / ul > <p > if the write lock is acquired then the value { @code true } is returned and the write lock { @code reentrantwritercount } is set to one .
token must be validated before being passed to this method .
repairs the security structure if broken by creating the admin role and user with default password .
/ * executes a traverse collecting all the result in the returning list<oidentifiable > . this could be memory expensive because for large results the list could be huge . it s always better to use it as an iterable and lazy fetch each result on next () call .
invoke {
tries to acquire lock during provided interval of time and returns either if provided time interval was passed or if lock was acquired .
( blueprints extension ) returns true if the edge is labeled with any of the passed strings .
( blueprints extension ) returns the record label if any otherwise null .
( blueprints extension ) this method does not remove connection from opposite side .
returns the connected incoming or outgoing vertex .
( blueprints extension ) returns the outgoing vertex in form of record .
( blueprints extension ) returns the incoming vertex in form of record .
returns the edge s label . by default orientdb binds the blueprints label concept to edge class . to disable this feature execute this at database level <code > alter database custom useclassforedgelabel = false < / code >
returns the edge id assuring to save it if it s transient yet .
returns a property value .
returns all the property names as set of string . out in and label are not returned as properties even if are part of the underlying document because are considered internal properties .
set a property value . if the edge is lightweight it s transparently transformed into a regular edge .
removed a property .
removes the edge from the graph . connected vertices aren t removed .
( blueprints extension ) returns the underlying record if it s a regular edge otherwise it created a document with no identity with the edge properties .
( blueprints extension ) converts the lightweight edge to a regular edge creating the underlying document to store edge s properties .
( blueprints extension ) returns the class name based on graph settings .
execute the alter database .
{
{
{
execute the command .
removes all entries from bonsai tree . put all but the root page to free list for further reuse .
deletes a whole tree . puts all its pages to free list for further reusage .
creates the database ( if it does not exist ) and initializes batch operations . call this once before starting to create vertices and edges .
flushes data to db and closes the db . call this once after vertices and edges creation .
creates a new vertex
creates a new edge between two vertices . if vertices do not exist they will be created
execute the command and return the odocument object created .
delete the current vertex .
compile the filter conditions only the first time .
parses the strategy keyword if found .
{
{
{
{
returns begin position and length for each value in embedded collection
execute the insert and return the odocument object created .
checks if the link must be fixed .
todo : init default value in a java ee environment if this element is not specified the default is jta . in a java se environment if this element is not specified a default of resource_local may be assumed .
execute the remove index .
the usual password field should be a json representation .
internal only . fills in one shot the record .
internal only . changes the identity of the record .
internal only . changes the identity of the record .
internal only . sets the version .
internal only . return the record type .
opens the database .
executes the remote call on the local node and send back the result
prints the error message for a caught exception according to a level passed as argument . it s composed of : - defined error message - exception message
builds the exception stack trace and prints it according to a level passed as argument .
performs index query and returns index cursor which presents subset of index data which corresponds to result of execution of given operator .
convert the item with the received key to a record .
{
{
register all the names for the same instance .
osecuritycomponent
derived implementations can override this method to provide new server user implementations .
returns the actual username if successful null otherwise .
if not supported by the authenticator return false .
osecurityauthenticator
analyzes a query filter for a possible indexation options . the results are sorted by amount of fields . so the most specific items go first .
add sql filter field to the search candidate list .
method that detaches all fields contained in the document to the given object
method that detaches all fields contained in the document to the given object
method that attaches all data contained in the object to the associated document
* returns the list of property names to be indexed
calculates the indexed class based on the class name
returns index metadata as an odocuemnt ( as expected by index api )
first set new current value then call next
interprets this key changes using the given { @link interpretation interpretation } .
execute the command and return the odocument object created .
delete the current edge .
truncates all the clusters the class uses .
check if the current instance extends specified schema class .
check if the current instance extends specified schema class .
adds a base class to the current one . it adds also the base class cluster ids to the polymorphic cluster ids array .
add different cluster id to the polymorphic cluster ids array .
todo handle evaluate record
serialize the link .
builds a { @link sortfield } from a configuration map . the map can contains up to three fields : field ( name ) reverse ( true / false ) and type { @link sortfield . type } .
reads the input stream in memory . this is less efficient than { @link #frominputstream ( inputstream int ) } because allocation is made multiple times . if you already know the input size use { @link #frominputstream ( inputstream int ) } .
reads the input stream in memory specifying the maximum bytes to read . this is more efficient than { @link #frominputstream ( inputstream ) } because allocation is made only once .
acquires direct memory buffer with native byte order . if there is free ( already released ) direct memory page we reuse it otherwise new memory chunk is allocated from direct memory .
put buffer which is not used any more back to the pool or frees direct memory if pool is full .
checks whether there are not released buffers in the pool
clears pool and dealocates memory .
convert the byte array to an int starting from the given offset .
parse the persistence . xml files referenced by the urls in the collection
parse the persistence . xml files referenced by the urls in the collection
fist tag of persistence . xml ( <persistence > ) have to have version attribute
encodes a value using the variable - length encoding from <a href = http : // code . google . com / apis / protocolbuffers / docs / encoding . html > google protocol buffers< / a > . zig - zag is not used so input must not be negative .
@param bytes to read bytes from
@param bytes to read bytes from
auto register myself as hook .
installs a database from the network .
guarantees that each class has own master cluster .
executes an operation protected by a distributed lock ( one per database ) .
avoids to dump the same configuration twice if it s unchanged since the last time .
this method is used to find item in collection using passed in comparator . only 0 value ( requested object is found ) returned by comparator is taken into account the rest is ignored .
this method is used to find an item in an array .
this method is used to find a number in an array .
compile the filter conditions only the first time .
determine clusters that are used in select operation
handles the record in result .
returns the temporary rid counter assuring it s unique per query tree .
in case of order by + skip + limit this method applies order by operation on partial result and discards overflowing results ( results > skip + limit )
report the tip to the profiler and collect it in context to be reported by tools like studio
parses the fetchplan keyword if found .
parses the nocache keyword if found .
use index to order documents by provided fields .
extract the content of collections and / or links and put it as result
single job status
delegates the execution to the configured command executor .
( internal only ) creates a link between a vertices and a graph element .
that is internal method which is called once we encounter any error inside of jvm . in such case we need to restart jvm to avoid any data corruption . till jvm is not restarted storage will be put in read - only state .
this method finds all the records which were updated starting from ( but not including ) current lsn and write result in provided output stream . in output stream will be included all thw records which were updated / deleted / created since passed in lsn till the current moment . deleted records are written in output stream first then created / updated records . all records are sorted by record id . data format : <ol > <li > amount of records ( single entry ) - 8 bytes< / li > <li > record s cluster id - 4 bytes< / li > <li > record s cluster position - 8 bytes< / li > <li > delete flag 1 if record is deleted - 1 byte< / li > <li > record version only if record is not deleted - 4 bytes< / li > <li > record type only if record is not deleted - 1 byte< / li > <li > length of binary presentation of record only if record is not deleted - 4 bytes< / li > <li > binary presentation of the record only if record is not deleted - length of content is provided in above entity< / li > < / ol >
this method finds all the records changed in the last x transactions .
starts to gather information about storage performance for current thread . details which performance characteristics are gathered can be found at { @link osessionstorageperformancestatistic } .
completes gathering performance characteristics for current thread initiated by call of { @link #startgatheringperformancestatisticforcurrentthread () }
scan the given transaction for new record and allocate a record id for them the relative record id is inserted inside the transaction for future use .
the commit operation can be run in 3 different conditions embedded commit pre - allocated commit other node commit . <bold > embedded commit< / bold > is the basic commit where the operation is run in embedded or server side the transaction arrive with invalid rids that get allocated and committed . <bold > pre - allocated commit< / bold > is the commit that happen after an preallocaterids call is done this is usually run by the coordinator of a tx in distributed . <bold > other node commit< / bold > is the commit that happen when a node execute a transaction of another node where all the rids are already allocated in the other node .
puts the given value under the given key into this storage for the index with the given index id . validates the operation using the provided validator .
rollbacks the given micro - transaction .
method that completes the cluster rename operation . <strong > it will not rename a cluster it just changes the name in the internal mapping< / strong >
executes the command request and return the result back .
register the cluster internally .
method which is called before any data modification operation to check alarm conditions such as : <ol > <li > low disk space< / li > <li > exception during data flush in background threads< / li > <li > broken files< / li > < / ol > if one of those conditions are satisfied data modification operation is aborted and storage is switched in read only mode .
sets a property value
execute the create class .
( blueprints extension ) counts the total items found . this method is more efficient than executing the query and browse the returning iterable .
execute the sync database .
{
{
deletes the record checking the version .
{
{
{
{
{
{
{
{
{
{
{
{
{
callback the registered hooks if any .
{
deletes the record without checking the version .
{
this method is internal it can be subject to signature change or be removed do not use .
{
{
{
{
saves a document to the database . behavior depends by the current running transaction if any . if no transaction is running then changes apply immediately . if an optimistic transaction is running then the record will be changed at commit time . the current transaction will continue to see the record as modified while others not . if a pessimistic transaction is running then an exclusive lock is acquired against the record . current transaction will continue to see the record as modified while others cannot access to it since it s locked . <p > if mvcc is enabled and the version of the document is different by the version stored in the database then a { @link oconcurrentmodificationexception } exception is thrown . before to save the document it must be valid following the constraints declared in the schema if any ( can work also in schema - less mode ) . to validate the document the { @link odocument#validate () } is called .
saves a document to the database . behavior depends by the current running transaction if any . if no transaction is running then changes apply immediately . if an optimistic transaction is running then the record will be changed at commit time . the current transaction will continue to see the record as modified while others not . if a pessimistic transaction is running then an exclusive lock is acquired against the record . current transaction will continue to see the record as modified while others cannot access to it since it s locked . <p > if mvcc is enabled and the version of the document is different by the version stored in the database then a { @link oconcurrentmodificationexception } exception is thrown . before to save the document it must be valid following the constraints declared in the schema if any ( can work also in schema - less mode ) . to validate the document the { @link odocument#validate () } is called .
saves a document specifying a cluster where to store the record . behavior depends by the current running transaction if any . if no transaction is running then changes apply immediately . if an optimistic transaction is running then the record will be changed at commit time . the current transaction will continue to see the record as modified while others not . if a pessimistic transaction is running then an exclusive lock is acquired against the record . current transaction will continue to see the record as modified while others cannot access to it since it s locked . <p > if mvcc is enabled and the version of the document is different by the version stored in the database then a { @link oconcurrentmodificationexception } exception is thrown . before to save the document it must be valid following the constraints declared in the schema if any ( can work also in schema - less mode ) . to validate the document the { @link odocument#validate () } is called .
returns the number of the records of the class iclassname .
returns the number of the records of the class iclassname considering also sub classes if polymorphic is true .
activates current database instance on current thread .
registers a stateful implementations a new instance will be created for each storage .
/ * ( non - javadoc )
calculates the index within a binary chunk corresponding to the given absolute position within this blob
parses the next word . it returns the word parsed if any .
parses the next word . if no word is found or the parsed word is not present in the word array received as parameter then a syntaxerror exception with the custom message received as parameter is thrown . it returns the word parsed if any .
parses the next sequence of chars .
parses optional keywords between the iwords . if a keyword is found but doesn t match with iwords then a syntaxerror is raised .
check for a separator
/ * this method returns the path from the source to the selected target and null if no path exists
execute the drop class .
remove both backup and primary configuration files on delete
convert the item requested .
browse the stream but just return the begin of the byte array . this is used to lazy load the information only when needed .
extracts the token extract id the access token exists or returning an empty extract if there is no one on the context it may occasionally causes unauthorized response since the token extract is empty .
extract the access token within the request or try to acquire a new one by delegating it to {
try to acquire the token using a access token provider .
attempt to copy an access token from the security context into the oauth2 context .
springbean
formassignee

 1date 2date 3date
jfinalthreadlocal

 



 performtype




 

dbaccesstaskmodel
task
dbaccesstask
taskassigneeassignmenthandler
taskmodelassigneeargs string [] 
operatortaskid
resource
input - > outputcopy
input - > outputcopy
sqlsessionfactorymybatis . cfg . xml
datasourcesqlsessionfactory
postgresqllimit
id
nodeparserparse transitiontransitionmodel
datasourcedbcp
datasource

 1
resultsetmetadatacolumindex
resultsetindexrequiredtype



 [ wf_process ]

servicecontextprocessserviceorderservicetaskservice
dbaccess
idid
idid




idid
idid
ididnodename 1nodenamenull 2nodenamenull
ididmodel
idid

readersql
sqlsql
oraclerownum
 .
elementtagname

xml




joinjoinforktask
joinjoinforktask




class
class
class
executiontasks


sessionfactoryhibernate . cfg . xmlsessionfactory configuration . initaccessdbobjectsessionfactory ioc



class



processstart
process

class
class
class
put
snakerengineapi springhelper
  : base . config . xml  : ext . config . xml  : snaker . xml
resourceservicecontext



classmethodnamemethod java
job

setter name / displayname / instanceurl


decisitionexpr

resultset
beanclass
taskid - > task_id
introspectorbeaninfopropertydescriptor []
process
idprocess cacheput
nameprocess cacheput
xmlput
idxmlput
processid






xml
decisitionexpr

executionprocess



 1forkjoinsubprocess 2any
jdbcblob

hibernateconnection
cglib
 1dbtransaction 2









 

 1 . wf_order wf_hist_order 2 . wf_task wf_hist_task 3 . wf_task_actor wf_hist_task_actor 4 . wf_cc_order
isormfalsemap
isormtrueorm
 databasemetadata 
processblobprocess
processblobprocess

json
keyvalue
keyvalue
properties
checks whether no more bytes will be returned .
reads a line into the given byte array .
reads a line into the given byte - array fragment using { @linkplain #all_terminators all terminators } .
reads a line into the given byte - array fragment .
returns the length of the underlying input stream if it is { @linkplain measurablestream measurable } .
skips the given amount of bytes by repeated reads .
skips over and discards the given number of bytes of data from this fast buffered input stream .
ensures that a range given by its first ( inclusive ) and last ( exclusive ) elements fits an array of given length .
ensures that a range given by an offset and a length fits an array of given length .
transforms two consecutive sorted ranges into a single sorted range . the initial ranges are {
performs a binary search on an already - sorted range : finds the first position where an element can be inserted without violating the ordering . sorting is by a user - supplied comparison function .
performs a binary search on an already sorted range : finds the last position where an element can be inserted without violating the ordering . sorting is by a user - supplied comparison function .
sorts the specified range of elements using the specified swapper and according to the order induced by the specified comparator using mergesort .
swaps two sequences of elements using a provided swapper .
sorts the specified range of elements using the specified swapper and according to the order induced by the specified comparator using a parallel quicksort .
sorts the specified range of elements using the specified swapper and according to the order induced by the specified comparator using parallel quicksort .
avalanches the bits of an integer by applying the finalisation step of murmurhash3 .
avalanches the bits of a long integer by applying the finalisation step of murmurhash3 .
clears the content of this {
appends the content of a specified buffer to the end of the currently represented stream .
truncates the overflow file to a given size if possible .
reads bytes from this byte - array input stream as specified in {
repositions the stream .
this method acquires details of individual transitions that comprise a larger refresh . <p > details of transitions in a refresh such as count and type can be useful to understand consumer performance and to troubleshoot issues relating to refresh failure . < / p >
metrics reporting implementation is provided by the extending subclass . if exceptions are not gracefully handled in the extending subclass then an exception there can fail the consumer refresh even though metrics reporting might not be mission critical . this method protects against that scenario by catching all exceptions logging that there was an exception and continuing with the consumer refresh .
await successful completion of all previously submitted tasks . throw exception of the first failed task if 1 or more tasks failed .
starts the building of a { @link hashindex } .
finds matches for a given query .
perform a compaction . it is expected that :
find candidate types for compaction . no two types in the returned set will have a dependency relationship either directly or transitively .
query an index with a single specified field . the returned value with be the ordinal of the matching record . <p > use a generated api or the generic object api to use the returned ordinal .
query an index with four or more specified fields . the returned value with be the ordinal of the matching record . <p > use a generated api or the generic object api to use the returned ordinal .
set the byte at the given index to the specified value
cleans snapshot to keep the last n snapshots . defaults to 5 .
hash a field in an object record .
determine whether two object field records are exactly equal .
augment the given selection by adding the references and the <i > transitive< / i > references of our selection .
remove any records from the given selection which are referenced by other records not in the selection .
augment the given selection with any records outside the selection which reference ( or transitively reference ) any records in the selection .
/ * note that this method is synchronized and it is the only method that modifies the {
reports metrics for when cycle is skipped due to reasons such as the producer not being the leader in a multiple - producer setting . in a multiple producer setting leader election typically favors long - lived leaders to avoid producer runs from frequently requiring to reload the full state before publishing data . when a cycle is skipped because the producer wasn t primary the current value of no . of consecutive failures and most recent cycle success time are retained and no cycle status ( success or fail ) is reported .
reports announcement - related metrics .
on cycle completion this method reports cycle metrics .
map of string header tags reading .
adds the specified pojo to the state engine . <p > unless previously initialized with { @link #initializetypestate ( class ) } the first time an instance of a particular type is added its schema is derived and added to the data model .
warning : experimental . the flatrecord feature is subject to breaking changes .
extracts the primary key from the specified pojo .
initializes the schema for the specified type in the data model . <p > the schema will be derived from the field and type names in <code > clazz< / code > and added to the state engine s data model ; schemas of types referenced from <code > clazz< / code > will also be added . this can be used to add a type s schema to the state engine without having to add any data for that type .
clear all bits to 0 .
return a new bit set which contains all bits which are contained in this bit set and which are not contained in the <code > other< / code > bit set . <p >
return a new bit set which contains all bits which are contained in * any * of the specified bit sets .
get the segment at <code > segmentindex< / code > . if this segment does not yet exist create it .
updates the producer metrics : cycles completed version and type s footprint and ordinals .
updates the producer metrics : cycles completed version and type s footprint and ordinals .
usage : java hollowpojogenerator -- argname1 = argvalue1 -- argname2 == argvalue2 . see {
read populated ordinals as a bit set from a stream and notify a listener for each populated ordinal .
check if the given value is contained in the set ( or if the given value satisfies the predicate condition . )
estimate the total number of bits used to represent the integer set .
initialize the state engine using a snapshot blob from the provided inputstream . <p > apply the provided { @link hollowfilterconfig } to the state .
update the state engine using a delta ( or reverse delta ) blob from the provided inputstream . <p > if a { @link hollowfilterconfig } was applied at the time the { @link hollowreadstateengine } was initialized with a snapshot it will continue to be in effect after the state is updated .
returns a string representation of the provided row s field value . if usefrom is true this will use the from value from the pair otherwise this will use the to value .
set the byte at the given index to the specified value
copy bytes from another bytedata to this array .
copies exactly data . length bytes from this segmentedbytearray into the provided byte array
checks equality for a specified range of bytes in two arrays
copies the data from the provided source array into this array guaranteeing that if the update is seen by another thread then all other writes prior to this call are also visible to that thread .
copies exactly data . length bytes from this segmentedbytearray into the provided byte array guaranteeing that if the update is seen by another thread then all other writes prior to this call are also visible to that thread .
copy bytes from the supplied inputstream into this array .
write a portion of this data to an outputstream .
ensures that the segment at segmentindex exists
returns the position of a field previously added to the map or - 1 if the field has not been added to the map .
called after initial pass . returns the sum total number of select buckets in the low 7 bytes and the bits required for the max set size in the high 1 byte .
usage : java hollowapigenerator -- argname1 = argvalue1 -- argname2 == argvalue2 . see {
determines whether dataset contains any collections schema
generate files under the specified directory
generate files based on dataset schemas under the specified directory
determine whether or not the specified ordinal contains the provided primary key value .
retrieve the primary key value for the specified ordinal .
initializes the data model for the given classes . <p > data model initialization is required prior to { @link #restore ( long hollowconsumer . blobretriever ) restoring } the producer . this ensures that restoration can correctly compare the producer s current data model with the data model of the restored data state and manage any differences in those models ( such as not restoring state for any types in the restoring data model not present in the producer s current data model ) . <p > after initialization a data model initialization event will be emitted to all registered data model initialization listeners { @link com . netflix . hollow . api . producer . listener . datamodelinitializationlistener listeners } .
initializes the producer data model for the given schemas . <p > data model initialization is required prior to { @link #restore ( long hollowconsumer . blobretriever ) restoring } the producer . this ensures that restoration can correctly compare the producer s current data model with the data model of the restored data state and manage any differences in those models ( such as not restoring state for any types in the restoring data model not present in the producer s current data model ) . <p > after initialization a data model initialization event will be emitted to all registered data model initialization listeners { @link com . netflix . hollow . api . producer . listener . datamodelinitializationlistener listeners } .
restores the data state to a desired version . <p > data model { @link #initializedatamodel ( class [] ) initialization } is required prior to restoring the producer . this ensures that restoration can correctly compare the producer s current data model with the data model of the restored data state and manage any differences in those models ( such as not restoring state for any types in the restoring data model not present in the producer s current data model )
invoke this method to alter runcycle behavior . if this producer is not primary runcycle is a no - op . note that by default singleproducerenforcer is instantiated as basicsingleproducerenforcer which is initialized to return true for isprimary ()
/ * publish the write state storing the artifacts in the provided object . visible for testing .
given these read states <p > * s ( cur ) at the currently announced version * s ( pnd ) at the pending version <p > ensure that : <p > s ( cur ) . apply ( forwarddelta ) . checksum == s ( pnd ) . checksum s ( pnd ) . apply ( reversedelta ) . checksum == s ( cur ) . checksum
add a { @link hollowtypestatelistener } to a type .
creates an object - based field path given a data set and the field path in symbolic form conforming to paths associated with a primary key .
creates a field path given a data set and the field path in symbolic form conforming to paths associated with a hash index .
creates a field path given a data set and the field path in symbolic form conforming to paths associated with a prefix index .
creates a field path given a data set and the field path in symbolic form .
associating the obj with an ordinal
returns an update plan that if executed will update the client to a version that is either equal to or as close to but less than the desired version as possible . this plan normally contains one snapshot transition and zero or more delta transitions but if no previous versions were found then an empty plan { @code hollowupdateplan . do_nothing } is returned .
includes the next delta only if it will not take us * after * the desired version
initialize field positions and field paths .
return the key to index in prefix index . override this method to support tokens for the key . by default keys are indexed as lower case characters . <pre > { @code string [] keys = super . getkey ( ordinal ) ; string [] tokens = keys [ 0 ] . split ( ) return tokens ; } < / pre >
query the index to find all the ordinals that match the given prefix . example - <pre > { @code hollowordinaliterator iterator = index . findkeyswithprefix ( a ) ; int ordinal = iterator . next () ; while ( ordinal ! = hollowordinaliterator . no_more_ordinal ) { // print the result using api } } < / pre > <p > for larger data sets querying smaller prefixes will be longer than querying for prefixes that are longer .
check if the given key exists in the index .
protected for tests
add a type plus recursively add any directly or transitively referenced types .
add a type plus recursively add any directly or transitively referenced types .
add an individual field from an object schema . this field will be either excluded or included depending on whether this is an exclude or include filter respectively .
add an individual field from an object schema plus recursively add any directly or transitively referenced types . this field will be either excluded or included depending on whether this is an exclude or include filter respectively .
add an individual field from an object schema plus recursively add any directly or transitively referenced types . this field will be either excluded or included depending on whether this is an exclude or include filter respectively .
parse a hollowfilterconfig from the specified string . the string should contain multiple lines . the first line should be either exclude or include . subsequent lines should be one of the following : <ul > <li > &lt ; typename&gt ; < / li > <li > &lt ; typename&gt ; . &lt ; fieldname&gt ; < / li > < / ul >
add a {
dependency types come before dependent types
make it easier to automatically use defaults for next major version
set the byte at the given index to the specified value
get the value of the byte at the specified index .
match any records which include a field with the provided fieldname and value .
match any records of the specified type which have the specified field set to the specified value .
set the paths for which we will inspect differences across the two states
optionally specify paths for which we will match records within an individual type s hierarchy
calculate the differences
should be called exclusively from the { @link hollowdiff } -- not intended for external consumption
this should be called exclusively from the {
comparison is based on the totaldiffscore () .
triggers a refresh to the latest version specified by the {
triggers async refresh after the specified number of milliseconds has passed . <p > any subsequent calls for async refresh will not begin until after the specified delay has completed .
if a { @link hollowconsumer . announcementwatcher } is not specified then this method will attempt to update to the specified version and if the specified version does not exist then to a different version as specified by functionality in the { @code blobretriever } . <p > otherwise an unsupportedoperationexception will be thrown . <p > this is a blocking call .
equivalent to calling { @link #getapi () } and casting to the specified api .
populate the provided { @link hollowreadstateengine } with the dataset currently in the provided { @link hollowwritestateengine }
populate the provided { @link hollowreadstateengine } with the dataset currently in the provided { @link hollowwritestateengine } . <p > apply the provided { @link hollowfilterconfig } .
update the provided { @link hollowreadstateengine } with the new state currently available in the { @link hollowwritestateengine } . <p > it is assumed that the readengine is currently populated with the prior state from the writeengine .
create a { @link hollowdataaccess } for the prior state of the supplied { @link hollowreadstateengine } after a delta has been applied .
create a { @link hollowdataaccess } for a { @link hollowhistory } . remap ordinal spaces for all prior historical versions in the { @link hollowhistory } for consistency .
create a { @link hollowdataaccess } for a historical state after a double snapshot occurs without a { @link hollowhistory } .
initializes the data model and restores from existing state .
runs a hollow cycle if successful cleans the mutations map .
parallel execution . modifies the mutation concurrenthashmap in parallel based on a callback . <p > note : this could be replaced with java 8 parallelstream and lambadas instead of callback interface < / p >
exclude the record which matches the specified key .
exclude any objects which are referenced by excluded objects .
write the header to the data output stream
warning : not thread - safe . should only be called within the update thread .
calculates the memory heap footprint and populated ordinals per type and total
when provided a set of { @link primarykey } will ensure that no duplicate records are added to the destination state .
perform the combine operation .
concatenates all fields in order to the bytedatabuffer supplied . this concatenation is the verbatim serialized representation in the fastblob .
returns the buffer which should be used to serialize the data for the field at the given position in the schema . <p >
write 4 consecutive bytes
write 8 consecutive bytes
returns a stream of matching ordinals . <p > the ordinals may be used with a generated api or the generic object api to inspect the matched records .
return an ordinal to the pool after the object to which it was assigned is discarded .
ensure that all future ordinals are returned in ascending order .
hash a key
hash a single key field
this method adds an element at nodeindex . note that this does not check for duplicates ; if the element already exists another instance of it will be added . this method is not thread - safe - you cannot call this method concurrently with itself or with { @link #getelements } .
return a list of elements at the specified node index . the returned list may contain duplicates . this method not thread - safe - the caller must ensure that no one calls { @link #addelement } concurrently with this method but calling this method concurrently with itself is safe .
resize the underlying storage to a multiple of what it currently is . this method is not thread - safe .
/ todo : many parse failures can cause out of memory errors .
adds a sequence of bytes to this map . if the sequence of bytes has previously been added to this map then its assigned ordinal is returned . if the sequence of bytes has not been added to this map then a new ordinal is assigned and returned . <p > this operation is thread - safe .
/ acquire the lock before writing .
if the preferredordinal has not already been used mark it and use it . otherwise delegate to the freeordinaltracker .
create an array mapping the ordinals to pointers so that they can be easily looked up when writing to blob streams .
reclaim space in the byte array used in the previous cycle but not referenced in this cycle . <p > <p > this is achieved by shifting all used byte sequences down in the byte array then updating the key array to reflect the new pointers and exclude the removed entries . this is also where ordinals which are unused are returned to the pool . <p >
compare the byte sequence contained in the supplied bytedatabuffer with the sequence contained in the map pointed to by the specified key byte by byte .
resize the ordinal map by increasing its capacity . <p > no action is take if the current capacity is sufficient for the given size . <p > warning : this operation is not thread - safe .
grow the key array . all of the values in the current array must be re - hashed and added to the new array .
get the hash code for the byte array pointed to by the specified key .
create an atomiclongarray of the specified size each value in the array will be empty_bucket_value
this method assumes the other traverser has the same match fields specified in the same order .
warning : not thread - safe . should only be called within the update thread .
finds the unique object an instance of the unique type for a given key .
starts the building of a { @link uniquekeyindex } .
swap underlying state engines between current and pending while keeping the versions consistent ; used after delta integrity checks have altered the underlying state engines .
parse a collection of { @link hollowschema } s from the provided reader .
parse a single { @link hollowschema } from the provided string .
calculates the type name from a given type . <p > if the type is annotated with { @link hollowtypename } then the type name is the value of the { @code hollowtypename . name } attribute . otherwise the type name is derived from the type itself . if the type is a { @code class } then the type name is the simple name of that class . if the type is a parameterized type and is assignable to a class of { @code list } { @code set } or { @code map } then the type name begins with the simple class name of the parameterized type s raw type followed by of followed by the result of calling this method with the associated parameterized types ( in order in - fixed by to ) . otherwise the type name is the simple class name of the parameterized type s raw type . <p > the translation from type to type name is lossy since the simple class name of a class is used . this means that no two types from different packages but with the same simple name can be utilized .
determine size of hash table capable of storing the specified number of elements with a load factor applied .
restores the data state to a desired version . <p > data model { @link #initializedatamodel ( class [] ) initialization } is required prior to restoring the producer . this ensures that restoration can correctly compare the producer s current data model with the data model of the restored data state and manage any differences in those models ( such as not restoring state for any types in the restoring data model not present in the producer s current data model )
run a compaction cycle will produce a data state with exactly the same data as currently but reorganized so that ordinal holes are filled . this may need to be run multiple times to arrive at an optimal state .
write the current state as a snapshot blob .
serialize the changes necessary to transition a consumer from the previous state to the current state as a delta blob .
adds the schema name to the set if the schema name doesn t correspond to a hollow primitive type . factored out to prevent bloat in the switch statement it is called from .
create a new state version . <p >
registers { @code duplicatedatadetectionvalidator } validators with the given { @link hollowproducer producer } for all object schema declared with a primary key . <p > this requires that the producer s data model has been initialized ( see { @link hollowproducer#initializedatamodel ( class [] ) } or a prior run cycle has implicitly initialized the data model . <p > for each { @link hollowtypewritestate write state } that has a { @link hollowobjectschema object schema } declared with a { @link primarykey primary key } a { @code duplicatedatadetectionvalidator } validator is instantiated with the primary key type name and registered with the given producer ( if a { @code duplicatedatadetectionvalidator } validator is not already registered for the same primary key type name ) .
rules : prepend get / is + upper case first char of field name
convert field path into param name
recreate the hash index entirely
query the index .
triggers async refresh after some random number of milliseconds have passed between now and the specified maximum number of milliseconds .
triggers async refresh after the specified number of milliseconds has passed .
add a type to be included in the diff report
run the diff
call this method after each time a delta occurs in the backing { @link hollowreadstateengine } . this is how the hollowhistory knows how to create a new { @link hollowhistoricalstate } .
call this method after each time a double snapshot occurs . <p > this method will replace the previous backing { @link hollowreadstateengine } with the newly supplied one stitch together all of the existing history with the new state currently in the new { @link hollowreadstateengine } and create a new { @link hollowhistoricalstate } to represent the transition .
removes the last { @code n } historical states .
encode the specified long as a variable length integer into the supplied { @link bytedatabuffer }
encode the specified long as a variable length integer into the supplied ouputstream
encode the specified int as a variable length integer into the supplied { @link bytedatabuffer }
encode the specified int as a variable length integer into the supplied outputstream
write the value as a varint into the array starting at the specified position .
read a variable length integer from the supplied {
read a variable length integer from the supplied inputstream
read a variable length long from the supplied {
determine the size ( in bytes ) of the variable length long in the supplied {
read a variable length long from the supplied inputstream .
determine the size ( in bytes ) of the specified value when encoded as a variable length integer .
count the number of variable length integers encoded in the supplied {
called when the activity is first created .
used internally for adding view . need because we override addview to pass - through to the refreshable view
used internally for {
called when the ui has been to be updated to be in the { @link state#refreshing } or { @link state#manual_refreshing } state .
called when the ui has been to be updated to be in the {
re - measure the loading views height and adjust internal padding as necessary
helper method which just calls scrollto () in the correct scrolling direction .
updates the view state when the mode has been set . this does not do any checking that the mode is different to current state so always updates .
actions a pull event
called when the activity is first created .
called when the activity is first created .
called when the activity is first created .
called when the activity is first created .
called when the activity is first created .
called when the activity is first created .
helper method for overscrolling that encapsulates all of the necessary function . <p / > this should only be used on adapterview s such as listview as it just calls through to overscrollby () with the scrollrange = 0 . adapterview s do not have a scroll range ( i . e . getscrolly () doesn t work ) .
helper method for overscrolling that encapsulates all of the necessary function . this is the advanced version of the call .
called when the activity is first created .
sets the empty view to be used by the adapter view . <p / > we need it handle it ourselves so that we can pull - to - refresh when the empty view is shown . <p / > please note you do <strong > not< / strong > usually need to call this method yourself . calling setemptyview on the adapterview will automatically call this method and set everything up . this includes when the android framework automatically sets the empty view based on it s id .
specifies the condition for the rule .
invokes the current rule s action and then moves down the chain to the successor if the rulestate of the current rule is next or the action ( s ) was not executed .
the method getone () gets the value of the single fact in the factmap .
the method getvalue () returns the value of the fact associated with the name passed in .
method getstrval () gets the string value of a fact in the factmap .
method getintval () gets the integer value of a fact in the factmap .
method getdblval () gets the double value of a fact in the factmap .
the method setvalue sets the value of the fact by its name . <br / > if no fact exists with the associated name a new fact is created with the specified name and value . <br / >
this put () method is a convenience method for adding a fact to a factmap . <br / > it uses the name of the fact as the key and the fact as the value .
adds a fact to the rule .
adds one or more facts into the rule .
adds a using constraint in the rule that restricts the facts supplied to the subsequent then action .
returns a new rulebuilder for the specified rule class .
returns a new rulebuilder for the default rule type .
specifies the fact type for the rule being built .
specifies the result type for the rule being built .
adds a fact to the rule using a name value pair to specify a new fact .
adds one or more facts to the rule .
specifies the condition for the rule .
adds a using constraint in the rule that restricts the facts supplied to the subsequent then action .
adds an action as a consumer to the rule .
convert the facts to properties with the
returns a rule instance
the run () method adds the rules [ via definerules () ] and runs the rules as long as at least one rule was added .
the given () method accepts the facts for this rulebook . the facts passed in will also be applied to all rules added to this rulebook .
the given () method accepts a key / value pair as a fact for this rulebook .
the addrule () method adds a rule to the end of the rules chain .
method getannotatedfields gets the fields annotated of a specific type from the class and its parent classes . <br / > the list is in order of closest parent = > current obj fields parent obj fields etc .
method getannotatedfield gets the first annotated field of the type of annotation specified .
method getannotatedmethods gets the methods annotated of a specific type from the class and its parent classes . <br / > the list is in order of closest parent = > current obj methods parent obj methods etc .
method getannotatedmethod the first annotated method of the type of annotation specified .
method getannotation returns the annotation on a class or its parent annotation .
this create () method is a convenience method to avoid using new and generic syntax .
the given () method accepts a name / value pair to be used as a fact .
the given () method accepts facts for the standarddecision .
the given () method accepts facts for the standarddecision .
the when () method accepts a {
the then () method accepts a {
the then () method accepts a {
the using () method reduces the facts to those specifically named here . the using () method only applies to the then () method immediately following it .
registers a rule to be audited .
updates the status of the rule & stores the status with the auditor .
gets a map of each rule name with its associated status .
specifies the result type for the rulebook .
adds a rule to the rulebook .
adds a rule to the rulebook .
the run ( object [] ) method runs the {
the given () method accepts a name / value pair to be used as a fact .
the given () method accepts facts to be evaluated in the rule .
the when () method accepts a {
the then () method accepts a { @link consumer } that performs an action based on facts .
the using () method reduces the facts to those specifically named here . the using () method only applies to the then () method immediately following it .
the addrule () method allows a rule to be added to the decisionbook in the abstract definerules method .
adds a then action into the rule .
addds a then action into the rule .
specifies the default result value . note : rulebooks that return a single result must have a default result value set .
resets the value of the result to its default value .
the method getvalue () returns the object contained in the result object .
the method setvalue () sets the object to be contained in the result object .
adds a rule to the rulebook .
adds a rule to the rulebook .
specifies the fact type
gets the pojo rules to be used by the rulebook via reflection of the specified package .
the combine () static method combines the contents of two arrays into a single array of the same type .
the combine () static method combines the contents of two arrays into a single array of the same type that contains no more than the maxelements number of elements .
reads empty line or throw an exception if a none empty line was found .
moves buffer until it finds the first content column ( skipping headers ) .
===========================================================
=======================================================================================================
convert list to array never returns null .
....................................................................................
port handling
examine images for build configuration and extract all ports
config can override ports
parse config specified ports
null ports can happen for ignored mappings
remove first element of list or null if list is empty
-------------------------
merge services of same name with the default service
save the images stream to a file
returns the url to access the service ; using the environment variables routes or service clusterip address
returns true if the given serviceport matches the intorstring value
returns the named port for the given service name or blank
returns the service host and port for the given environment variable name .
adds the given key and value pair into the map if the map does not already contain a value for that key
add all values of a map to another map but onlfy if not already existing .
returns a new map with all the entries of map1 and any from map2 which don t override map1 .
copies all of the elements i . e . the mappings from toput map into ret if toput isn t null .
============================================================================================================
============================================================================================================
configured
a simple utility function to watch over pod until it gets ready
== utility methods ==========================
=================
validates that the given value is valid according to the kubernetes id parsing rules throwing an exception if not .
loads the kubernetes json and converts it to a list of entities
returns the resource version for the entity or null if it does not have one
creates an intorstring from the given string which could be a number or a name
creates an intorstring from the given string which could be a number or a name
returns true if the pod is running and ready
returns the current context in the given config
returns true if we already have a route created for the given name
replaces all text of the form <code > $ { foo } < / code > with the value in the properties object
==========================================================================================================
forwards a port to the newest pod matching the given selector . if another pod is created it forwards connections to the new pod once it s ready .
====================================================
returns true if the maven project has a dependency with the given groupid and artifactid ( if not null )
returns the version associated to the dependency dependency with the given groupid and artifactid ( if present )
returns the plugin with the given groupid ( if present ) and artifactid .
returns true if any of the given resources could be found on the given class loader
returns the version from the list of pre - configured versions of common groupid / artifact pairs
returns true if this cluster is a traditional openshift cluster with the <code > / oapi< / code > rest api or supports the new <code > / apis / image . openshift . io< / code > api group
read all kubernetes resource fragments from a directory and create a { @link kuberneteslistbuilder } which can be adapted later .
read a kubernetes resource fragment and add meta information extracted from the filename to the resource descriptor . i . e . the following elements are added if not provided in the fragment :
read fragment and add default values
===============================================================================================
convert a map of env vars to a list of k8s envvar objects .
uses reflection to copy over default values from the defaultvalues object to the targetvalues object similar to the following :
merges the given resources together into a single resource .
returns a merge of the given maps and then removes any resulting empty string values ( which is the way to remove say a label or annotation when overriding
we could also use an annotation?
reads the configuration from the file .
flattens a nested map into a map<string string > .
converts a {
adds a port to the list .
========================================================================================
method used in mojo
gets plugin configuration values . since there can be inner values it returns a map of objects where an object can be a simple type list or another map .
gets configuration values . since there can be inner values it returns a map of objects where an object can be a simple type list or another map .
download with showing the progress a given url and store it in a file
find a free ( on localhost ) random port in the specified range after the given number of attempts .
compares two version strings such that 1 . 10 . 1 > 1 . 4 etc
find a profile . profiles are looked up at various locations :
find an enricher or generator config possibly via a profile and merge it with a given configuration .
lookup profiles from a given directory and merge it with a profile of the same name found in the classpath
read all default profiles first then merge in custom profiles found on the classpath
read all profiles found in the classpath .
check for various variations of profile files
prepend meta - inf location
load a profile from an input stream . this must be in yaml format
find all classes below a certain directory which contain main () classes
=================================
this method overrides the imagepullpolicy value by the value provided in xml config .
returns true if we are in openshift s2i binary building mode
this method just makes sure that the replica count provided in xml config overrides the default option ; and resource fragments are always given topmost priority .
returns the first child element for the given name
================================================================================================
applies the given dtos onto the kubernetes master
applies the given dtos onto the kubernetes master
creates / updates the template and processes it returning the processed dtos
installs the template into the namespace without processing it
creates / updates a service account and processes it returning the processed dtos
removes all the tags with the given name
returns true if the namespace is created
creates and return a project in openshift
returns true if the projectrequest is created
returns the namespace defined in the entity or the configured namespace
logs an error applying some json to kubernetes and optionally throws an exception
====================================================================================
=============================================================================
this method will create a default namespace or project if a namespace property is specified in the xml resourceconfig or as a parameter to a mojo .
this method will annotate all the items in the kuberneteslistbuilder with the created new namespace or project .
transforms the dom object into a map . this map can contain pairs key / value where value can be a simple type another map ( inner objects ) and a list of simple types .
hook for adding extra environment vars
parses a duration string anr returns its value in seconds .
parses a duration string anr returns its value in nanoseconds .
scan the project s output directory for certain files .
should we try to create an external url for the given service? <p / > by default lets ignore the kubernetes services and any service which does not expose ports 80 and 443
lets disable openshift - only features if we are not running on openshift
returns true if there is an existing ingress rule for the given service
returns the root project folder
returns the root project folder
customization hook called by the base plugin .
this method reads properties file to load custom mapping between kinds and filenames .
customization hook called by the base plugin .
get generator context
get generator config
get enricher context
get enricher config
====================================================================================================
lets use the project and its classpath to try figure out what default icon to use
copies any local configuration files into the app directory
to use embedded icons provided by the fabric8 - console
returns the spring boot configuration ( supports application . properties and application . yml ) or an empty properties object if not found
returns the given properties resource on the project classpath if found or an empty properties object if not
determine the spring - boot major version for the current project
create a list of services ordered according to the ordering given in the service descriptor files . note that the descriptor will be looked up in the whole classpath space which can result in reading in multiple descriptors with a single path . note that the reading order for multiple resources with the same name is not defined .
allow enricher to add metadata to the resources .
=============================================================================================
returns the thorntail configuration ( supports project - defaults . yml ) or an empty properties object if not found
get the raw untyped configuration or an empty map
get a config value with a default . if no value is given as a last resort project properties are looked up .
/ * add exception rules to ignore validation constraint from json schema for openshift / kubernetes resources . some fields in json schema which are marked as required but in reality it s not required to provide values for those fields while creating the resources . e . g . in deploymentconfig ( https : // docs . openshift . com / container - platform / 3 . 6 / rest_api / openshift_v1 . html#v1 - deploymentconfig ) model status field is marked as required .
validates the resource descriptors as per json schema . if any resource is invalid it throws @ { @link constraintviolationexception } with all violated constraints
build a flattened representation of the yaml tree . the conversion is compliant with the thorntail spring - boot rules .
artifactid is used for setting a resource name ( service pod ... ) in kubernetes resource . the problem is that a kubernetes resource name must start by a char . this method returns a valid string to be used as kubernetes name .
get watcher config
returns the template if the list contains a single template only otherwise returns null
==================================================================================
get a reference date
this method detects if the user has changed the configuration of an entity . <p / > it compares the <b > user< / b > configuration of 2 object trees ignoring any runtime status or timestamp information .
compares 2 instances of the given kubernetes dto class to see if the user has changed their configuration . <p / > this method will ignore properties {
=============================================================================================
get a config value with a default
get a config value with a default . if no value is given as a last resort project properties are looked up .
return full configuration as raw string - string values
order elements according to the order provided by the include statements . if no includes has been configured return the given list unaltered . otherwise arrange the elements from the list in to the include order and return a new list .
merge in another processor configuration with a lower priority . i . e . the latter a config is in the argument list the less priority it has . this means :
only good for small list ( that s what we expect for enrichers and generators )
add the base image either from configuration or from a given selector
use istag as default for redhat versions of this plugin
get image name with a standard default
get the docker registry where the image should be located . it returns null in openshift mode .
returns the absolute path to a resource addressed by the given <code > url< / code >
returns true if in offline mode false if not speciied . can be overriden by
returns the external access to the given service name
creates an iterable to walk the exception from the bottom up ( the last caused by going upwards to the root exception ) .
check a global prop from the project or system props
- default
create jest client with uri
create internal elasticsearch node .
list all official es plugins available on classpath .
extract the distance string from a { @link org . springframework . data . geo . distance } object .
add mapping for @field annotation
add mapping for @multifield annotation
parse a { @link graphqlconfiguration } from json .
gets a client metadata id at the time of payment activity . once a user initiates a paypal payment from their device paypal uses the client metadata id to verify that the payment is originating from a valid user - consented device and application . this helps reduce fraud and decrease declines . this method must be called prior to initiating a pre - consented payment ( a future payment ) from a mobile device . pass the result to your server to include in the payment request sent to paypal . do not otherwise cache or store this value .
gets a client metadata id at the time of payment activity . once a user initiates a paypal payment from their device paypal uses the client metadata id to verify that the payment is originating from a valid user - consented device and application . this helps reduce fraud and decrease declines . this method must be called prior to initiating a pre - consented payment ( a future payment ) from a mobile device . pass the result to your server to include in the payment request sent to paypal . do not otherwise cache or store this value .
used to parse a response from the braintree gateway to be used for american express rewards balance .
convert an api response to an { @link venmoaccountnonce } .
fetches the capabilities of a card . if the card needs to be enrolled use { @link unionpay#enroll ( braintreefragment unionpaycardbuilder ) } . <p / > on completion returns the { @link unionpaycapabilities } to { @link com . braintreepayments . api . interfaces . unionpaylistener#oncapabilitiesfetched ( unionpaycapabilities ) } <p / > on error an exception will be passed back to { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) }
enrolls a union pay card . only call this method if the card needs to be enrolled . check { @link unionpay#fetchcapabilities ( braintreefragment string ) } if your card needs to be enrolled . <p / > on completion returns a enrollmentid to { @link com . braintreepayments . api . interfaces . unionpaylistener#onsmscodesent ( string boolean ) } this enrollmentid needs to be applied to { @link unionpaycardbuilder } along with the sms code collected from the merchant before invoking { @link unionpay#tokenize ( braintreefragment unionpaycardbuilder ) } <p / > on error an exception will be passed back to { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) }
create a { @link com . braintreepayments . api . models . cardnonce } . note that if the card is a unionpay card { @link unionpaycardbuilder#enrollmentid ( string ) } and { @link unionpaycardbuilder#smscode ( string ) } need to be set for tokenization to succeed . <p / > on completion returns the { @link com . braintreepayments . api . models . paymentmethodnonce } to { @link com . braintreepayments . api . interfaces . paymentmethodnoncecreatedlistener } . <p / > if creation fails validation { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } will be called with the resulting { @link com . braintreepayments . api . exceptions . errorwithresponse } . <p / > if an error not due to validation ( server error network issue etc . ) occurs { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } will be called with the { @link exception } that occurred .
convert an api response to a { @link localpaymentresult } .
generates a { @link localpaymentresult } from the { @link jsonobject } .
launches an { @link intent } pointing to the venmo app on the google play store
start the pay with venmo flow . this will app switch to the venmo app . <p / > if the venmo app is not available { @link appswitchnotavailableexception } will be sent to { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } .
parse a { @link cardconfiguration } from json .
gets the rewards balance associated with a braintree nonce . only for american express cards .
create a paypalpaymentresource from a jsonstring . checks for keys associated with single payment and billing agreement flows .
make a http get request to braintree using the base url path and authorization provided . if the path is a full url it will be used instead of the previously provided url .
make a http post request to braintree using the base url path and authorization provided . if the path is a full url it will be used instead of the previously provided url .
makes a synchronous http post request to braintree using the base url path and authorization provided . @see braintreehttpclient#post ( string string httpresponsecallback )
parses the venmo configuration from json .
used to parse a response from the braintree gateway to be used for 3d secure .
collect device information for fraud identification purposes .
collect device information for fraud identification purposes . this should be used in conjunction with a non - aggregate fraud id .
collect paypal device information for fraud identification purposes .
collect device information for fraud identification purposes from paypal only .
check if an app has the correct matching signature . used to prevent malicious apps from impersonating other apps .
retrieves the current list of { @link paymentmethodnonce } s for the current customer . <p / > when finished the { @link java . util . list } of { @link paymentmethodnonce } s will be sent to { @link paymentmethodnoncesupdatedlistener#onpaymentmethodnoncesupdated ( list ) } .
deletes a payment method owned by the customer whose id was used to generate the { @link clienttoken } used to create the { @link braintreefragment } . <p / > note : this method only works with android lollipop ( > = 21 ) and above . this will invoke { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } when <ul > <li > a { @link com . braintreepayments . api . models . tokenizationkey } is used . < / li > <li > the device is below lollipop . < / li > <li > if the request fails . < / li > <ul / >
get a { @link pendingrequest } containing an { @link intent } used to start a paypal authentication request using the best possible authentication mechanism : wallet or browser .
gets a { @link result } from an { @link intent } returned by either the paypal wallet app or the browser .
gets a client metadata id at the time of payment activity . once a user initiates a paypal payment from their device paypal uses the client metadata id to verify that the payment is originating from a valid user - consented device and application . this helps reduce fraud and decrease declines . this method must be called prior to initiating a pre - consented payment ( a future payment ) from a mobile device . pass the result to your server to include in the payment request sent to paypal . do not otherwise cache or store this value .
verification is associated with a transaction amount and your merchant account . to specify a different merchant account ( or in turn currency ) you will need to specify the merchant account id when <a href = https : // developers . braintreepayments . com / android / sdk / overview / generate - client - token > generating a client token< / a >
verification is associated with a transaction amount and your merchant account . to specify a different merchant account ( or in turn currency ) you will need to specify the merchant account id when <a href = https : // developers . braintreepayments . com / android / sdk / overview / generate - client - token > generating a client token< / a >
verification is associated with a transaction amount and your merchant account . to specify a different merchant account ( or in turn currency ) you will need to specify the merchant account id when <a href = https : // developers . braintreepayments . com / android / sdk / overview / generate - client - token > generating a client token< / a >
parse a { @link kountconfiguration } from json .
create a { @link com . braintreepayments . api . models . cardnonce } . <p / > on completion returns the { @link com . braintreepayments . api . models . paymentmethodnonce } to { @link com . braintreepayments . api . interfaces . paymentmethodnoncecreatedlistener } . <p / > if creation fails validation { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } will be called with the resulting { @link com . braintreepayments . api . exceptions . errorwithresponse } . <p / > if an error not due to validation ( server error network issue etc . ) occurs { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } will be called with the { @link exception } that occurred .
returns the value mapped by name if it exists coercing it if necessary or fallback if no such mapping exists .
parses a response from the braintree gateway for a list of payment method nonces .
parses a { @link paymentmethodnonce } from json .
parses a { @link paymentmethodnonce } from json .
1 . look for exact match of environment . ( could be mock live or a particular host : port . ) 2 . if environment is anything other than mock or live then look for develop . 3 . look for live . ( there should always be a live endpoint specified in any v3 browser - switch recipe . )
defines the host to be used in the cancellation url for browser switch ( the package name will be used as the scheme )
defines the host to be used in the success url for browser switch ( the package name will be used as the scheme )
returns the browser recipe that can handle checkout or null if there is none .
returns the browser recipe that can handle billing agreement or null if there is none .
convert an api response to a { @link cardnonce } .
populate properties with values from a { @link jsonobject } .
parse an { @link analyticsconfiguration } from json .
create a { @link paymentmethodnonce } in the braintree gateway . <p / > on completion returns the { @link paymentmethodnonce } to { @link paymentmethodnoncecallback } . <p / > if creation fails validation { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } will be called with the resulting { @link errorwithresponse } . <p / > if an error not due to validation ( server error network issue etc . ) occurs { @link com . braintreepayments . api . interfaces . braintreeerrorlistener#onerror ( exception ) } ( throwable ) } will be called with the { @link exception } that occurred .
make a http get request to using the base url and path provided . if the path is a full url it will be used instead of the previously provided base url .
make a http post request using the base url and path provided . if the path is a full url it will be used instead of the previously provided url .
performs a synchronous post request .
convert an api response to a { @link visacheckoutnonce } .
prepares the payment flow for a specific type of local payment .
initiates the browser switch for a payment flow by opening a browser where the customer can authenticate with their bank .
returns an { @link authorization } of the correct type for a given { @link string } .
method to extract an error for an individual field e . g . creditcard customer etc .
convert an api response to a { @link paypalaccountnonce } .
generates a { @link paypalaccountnonce } from the { @link jsonobject } .
create a new instance of { @link braintreefragment } using the client token and add it to the { @link appcompatactivity } s { @link fragmentmanager } .
adds a listener .
removes a previously added listener .
obtain an instance of a { @link googleapiclient } that is connected or connecting to be used for android pay . this instance will be automatically disconnected in { @link braintreefragment#onstop () } and automatically connected in { @link braintreefragment#onresume () } . <p / > connection failed and connection suspended errors will be sent to { @link braintreeerrorlistener#onerror ( exception ) } .
parse an { @link googlepaymentconfiguration } from json .
starts the billing agreement flow for paypal with custom paypal approval handler .
create a paypalpaymentresource on behalf of the merchant . to be used in the paypal checkout flows for single payment and billing agreement .
the result from paypal s request .
parse the paypal response url using onetouchcore .
used to parse a response from the braintree gateway to be used for 3d secure .
parse an { @link paypalconfiguration } from json .
add user - defined words to the noun dictionary . spaced words are ignored .
remove user - defined word list from the dictionary for the specified koreanpos .
transforms the tokenization output to list<koreantokenjava >
tokenize with the builder options into a string iterable .
extract phrases from korean input text
detokenize the input list of words .
returns an unmodifiable { @link chararrayset } . this allows to provide unmodifiable views of internal sets for read - only use .
reads size amount of bytes from ch into a new bytebuffer allocated from a buffer buf
/ * [ 0 .. 1 ]
/ * [ 0 .. 1 ]
finds next nth h . 264 bitstream nal unit ( 0x00000001 ) and returns the data that preceeds it as a bytebuffer slice
finds next nth h . 264 bitstream nal unit ( 0x00000001 ) and returns the data that preceeds it as a bytebuffer slice
encodes avc frame in iso bmf format . takes annex b format .
encodes avc frame in iso bmf format . takes annex b format .
decodes avc packet in iso bmf format into annex b format .
decodes avc packet in iso bmf format into annex b format .
wipes avc parameter sets ( sps / pps ) from the packet
wipes avc parameter sets ( sps / pps ) from the packet ( inplace operation )
creates a mp4 sample entry given avc / h . 264 codec private .
creates a mp4 sample entry given avc / h . 264 codec private .
joins buffers containing individual nal units into a single annexb delimited buffer . each nal unit will be separated with 00 00 00 01 markers . allocates a new byte buffer and writes data into it .
joins buffers containing individual nal units into a single annexb delimited buffer . each nal unit will be separated with 00 00 00 01 markers .
get block of ( possibly interpolated ) luma pixels
fullpel ( 0 0 ) unsafe
halfpel ( 2 0 ) horizontal int argument version
halfpel ( 2 0 ) horizontal unsafe
hpel ( 0 2 ) vertical unsafe
qpel : ( 1 0 ) horizontal
qpel vertical ( 0 3 )
hpel horizontal qpel vertical ( 2 1 )
hpel horizontal hpel vertical ( 2 2 )
hpel ( 2 2 ) unsafe
qpel ( 2 3 ) unsafe
qpel horizontal hpel vertical ( 1 2 )
qpel ( 1 2 ) unsafe
qpel ( 1 1 ) unsafe
qpel horizontal qpel vertical ( 1 3 )
qpel horizontal qpel vertical ( 3 1 )
qpel ( 3 1 ) unsafe
chroma ( 0 0 )
chroma ( x 0 )
chroma ( x 0 )
chroma ( x x )
decode an array of 4 bit element ids optionally interleaved with a stereo / mono switching bit .
returns a profile instance for the given index . if the index is not between 1 and 23 inclusive unknown is returned .
converts floating point taps to fixed precision taps .
wrong usage of javascript keyword : in
/ * parameter is also called k0
/ * parameter is also called k2
/ * calculate the master frequency table from k0 k2 bs_freq_scale and bs_alter_scale
/ * this function finds the number of bands using this formula : bands * log ( a1 / a0 ) / log ( 2 . 0 ) + 0 . 5
/ * version for bs_freq_scale > 0
/ * calculate the derived frequency border tables from f_master
reads one full segment till the next marker . will read as much data as the provided buffer fits if the provided buffer doesn t fit all data will return more_data .
reads one full segment till the next marker . will allocate the necessary buffer to hold the full segment . internally uses a growing collection of smaller buffers since the segment size is intitially unkwnown .
there is a method in the class ( or one of its parents ) having the same name with the method named [ readtree ] but is less generic
finds maximum frame of a sequence by bisecting the range .
pass 2 : process rows from work array store into output array .
/ * allocate and fill in the sample_range_limit table
tries to modify movie header in place according to what s implemented in the edit the file gets pysically modified if the operation is successful . no temporary file is created .
tries to modify movie header in place according to what s implemented in the edit . copies modified contents to a new file .
/ * calculate linear prediction coefficients using the covariance method
/ * fixed point : bwarray = coef
/ * ========== decoding ==========
calculates track duration considering edits
finds timevalue of a frame number
finds frame by timevalue
converts media timevalue to edited timevalue
converts edited timevalue to media timevalue
calculates frame number as it shows in quicktime player
calculates and formats standard time as in quicktime player
calculates and formats tape timecode as in quicktime player
calculates and formats tape timecode as in quicktime player
converts timevalue to frame number based on timecode track
formats tape timecode based on frame counter
creates packed 4bit list with 7 values in it
sets a 4 bit value into the list
determines if two colors match . aside from simply comparing the objects this function also takes into account lables any any_interleaved any planar .
calculates the component size based on the fullt size and color subsampling of the given component index .
get frame at current position in jcodec native image
get frame at current position in jcodec native image
get frame at a specified second as jcodec image
get frame at a specified second as jcodec image
get frame at a specified frame number as jcodec image
get frame at a specified frame number as jcodec image
get a specified frame by number from an already open demuxer track
get a specified frame by second from an already open demuxer track
get a specified frame by number from an already open demuxer track ( sloppy mode i . e . nearest keyframe )
get a specified frame by second from an already open demuxer track ( sloppy mode i . e . nearest keyframe )
does not modify packets
only for ltp : no overlapping no short blocks
/ * ( non - javadoc )
reads the next four bytes .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
creates a cropped clone of this picture .
6 * 16 * 2 + 10 * 8 + 4 * 16 * 2 = 192 + 80 + 128 = 400 additions
/ * size 64 only!
creates wav header for the specified audio format
takes single channel wavs as input produces multi channel wav
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
wrong usage of javascript keyword : in
reads one mpeg1 / 2 video frame from mpeg1 / 2 elementary stream into a provided buffer .
reads one mpeg1 / 2 video frame from mpeg1 / 2 elementary stream .
parses the input arrays as a decoderspecificinfo as used in mp4 containers .
encodes one symbol either 0 or 1
static int i = 0 ;
}
splits track on the timevalue specified
decodes one frame of aac data in frame mode and returns the raw pcm data .
sets the endianness for the data .
deblocks bottom edge of topoutmb right edge of leftoutmb and left / top and inner block edges of outmb
deblocks p - macroblock
encodes a frame into a movie .
encodes unsigned integer with given length
this method is used mostly during reading ebml bitstream . it asnwers the question what is the length of an integer ( signed / unsigned ) encountered in the bitstream
this method is used mostly during writing ebml bitstream . it answers the following question how many bytes should be used to encode unsigned integer value
wrong usage of javascript keyword : in
wrong usage of javascript keyword : in
wrong usage of javascript keyword : in
/ * table 2
/ * table 3
/ * table 4
/ * table 5
/ * table 6
/ * table 7
/ * table 8
/ * table 9
/ * table 12
/ * table 10
/ * table 11
parses pat ( program association table )
add a packet to the underlying file
reads an ebml id from the channel . ebml ids have length encoded inside of them for instance all one - byte ids have first byte set to 1 like 0xa3 or 0xe7 whereas the two - byte ids have first byte set to 0 and second byte set to 1 thus : 0x42 0x86 or 0x42 0xf7
searching for the next tag in a file after corrupt segment
/ * furthermore we scale the results by 2pass1_bits .
perform the inverse dct on one block of coefficients .
decodes one bin from arithmetice code word
special decoding process for symbols with uniform distribution
finds next nth mpeg bitstream marker 0x000001xx and returns the data that preceeds it as a bytebuffer slice
/ * first build into temp vector to be able to use previous vector on error
/ * real filter size 2
/ * complex filter size 4
/ * complex filter size 8
/ * complex filter size 12
/ * read huffman data coded in either the frequency or the time direction
/ * binary search huffman decoding
/ * limits the value i to the range [ min max ]
/ * delta decode array
/ * in : log2 value of the modulo value to allow using and instead of mod
/ * parse the bitstream data decoded in ps_data ()
/ * decorrelate the mono signal using an allpass filter
/ * main parametric stereo decoding function
returns a sample frequency instance for the given index . if the index is not between 0 and 11 inclusive sample_frequency_none is returned .
this may be a result of color greening out in long gops .
creates a cropped clone of this picture .
sectiondataresilience = hdecoder - > aacsectiondataresilienceflag
starts dct reconstruction
recalculates image based on new dct coefficient
finalizes dct calculation
constructs this decoder from a portion of a stream that contains annexb delimited ( 00 00 00 01 ) sps / pps nal units . sps / pps nal units are 0x67 and 0x68 respectfully .
todo : this may be optimized of - course if it turns out to be a frequently called method
merge bits of a to b
32 bit rewind and reverse
64 bit rewind and reverse
/ * ========= decoding ==========
}
get frame at a specified second as awt image
get frame at a specified second as awt image
get frame at current position in awt image
get frame at current position in awt image
get frame at current position in awt image
get frame at a specified frame number as awt image
get frame at a specified frame number as awt image
get a specified frame by number from an already open demuxer track
get a specified frame by second from an already open demuxer track
get a specified frame by number from an already open demuxer track ( sloppy mode i . e . nearest keyframe )
get a specified frame by second from an already open demuxer track ( sloppy mode i . e . nearest keyframe )
seeks to a previous key frame prior or on the given frame if the track is not seekable returns 0 .
returns a pixel buffer of a suitable size to hold the given video frame . the video size is taken either from the video metadata or by analyzing the incoming video packet .
wrong usage of javascript keyword : in
wrong usage of javascript keyword : in
gain compensation and overlap - add : - the gain control function is calculated - the gain control function applies to imdct output samples as a another imdct window - the reconstructed time domain signal produces by overlap - add
produces gain control function data stores it in function array
/ * calculates a fragment modification function by interpolating the gain values of the gain change positions
transformes the exponent value of the gain to the id of the gain change point
calculates a fragment modification function the interpolated gain value between the gain values of two gain change positions is calculated by the formula : f ( a b j ) = 2^ ((( 8 - j ) log2 ( a ) + j * log2 ( b )) / 8 )
generic byte - array to integer - array conversion
generic integer - array to byte - array conversion
converts pcm samples stored in buf and described with format to float array representation
converts float pcm samples stored in floatbuf to integer representation according to format and stores them in buf
interleaves audio samples in ins into outb using sample size from the format
deinterleaves audio samples from inb into outs using sample size from format
retrieves coded size of this video track .
a dispersed map . every odd line starts from the ( n / 2 ) th group
a boxout macroblock to slice group mapping . only applicable when there s exactly 2 slice groups . slice group 1 is a background while slice group 0 is a box in the middle of the frame .
a macroblock to slice group map that fills frame column by column
utility method to read a batch of uls
utility method to read a batch of int32
get frame at a specified second as awt image
get frame at a specified second as awt image
get frame at current position in awt image
get frame at a specified frame number as awt image
get frame at a specified frame number as awt image
get a specified frame by number from an already open demuxer track
get a specified frame by second from an already open demuxer track
get a specified frame by number from an already open demuxer track ( sloppy mode i . e . nearest keyframe )
get a specified frame by second from an already open demuxer track ( sloppy mode i . e . nearest keyframe )
used to auto - detect mpeg audio ( mp3 ) files
calculates median prediction
encodes dct / wht coefficients into the provided instance of a boolean encoder
wrong usage of javascript keyword : in
wrong usage of javascript keyword : in
encode this picture into h . 264 frame . frame type will be selected by encoder .
encode this picture as an idr frame . idr frame starts a new independently decodeable video sequence
encode this picture as a p - frame . p - frame is an frame predicted from one or more of the previosly decoded frame and is usually 10x less in size then the idr frame .
returns the name of the numbered property . <br > <br >
returns the name of the named property . <br > <br >
sets a property on this object . <br > <br > all avoptions supported by the underlying avclass are supported . <br > <br >
looks up the property name and sets the<br > value of the property to value . <br > <br >
gets the value of this property and returns as an rational ; <br > <br >
sets all properties in valuestoset on this configurable object . <br > <br >
returns a list of all codecs supported for this object .
returns a list of all codec tags supported for this container .
get the codec . id for the n th codec supported by this container . <br > <br >
get the number of ferry objects we believe are still in use . <p > this may be different than what you think because the java garbage collector may not have collected all objects yet . < / p > <p > also this method needs to walk the entire ferry reference heap so it can be expensive and not accurate ( as the value may change even before this method returns ) . use only for debugging . < / p >
dump the contents of our memory cache to the log . <p > this method requires a global lock in order to run so only use for debugging . < / p >
add a reference to the set of references we ll collect .
the actual gc ;
starts a new ferry collection thread that will wake up whenever a memory reference needs clean - up from native code . <p > this thread is not started by default as ferry calls {
internal only .
internal only . allocate a new block of bytes . called from native code . <p > will retry many times if it can t get memory backing off in timeouts to get there . < / p > <p > callers must eventually call {
adds a picture to this source . note : if you add a picture to a filtersource<br > be careful with re - using or rewriting the underlying data . filters will<br > try hard to avoid copying data so if you change the data out from under<br > them unexpected results can occur . <br >
load the given library into the given application .
looks for a url in a classpath and if found unpacks it
finds all . humble temp files in the temp directory and nukes them .
return default channel layout for a given number of channels .
get the index of a channel in channel_layout . <br > <br > <p > <br > use this method to find out which index into channel data corresponds<br > to the channel you care about . the way you use this differs depending<br > on whether your audio is packed or planar . to illustrate let s assume<br > you have ch_layout_stereo audio and you ask for the index of ch_front_left <br > and we return 1 ( indexes are zero based ) . <br > < / p > <p > <br > if packed then audio is laid out in one big buffer as rlrlrlrlrlrlrlrl audio <br > and every 2nd ( 1 + 1 ) sample is the left channel<br > < / p > <p > <br > if planar then audio is out in two buffer as rrrrrrrr and llllllll and the<br > second plan ( 1 + 1 ) is the left channel . <br > < / p > <br > <br >
get the channel with the given index in channel_layout .
return the pixel format corresponding to name . <br > <br > if there is no pixel format with name name then looks for a<br > pixel format with the name corresponding to the native endian<br > format of name . <br > for example in a little - endian system first looks for gray16 <br > then for gray16le . <br > <br > finally if no pixel format has been found returns av_pix_fmt_none .
returns the i th pixel format descriptor that is known to humble video<br > <br >
utility function to swap the endianness of a pixel format . <br > <br > pix_fmt the pixel format<br > <br >
find the buffer size that would be necessary to store an image<br > with the given qualities .
create a new packet
allocate a new packet that wraps an existing buffer . <br > <br > note : at least 16 bytes of the passed in buffer will be used<br > for header information so the resulting packet . getsize () <br > will be smaller than buffer . getbuffersize () . <br > <br >
allocate a new packet wrapping the existing contents of<br > a passed in packet . callers can then modify<br > #getpts () <br > #getdts () and other get / set methods without<br > modifying the original packet . <br > <br >
allocate a new packet . <br > <p > <br > note that any buffers this packet needs will be<br > lazily allocated ( i . e . we won t actually grab all<br > the memory until we need it ) . <br > < / p > <br >
get any underlying raw data available for this packet . <br > <br >
get the n th item of sidedata . <br > <p > <br > warning : callers must ensure that the the packet object<br > this is called form is not reset or destroyed while using this buffer <br > as unfortunately we cannot ensure this buffer survives the<br > underlying packet data . <br > < / p > <br > <br >
get the n th item of sidedata . <br > <br >
find a given filter by name . <br > <br >
{
{
{ @inheritdoc }
{
{
parameters that describe how pixels are packed . <br > if the format has 2 or 4 components then alpha is last . <br > if the format has 1 or 2 components then luma is 0 . <br > if the format has 3 or 4 components <br > if the rgb flag is set then 0 is red 1 is green and 2 is blue ; <br > otherwise 0 is luma 1 is chroma - u and 2 is chroma - v .
prints the version of this library to system . out along with some information on what this jar is .
the default timebase used by media if not otherwise specified .
if this iproperty is of the type type#property_flags this method will<br > give you another iproperty representing a constant setting for that flag . <br > <br >
if this iproperty is of the type type#property_flags this method will<br > give you another iproperty representing a constant setting for that flag . <br > <br >
create a new demuxer
get the demuxerformat associated with this demuxer<br > or null if unknown .
open this container and make it ready for reading optionally<br > reading as far into the container as necessary to find all streams . <br > <p > the caller must call #close () when done but if not the<br > demuxer will eventually close<br > them later but warn to the logging system . <br > <br >
close the container . open () must have been called first or<br > else an error is returned . <br > <p > <br > if this method exits because of an interruption <br > all resources will be closed anyway . <br > < / p >
get the stream at the given position . <br > <br >
reads the next packet in the demuxer into the packet . this method will<br > release any buffers currently held by this packet and allocate<br > new ones . <br > <p > <br > for non - blocking io data sources it is possible for this method<br > to return as successful but with no complete packet . in that case<br > the caller should retry again later ( think eagain ) semantics . <br > < / p > <br > <br >
attempts to read all the meta data in this stream potentially by reading ahead<br > and decoding packets . <br > <p > <br > any packets this method reads ahead will be cached and correctly returned when you<br > read packets but this method can be non - blocking potentially until end of container<br > to get all meta data . take care when you call it . <br > < / p > <p > after this method is called other meta data methods like #getduration () should<br > work . < / p >
set the flag . <br > <br >
get the keyvaluebag of media metadata for this object <br > or null if none . <br > <p > <br > if the demuxer or istream object<br > that this keyvaluebag came from was opened<br > for reading then changes via keyvaluebag#setvalue ( string string ) <br > will have no effect on the underlying media . <br > < / p > <br > <p > <br > if the demuxer or istream object<br > that this keyvaluebag came from was opened<br > for writing then changes via keyvaluebag#setvalue ( string string ) <br > will have no effect after demuxer#writeheader () <br > is called . <br > < / p > <br >
seek to timestamp ts . <br > <br > seeking will be done so that the point from which all active streams<br > can be presented successfully will be closest to ts and within min / max_ts . <br > active streams are all streams that have stream . getdiscardsetting &lt ; <br > codec . discard_all . <br > <br > if flags contain seekflags . seek_byte then all timestamps are in bytes and<br > are the file position ( this may not be supported by all demuxers ) . <br > if flags contain seekflags . seek_frame then all timestamps are in frames<br > in the stream with stream_index ( this may not be supported by all demuxers ) . <br > otherwise all timestamps are in units of the stream selected by stream_index<br > or if stream_index is - 1 in ( 1 / global . default_pts_microseconds } units . <br > if flags contain seekflags . seek_any then non - keyframes are treated as<br > keyframes ( this may not be supported by all demuxers ) . <br > <br >
start playing a network source . call #pause () to pause .
pause a playing network source . call #play () to unpause . <br > <br >
creates a new irational object by copying ( by value ) this object . <br > <br >
compare a rational to this rational<br >
compare two rationals<br >
reduce a fraction to it s lowest common denominators . <br > this is useful for framerate calculations . <br >
reduce a fraction to it s lowest common denominators . <br > this is useful for framerate calculations . <br >
multiplies this number by arg<br >
multiples a by b . <br >
divides this rational by arg . <br >
divides a by b . <br >
subtracts arg from this rational<br >
subtracts a from b . <br >
adds arg to this rational<br >
adds a to b . <br >
takes a value scaled in increments of origbase and gives the<br > equivalent value scaled in terms of this rational . <br > <br >
takes a value scaled in increments of origbase and gives the<br > equivalent value scaled in terms of this rational . <br > <br >
get a new rational that will be set to 0 / 1 . <br > the rational will not have #init () called<br > and hence will be modifiable by #setvalue ( double ) <br > until #init () is called . <br >
converts a double precision floating point number to a rational . <br >
creates deep copy of a rational from another rational . <br > <br >
create a rational from a numerator and denominator . <br > <br > we will always reduce this to the lowest num / den pair<br > we can but never having den exceed what was passed in . <br > <br >
takes a value scaled in increments of origbase and gives the<br > equivalent value scaled in terms of this rational . <br > <br >
takes a value scaled in increments of origbase and gives the<br > equivalent value scaled in terms of this rational . <br > <br >
rescales a long value to another long value . <br > <p > <br > this method doesn t use irational values but<br > instead uses numerators and denominators<br > passed in by the caller . it will not result<br > in any memory allocations . <br > < / p > <br > <br >
opens a file and plays the video from it on a screen at the right rate .
takes the video picture and displays it at the right time .
gets a collection of all codecs installed on this system .
create a converter .
create a converter .
create a encoder that will use the given codec . <br > <br >
creates a encoder from a given encoder<br >
open this coder using the given bag of codec - specific options . <br > <br >
encode the given mediapicture using this encoder . <br > <br > the mediapicture will allocate a buffer to use internally for this and<br > will free it when the frame destroys itself . <br > <br > also when done in order to flush the encoder caller should call<br > this method passing in 0 ( null ) for frame to tell the encoder<br > to flush any data it was keeping a hold of . <br > <br >
encode the given mediaaudio using this encoder . <br > <br > callers should call this repeatedly on a set of samples until<br > we consume all the samples . <br > <br > also when done in order to flush the encoder caller should call<br > this method passing in 0 ( null ) for samples to tell the encoder<br > to flush any data it was keeping a hold of . <br > <br >
encode the given media using this encoder . <br > <br > callers should call this repeatedly on a media object ntil<br > we consume all the media . <br > <br > also when done in order to flush the encoder caller should call<br > this method passing in 0 ( null ) for media to tell the encoder<br > to flush any data it was keeping a hold of . <br > <br >
{
{
get the descriptor for the given id .
print out all configurable options on the { @link configurable } object .
print information about the property on the configurable object .
configures an {
configures an {
set the time base that time stamps of this object are represented in . <br > <br >
find a descriptor given a { @link bufferedimage } .
create a converter which translates betewen { @link bufferedimage } and { @link mediapicture } types . the { @link io . humble . video . pixelformat . type } and size are extracted from the passed in picture . this factory will attempt to create a converter which can perform the translation . if no converter can be created a descriptive { @link unsupportedoperationexception } is thrown .
create a converter which translates between { @link bufferedimage } and { @link mediapicture } . this factory will attempt to create a converter which can perform the translation . if no converter can be created a descriptive { @link unsupportedoperationexception } is thrown .
create a converter which translates between { @link bufferedimage } and { @link mediapicture } types . the { @link bufferedimage } type and size are extracted from the passed in image . this factory will attempt to create a converter which can perform the translation . if no converter can be created a descriptive { @link unsupportedoperationexception } is thrown .
create a converter which translates between { @link bufferedimage } and { @link mediapicture } types . this factory will attempt to create a converter which can perform the translation . if no converter can be created a descriptive { @link unsupportedoperationexception } is thrown .
create a converter which translates betewen { @link bufferedimage } and { @link mediapicture } types . this factory will attempt to create a converter which can perform the translation . if different image and pictures sizes are passed the converter will resize during translation . if no converter can be created a descriptive { @link unsupportedoperationexception } is thrown .
convert a { @link bufferedimage } of any type to { @link bufferedimage } of a specified type . if the source image is the same type as the target type then original image is returned otherwise new image of the correct type is created and the content of the source image is copied into the new image .
checks the current parachute and recreates ( reloads ) our payload if needed .
{
{
{
{
register a new protocol name for this factory that humble . io will use for the given protocol .
generates a unique name suitable for using in the map methods for the url parameter .
maps a { @link iurlprotocolhandler } to a url that humble can open .
maps a { @link datainput } object to a url for use by humble .
maps a { @link datainput } object to a url for use by humble .
maps a { @link dataoutput } object to a url for use by humble .
maps a { @link dataoutput } object to a url for use by humble .
maps a { @link randomaccessfile } object to a url for use by humble .
maps a { @link randomaccessfile } object to a url for use by humble .
maps a { @link readablebytechannel } to a url for use by humble .
maps a { @link readablebytechannel } to a url for use by humble .
maps a { @link writablebytechannel } to a url for use by humble .
maps a { @link writablebytechannel } to a url for use by humble .
maps a { @link bytechannel } to a url for use by humble .
maps a { @link bytechannel } to a url for use by humble .
maps an { @link inputstream } to a url for use by humble .
maps an { @link inputstream } to a url for use by humble .
maps an { @link outputstream } to a url for use by humble .
maps an { @link outputstream } to a url for use by humble .
maps a { @link datainput } or { @link dataoutput } object to a url for use by humble .
maps an { @link readablebytechannel } or { @link writablebytechannel } to a url for use by humble .
maps an { @link inputstream } or { @link outputstream } to a url for use by humble .
maps a { @link iurlprotocolhandler } to a url that humble can open .
maps the given url or file name to the given { @link iurlprotocolhandler } or so that humble calls to open the url it will call back to the handler .
unmaps a registration between a url and the underlying i / o objects . <p > if url contains a protocol it is ignored when trying to find the matching io stream . < / p >
{
returns a new logger object for this loggername . <br > <br >
get a logger object but ask the logger code to<br > free it up once the javavm shuts down . use at your<br > own risk . <br > <br >
log the message to the logger using sprintf () format<br > strings . <br > <br >
create a new mediaaudioresampler .
convert audio . <br > <br > in can be set to null to flush the last few samples out at the<br > end . <br > <br > if more input is provided than output space then the input will be buffered . <br > you can avoid this buffering by providing more output space than input . <br > conversion will run directly without copying whenever possible . <br > <br >
get the timebase used when outputting time stamps for audio . <br > <br > defaults to 1 / ( the lowest common multiple of getinputsamplerate () <br > and getoutputsamplerate () ) in order to ensure that no rounding<br > of time stamps occur . <br > <br > for example if the input sample rate is 22050 and the output sample<br > rate is 44100 then the output time base will be ( 1 / 44100 ) . but if the<br > input sample rate is 48000 and the output sample rate is 22050 then<br > the output time base will be ( 1 / lcm ( 48000 22050 )) which will be 1 / 7056000<br > ( trust me ) . this is done so that timestamp values do not get rounded ( and<br > therefore introduce drift ) .
set the timebase to use for timestamps on output audio . <br > <br >
get an ordered sequence of index entries in this { @link stream } .
get the ( sometimes estimated ) average frame rate of this container . <br > for variable frame - rate containers ( they do exist ) this is just<br > an approximation . better to use gettimebase () . <br > <br > for contant frame - rate containers this will be 1 / ( gettimebase () ) <br > <br >
the time base in which all timestamps ( e . g . presentation time stamp ( pts ) <br > and decompression time stamp ( dts )) are represented . for example<br > if the time base is 1 / 1000 then the difference between a pts of 1 and<br > a pts of 2 is 1 millisecond . if the timebase is 1 / 1 then the difference<br > between a pts of 1 and a pts of 2 is 1 second . <br > <br >
gets the sample aspect ratio . <br > <br >
get the underlying container for this stream or null if humble video<br > doesn t know . <br > <br >
get the keyvaluebag for this object <br > or null if none . <br > <p > <br > if the container or stream object<br > that this keyvaluebag came from was opened<br > for reading then changes via keyvaluebag#setvalue ( string string ) <br > will have no effect on the underlying media . <br > < / p > <br > <p > <br > if the container or stream object<br > that this keyvaluebag came from was opened<br > for writing then changes via keyvaluebag#setvalue ( string string ) <br > will have no effect after container#writeheader () <br > is called . <br > < / p > <br >
search for the given time stamp in the key - frame index for this stream . <br > <p > <br > not all containerformat implementations<br > maintain key frame indexes but if they have one <br > then this method searches in the stream index<br > to quickly find the byte - offset of the nearest key - frame to<br > the given time stamp . <br > < / p > <br >
get the indexentry at the given position in this<br > stream object s index . <br > <p > <br > not all containerformat types maintain<br > stream indexes but if they do <br > this method can return those entries . <br > < / p > <br > <p > <br > do not modify the container this stream<br > is from between calls to this method and<br > #getnumindexentries () as indexes may<br > be compacted while processing . <br > < / p > <br >
for containers with stream . disposition . disposition_attached_pic <br > this returns a read - only copy of the packet containing the<br > picture ( needs to be decoded separately ) .
gets a collection of all codecs installed on this system .
returns a list of supported frame - rates this codec can encode video to .
returns a list of supported pixel formats this codec can encode video in .
returns a list of supported audio sample rates this codec can encode audio in .
returns a list of supported audio sample formats this codec can encode audio in .
returns a list of supported audio channel layouts this codec can encode audio in .
find a codec that can be used for encoding . <br >
find a codec that can be used for encoding . <br >
find a codec that can be used for encoding . <br >
find a codec that can be used for decoding . <br >
find a codec that can be used for decoding . <br >
find a codec that can be used for decoding . <br >
ask us to guess an encoding codec based on the inputs<br > passed in . <br > <p > <br > you must pass in at least one non null fmt shortname <br > url or mime_type . <br > < / p > <br >
get the icodec at the given index . <br > <br >
return the supported frame rate at the given index . <br > <br >
return the supported video pixel format at the given index . <br > <br >
get the supported sample format at this index . <br > <br >
get the supported audio channel layout at this index . <br > <br > the value returned is a bit flag representing the different<br > types of audio layout this codec can support . test the values<br > by bit - comparing them to the audiochannel . layout<br > enum types . <br > <br >
get the supported codecprofile at this index . <br > <br >
resample in to out based on the resampler parameters . <br > <br > resamples the in picture based on the parameters set when<br > this resampler was constructed . <br > <br >
a more precisely typed way to call #resample
get a new picture resampler . <br > <br >
{
{
{
get the set of keys currently in this {
get the value for the given key . <br > <br >
sets the value for the given key to value . this overrides<br > any prior setting for key or adds key to the meta - data<br > if appropriate . <br > <br >
create a new keyvaluebag bag of properties with<br > no values set .
sets the value for the given key to value . this overrides<br > any prior setting for key or adds key to the meta - data<br > if appropriate . <br > <br >
open this coder using the given bag of codec - specific options . <br > <br >
the codec this streamcoder will use . <br > <br >
get the time base this stream will encode in or the time base we<br > detect while decoding . <br > <br >
set the time base we ll use to encode with . a no - op when decoding . <br > <br > as a convenience we forward this call to the stream#settimebase () <br > method . <br > <br >
set a flag to true or false .
set a flag2 to true or false .
get the decoder that can decode the information in this demuxer stream .
get the demuxer this demuxerstream belongs to .
return a collection of all output formats installed on this system .
return the sink format in the list of registered sink formats<br > which best matches the provided parameters or return null if<br > there is no match . <br > <br >
get the codec . id for the n th codec supported by this container . <br > <br >
return an object for the input format at the given index . <br > <br >
creates a new filtergraph .
add a filter with the given name to the graph . <br >
add a filteraudiosource . <br >
add a filterpicturesource . <br >
add a filteraudiosink . <br >
add a filterpicturesink . <br >
queue a command for one or more filter instances . <br > <br >
create a new indexentry with the specified<br > values . <br > <br >
create a filter given the name . <br > <br >
create a filter given the type . <br > <br >
get the type of this filter .
filter the input buffer into the output buffer . <br > <br >
filters a packet in place ( i . e . the prior contents will be replaced<br > with the filtered data ) . <br > <br > this method assumes packet . getcoder () is the coder that is being used<br > for outputting the packet to a stream . if this is not the case use<br > the other filter mechanism and construct packets yourself . <br > <br >
absolute bulk put method . <p > this method transfers bytes into this buffer from the given source array . if there are more bytes to be copied from the array than there is space remaining at the specified destination offset then no bytes are transferred and a java . nio . bufferoverflowexception is thrown . < / p > <p > this method is equivalent to calling { @link #getbytebuffer ( int int ) } yourself and copying the bytes over but is more efficient in the { @link jnimemorymanager . memorymodel#native_buffers } memory model . < / p >
returns up to length bytes starting at offset in the underlying buffer we re managing .
returns up to length bytes starting at offset in the underlying buffer we re managing and also passed back a { @link jnireference } that can optionally be used by the caller to free the underlying native memory .
allocate a new buffer of at least buffersize . <br > <br >
allocate a new buffer of at least buffersize . <br > <br >
allocate a new buffer and copy the data in buffer into<br > the new buffer object . <br > <br >
create a new buffer object that uses the direct byte buffer<br > passed in by reference ( i . e . it directly uses the bytes in<br > the direct byte buffer ) . <br > <br >
get a connection to the speaker if available .
play the given bytes ( in {
re - sample a picture .
test that the passed image is valid and conforms to the converters specifications .
test that the passed picture is valid and conforms to the converters specifications .
{
{
get the filtergraph this filterlink belongs to .
define the time base used by the pts of the frames / samples<br > which will pass through this link . <br > during the configuration stage each filter is supposed to<br > change only the output timebase while the timebase of the<br > input link is assumed to be an unchangeable property . <br > <br >
insert a filter into this link between the current input and output . <br >
get the time base that time stamps of this object are represented in . <br > <br >
get any meta - data associated with this media item
sets the timebase on this object . <br > <br > note : this will not automatically rescale the timestamp set -- so if you change<br > the timebase you almost definitely want to change the timestamp as well .
register a new factory for iurlprotocolhandlers for a given protocol . <p > ffmpeg is very picky ; protocols must be only alpha characters ( no numbers ) . < / p >
/ * get a iurlprotocolhandler for this url . <p > important : this function is called from native code and so the name and signature cannot change without changing the native code . < / p > <p > this function is eventually invoked whenever someone tries to call url_open ( yourprotocol : ... flags ) from ffmpeg native code . it returns a protocol handler which will then have open ( ... ) called on it . < / p > @param url the url we want to handle . @param flags any flags that the url_open () function will want to pass .
get the resource portion of a url . for example for the url <pre > http : // www . humble . io / video < / pre > the protocol string is <code > http< / code > and the resource string is <code > www . humble . io / video< / code >
get the protocol portion of a url . for example for the url <pre > http : // www . humble . io / video < / pre > the protocol string is <code > http< / code > and the resource string is <code > // www . humble . io / video< / code >
get the cpu architecture based on the passed in javacpuarch specifier .
return a cpuarch from parsing a gnu autoconf triple .
get the osfamily based on the passed in osname specifier .
return an os family from parsing a gnu autoconf triple .
get a string representation of the time stamp for this { @link media } . the format of the resulting string is specified by the format parameter . see { @link java . util . formatter } for details on how to specify formats however a good place to start is with the following format : <b > %1$th : %1$tm : %1$ts . %1$tl< / b >
get the time base that time stamps of this object are represented in . <br > <br > caller must release the returned value . <br > <br >
opens a file and plays the audio from it on the speakers .
takes a media container ( file ) as the first argument opens it opens up the default audio device on your system and plays back the audio .
releases any underlying native memory and marks this object as invalid . <p > normally ferry manages when to release native memory . < / p > <p > in the unlikely event you want to control exactly when a native object is released each humble object has a {
@deprecated use { @link jnilibrary } instead .
this is the method that actually loads the library . it maintains an object level lock and since this class only allows a singleton object that is a class - level lock . that means if you re loading a library on one thread other threads will block until it finishes .
tell the cache that we ve loaded this version .
iterates through the set of alibcandidates until it succeeds in loading a library . if it succeeds it lets the cache know .
for a given library and the os we re running on this method generates a list of potential absolute file paths that { @link #loadcandidatelibrary ( string long string [] ) } should attempt ( in order ) to load . this method will not check for existence and readability of the file we re attempting to load .
initialize the paths we ll search for libraries in .
checks our cache to see if we ve already loaded this library .
create a decoder that will use the given codec . <br > <br >
creates a decoder from a given coder ( either an encoder or a decoder ) . <br >
decode this packet into output . it will<br > try to fill up the audio samples object starting<br > from the byteoffset inside this packet . <br > <p > <br > the caller is responsible for allocating the<br > mediaaudio object . this function will overwrite<br > any data in the samples object . <br > < / p > <br >
decode this packet into output . <br > <br > the caller is responsible for allocating the<br > mediapicture object . this function will potentially<br > overwrite any data in the frame object but<br > you should pass the same mediapicture into this function<br > repeatedly until media . iscomplete () is true . <br > <p > <br > note on memory for mediapicture : for a multitude of reasons <br > if you created mediapicture from a buffer decodevideo will discard<br > it and replace it with a buffer that is aligned correctly for different<br > cpus and different codecs . if you must have a copy of the image data<br > in memory managed by you then pass in a mediapicture allocated without<br > a buffer to decodevideo and then copy that into your own media picture . <br > < / p > <br > <br >
decode this packet into output . it will<br > try to fill up the media object starting<br > from the byteoffset inside this packet . <br > <p > <br > the caller is responsible for allocating the<br > correct underlying media object . this function will overwrite<br > any data in the samples object . <br > < / p > <br >
records the screen
explicitly deletes the underlying native storage used by the object this object references . the underlying native object is now no long valid and attempts to use it could cause unspecified behavior .
adds audio to this source . note : if you had audio to a filtersource<br > be careful with re - using or rewriting the underlying data . filters will<br > try hard to avoid copying data so if you change the data out from under<br > them unexpected results can occur . <br >
resample in to out based on the resampler parameters . <br > <br > resamples the in media based on the parameters set when<br > this resampler was constructed . <br > <br >
return a sample format corresponding to name or sample_fmt_none<br > on error .
return the planar&lt ; - &gt ; packed alternative form of the given sample format or<br > sample_fmt_none on error . if the passed sample_fmt is already in the<br > requested planar / packed format the format returned is the same as the<br > input .
get the packed alternative form of the given sample format . <br > <br > if the passed sample_fmt is already in packed format the format returned is<br > the same as the input . <br > <br >
get the planar alternative form of the given sample format . <br > <br > if the passed sample_fmt is already in planar format the format returned is<br > the same as the input . <br > <br >
get the size of a buffer in bytes that would be required to hold the<br > number of samples of audio in the given format and with the given number of channels .
get the size of a plane of audio bytes that would be required to hold the<br > number of samples of audio in the given format and with the given number of channels . <br > <p > <br > if format is packed then this method returns the same number as #getbuffersizeneeded ( int int type ) . <br > < / p >
creates a new muxer . <br > <br > one of the three passed in parameter must be non - null . if the muxer requires a url to write to <br > then that must be specified . <br > <br >
get the muxerformat associated with this muxer<br > or null if unknown .
open the muxer and write any headers . <br > <br >
adds a new stream that will have packets written to it . <br > <br > note on thread safety : callers must ensure that the coder is not encoding or decoding<br > packets at the same time that muxer#open or muxer#close is being called . <br > <br >
get the muxerstream at the given position .
writes the given packet to the muxer . <br > <br >
jnihelper . swg : end generated code
get the codecid for the n th codec supported by this container . <br > <br >
find demuxerformat based on the short name of the input format . <br >
return an object for the demuxerformats at the given index . <br > <br >
the number of streams in this container . <br > <p > if this container is a source this will query the stream and find out<br > how many streams are in it . < / p > <p > if the current thread is interrupted while this blocking method<br > is running the method will return with a negative value . <br > to check if the method exited because of an interruption<br > pass the return value to error#make ( int ) and then<br > check error#gettype () to see if it is<br > error . type#error_interrupted . <br > < / p > <br > <br >
get the coder that this stream was created with . <br > note : this can be either an encoder or a decoder .
get the muxer that this stream belongs to .
creates a signed setscript object .
decodes the given base58 string into the original data bytes .
generates a 15 - word random seed . this method implements the bip - 39 algorithm with 160 bits of entropy .
returns object by its id .
returns transactions by address with limit .
returns transactions by address with limit after passed transaction id .
returns seq of block headers
returns block by its signature .
sends a signed object and returns its id .
sets a validating script for an account .
compiles a script .
write the contents of a given object
len < 127 !!!!!
assumes class header + len already read
compressed version
write prim array no len no tag
does not write length just plain bytes
used to write uncompressed int ( guaranteed length = 4 ) at a ( eventually recent ) position
writes current buffer to underlying output and resets buffer .
throws fstbuffertoosmallexception in case object does not fit into given range
determines classname tagging . overrifing can enforce class tags always or ( json ) write as special attribute
in case readclass already reads full minbin value
will throw an fstbuffertoosmallexception if buffer is too small .
len < 127 !!!!!
assumes class header + len already read
obsolete
hack to update underlying file in slices handed out to app
returns the specificity of the specified class as defined above .
returns the lineage of the specified class ordered by specificity ( the class itself is at position 0 since it is most specific in its lineage ) .
privileged method . you gotta know what your doing here ..
get an entry . the returned bytesource must be processed immediately as it will be reused internally on next get warning : concurrent modification ( e . g . add remove elements during iteration ) is not supported and not checked . collect keys to change inside iteration and perform changes after iteration is finished .
remove the key from the binary map
}
uncompressed version
compressed version
does not write length just plain bytes
length < 127 !!!!!
used to write uncompressed int ( guaranteed length = 4 ) at a ( eventually recent ) position
if output stream is null just encode into a byte array
allocates a structaccessor ( pointer ) matching the struct data expected in the byte array at given position . the resulting pointer object is not volatile ( not a cached instance )
allocates a structaccessor ( pointer ) matching the struct data expected in the byte array at given position with given classid . the resulting pointer object is not volatile ( not a cached instance ) . the class id should match the struct stored in the byte array . ( classid must be the correct struct or a superclass of it )
create a json conf with given attributes . note that shared refs = true for jason might be not as stable as for binary encodings as fst relies on stream positions to identify objects within a given input so any inbetween formatting will break proper reference resolution .
debug only very slow ( creates config with each call ) . creates new conf so custom serializers are ignored .
register a custom serializer for a given class or the class and all of its subclasses . serializers must be configured identical on read / write side and should be set before actually making use of the configuration .
special configuration used internally for struct emulation
reuse heavy weight objects . if a fststream is closed objects are returned and can be reused by new stream instances . the objects are held in soft references so there should be no memory issues . fixme : point of contention !
for optimization purposes do not use to benchmark processing time or in a regular program as this methods creates a temporary binaryoutputstream and serializes the object in order to measure the size .
clear cached softref s and threadlocal .
utility for thread safety and reuse . do not close the resulting stream . however you should close the given inputstream in
take the given array as input . the array is not copied .
take the given array and copy it to input . the array is copied
utility for thread safety and reuse . do not close the resulting stream . however you should close the given outputstream out
init right after creation of configuration not during operation as it is not threadsafe regarding mutation currently only for minbin serialization
shorthand for registercrossplatformclassmapping ( _ _ )
get cross platform symbolic class identifier
convenience
convenience . ( object must be serializable )
warning : avoids allocation + copying . the returned bytearray is a direct pointer to underlying buffer . the int length [] is expected to have at least on element . the buffer can be larger than written data therefore length [ 0 ] will contain written length .
utility / debug method . use asbytearray for programmatic use as the byte array will already by utf - 8 and ready to be sent on network .
helper to write series of objects to streams / files > integer . max_value . it - serializes the object - writes the length of the serialized object to the stream - the writes the serialized object data
@see encodetostream
sideeffecting : if no ser is found next lookup will return null immediate
write an int type with header
encode int without header tag
encode int using only as much bytes as needed to represent it
write primitive array + header . no floating point or object array allowed . just int based types
allow write through to underlying byte for performance reasons
read into preallocated array allows to write to different type ( e . g . boolean [] from byte [] )
///////////////////////////////////////////////////
avoid creation of dummy ref
hook for debugging profiling . register a fstserialisationlistener to use
hook for debugging profiling . empty impl you need to subclass to make use of this hook
splitting this slows down ...
if class is same as last referenced returned cached clzinfo else do a lookup
write identical to other version but take field values from hashmap ( because of annoying putfield / getfield feature )
incoming array is already registered
if out == null = > automatically create / reuse a bytebuffer
@return a copy of written bytes . warning : if the stream has been flushed this will fail with an exception . a flush is triggered after each 1st level writeobject .
some jdk classes hash for objectstream so provide the same instance always
modify content of this structstring . the length of the new string must not exceed the length of internal char array
does not write class tag and length
resets stream ( positions are lost )
set this struct pointer to base array at given offset ( = bufoff + index )
set this struct pointer to base array at given index
move offsets and memorybase to given pointer and return the pointer . eases dereferencing of nested structs without object creation . if the given pointer is null a new one will be created ( alloc ) <pre > mystruct st = fststructfactory . getinstance () . createemptystructpointer ( fststruct . class ) ; otherstruct . getembeddedmystruct () . to ( st ) ; < / pre >
returns a complete copy of this object allocating a new bytez capable of holding the data .
works only if change tracking is enabled
@return a temporary per thread instance of bytebuffer pointing to this structs data . the length of the buffer is same as the length of this struct .
create a new struct array of same type as template
create a new struct array of same type as template
collects all changes and rebases .
add an object to the register return handle if already present . called during write only
warning : concurrent modification ( e . g . add remove elements during iteration ) is not supported and not checked . collect keys to change inside an iteration and perform changes on the map after iteration is finished .
throws fstbuffertoosmallexcpetion in case object does not fit into given range zero copy method
throws fstbuffertoosmallexcpetion in case object does not fit into given range
map given object to a target type . ( needs support in coercewriting also ) note one could add a pluggable serializer / coercer pattern here if required . skipped for now for simplicity .
add bytes to the queue . again by using ( reusable ) wrapper classes any kind of memory ( offheap byte arrays nio bytebuffer memory mapped ) can be added .
read up to destlen bytes ( if available ) . note you can use heapbytez ( implements bytesink ) in order to read to a regular byte array . heapbytez wrapper can be reused to avoid unnecessary allocation . also possible is bytebufferbasicbytes to read into a bytebuffer and mallocbytes or mmfbytes to read into unsafe alloc ed off heap memory or persistent mem mapped memory regions .
convenience method to read len byte array . throws an excpetion if not enough data is present
read an int . throws an exception if not enough data is present
unread len bytes
for read = > always increase handle ( wg . replaceobject )
set thread pool enabled . this thread pool is not for the service threads it is for the user service method . if your service method takes a long time or will be blocked please set this property to be true .
set embedded cassandra up and spawn it in a new thread .
truncate data in keyspace except specified tables
copies a resource from within the jar to a directory .
print all of the thread s information and stack traces .
return the correctly - typed { @link class } of the given object .
check if a remote port is taken
returns an empty subscriber state with - 1 as total updates master as false and server state as empty
gemm performs a matrix - matrix operation c : = alpha * op ( a ) * op ( b ) + beta * c where c is an m - by - n matrix op ( a ) is an m - by - k matrix op ( b ) is a k - by - n matrix .
her2k performs a rank - 2k update of an n - by - n hermitian matrix c that is one of the following operations : c : = alpha * a * conjg ( b ) + conjg ( alpha ) * b * conjg ( a ) + beta * c for trans = n or n c : = alpha * conjg ( b ) * a + conjg ( alpha ) * conjg ( a ) * b + beta * c for trans = c or c where c is an n - by - n hermitian matrix ; a and b are n - by - k matrices if trans = n or n a and b are k - by - n matrices if trans = c or c .
syrk performs a rank - n update of an n - by - n symmetric matrix c that is one of the following operations : c : = alpha * a * a + beta * c for trans = n or n c : = alpha * a * a + beta * c for trans = t or t c or c where c is an n - by - n symmetric matrix ; a is an n - by - k matrix if trans = n or n a is a k - by - n matrix if trans = t or t c or c .
gemm performs a matrix - matrix operation c : = alpha * op ( a ) * op ( b ) + beta * c where c is an m - by - n matrix op ( a ) is an m - by - k matrix op ( b ) is a k - by - n matrix .
hemm performs one of the following matrix - matrix operations : c : = alpha * a * b + beta * c for side = l or l c : = alpha * b * a + beta * c for side = r or r where a is a hermitian matrix b and c are m - by - n matrices .
herk performs a rank - n update of a hermitian matrix that is one of the following operations : c : = alpha * a * conjug ( a ) + beta * c for trans = n or n c : = alpha * conjug ( a ) * a + beta * c for trans = c or c where c is an n - by - n hermitian matrix ; a is an n - by - k matrix if trans = n or n a is a k - by - n matrix if trans = c or c .
her2k performs a rank - 2k update of an n - by - n hermitian matrix c that is one of the following operations : c : = alpha * a * conjg ( b ) + conjg ( alpha ) * b * conjg ( a ) + beta * c for trans = n or n c : = alpha * conjg ( b ) * a + conjg ( alpha ) * conjg ( a ) * b + beta * c for trans = c or c where c is an n - by - n hermitian matrix ; a and b are n - by - k matrices if trans = n or n a and b are k - by - n matrices if trans = c or c .
syrk performs a rank - n update of an n - by - n symmetric matrix c that is one of the following operations : c : = alpha * a * a + beta * c for trans = n or n c : = alpha * a * a + beta * c for trans = t or t c or c where c is an n - by - n symmetric matrix ; a is an n - by - k matrix if trans = n or n a is a k - by - n matrix if trans = t or t c or c .
yr2k performs a rank - 2k update of an n - by - n symmetric matrix c that is one of the following operations : c : = alpha * a * b + alpha * b * a + beta * c for trans = n or n c : = alpha * a * b + alpha * b * a + beta * c for trans = t or t where c is an n - by - n symmetric matrix ; a and b are n - by - k matrices if trans = n or n a and b are k - by - n matrices if trans = t or t .
syr2k performs a rank - 2k update of an n - by - n symmetric matrix c that is one of the following operations : c : = alpha * a * b + alpha * b * a + beta * c for trans = n or n c : = alpha * a * b + alpha * b * a + beta * c for trans = t or t where c is an n - by - n symmetric matrix ; a and b are n - by - k matrices if trans = n or n a and b are k - by - n matrices if trans = t or t .
?trsm solves one of the following matrix equations : op ( a ) * x = alpha * b or x * op ( a ) = alpha * b where x and b are m - by - n general matrices and a is triangular ; op ( a ) must be an m - by - m matrix if side = l or l op ( a ) must be an n - by - n matrix if side = r or r . for the definition of op ( a ) see matrix arguments . the routine overwrites x on b .
get the onnx op descriptors by name
get the allocation mode from the context
set the allocation mode for the nd4j context the value must be one of : heap java cpp or direct or an
this method releases previously allocated memory chunk
calculate the output shape for this op
{
this method executes given graph and returns results
and
or over the whole ndarray given some condition
and over the whole ndarray given some condition
and over the whole ndarray given some condition with respect to dimensions
or over the whole ndarray given some condition with respect to dimensions
based on the matching elements op to based on condition to with function function
this method sets provided number to all elements which match specified condition
choose from the inputs based on the given condition . this returns a row vector of all elements fulfilling the condition listed within the array for input
choose from the inputs based on the given condition . this returns a row vector of all elements fulfilling the condition listed within the array for input . the double and integer arguments are only relevant for scalar operations ( like when you have a scalar you are trying to compare each element in your input against )
based on the matching elements op to based on condition to with function function
based on the matching elements op to based on condition to with function function
this method returns first index matching given condition
this method converts this functionproperties instance to flatbuffers representation
this method creates new functionproperties instance from flatbuffers representation
this method converts multiple functionproperties to flatbuffers representation
this method updates state with given throwable
this method updates state only if it wasn t set before
normalize a value ( val - min ) / ( max - min )
this will merge the coordinates of the given coordinate system .
this returns the coordinate split in a list of coordinates such that the values for ret [ 0 ] are the x values and ret [ 1 ] are the y values
this will partition the given whole variable data applytransformtodestination in to the specified chunk number .
this returns the coordinate split in a list of coordinates such that the values for ret [ 0 ] are the x values and ret [ 1 ] are the y values
convert an onnx type to the proper nd4j type
this method initiates shutdown sequence for this instance .
returns titles line as string appointed by title index ( 0 .. 5 ) . <br > columns are separated with char | . <br > if title index is < 0 returns ? . <br > if title index is > 5 returns ? . <br >
returns values line as string . <br > columns are separated with char | . <br >
get the current device architecture
returns a subset of this array based on the specified indexes
adjust the flags array according on the current context : - in case of a vector or a scalar we need to keep flags to 0 - there must always be at least 2 non - flags dimensions - we must keep the flags dimensions of the original array
rearrange matrix columns into blocks
pooling 2d implementation
implement column formatted images @param img the image to process @param kh the kernel height @param kw the kernel width @param sy the stride along y @param sx the stride along x @param ph the padding width @param pw the padding height @param pval the padding value ( not used ) @param issamemode whether padding mode is same @return the column formatted image
nd convolution
instantiate a compression descriptor from the given bytebuffer
return a direct allocated bytebuffer from the compression codec . the size of the bytebuffer is calculated to be : 40 : 8 + 32 two ints representing their enum values for the compression algorithm and optype
helper method to create batch from list of aggregates for cases when list of aggregates is higher then batchlimit
calculate the update based on the given gradient
input arrays must have same number of dimensions
sets the data optype
generate a linearly spaced vector
returns a vector with all of the elements in every nd array equal to the sum of the lengths of the ndarrays
returns a column vector where each entry is the nth bilinear product of the nth slices of the two tensors .
reverses the passed in matrix such that m [ 0 ] becomes m [ m . length - 1 ] etc
merge the vectors and append a bias . each vector must be either row or column vectors . an exception is thrown for inconsistency ( mixed row and column vectors )
create a random ( uniform 0 - 1 ) ndarray with the specified shape and order
generate a random normal n ( 0 1 ) with the specified order and shape
creates an ndarray with the specified data
creates an 1 x num ndarray with the specified value
creates an shape ndarray with the specified value
concatenate ndarrays along a dimension
create an ndarray of ones
create an ndarray of ones
creates a complex ndarray with the specified shape
create an ndrray with the specified shape
create an ndrray with the specified shape
create an ndrray with the specified shape
creates a complex ndarray with the specified shape
create a scalar ndarray with the specified offset
create a scalar nd array with the specified value and offset
create a scalar nd array with the specified value and offset
create a scalar ndarray with the specified offset
create a scalar nd array with the specified value and offset
returns true if the updater has accumulated enough ndarrays to replicate to the workers
subtract two complex numbers in - place
multiply two complex numbers inplace
divide two complex numbers in - place
create complex number where the
create complex number where the
return the sin value of the given complex number
return the ceiling value of the given complex number
return the log value of the given complex number
return the absolute value of the given complex number
raise a complex number to a power
returns the exp of a complex number : let r be the realcomponent component and i be the imaginary let ret be the complex number returned ret - > exp ( r ) * cos ( i ) exp ( r ) * sin ( i ) where the first number is the realcomponent component and the second number is the imaginary component
returns the exp of a complex number : let r be the realcomponent component and i be the imaginary let ret be the complex number returned ret - > exp ( r ) * cos ( i ) exp ( r ) * sin ( i ) where the first number is the realcomponent component and the second number is the imaginary component
returns the exp of a complex number : let r be the realcomponent component and i be the imaginary let ret be the complex number returned ret - > exp ( r ) * cos ( i ) exp ( r ) * sin ( i ) where the first number is the realcomponent component and the second number is the imaginary component
get a context
this method frees specific chunk of memory described by allocationpoint passed in
returns a subset of this array based on the specified indexes
merge the list of datasets in to one list . all the rows are merged in to one dataset
binarizes the dataset such that any number greater than cutoff is 1 otherwise zero
gets a copy of example i
gets a copy of example i
sample a dataset
this method returns memory used by this dataset
make a string representation of the exception .
given a full hostname return the word upto the first dot .
the same as string . format ( locale . english format objects ) .
given an array of strings return a comma - separated list of its elements .
given an array of bytes it will convert the bytes to a hex string representation of the bytes
formats time in ms and appends difference ( finishtime - starttime ) as returned by formattimediff () . if finish time is 0 empty string is returned if start time is 0 then difference is not appended to return value .
returns an arraylist of strings .
returns a collection of strings .
returns a collection of strings .
splits a comma separated value <code > string< / code > trimming leading and trailing whitespace on each value . duplicate and empty values are removed .
splits a comma or newline separated value <code > string< / code > trimming leading and trailing whitespace on each value .
split a string using the given separator
split a string using the given separator with no escaping performed .
finds the first occurrence of the separator character ignoring the escaped separators starting from the index . note the substring between the index and the position of the separator is passed .
escape <code > chartoescape< / code > in the string with the escape char <code > escapechar< / code >
unescape <code > chartoescape< / code > in the string with the escape char <code > escapechar< / code >
escapes html special characters present in the string .
concatenates strings using a separator .
convert some_stuff to somestuff
matches a template string against a pattern replaces matched tokens with the supplied replacements and returns the result . the regular expression must use a capturing group . the value of the first capturing group is used to look up the replacement . if no replacement is found for the token then it is replaced with the empty string .
get stack trace for a given thread .
compare strings locale - freely by using string#equalsignorecase .
<p > checks if the string contains only unicode letters . < / p >
inverts a matrix
compute the factorial of the non - negative integer .
this method returns if host side has actual copy of data
this method returns if device side has actual copy of data
this method creates shapeinformation buffer based on shape being passed in
this method creates shapeinformation buffer based on shape & order being passed in
returns whether the given shape is a vector
a port of numpy s reshaping algorithm that leverages no copy where possible and returns null if the reshape couldn t happen without copying
infer the order for the ndarray based on the array s strides
compute the offset for the given array given the indices
convert the given int indexes to nd array indexes
get array shape from an int []
extracts files to the specified destination
special method for
reallocate the native memory of the buffer
this method executes given customop
copy from the given from buffer to the to buffer at the specified offsets and strides
start a server based on the given subscriber . note that for the port to start the server on you should set the statusserverportfield on the subscriber either manually or via command line . the server defaults to port 9000 .
this method moves specified databuffer to cuda constant memory space .
please note : this method implementation is hardware - dependant . please note : this method does not allow concurrent use of any array
this method returns databuffer with contant equal to input array .
based on the passed in array compute the shape offsets and strides for the given indexes @param indexes the indexes to compute this based on
returns a kafka connection uri
cosine similarity
atan2 operation new indarray instance will be returned note the order of x and y parameters is opposite to that of java . lang . math . atan2
ceiling function
sin function
sin function
sinh function
hard tanh
hard tanh
element - wise power function - x^y performed element - wise
log on arbitrary base
eps function
eps function
eps function
maximum function with a scalar
element wise maximum function between 2 indarrays
minimum function with a scalar
element wise minimum function between 2 indarrays
stabilize to be within a range of k
abs function
exp function
elementwise exponential - 1 function
identity function
sqrt function
tanh function
log function
log of x + 1 function
apply the given elementwise op
apply the given elementwise op
raises a square matrix to a power <i > n< / i > which can be positive negative or zero . the behavior is similar to the numpy matrix_power () function . the algorithm uses repeated squarings to minimize the number of mmul () operations needed <p > if <i > n< / i > is zero the identity matrix is returned . < / p > <p > if <i > n< / i > is negative the matrix is inverted and raised to the abs ( n ) power . < / p >
prepare the boundaries for processing
adjust final scheme to presence of bounds
returns the next element in the iteration .
nd convolution
cholesky decomp
q r decomp
this method returns allocationshape for specific array that takes in account its real shape : offset length etc
this method returns allocationshape for the whole databuffer .
check if a file exists in the path
custom deserialization for java serialization
this method ensures the events in the beginning of fifo queues are finished
create a complex ndarray from the passed in indarray
create a complex ndarray from the passed in indarray
symmetric in place shuffle of an ndarray along a specified set of dimensions . each array in list should have it s own dimension at the same index of dimensions array
create from an in memory numpy pointer
create from a given numpy file .
this method provides pointerspair to memory chunk specified by allocationshape
this method does allocation from a given workspace
this method notifies locker that specific object was added to tracking list
calculate the update based on the given gradient
writes the bytes for the object to the output . <p > this method should not be called directly instead this serializer can be passed to { @link kryo } write methods that accept a serialier .
reads bytes and returns a new object of the specified concrete optype . <p > before kryo can be used to read child objects { @link kryo#reference ( object ) } must be called with the parent object to ensure it can be referenced by the child objects . any serializer that uses { @link kryo } to read a child object may need to be reentrant . <p > this method should not be called directly instead this serializer can be passed to { @link kryo } read methods that accept a serialier .
returns true if bth the master and responder are started .
this is one of the main entry points for ops that are executed without respect to dimension .
fixme : remove cudacontext return optype . we just don t need it
this method forces all currently enqueued ops to be executed immediately
retrieves the device pointer for the given data buffer
retrieves the device pointer for the given data buffer
please note : specific implementation on systems without special devices can return hostpointer here
returns requested classpathresource as inputstream object
this method returns deviceid for given thread identified by threadid
this method pairs specified thread & device
this method returns device id available . round - robin balancing used here .
loads the specified library . the full name of the library is created by calling { @link libutils#createlibname ( string ) } with the given argument . the method will attempt to load the library as a as a resource ( for usage within a jar ) and if this fails using the usual system . loadlibrary call .
load the library with the given name from a resource . the extension for the current os will be appended .
load the library with the given name from a resource . the extension for the current os will be appended .
load the library with the given name from a resource . the extension for the current os will be appended .
get the name of the os for libary discovery on the classpath
creates the name for the native library with the given base name for the current operating system and architecture . the resulting name will be of the form<br / > basename - ostype - archtype<br / > where ostype and archtype are the <strong > lower case< / strong > strings of the respective enum constants . example : <br / > jcuda - windows - x86<br / >
calculates the current archtype
publish to a kafka topic based on the connection information
start the server
create a data buffer based on the given pointer data buffer optype and length of the buffer
this method checks if any op operand has data optype of int and throws exception if any .
add two complex numbers in - place
multiply two complex numbers inplace
divide two complex numbers in - place
drop - in replacement wrapper for basedatabuffer . read () method aware of compresseddatabuffer
this method assigns specific value to either specific row or whole array . array is identified by key
local response normalization operation .
conv1d operation .
conv2d operation .
average pooling 2d operation .
max pooling 2d operation .
avg pooling 3d operation .
max pooling 3d operation .
separable conv2d operation .
depthwise conv2d operation . this is just separable convolution with only the depth - wise weights specified .
deconv2d operation .
returns the covariance matrix of a data set of many records each with n features . it also returns the average values which are usually going to be important since in this version all modes are centered around the mean . it s a matrix that has elements that are expressed as average dx_i * dx_j ( used in procedure ) or average x_i * x_j - average x_i * average x_j
calculates the principal component vectors and their eigenvalues ( lambda ) for the covariance matrix . the result includes two things : the eigenvectors ( modes ) as result [ 0 ] and the eigenvalues ( lambda ) as result [ 1 ] .
this method resets all counters
this method returns op class opname
create a complex ndarray from the passed in indarray
allocate and return a new array based on the vertex id and weight initialization .
a getter for the allocated ndarray with this { @link sdvariable } .
returns the shape of this variable
evaluate the result of this variable
this method creates compressed indarray from java double array skipping usual indarray instantiation routines
returns the exponential of a complex ndarray
center an array
truncates an ndarray to the specified shape . if the shape is the same or greater it just returns the original array
pads an ndarray with zeros
find the index of the element with maximum absolute value
this method duplicates array and stores it to all devices
this method will be started in context of executor either shard client or backup node
eulers constant .
euler - mascheroni constant .
the square root .
the cube root .
the integer root .
the hypotenuse .
the hypotenuse .
the exponential function .
the base of the natural logarithm .
the natural logarithm .
the natural logarithm .
the natural logarithm .
power function .
raise to an integer power and round .
trigonometric sine .
the trigonometric tangent .
the inverse trigonometric sine .
the inverse trigonometric tangent .
the hyperbolic cosine .
the hyperbolic sine .
the hyperbolic tangent .
the inverse hyperbolic sine .
the inverse hyperbolic cosine .
the gamma function .
pochhammers function .
reduce value to the interval [ 0 2 * pi ] .
reduce value to the interval [ - pi / 2 pi / 2 ] .
riemann zeta function .
riemann zeta function .
broadhurst ladder sequence .
add and round according to the larger of the two ulps .
subtract and round according to the larger of the two ulps .
multiply and round .
multiply and round .
multiply and round .
multiply and round .
divide and round .
divide and round .
append decimal zeros to the value . this returns a value which appears to have a higher precision than the input .
boost the precision by appending decimal zeros to the value . this returns a value which appears to have a higher precision than the input .
convert an absolute error to a precision .
update the opname for the variable with the given vertex id
get the function by the { @link differentialfunction#getownname () }
put the function for id
returns the inputs for the given function
update the ndarray for the given vertex id .
adds an ndarray for a given vertex id . use { @link #updatearrayforvarname ( string indarray ) } if the array already exists .
get the shape for the given vertex id . note that if an array is defined it will use that shape instead . <p > a shape * and * an array should not be defined at the same time . this wastes memory . the internal map used for tracking shapes for particular vertex ids should also delete redundant shapes stored to avoid redundant sources of information .
update a vertex id with the given shape . note that you should use { @link #putshapeforvarname ( string int [] ) } if you want to add a new shape . update is meant to be an in place replacement of the shape for the vertex id * only * .
associate a vertex id with the given shape .
associate the array with the given variable .
get the property for a given function
add a property for the given function
adds outgoing arguments to the graph . also checks for input arguments and updates the graph adding an appropriate edge when the full graph is declared .
adds incoming args to the graph
returns true if this function already has defined arguments
evaluate the given inputs based on the current graph
variable initialization with 1 . 0
return a variable of all 1s with the same shape as the input
return a variable of all 0s with the same shape as the input
variable initialization with a specified { @link weightinitscheme }
initialize a { @link sdvariable } reference tying this variable to this samediff instance . <p > { @link ndarraysupplierinitscheme } is used to ensure that if the array is allocated anywhere and { @link samediff } instance to exist as a copy of the variable .
remove an argument for a function . note that if this function does not contain the argument it will just be a no op .
assign a vertex id to a gradient
average pooling 2d operation .
average pooling 2d operation .
max pooling 2d operation .
average pooling 3d operation .
max pooling 3d operation .
max pooling 3d operation .
conv1d operation .
conv1d operation .
local response normalization operation .
local response normalization operation .
conv2d operation .
depth - wise conv2d operation .
depth - wise conv2d operation .
separable conv2d operation .
separable conv2d operation .
deconv2d operation .
deconv2d operation .
conv3d operation .
conv3d operation .
batch norm operation .
batch norm operation .
lstm unit
the gru cell
generate the variables based on the given input op and return the output variable names .
u
executes the list of operations . this exec method is for only invoking operations rather than creating them
creates a while statement
exec a given function
exec the given function given the ops
builds a backwards graph and executes the operations on that graph .
exec a backwards operation and return the end result
add this vertex id as a place holder
resolve all ndarrays by updating the variables for each array specified in the given map . an { @link illegalstateexception } will be thrown if not all arrays are specified for resolution .
returns true if all place holder variables are resolved . a place holder variable is resolved when { @link #getvariable ( string ) } getarr () does not return null and the shape is properly resolved .
add one or or more place holder variables for the given vertex id . <p > note that if a vertex id in placeholdervariables isn t present in this samediff instance anyways an { @link nd4jillegalstateexception } is thrown
creates and executes a list of operations based on the given variables passed in . { @link #resolvevariableswith ( map ) } is called
get the { @link sdvariable } associated with each function based on the { @link differentialfunction#outputvariables () } () }
updates the variable name property on the passed in variable the reference in samediff and returns the variable . <p > note that if null for the new variable is passed in it will just return the original input variable .
creates and executes a list of operations
print the given function for debugging ( will not print functions )
permute indices for the samediff / dl4j format . due to the dl4j format being nchw this is a simple routine for returning permute indices . this is typically used for model import .
update the { @link indarray } ndarray for the given variable name
this method exports given samediff instance into flatbuffers
this method returns flattened graph .
this method converts enums for datatype
this method converts enums for datatype
this method return operation id for given op name / type pair .
this method converts enums for datatype
this method converts enums for datatype
this method returns pointer to allocated memory chunk
set the data for the underlying array . if the underlying buffer s array is equivalent to this array it returns ( avoiding an unneccessary copy )
returns the length for the given data optype
get the allocation mode from the context
gets the name of the alocation mode
get the allocation mode from the context
set the allocation mode for the nd4j context the value must be one of : heap java cpp or direct or an
this method returns op id number for given opname
/ * @override public memoryworkspace getworkspaceforcurrentthread ( @nonnull workspaceconfiguration configuration @nonnull string id ) { ensurethreadexistense () ;
this method destroys all workspaces allocated in current thread
this method prints out basic statistics for workspaces allocated in current thread
gemv computes a matrix - vector product using a general matrix and performs one of the following matrix - vector operations : y : = alpha * a * x + beta * y for trans = n or n ; y : = alpha * a * x + beta * y for trans = t or t ; y : = alpha * conjg ( a ) * x + beta * y for trans = c or c . here a is an m - by - n band matrix x and y are vectors alpha and beta are scalars .
gemv computes a matrix - vector product using a general matrix and performs one of the following matrix - vector operations : y : = alpha * a * x + beta * y for trans = n or n ; y : = alpha * a * x + beta * y for trans = t or t ; y : = alpha * conjg ( a ) * x + beta * y for trans = c or c . here a is an m - by - n band matrix x and y are vectors alpha and beta are scalars .
gbmv computes a matrix - vector product using a general band matrix and performs one of the following matrix - vector operations : y : = alpha * a * x + beta * y for trans = n or n ; y : = alpha * a * x + beta * y for trans = t or t ; y : = alpha * conjg ( a ) * x + beta * y for trans = c or c . here a is an m - by - n band matrix with ku superdiagonals and kl subdiagonals x and y are vectors alpha and beta are scalars .
performs a rank - 1 update of a general m - by - n matrix a without conjugation : a : = alpha * x * y + a .
performs a rank - 1 update of a general m - by - n matrix a without conjugation : a : = alpha * x * y + a .
hemv computes a matrix - vector product using a hermitian matrix : y : = alpha * a * x + beta * y . here a is an n - by - n hermitian band matrix with k superdiagonals x and y are n - element vectors alpha and beta are scalars .
?her2 performs a rank - 2 update of an n - by - n hermitian matrix a : a : = alpha * x * conjg ( y ) + conjg ( alpha ) * y * conjg ( x ) + a .
?hpmv computes a matrix - vector product using a hermitian packed matrix : y : = alpha * a * x + beta * y . here a is an n - by - n packed hermitian matrix x and y are n - element vectors alpha and beta are scalars .
hpr2 performs a rank - 2 update of an n - by - n packed hermitian matrix a : a : = alpha * x * conjg ( y ) + conjg ( alpha ) * y * conjg ( x ) + a .
sbmv computes a matrix - vector product using a symmetric band matrix : y : = alpha * a * x + beta * y . here a is an n - by - n symmetric band matrix with k superdiagonals x and y are n - element vectors alpha and beta are scalars .
syr2 performs a rank - 2 update of an n - by - n symmetric matrix a : a : = alpha * x * y + alpha * y * x + a .
trmv computes a matrix - vector product using a triangular matrix .
receive an ndarray
/ * given a list of labels return the bernoulli prob that the masks will be sampled at to meet the target minority label distribution
execute an accumulation along one or more dimensions
this method executes specific randomop against specified rng
this method encodes array as thresholds updating input array at the same time
this method encodes array as thresholds updating input array at the same time
this method decodes thresholds array and puts it into target array
normalize a data array
denormalize a data array
map a tensorflow node name to the samediff equivalent for import
scalarop along dimension
this method takes arbitrary sized list of {
this method return set of key / value and key / key / value objects describing current environment
this method executes specific randomop against specified rng
this method executes given customop
this command is possible to issue only from shard
this command is possible to issue only from shard
assert that no workspaces are currently open
nd convolution
this method returns an array consisting of each of the training samples for each label in each sample the negative log likelihood of that value falling within the given gaussian mixtures .
this method requests to change state to tick .
this method requests to change state to toe
this method requests release toe status back to tack .
this method returns the current memory state
this method build
vector aggregations are saved only by shards started aggregation process . all other shards are ignoring this meesage
initializes this data transform fetcher from the passed in datasets
set the value for this function . note that if value is null an { @link nd4jillegalstateexception } will be thrown .
this method executes preconfigured number of host memory garbage collectors
this method returns actual device pointer valid for current object
this method should be called to make sure that data on host side is actualized
this method allocates required chunk of memory in specific location <p > please note : do not use this method unless you re 100% sure what you re doing
convert a {
create a {
create thee databuffer type frm the given type relative to the bytes in arrow in class : {
this method provides pointerspair to memory chunk specified by allocationshape
this method frees specific chunk of memory described by allocationpoint passed in
gets feature specific learning rates adagrad keeps a history of gradients being passed in . note that each gradient passed in becomes adapted over time hence the opname adagrad
this method makes sure host memory contains latest data from gpu
create from a matrix . the rows are the indices the columns are the individual element in each ndarrayindex
broadcast add op . see : {
broadcast copy op . see : {
broadcast divide op . see : {
broadcast equal to op . see : {
broadcast greater than op . see : {
broadcast greater than or equal to op . see : {
broadcast less than op . see : {
broadcast less than or equal to op . see : {
broadcast not equal to op . see : {
broadcast reverse division op . see : {
broadcast reverse subtraction op . see : {
broadcast max op . see : {
broadcast min op . see : {
broadcast absolute max op . see : {
broadcast absolute min op . see : {
returns the properties for a given function
returns true if this function has place holder inputs
perform automatic differentiation wrt the input variables
the offsets ( begin index ) for each index
format the given ndarray as a string
this method converts given tf
convert an ndarray to a blob
load a complex ndarray from a blob
save the ndarray
copy real numbers to arr
copy imaginary numbers to the given ndarray
returns an ndarray with 1 if the element is epsilon equals
in place epsilon equals than comparison : if the given number is less than the comparison number the item is 0 otherwise 1
returns the squared ( euclidean ) distance .
returns the ( 1 - norm ) distance .
inserts the element at the specified index
assigns the given matrix ( put ) to the specified slice
compute complex conj ( in - place ) .
inserts the element at the specified index
assigns the given matrix ( put ) to the specified slice
inserts the element at the specified index
assign all of the elements in the given ndarray to this ndarray
get whole rows from the passed indices .
dimshuffle : an extension of permute that adds the ability to broadcast various dimensions . <p / > see theano for more examples . this will only accept integers and xs . <p / > an x indicates a dimension should be broadcasted rather than permuted .
insert a row in to this array will throw an exception if this ndarray is not a matrix
insert a column in to this array will throw an exception if this ndarray is not a matrix
inserts the element at the specified index
in place addition of a column vector
in place addition of a column vector
in place addition of a column vector
in place addition of a column vector
in place addition of a column vector
in place addition of a column vector
in place addition of a column vector
in place addition of a column vector
perform an copy matrix multiplication
copy ( element wise ) division of two matrices
copy ( element wise ) multiplication of two matrices
copy subtraction of two matrices
copy addition of two matrices
perform an copy matrix multiplication
in place ( element wise ) multiplication of two matrices
in place subtraction of two matrices
in place addition of two matrices
set the value of the ndarray to the specified value
reverse division
reverse division ( in - place )
reverse subtraction
reverse subtraction ( in - place )
returns a scalar ( individual element ) of a scalar ndarray
flattens the array for linear indexing
computes the eigenvalues of a general matrix .
computes the eigenvalues and eigenvectors of a general matrix . <p / > for matlab users note the following from their documentation : the columns of v present eigenvectors of a . the diagonal matrix d contains eigenvalues . <p / > this is in reverse order of the matlab eig ( a ) call .
compute generalized eigenvalues of the problem a x = l b x . the data will be unchanged no eigenvectors returned .
{
finds the element of a vector that has the largest absolute value .
copy a vector to another vector .
computes a vector - scalar product and adds the result to a vector .
computes a vector - scalar product and adds the result to a vector .
computes a vector by a scalar product .
normalize a data array
denormalize a data array
merge the specified labels and label mask arrays ( i . e . concatenate the examples )
merge the specified 2d arrays and masks . see { @link #mergefeatures ( indarray [] indarray [] ) } and { @link #mergelabels ( indarray [] indarray [] ) }
merge the specified 4d arrays and masks . see { @link #mergefeatures ( indarray [] indarray [] ) } and { @link #mergelabels ( indarray [] indarray [] ) }
this method executes given graph and returns results
can we do the op ( x = op ( x )) directly on the arrays without breaking x up into 1d tensors first? in general this is possible if the elements of x are contiguous in the buffer or if every element of x is at position offset + i * elementwisestride in the buffer
can we do the transform op ( x = op ( x y )) directly on the arrays without breaking them up into 1d tensors first?
tensor1dstats used to efficiently iterate through tensors on a matrix ( 2d ndarray ) for element - wise ops for example the offset of each 1d tensor can be calculated using only a single tensoralongdimension method call hence is potentially faster than approaches requiring multiple tensoralongdimension calls . <br > note that this can only ( generally ) be used for 2d ndarrays . for certain 3 + d ndarrays the tensor starts may not be in increasing order
this method calculates dot of gives rows
mean squared error : l = mean ( ( predicted - label ) ^2 )
multi - class cross entropy loss function : <br > l = sum_i actual_i * log ( predicted_i )
determine the number of weight entries that are non - zero after broadcasting
perform the final reduction on the loss function
initialize this capturetypeimpl . this is needed for type variable bounds referring to each other : we need the capture of the argument .
throw an illegalstateexception if the class does not have a no - arg constructor .
gets a constructor that has the specified types of arguments . throw an illegalstateexception if the class does not have such a constructor .
wraps any non - runtime exceptions with a runtime exception
checked exceptions are lame .
checked exceptions are lame .
just like class . isassignablefrom () but does the right thing when considering autoboxing .
gets the annotation that has the specified type or null if there isn t one
get the declared annotation ignoring any inherited annotations
is the declared annotation present ignoring any inherited annotations
create a resultproxy for the given interface .
/ * ( non - javadoc )
converts an entity to an object of the appropriate type for this metadata structure . does not check that the entity is appropriate ; that should be done when choosing which entitymetadata to call .
the problem is projectionentity ; there s no way to create an entityvalue with a projectionentity so we can t use the standard translation system for {
converts an object to a datastore entity with the appropriate key type .
/ * ( non - javadoc )
modifies the instance
converts the textual operator ( > < = etc ) into a filteroperator . forgiving about the syntax ; ! = and < > are not_equal = and == are equal .
modifies the instance
modifies the instance
modifies the instance
modifies the instance
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
get an iterator over the keys . not part of the public api but used by querykeysimpl . assumes that setkeysonly () has already been set .
the builder api is programmer - hostile
the builder api is programmer - hostile
the builder api is programmer - hostile
create the proxy that does retries . adds a strict error handler to the service .
/ * ( non - javadoc )
/ *
iterate through all pending futures and get () them forcing any callbacks to be called . this is used only by the asynccachefilter ( if using cache without objectify ) or objectifyfilter ( if using objectify normally ) because we don t have a proper hook otherwise .
<p > all @entity and @subclass classes ( for both entity and embedded classes ) must be registered before using objectify to load or save data . this method must be called in a single - threaded mode sometime around application initialization . < / p >
gets metadata for the specified kind
perform a keys - only query .
perform a keys - only plus batch gets .
a normal non - hybrid query
a projection query . bypasses the session entirely .
the fundamental query count operation . this doesn t appear to be implemented in the new sdk so we simulate with a keys - only query .
detects integer . max_value and prevents oom exceptions
loads them ; note that it s possible for some loaded results to be null
copies an array of primitive longs while boxing them at the same time and then converting into a list . can t use { @link arrays#aslist ( object [] ) } directly as that will create a list of arrays instead .
like now () but throws notfoundexception instead of returning null .
create a log a message for a given path
key . create ( key ) is easier to type than new key<blah > ( key )
key . create ( blah . class id ) is easier to type than new key<blah > ( blah . class id )
key . create ( blah . class name ) is easier to type than new key<blah > ( blah . class name )
key . create ( urlsafestring ) is easier to type than new key<blah > ( urlsafestring )
create a key from a registered pojo entity .
<p > the new cloud sdk key doesn t have compareto () so we reimplement the logic from the old gae sdk . < / p >
i have no idea what this is about it was in the old logic
easy null - safe conversion of the raw key .
easy null - safe conversion of the typed key .
<p > determines the kind for a class as understood by the datastore . the first class in a hierarchy that has @entity defines the kind ( either explicitly or as that class simplename ) . < / p >
<p > recursively looks for the @entity annotation . < / p >
get the kind from the class if the class has an
checks if the given type is a class that is supposed to have type parameters but doesn t . in other words if it s a really raw type .
checks if the capture of subtype is a subtype of supertype
returns the direct supertypes of the given type . resolves type parameters .
returns the exact type of the given field in the given type . this may be different from <tt > f . getgenerictype () < / tt > when the field was declared in a superclass or <tt > type< / tt > has a type parameter that is used in the type of the field or <tt > type< / tt > is a raw type .
applies capture conversion to the given type .
get the relevant translator creating it if necessary .
get the populator for the specified class . this requires looking up the translator for that class and then getting the populator from it .
/ *
/ *
figure out if there is an index instruction for the whole class .
determine if we should create a property for the field . things we ignore : static final
determine if we should create a property for the method ( ie
get all the persistable fields and methods declared on a class . ignores superclasses .
gets the key metadata but only if this was an
gets a result using the session cache if possible .
turn this into a result set
possibly pulls some values from the stuffed collection
/ *
/ *
recursively go through the class hierarchy adding any discriminators that are indexed
register a subclass translator with this class translator . that way if we get called upon to translate an instance of the subclass we will forward to the correct translator .
get the component type of a collection .
get the key type of a map .
recursive method which reverses the path into a forwardpath .
get the complete path in this chain typically for error messages or debugging
create the full x . y . z string
root is 0 top level entity properties are 1 embedded things are higher .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
<p > gets the buckets for the specified keys . a bucket is built around an identifiablevalue so you can putall () them without the risk of overwriting other threads changes . buckets also hide the underlying details of storage for negative empty and uncacheable results . < / p >
update a set of buckets with new values . if collisions occur resets the memcache value to null .
revert a set of keys to the empty state . will loop on this several times just in case the memcache write fails - we don t want to leave the cache in a nasty state .
put buckets in the cache checking for cacheability and collisions .
bulk get on keys getting the raw objects
basically a list comprehension of the keys for convenience .
recursively go through the class hierarchy looking for the idmeta and parentmeta fields .
sets the key ( from the container ) onto the pojo id / parent fields . also doublechecks to make sure that the key fields aren t present in the container which means we re in a very bad state .
sets the key onto the pojo id / parent fields
sets the key on a container from the pojo .
gets a key composed of the relevant id and parent fields in the object .
gets a key composed of the relevant id and parent fields in the object .
sets the numeric id field
get the contents of the
recursively register this subclass with all the superclass translators . this works because we cache translators uniquely in the factory .
creates a type of class <tt > clazz< / tt > with <tt > arguments< / tt > as type arguments . <p > for example : <tt > parameterizedclass ( map . class integer . class string . class ) < / tt > returns the type <tt > map&lt ; integer string&gt ; < / tt > .
creates a type of <tt > clazz< / tt > nested in <tt > owner< / tt > .
creates a type of <tt > clazz< / tt > with <tt > arguments< / tt > as type arguments nested in <tt > owner< / tt > . <p > in the ideal case this returns a { @link parameterizedtype } with all generic information in it . if some type arguments are missing or if the resulting type simply doesn t need any type parameters it returns the raw <tt > clazz< / tt > . note that types with some parameters specified and others not don t exist in java . <p > if the caller does not know the exact <tt > owner< / tt > type or <tt > arguments< / tt > <tt > null< / tt > should be given ( or { @link #parameterizedclass ( class type ... ) } or { @link #innerclass ( type class ) } could be used ) . if they are not needed ( non - generic owner and / or <tt > clazz< / tt > has no type parameters ) they will be filled in automatically . if they are needed but are not given the raw <tt > clazz< / tt > is returned . <p > the specified <tt > owner< / tt > may be any subtype of <tt > clazz . getdeclaringclass () < / tt > . it is automatically converted into the right parameterized version of the declaring class . if <tt > clazz< / tt > is a <tt > static< / tt > ( nested ) class the owner is not used .
check if the type arguments of the given type are within the bounds declared on the type parameters . only the type arguments of the type itself are checked the possible owner type is assumed to be valid . <p > it does not follow the checks defined in the <a href = http : // java . sun . com / docs / books / jls / third_edition / html / typesvalues . html#4 . 5 > jls< / a > because there are several problems with those ( see http : // stackoverflow . com / questions / 7003009 for one ) . instead this applies some intuition and follows what java compilers seem to do .
checks if the intersection of two types is not empty .
transforms the given owner type into an appropriate one when constructing a parameterized type .
creates a wildcard type with an upper bound . <p > for example <tt > wildcardextends ( string . class ) < / tt > returns the type <tt > ? extends string< / tt > .
creates a wildcard type with a lower bound . <p > for example <tt > wildcardsuper ( string . class ) < / tt > returns the type <tt > ? super string< / tt > .
checks not only the listed annotations but also annotations on the class .
add / overwrite a sv .
convenience method
add all entries in the other session to this one
eliminate any deferred operations against the entity . used when an explicit save ( or delete ) was executed against the key so we no longer need the deferred operation .
gets the result possibly from the session putting it in the session if necessary . also will recursively prepare the session with
starts asychronous fetching of the batch .
create a ref for the key and maybe start a load operation depending on current load groups .
asynchronously translate raw to processed ; might produce successive load operations as refs are filled in
fetch the keys from the async datastore using the current transaction context
converts a datastore entity into a typed pojo object
convenince method that creates a composite filter with any existing filter ( if present )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
<p > gets the key<t > given an object that might be a key key<t > or entity . < / p >
<p > gets the raw datstore key given an object that might be a key key<t > or entity . < / p >
construct a key from a long or string id
construct a key<? > from a long or string id
null - safe extraction of the raw key
make a list of key<? > s
gets the string or long id from the key as a value or null if incomplete
understands both the legacy format ag1zfnzvb2rvb2r5bmuwcgclegfcgaem and new format providing the key either way .
this version goes back to life without a transaction but preserves current options . we use the session from the parent ie life before transactions .
/ * ( non - javadoc )
/ * ( non - javadoc )
we need to make sure the parentsession is the transactionless session not the session for our transaction . this gives proper transaction isolation .
/ *
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
one attempt at executing a transaction
tests whether a set of conditions match .
get the current objectify instance associated with this ref
might produce a caching version if caching is enabled .
<p > construct an instance of the specified type . objectify uses this method whenever possible to create instances of entities condition classes or other types ; by overriding this method you can substitute guice or other dependency injection mechanisms . by default it constructs with a simple no - args constructor . < / p >
<p > construct a collection of the specified type and the specified size for use on a pojo field . you can override this with guice or whatnot . < / p >
<p > construct a map of the specified type for use on a pojo field . you can override this with guice or whatnot . < / p >
named differently so you don t accidentally use the object form
allocates a single id from the allocator for the specified kind . safe to use in concert with the automatic generator . this is just a convenience method for allocateids () .
<p > preallocate multiple unique ids within the namespace of the specified entity class . these ids can be used in concert with the normal automatic allocation of ids when save () ing entities with null long id fields . < / p >
preallocate a contiguous range of unique ids within the namespace of the specified entity class and the parent key . these ids can be used in concert with the normal automatic allocation of ids when put () ing entities with null long id fields .
allocate num copies of the incompletekey
the method to call at any time to get the current objectify which may change depending on txn context . normally you should use the static {
<p > start a scope of work . this is the outermost scope of work typically created by the objectifyfilter or by one of the methods on objectifyservice . you need one of these to do anything at all . < / p >
this is only public because it is used from the impl package ; don t use this as a public api
pops context off of stack after a transaction completes . for internal housekeeping only .
/ *
<p > runs one unit of work making the root objectify context available . this does not start a transaction but it makes the static ofy () method return an appropriate object . < / p >
the datastore has a weird behavior of reordering values in a list so that indexed ones come before nonindexed ones . this can really mess up ordered lists . so if we find a heterogeneous list we need to force index everything .
coerces the value to be a number of the specified type ; needed because all numbers come back from the datastore as long / double and this screws up any type that expects something smaller . we don t need to worry about primitive types because we wrapped the class earlier .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
key . create ( blah . class id ) is easier to type than new key<blah > ( blah . class id )
creates a ref from a registered pojo entity
obtain the entity value throwing an exception if the entity was not found .
adds a value to the set associated with the key .
this version also checks to see if we are done and we still need to call the trigger . if so it calls it .
clever enough to recognize that an empty set of conditions means always .
call this when a load process completes . executes anything in the batch and then executes any delayed operations .
create a ref for the key and maybe start a load operation depending on current load groups .
delays an operation until the context is done () . typically this is for lifecycle methods .
get the container object which is appropriate for the specified property . go up the chain looking for a compatible type ; the first one found is the container . if nothing found throw an exception .
we re just tracking statistics so we don t really need to worry about these stepping on each other ; if there s a hit or miss lost no big deal .
quietly perform the get () on a future
properly unwraps executionexception throwing the relevant original cause . otherwise runtimeexceptions get thrown and checked exceptions get wrapped in a runtimeexception .
coerces the value to be a number of the specified type ; needed because all numbers come back from the datastore as long / double and this screws up any type that expects something smaller . we don t need to worry about primitive types because we wrapped the class earlier .
obtains the translator appropriate for this type and annotations . may be a cached translator ; if not one will be discovered and cached .
get the translator for a root entity class
create a translator from scratch by going through the discovery process .
gets the appropriate value from the container and sets it on the appropriate field of the pojo .
gets the relevant property from the container detecting alsoload collisions .
set this raw datastore value on the relevant property of the pojo doing whatever translations are necessary .
sets the property on the pojo to the value . the value should already be translated . todo : sensitive to the value possibly being a result<? > wrapper in which case it enqueues the set operation until the loadcontext is done .
gets the appropriate field value from the pojo and puts it in the container at the appropriate prop name and with the appropriate indexing .
get the value for the property and translate it into datastore format .
write any extensions that may exist in a message .
writes a string that represents a contentcategory s json name returning success status . if the factory is in strict mode the category name is validated .
writes an array of contentcategory if not empty .
processes the raw snippet that was set by the bid making any transformations necessary .
serializes a {
serializes a { @link bidrequest } to json streamed into an { @link writer } .
serializes a { @link bidrequest } to json streamed into an { @link outputstream } .
serializes a {
serializes a {
serializes a { @link bidresponse } to json streamed to a { @link outputstream } .
serializes a { @link bidresponse } to json streamed to a { @link writer } .
serializes a {
@return the openrtb seatbid with the specified id ; will be created if not existent . the id should be present in the request s wseat .
iterates all bids .
iterates all bids from a specific seat .
finds a bid by id .
finds bids by a custom criteria .
finds bids by a custom criteria .
updates bids from all seats .
updates bids from a given seat .
remove bids by bid .
remove bids by seat and bid .
finds an { @link imp } by id .
find an { @link imp } by its id and its { @link banner } s id .
optimized code for most filtered lookups . this is worth the effort because bidder code may invoke these lookup methods intensely ; common cases like everything - filtered or nothing - filtered are very dominant ; and simpler code previously used needed lots of temporary collections .
adds impression type subfilters to a base filter to further restricts impressions that contain a banner video and / or native object .
performs a filter by seat .
serializes a {
serializes a { @link nativerequest } to json streamed into an { @link writer } .
serializes a { @link nativerequest } to json streamed into an { @link outputstream } .
serializes a {
serializes a {
serializes a { @link nativeresponse } to json streamed to a { @link outputstream } .
serializes a { @link nativeresponse } to json streamed to a { @link writer } .
serializes a {
read any extensions that may exist in a message .
special case for empty - string input . returning null in non -
register an extension reader .
register an extension writer bound to a specific field name . this writer will be used in preference to a non - field - specific writer that may exist for the same class .
register an extension writer not bound to any a field name ( so this serializer can be used for any extension of the provided class ) .
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
processes the context s response in - place modifying properties that may contain macros .
processes all fields of a bid that should support macro expansion .
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
desserializes a {
given a message - or - builder returns a message invoking the builder if necessary .
given a message - or - builder return a builder invoking tobuilder () if necessary .
updates every builder from a sequence .
runs a filter through a sequence of objects .
returns a copy of a { @link message } that contains only fields that pass a filter . this will be executed recursively for fields which are child messages .
returns the current field name or empty string if none .
starts an object skipping the { token and if necessary a field name before it .
returns {
starts an array skipping the [ token and if necessary a field name before it .
returns {
skips a field name if necessary returning the current token then .
skips a field name if necessary returning the current token then which must be the start of an array or object : { or [ .
writes a boolean as int where false = 0 and true = 1 .
writes a string array if not empty .
writes an int array if not empty .
writes a long using quotes only if it s too big ( over 53 - bit mantissa ) .
writes a long using quotes only if it s too big ( over 53 - bit mantissa ) .
writes a long array if not empty using quotes for values that are too big .
writes a enum value as an int using its protobuf number .
writes a enum value as an int using its protobuf number .
writes a enum array if not empty .
reads from either a json value string ( containing csv ) or a json array . the dual input format is needed because some fields ( e . g . keywords ) were allowed to be of either type in openrtb 2 . 2 ; now in 2 . 3 they are all csv strings only . todo : simplify this to only accept csv strings after 2 . 2 compatibility is dropped .
resolve relative url - s and fix a few java . net . url errors in handling of urls with embedded params and pure query targets .
handle the case in rfc3986 section 5 . 4 . 1 example 7 and similar .
handles cases where the url param information is encoded into the base url as opposed to the target . <p > if the taget contains params ( i . e . ; xxxx ) information then the target params information is assumed to be correct and any base params information is ignored . if the base contains params information but the tareget does not then the params information is moved to the target allowing it to be correctly determined by the java . net . url class .
partitions of the hostname of the url by .
returns the lowercased hostname for the url or null if the url is not well formed .
returns the page for the url . the page consists of the protocol host and path but does not include the query string . the host is lowercased but the path is not .
return one or more strings regardless of whether they are represented as a single string or a list in the config or an empty list if no value could be found for that key .
if the config consists of a single key config its values are used instead
returns an instance of the protocol to use for a given url
used for redirections or when discovering sitemap urls . the custom key / values are added to the target metadata post - filtering .
generates a warc info entry which can be stored at the beginning of each warc file .
modify verbatim http response headers : remove or replace headers <code > content - length< / code > <code > content - encoding< / code > and <code > transfer - encoding< / code > which may confuse warc readers . ensure that the header end with a single empty line ( <code > \ r \ n \ r \ n< / code > ) .
get the actual fetch time from metadata and format it as required by the warc - date field . if no fetch time is found in metadata ( key {
returns a normalised value of the content attribute for the refresh tag
determine which metadata should be transfered to an outlink . adds additional metadata like the url path .
determine which metadata should be persisted for a given document including those which are not necessarily transferred to the outlinks
populates a list of rules off of jsonnode .
/ * -------------------------- * <implementation : urlfilter > * --------------------------
add the key value to the metadata object for a given url *
add a new url
returns a normalised doc id based on the url of a document *
remove the non - cloudsearch - legal characters . note that this might convert two fields to the same name .
creates a connection with a default listener . the values for bolt type are [ indexer status metrics ]
identifies the charset of a document based on the following logic : guess from the byteordermark - else if the same charset is specified in the http headers and the html metadata then use it - otherwise use icu s charset detector to make an educated guess and if that fails too returns utf - 8 .
detects any boms and returns the corresponding charset
use a third party library as last resort to guess the charset from the bytes .
attempt to find a meta tag in the html that hints at the character set used to write the document .
examines the first bytes of the content for a clue of whether this document is a sitemap based on namespaces . works for xml and non - compressed documents only .
returns the host domain ip of a url so that it can be partitioned for politeness depending on the value of the config <i > partition . url . mode< / i > .
set the value for a given key . the value can be null .
returns the first non empty value found for the keys or null if none found .
returns the first available driver *
called by extensions of this class *
get a list of cookies based on the cookies string taken from response header and the target url .
helper method to check if url matches a cookie domain .
compose unique key to store and access robot rules in cache for given url
returns the robots rules from the cache or empty rules if not found
get the rules from robots . txt which applies for the given { @code url } . robot rules are cached for a unique combination of host protocol and port . if no rules are found in the cache a http request is send to fetch {{ protocol : // host : port / robots . txt }} . the robots . txt is then parsed and the rules are cached to avoid re - fetching and re - parsing it again .
called by the parser bolts
extracts meta tags based on the value of the content attribute *
adds a normalised representation of the directives in the metadata *
must be called by extending classes to store and collect in one go
try the rules from the hostname domain name metadata and global scopes in this order . returns true if the url should be removed false otherwise . the value returns the value of the first matching rule be it positive or negative .
this function does the replacements by iterating through all the regex patterns . it accepts a string url as input and returns the altered string . if the normalized url is an empty string the function will return null .
populates a list of rules off of jsonnode .
reads the configuration file and populates a list of rules .
basic filter to remove query parameters from urls so parameters that don t change the content of the page can be removed . an example would be a google analytics query parameter like utm_campaign which might have several different values for a url that points to the same content . this is also called when removing attributes where the value is a hash .
a common error to find is a query string that starts with an & instead of a ? this will fix that error . so http : // foo . com&a = b will be changed to http : // foo . com?a = b .
remove % encoding from path segment in url for characters which should be unescaped according to <a href = https : // tools . ietf . org / html / rfc3986#section - 2 . 2 > rfc3986< / a > as well as non - standard implementations of percent encoding see <https : // en . wikipedia . org / wiki / percent - encoding#non - standard_implementations > .
convert path segment of url from unicode to utf - 8 and escape all characters which should be escaped according to <a href = https : // tools . ietf . org / html / rfc3986#section - 2 . 2 > rfc3986< / a > ..
returns an s3 client given the configuration *
loads and configure the navigationfilters based on the storm config if there is one otherwise returns an emptynavigationfilters .
add an additional record format at given position
returns the amount of time to wait if the backend was queried too recently and needs throttling or - 1 if the backend can be queried straight away .
indicates whether enough time has elapsed since receiving the results of the previous query so that a new one can be sent even if the buffer is not empty . applies to asynchronous clients only .
loads and configure the parsefilters based on the storm config if there is one otherwise returns an emptyparsefilter .
append a node to the current container .
receive notification of ignorable whitespace in element content .
receive notification of a processing instruction .
report an xml comment anywhere in the document .
receive notification of cdata .
report the start of dtd declarations if any .
begin the scope of a prefix - uri namespace mapping .
set the {
parses the robots content using the { @link simplerobotrulesparser } from crawler commons
determine whether a document should be indexed based on the presence of a given key / value or the robotstags . robots_no_index directive .
returns a mapping field name / values for the metadata to index *
returns the value to be used as the url for indexing purposes if present the canonical value is used instead
returns a trimmed string or the original one if it is below the threshold set in the configuration .
/ * ( non - javadoc )
/ * ( non - javadoc )
returns the first matching custom interval
loads and configure the urlfilters based on the storm config if there is one otherwise returns an empty urlfilter .
returns a scheduler instance based on the configuration *
submits the topology with the name taken from the configuration *
submits the topology under a specific name *
converts excel rows into a list of objects
converts excel rows into a list of objects
converts excel rows into a list of objects
converts excel rows into a list of objects
converts excel rows into a list of objects
converts excel rows into a list of objects
converts excel rows into a list of objects
using this to hold inner objects that will be mapped to the main object *
* modified this method so that for each time it reads a cell it doesn t need to check all fields even after it as found the matching field
sets the number of items to be displayed on the wheel .
taken and modified from android source for api < 11
<p > sets the wheel s drawable that can also rotate with the items . < / p > <p > note if the drawable has infinite lines of symmetry then you should set the wheel drawable to not rotate see { @link #setwheeldrawablerotatable ( boolean ) } . in other words if the drawable doesn t look any different whilst it is rotating you should improve the performance by disabling the drawable from rotating . < / p >
sets the empty item drawable that is drawn when outside of the adapter range .
set the angle of the wheel instantaneously . note this does not animate to the provided angle .
checks to see if the selectedposition has changed .
invalidate the drawable at the specific position so that the next draw call will refresh the drawable at this given position in the adapter .
converts the raw position to a position within the wheel item bounds .
estimates the wheel s new angle and angular velocity
get the materials darker contrast
clamps the value to a number between 0 and the upperlimit
matches text against a wildcard pattern where ? is single letter and * is zero or more letters .
@return source loader that extracts source files
writes coverage data to json file .
/ * create new arraychar with given indeximpl and backing store . should be private .
copy from javaarray to storage using the iterator : used by factory ( object ) ;
trasfer data to a bytebuffer . note we cast char to byte discarding top byte if any . this is because cdm char is really a byte not a java char .
create a string out of this rank one arraychar object . if there is a null ( 0 ) value in the arraychar array the string will end there . the null is not returned as part of the string .
create a string out of this rank two arraychar object . this treats the arraychar as a 1d array of strings . if there is a null ( 0 ) value in the arraychar array the string will end there . the null is not returned as part of the string .
create a string out of this arraychar object . the rank must be 1 or greater . if there is a null ( 0 ) value in the arraychar array the string will end there . the null is not returned as part of the string . <p / > if rank = 1 then this will make a string out of the entire chararray ignoring ima . if rank is greater than 1 then make a string out of the characters of the last dimension indexed by ima . this method treats the chararray like an array of strings and allows you to iterate over them eg for a 2d arraychar : <p > <code > arraychar ca ; index ima = ca . getindex () ; for ( int i = 0 ; i<ca . getshape () [ 0 ] ; i ++ ) string s = ca . getstring ( ima . set0 ( i )) ; < / code >
set the arraychar values from the characters in the string . rank must be 1 . if string longer than arraychar ignore extra chars ; if shorter fill with 0 .
set the arraychar values from the characters in the string . rank must be 2 . this treats the arraychar as a 1d array of strings . if string val longer than arraychar ignore extra chars ; if shorter fill with 0 . <p / > <p > <code > string [] val = new string [ n ] ; arraychar ca ; index ima = ca . getindex () ; for ( int i = 0 ; i<n ; i ++ ) ca . setstring ( i val [ i ] ) ; < / code >
set the arraychar values from the characters in the string . rank must be 1 or greater . if string longer than arraychar ignore extra chars ; if shorter fill with 0 . if rank 1 set entire arraychar ignoring ima . if rank > 1 treat the arraychar like an array of strings of rank - 1 and set the row indexed by ima . for example rank 3 : <p > <code > string [] [] val ; arraychar ca ; index ima = ca . getindex () ; int rank0 = ca . getshape () [ 0 ] ; int rank1 = ca . getshape () [ 1 ] ; <p / > for ( int i = 0 ; i<rank0 ; i ++ ) for ( int j = 0 ; j<rank1 ; j ++ ) { ima . set ( i j ) ; ca . setstring ( ima val [ i ] [ j ] ) ; } < / code >
make this into the equivilent 1d arrayobject of strings .
create an arraychar from a string
create an arraychar from an arrayobject of strings .
create an arraychar from an arrayobject of strings . inverse of make1dstringarray . copies the data .
dot product of matrix and vector : return m dot v
matrix multiply : return m1 * m2 .
matrix multiply by a diagonal matrix store result in this : this = this * diag
reference time is the start time of the first forecast other forecasts at 6 - hour intervals . number in ave = number of forecast used
see http : // www . nco . ncep . noaa . gov / pmb / docs / grib2 / grib2_doc . shtml
overrides the gisfeaturerenderer draw () method to draw contours and with contour labels .
show the window .
show if not iconified
all the work is here so can be called recursively
for the compressed data read all out into a array and then parse into requested
compute the size of the file without writing
write a netcdf / cf file from a griddataset
write equivilent uncompressed version of the file .
count the number of records in a grib1 file .
factory method for constructing a unitname from a name and a plural form of the name .
factory method for constructing a unitname from a name a plural form of the name and a symbol .
returns the plural form of a name . regular rules are used to generate the plural form .
choose a resolution based on # seconds
determine if the given date is included in this date range . the date range includes the start and end dates .
determine if the given range intersects this date range .
determine if the given range intersects this date range .
intersect with another date range
extend this date range by the given one .
extend this date range by the given date .
set the starting date . makes usestart true . if useend recalculate the duration else recalculate end .
set the ending date . makes useend true . if usestart recalculate the duration else recalculate start .
set the duration of the interval . makes useduration true . if usestart recalculate end else recalculate start .
assumes not moving
save all data in the persistentstore
add a mapbean to the user interface
actions that control the dataset
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and the specified x y index for lat - lon point .
/////////////////
entry point for the scanner . returns the token identifier corresponding to the next token and prepares to return the semantic value of the token .
entry point for error reporting . emits an error in a user - defined way . part of lexer interface .
open a netcdf dataset using netcdfdataset . defaultenhancemode plus coordsystems and turn into a dtcoveragedataset .
open a netcdf dataset using netcdfdataset . defaultenhancemode plus coordsystems and turn into a dtcoveragedataset .
the name of the dataset is the last part of the location
find the named geogrid .
find the named geogrid .
create a string of the parameters .
this returns true when the line between pt1 and pt2 crosses the seam . when the cone is flattened the seam is lon0 + - 180 .
/ * public projectionpoint latlontoproj ( latlonpoint latlon projectionpointimpl result ) { double tox toy ; double fromlat = latlon . getlatitude () ; double fromlon = latlon . getlongitude () ;
also see snyder p 101
/ * public latlonpoint projtolatlon ( projectionpoint world latlonpointimpl result ) { double tolat tolon ; double fromx = world . getx () - falseeasting ; double fromy = world . gety () - falsenorthing ; double rhop = rho ;
/ * proj + inv + proj = aea + lat_0 = 23 . 0 + lat_1 = 29 . 5 + lat_2 = 45 . 5 + a = 6378137 . 0 + rf = 298 . 257222101 + b = 6356752 . 31414 + lon_0 = - 96 . 0
a path is file if it has no base protocol or is file :
extension to access a raw byte stream
returns a clone of this <code > alias< / code > . see dapnode . clonedag ()
adapted from the package - private basicdayofmonthdatetimefield
adapted from the package - private basicdayofmonthdatetimefield
return y x ranges
wml2 : collection
wml2 : collection / wml2 : observationmember / om : om_observation
/////////////////////////////////////////////
/////////////////////////////////////////////
2006 - 10 - 23t17 : 59 : 39 18 . 415434 - 93 . 480526 - 26 . 8 1
set values on the ui
make it easy to test by using dimension list
register the given directory with the watchservice
process all events for keys queued to the watcher
copy on modify
register a class that implements a featuredatasetfactory .
register a class that implements a featuredatasetfactory .
register a class that implements a featuredatasetfactory . find out which type by calling getfeaturetype () .
open a dataset as a featuredataset .
wrap a netcdfdataset as a featuredataset .
determine if factory type matches wanted feature type .
try to determine the feature type of the dataset by examining its metadata .
read directly from file without going through the buffer . all reading goes through here or readtobytechannel ;
write an catalog to the httpservletresponse return the size in bytes of the catalog written to the response .
write a catalog in html make it look like a file directory .
public static final string unidata_css
public static final string unidata_head
if a catalog exists and is allowed ( not filtered out ) for the given path return the catalog as an catalog . otherwise return null . <p > the validity of the returned catalog is not guaranteed . use catalog . check () to check that the catalog is valid .
barfola on the return type
rigamorole to modify invariant catalogs ; we may need to add global services
initialize the httpclient layer .
get the content from a url . for large returns its better to use getresponseasstream .
put content to a url using http put . handles one level of 302 redirection .
////////////////////
performs the relatove operation ( relop ) indicated by the parameter <code > oprtr< / code > on the 2 passed basetypes if appropriate . <p / > obviously some type don t compare logically such as asking if string is less than a float . for these non sensical operations and <code > invalidoperatorexception< / code > is thrown .
******************************************************************************************
------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------
capabilities processors
isolate front page builder so we can override if desired for testing .
///////////////////////////////////////////////////////////////////////
this catalog lists the individual files comprising the collection .
see top javadoc for possible urls
///////////////////////////////////
look how come we arent using metadataextractor ??
returns visitor . obtain () either a griddataset or a netcdfdataset
/ * case 0 : path / dataset ( dataset = ) // single dataset case 1 : path / dataset ( dataset = best twod tp ) // single group case 2 : path / dataset / groupname // dataset with group case 3 : path / groupname // single dataset not sure this is actually used ??
kinda kludgey but trying not keep urls stable
cannot do approx equals and be consistent with hashcode so make seperate call
factory method for constructing an identifier from a name plural and symbol .
parse an attribute spec
read the header of input file and parsing the nowrad part
read and parse the header of the nids / tdwr file
construct a raster dataset for nids raster products ;
parsing the product information into netcdf dataset
convert two short into a integer
convert bytes into integer
get jave date
set a static property . supported static properties : <ul > <li > syncextendonly = true : assume all file changes are syncextend only . < / ul >
should match makevalidnetcdfobjectname ()
convert a name to a legal netcdf - 3 name .
determine if the given name can be used for a dimension attribute or variable name . should match makevalidnetcdf3objectname .
read existing file
data reading
read data from record structure . for n3 this is the only possible structure and there can be no nesting . read all variables for each record put in bytebuffer .
read data from record structure that has been subsetted . read one record at at time put requested variable into arraystructurema .
protected hashmap dimhash = new hashmap ( 50 ) ;
write
update the value of an existing attribute . attribute is found by name which must match exactly . you cannot make an attribute longer or change the number of values . for strings : truncate if longer zero fill if shorter . strings are padded to 4 byte boundaries ok to use padding if it exists . for numerics : must have same number of values .
fill buffer with fill value
////////////////////////////////////////////////////////////////////////////////////////////
/ * @override public boolean sync () throws ioexception { if ( syncextendonly ) return syncextend () ;
read the data values ( parameters are ignored ) . use the start stop and stride values typically set by the constraint evaluator .
make the level values from the specifications
make a time struct from the index .
make a gradstimestruct from the calendar state
replace the time template parameters in a filename
does this file definition have a time template in it?
does the line between these two points cross the projection seam .
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert lat / lon coordinates to projection coordinates .
convert lat / lon coordinates to projection coordinates .
adds a function to the library . the function will be inspected to determine whether it is a boolean or basetype function .
retrieves a boolean function from the library . if the function is not found the library will attempt to load it using the mechanism described in the class documentation .
retrieves a basetype function from the library . if the function is not found the library will attempt to load it using the mechanism described in the class documentation .
tries to load a function with the given name .
look for aliases .
genprocess
/ levels
/ * <entry > <grib1id > 222< / grib1id > <fnmocid > mid_cld< / fnmocid > <name > mid_cld< / name > <description > middle cloud layer< / description > <status > deprecated< / status > < / entry >
build an unnamed invcatalog for this datasetsource and return the top - level invdataset . the resultservice for this datasetsource is used to create the invservice for the new invcatalog . each invdataset in the catalog is named with the location of the object they represent on the dataset source .
return a list of the invdatasets contained in the given collection dataset on this datasetsource .
gets parameter table then grib1 parameter based on number .
gets the levelname .
gets the leveldescription .
gets the levelunit .
gets the projectiontype .
is this a verticalcoordinate .
is this a layer?
/ * message coveragedataset { required string name = 1 ; repeated attribute atts = 2 ; required rectangle latlonrect = 3 ; optional rectangle projrect = 4 ; required calendardaterange timerange = 5 ;
/ * message rectangle { required double startx = 1 ; required double starty = 2 ; required double incx = 3 ; required double incy = 4 ; }
/ * message calendardaterange { required int64 start = 1 ; required int64 end = 2 ; required int32 calendar = 3 ; // calendar ordinal }
/ * message coverage { required string name = 1 ; // short name required datatype datatype = 2 ; optional bool unsigned = 3 [ default = false ] ; repeated attribute atts = 4 ; required string coordsys = 5 ; }
/ * message coordsys { required string name = 1 ; // must be unique in dataset s coordsys repeated string axisnames = 2 ; repeated string transformnames = 3 ; optional coveragetype coveragetype = 5 ; } }
/ * message coordtransform { required bool ishoriz = 1 ; required string name = 2 ; repeated attribute params = 3 ; }
/ * message coordaxis { required string name = 1 ; required datatype datatype = 2 ; required int32 axistype = 3 ; // ucar . nc2 . constants . axistype ordinal required int64 nvalues = 4 ; required string units = 5 ; optional bool isregular = 6 ; required double min = 7 ; // required ?? required double max = 8 ; optional double resolution = 9 ; }
public enum type { coverage curvilinear grid swath fmrc }
/ * message georeferencedarray { required string gridname = 1 ; // full escaped name . required datatype datatype = 2 ; optional bool bigend = 3 [ default = true ] ; optional uint32 version = 4 [ default = 0 ] ; optional compress compress = 5 [ default = none ] ; optional uint32 uncompressedsize = 6 ;
from http : // blog . eyallupu . com / 2011 / 11 / java - 7 - working - with - directories . html
register a class that implements a coordinate transform .
register a class that implements a coordinate transform .
register a class that implements a coordinate transform .
make a coordinatetransform object from the parameters in a coordinate transform variable using an intrinsic or registered coordtransbuilder .
create a dummy coordinate transform variable based on the given coordinatetransform . this creates a scalar variable with dummy data and adds the parameters of the coordinatetransform as attributes .
make a coordinatetransform object from the parameters in a gridcoordtransform using an intrinsic or registered coordtransbuilder .
fires a propertychangeevent : <ul > <li > propertyname = dataset or file getnewvalue () = invdataset chosen . <li > propertyname = datasets getnewvalue () = invdataset [] chosen . this can only happen if you have set doresolve = true and the resolved dataset is a list of datasets . <li > propertyname = invaccess getnewvalue () = invaccess chosen . < / ul >
wrap this in a jdialog component .
standalone application .
get the 1d vertical coordinate array for this time step and point
//////////////
private metadatamanager mm ;
iterate through the observations
************************************************************************ default handler for opendap . html requests . returns an html form and javascript code that allows the user to use their browser to select variables and build constraints for a data request . the dds and das for the data set are used to build the form . the types in opendap . servlet . www are integral to the form generation .
************************************************************************ gets a dds for the specified data set and builds it using the class factory in the package <b > opendap . servlet . www< / b > . <p / > currently this method uses a deprecated api to perform a translation of dds types . this is a known problem and as soon as an alternate way of achieving this result is identified we will implement it . ( your comments appreciated! )
/ * take from degrib repository : http : // slosh . nws . noaa . gov / pubview / degrib / src / degrib / metaname . c?root = degrib&view = markup apparently for center 8 subcenter 0 and subcenter 255 ( ! )
throws unsupportedoperationexception unless the time zone is utc
encode an array of primitive values .
write out a prefix count
write out an array of atomic values
write out a set of bytes
deliberate choke point for debugging
check if this is a point datatype . if so a tableanalyser is used to analyze its structure . the tableanalyser is reused when the dataset is opened . <ol > <li > can handle any_point featuretype . <li > must have time lat lon axis ( from coordsysbuilder ) <li > call tableanalyzer . factory () to create a tableanalyzer <li > tableanalyzer must agree it can handle the requested featuretype < / ol >
************************************************************************* this method is used to convert special characters into their actual byte values . <p / > for example in a url the space character is represented as %20 this method will replace that with a space charater . ( a single value of 0x20 )
************************************************************************* processes an incoming <code > httpservletrequest< / code > . uses the content of the <code > httpservletrequest< / code > to create a <code > reqstate< / code > object in that caches the values for : <ul > <li > <b > dataset< / b > the data set name . ( accessible using <code > setdataset () < / code > and <code > getdataset () < / code > ) < / li > <li > <b > ce< / b > the constraint expression . ( accessible using <code > setce () < / code > and <code > getce () < / code > ) < / li > <li > <b > requestsuffix< / b > the request suffix used by opendap dap2 to indicate the type of response desired by the client . ( accessible using <code > setrequestsuffix () < / code > and <code > getrequestsuffix () < / code > ) < / li > <li > <b > isclientcompressed< / b > does the requesting client accept a compressed response?< / li > <li > <b > servletconfig< / b > the <code > servletconfig< / code > object for this servlet . < / li > <li > <b > servername< / b > the class name of this server . < / li > <li > <b > requesturl< / b > the url that that was used to call thye servlet . < / li > < / ul >
************************************************************************* evaluates the ( private ) request object to determine if the client that sent the request accepts compressed return documents .
/ * # code table 4 . 2 - parameter number by product discipline and parameter category 0 0 estimated precipitation ( kg m - 2 ) 1 1 instantaneous rain rate ( kg m - 2 s - 1 ) 2 2 cloud top height ( m ) 3 3 cloud top height quality indicator ( code table 4 . 219 ) 4 4 estimated u - component of wind ( m / s ) 5 5 estimated v - component of wind ( m / s ) 6 6 number of pixel used ( numeric ) 7 7 solar zenith angle ( deg ) 8 8 relative azimuth angle ( deg ) 9 9 reflectance in 0 . 6 micron channel ( % ) 10 10 reflectance in 0 . 8 micron channel ( % ) 11 11 reflectance in 1 . 6 micron channel ( % ) 12 12 reflectance in 3 . 9 micron channel ( % ) 13 13 atmospheric divergence ( / s ) 14 14 cloudy brightness temperature ( k ) 15 15 clear - sky brightness temperature ( k ) 16 16 cloudy radiance ( with respect to wave number ) ( w m - 1 sr - 1 ) 17 17 clear - sky radiance ( with respect to wave number ) ( w m - 1 sr - 1 ) 18 18 reserved 19 19 wind speed ( m / s ) 20 20 aerosol optical thickness at 0 . 635 um 21 21 aerosol optical thickness at 0 . 810 um 22 22 aerosol optical thickness at 1 . 640 um 23 23 angstrom coefficient # 24 - 26 reserved 27 27 bidirectional reflectance factor ( numeric ) 28 28 brightness temperature ( k ) 29 29 scaled radiance ( numeric ) # 30 - 191 reserved # 192 - 254 reserved for local use 255 255 missing
stuff to do after ui is complete
assume that its done in the event thread
public griddatatype getfield () { return currentfield ; }
/ * table c - sub - centers for center 9 us nws field stations from bdgparm . f john halquist <john . halquist
order : num name desc unit
does not handle non - standard calendars
reletive error in position - grib numbers sometimes miscoded
/ * code table code table 3 . 2 - shape of the earth ( 3 . 2 ) 0 : earth assumed spherical with radius = 6 367 470 . 0 m 1 : earth assumed spherical with radius specified ( in m ) by data producer 2 : earth assumed oblate spheroid with size as determined by iau in 1965 ( major axis = 6 378 160 . 0 m minor axis = 6 356 775 . 0 m f = 1 / 297 . 0 ) 3 : earth assumed oblate spheroid with major and minor axes specified ( in km ) by data producer 4 : earth assumed oblate spheroid as defined in iag - grs80 model ( major axis = 6 378 137 . 0 m minor axis = 6 356 752 . 314 m f = 1 / 298 . 257 222 101 ) 5 : earth assumed represented by wgs84 ( as used by icao since 1998 ) 6 : earth assumed spherical with radius of 6 371 229 . 0 m 7 : earth assumed oblate spheroid with major or minor axes specified ( in m ) by data producer 8 : earth model assumed spherical with radius of 6 371 200 m but the horizontal datum of the resulting latitude / longitude field is the wgs84 reference frame
also see snyder p 101
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
/ * parse invocation interface
call this to parse a dds
call this to parse a das
call this to parse an error {} body
/ * use the initial keyword to indicate what we are parsing
/ * since there is no common parent class for basetype attribute and attributetable provide a type specific name getter .
initialize the file read in all the metadata ( ala dm_open )
initialize this reader . get the grid specific info
swap the grid header avoiding strings
read the grid
read an integer
for testing purposes
writes a constraint ows element out .
writes headers and service sections
takes all added operations and writes an operations metadata section .
look - needs to be a directory or maybe an mfile collection
read all the files in a directory and process them . files are sorted by filename .
read a log file .
initialize the file read in all the metadata ( ala dm_open )
initialize this reader . get the grid specific info
run the program
get the grid packing type
find the first grid with this name
read the data
unpack a packed grid
read packed data
unpack grib data packed into ints
read packed grib1 data using ucar . grib code
read packed grib2 data
for gempakgridreader
print out the navigation block so it looks something like this : <pre > grid navigation : projection : lcc angles : 25 . 0 - 95 . 0 25 . 0 grid size : 93 65 ll corner : 12 . 19 - 133 . 46 ur corner : 57 . 29 - 49 . 38 < / pre >
print out the analysis block so it looks something like this :
print out the grids .
list out the grid information ( aka gdinfo )
gb2_ornt <p / > this function checks the fields scanning mode flags and re - orders the grid point values so that they traverse left to right for each row starting at the bottom row . <p / > gb2_ornt ( kx ky scan_mode ingrid fgrid iret ) <p / > input parameters : kx int number of columns ky int number of rows scan_mode int grib2 scanning mode flag * ingrid float unpacked grib2 grid data <p / > output parameters : * fgrid float unpacked grid data * iret int return code - 40 = scan mode not implemented <p / > log : s . gilbert 1 / 04
convert bits ( nb ) to unsigned int .
get the next byte
adds a variable to the container .
coverity [ call_super ]
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
returns a clone of this <code > vector< / code > . see dapnode . clonedag ()
get calendar date from fields . uses utz time zone
create calendardate from a java . util . date . uses standard calendar .
create calendardate from msecs since epoch uses standard calendar .
create calendardate from msecs since epoch uses the given calendar .
get calendardate from iso date string
get calendardate from iso date string
get calendardate from udunit date string
/ * millisec ( periodtype . millis () ) second ( periodtype . seconds () ) minute ( periodtype . minutes () ) hour ( periodtype . hours () ) day ( periodtype . days () ) month ( periodtype . months () ) year ( periodtype . years () )
calendar date field
calendar date field
truncate the calendardate by zeroing all the fields that are less than the field . so 2013 - 03 - 01t19 : 30 becomes 2013 - 03 - 01t00 : 00 if the field is day
get difference between two calendar dates in given field units
/ * package access
create an atomic valued variable .
create an array of structures . warning : the underlying cdm code ( esp . netcdfdataset ) apparently does not support nested structure arrays ; so this code may throw an exception .
create a sequence . warning : the underlying cdm code ( esp . netcdfdataset ) apparently does not support nested sequence arrays .
invoked once on first request so that everything is available especially spring stuff .
setup for each request
controller entry point ( s )
reifiers
given a typical string insert backslashes before and \\ characters and control characters .
////////////////////////////////////////////////
convert a list of ucar . ma2 . range to a list of slice more or less the inverst of create cdmranges
test a list<range > against a list<dapdimension > to see if the range list represents the whole set of dimensions within the specified indices .
test a list<range > against a list<slice > to see if the range list is whole wrt the slices
test a list<range > against the cdm variable s dimensions to see if the range list is whole wrt the dimensions
netcdfdataset can wrap a netcdffile . goal of this procedure is to get down to the lowest level netcdffile instance .
test if any dimension is variable length
compute the shape inferred from a set of slices . effective means that any trailing vlen will be ignored .
extract as a long value from a ( presumably ) atomic typed array of values ; dataset position is presumed correct .
extract as a double value from a ( presumably ) atomic typed array of values ; dataset position is presumed correct .
convert an array of one type of values to another type
/ * static public ucar . ma2 . array arrayslice ( ucar . ma2 . array array section section ) throws dapexception { case it out . if ( !dapvar . getbasetype () . isstructtype () ) { // = > atomic type if ( dapvar . istoplevel () ) { simplest case : use createview but watch out for final vlen list<range > ranges = section . getranges () ; try { if ( cdmutil . hasvlen ( ranges )) return array . section ( ranges . sublist ( 0 ranges . size () - 2 )) ; else return array . section ( ranges ) ; } catch ( invalidrangeexception ire ) { throw new dapexception ( ire ) ; } } else throw new unsupportedoperationexception () ; // same as other cdm } else { // struct type assert ( array instanceof cdmarraystructure ) ; cdmarraystructure struct = ( cdmarraystructure ) array ; if ( dapvar . istoplevel () ) { build a new arraystructure containing the relevant instances . int [] shape = section . getshape () ; structuremembers sm = new structuremembers ( struct . getstructuremembers () ) ; arraystructurema slice = new arraystructurema ( sm shape ) ; cdmodometer odom = new cdmodometer ( dapvar . getdimensions () section . getranges () ) ; compute the number of structuredata instances we need long totalsize = section . computesize () ; list<structuremembers . member > mlist = sm . getmembers () ; structuredata [] newdata = new structuredata [ ( int ) totalsize ] ; for ( int i = 0 ; odom . hasnext () ; odom . next () i ++ ) { long recno = odom . index () ; structuredataw clone = new structuredataw ( sm ) ; newdata [ i ] = clone ; structuredata record = struct . getstructuredata (( int ) recno ) ; for ( int j = 0 ; j < mlist . size () ; j ++ ) { structuremembers . member m = mlist . get ( j ) ; clone . setmemberdata ( m record . getarray ( m )) ; } } return slice ; } else throw new unsupportedoperationexception () ; // same as other cdm } }
convert a section + variable to a constraint <p > <p > static public view sectiontoview ( cdmdsp dsp variable v section section ) throws dapexception { if ( section == null || section . getrank () == 0 ) return null ; // get the corresponding dapnode dapvariable dv = ( dapvariable ) dsp . getnode () . get ( v ) ; if ( dv == null ) throw new dapexception ( variable has no corresponding dap node : + v . getfullname () ) ; // get the structure path wrt dapdataset for dv // and use path plus the section to construct a constraint list<dapvariable > structpath = daputil . getstructurepath ( dv ) ; list<range > ranges = section . getranges () ; view view = new view ( dmr ) ; int next = 0 ; for ( int i = 0 ; i < structpath . size () ; i ++ ) { dv = structpath . get ( i ) ; int rank = dv . getrank () ; viewvariable vv = new viewvariable ( dv ) ; list<slice > slices = new arraylist<slice > ( rank ) ; for ( int j = 0 ; j < rank ; j ++ next ++ ) { if ( next > = ranges . size () ) throw new dapexception ( range :: rank mismatch ) ; range range = ranges . get ( next ) ; slice slice = new slice ( range . first () range . last () range . stride () ) . validate () ; slices . add ( slice ) ; } vv . setslices ( slices ) ; view . put ( dv vv ) ; } view . validate ( view . expand ) ; return view ; }
convert given value of this unit to the new unit . <em > note : the current value of this unit ignored the given value is used instead . this is different than ucar . units or simpleunit . < / em >
add the time amount to the given date return a new date .
multiplies this unit by another unit .
divides this unit by another unit .
divides this unit into another unit .
raises this unit to a power .
converts a numeric value from this unit to the underlying derived unit .
converts numeric values from this unit to the underlying derived unit .
converts a numeric value from the underlying derived unit to this unit .
returns the canonical string representation of the unit .
tests this class .
read the section of data described by want
/ * sectioniterable iterates over the source indexes corresponding to vindex s sparsearray . iosp : works because variable coordinate corresponds 1 - 1 to grib coordinate . gribcoverage : must translate coordinates to grib coordinate index . want . getshape () indicates the result array shape . sectioniterable . next ( int [] index ) is not used here .
/ * iterates using sectioniterable . next ( int [] index ) . the work of translating that down into partition heirarchy and finally to a gc is all in variableindexpartitioned . getdatarecord ( int [] index ) want . getshape () indicates the result array shape .
coordinate based subsetting for coverage
read all of the data records that have been added . the full ( x y ) record is read the reciever will subset the ( x y ) as needed .
double - check idiom for lazy initialization of instance fields . see effective java 2nd ed p . 283 .
subset
might need to override for efficiency
find the named service declared in the top level of this catalog .
resolve reletive uris using the catalog s base uri . if the uristring is not reletive then no resolution is done . this also allows baseuri to be a file : scheme .
retrieve string value ; only call if isstring () is true .
this method returns the gate size in meters
this method returns the starting gate in meters
this method returns the number of gates
read data from this record .
instances which have same content are equal . <p / > public boolean equals ( object oo ) { if ( this == oo ) return true ; if ( ! ( oo instanceof level2record )) return false ; return hashcode () == oo . hashcode () ; } <p / > / ** override object . hashcode () to implement equals . * public int hashcode () { if ( hashcode == 0 ) { int result = 17 ; result = 37 * result + elevation_num ; // result = 37 * result + cut ; // result = 37 * result + datatype ; hashcode = result ; } return hashcode ; } private volatile int hashcode = 0 ;
write a netcdfdataset as an ncml - g document to the specified stream .
/ * private element makereferencesys ( referencesystem referencesystem ) { element elem = new element ( referencecoordinatesystem thredds . client . catalog . catalog . ncmlns ) ; elem . setattribute ( name referencesystem . getname () ) ; elem . setattribute ( authority referencesystem . getauthority () ) ; if ( referencesystem . getreferencetype () ! = null ) elem . setattribute ( type referencesystem . getreferencetype () . tostring () ) ;
/////////////////////////////
deal with having components on more than one line
return the requested dataset if it is the ancestor dataset or an allowed descendant of the ancestor dataset otherwise return null . the given filter determines whether a dataset is allowed or not .
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and point
create a projectionrect from the given latlonrect . handles lat / lon points that do not intersect the projection panel .
////////////////////////////////////////////////////////////////////////////////////////////////////////
this converts udunits to ucum . <br > udunits : http : // www . unidata . ucar . edu / software / udunits / udunits - 1 / etc / udunits . dat http : // www . unidata . ucar . edu / software / udunits / udunits - 2 / udunits2 . html i worked with v 2 . 1 . 9 <br > ucum : http : // unitsofmeasure . org / ucum . html i worked with version : 1 . 8 $revision : 28894 $ <p / > <p > udunits supports lots of aliases ( short and long ) and plurals ( usually by adding s ) . these all get reduced to ucum s short and canonical - only units . <p / > <p > notes : <ul > <li > this method is a strictly case sensitive . the only udunits that should be capitalized ( other than acronyms ) are btu gregorian ... julian ... pi . <br > the only udunits that may be capitalized are celsius fahrenheit kelvin rankine . <li > for 10 to the ucum allows 10 * or 10^ . this method uses 10^ . <li > ntu becomes { ntu } . <li > psu or psu becomes { psu } . < / ul > <p / > return the udunits converted to ucum . null returns null . returns . throws exception if trouble .
this converts one udunits term ( perhaps with metric prefix ( es )) to the corresponding ucum string . if udunits is just metric prefix ( es ) this returns the prefix acronym ( s ) with { count } as suffix ( e . g . dkilo returns dk { count } ) . if this can t completely convert udunits it returns the original udunits ( e . g . kilobobs remains kilobobs ( to avoid exact becoming ect ) .
this converts ucum to udunits . <br > udunits : http : // www . unidata . ucar . edu / software / udunits / udunits - 1 / etc / udunits . dat http : // www . unidata . ucar . edu / software / udunits / udunits - 2 / udunits2 . html <br > ucum : http : // unitsofmeasure . org / ucum . html <p / > <p > ucum tends to be short canonical - only and strict . many ucum units are the same in udunits . <p / > <p > udunits supports lots of aliases ( short and long ) and plurals ( usually by adding s ) . this tries to convert ucum to a short common udunit units . <p / > <p > problems : <ul > <li > ucum has only deg no concept of degree_east|north|true|true . < / ul > <p / > <p > notes : <ul > <li > this method is a strictly case sensitive . <li > for 10 to the ucum allows 10 * or 10^ . this method uses 10^ . <li > { ntu } becomes ntu . <li > { psu } becomes psu . < / ul > <p / > return the ucum converted to udunits . null returns null . returns .
this converts one ucum term ( perhaps with metric prefix ( es )) ( to the corresponding udunits string . if ucum is just metric prefix ( es ) this returns the metric prefix acronym ( s ) with { count } as suffix ( e . g . dkilo returns dk { count } ) . if this can t completely convert ucum it returns the original ucum ( e . g . kilobobs remains kilobobs ( to avoid exact becoming ect ) .
reads the contents of { @code inputstream } into a hashmap . each key - value pair in the input will result in an entry in the map . <p / > the specified stream remains open after this method returns .
center name from table c - 1 or c - 11
center name from table c - 1 or c - 11
not supported by simplecatalogbuilder .
extract the lat / lon / alt bounding boxes from the dataset .
extract a list of data variables ( and their canonical names if possible ) from the dataset .
/////////////////////////////////////////////////////////////////////////////
create a calendardateunit from a calendar name and a udunit string = unit since calendardate
create a calendardateunit from a calendar and a udunit string = unit since calendardate
create a calendardateunit from a calendar a calendarperiod . field and a base date
inverse of makecalendardate
inverse of makeoffsetfromrefdate
//////////////////////////////////////////////////////////////////////////////////////////
/ * public java . io . file choosefile () { if ( !readok ) return null ; w . show () ;
allow user to select file then return the filename in canonical form always using / never \
returns the corresponding quantity dimension .
tests this class .
check if this is a valid sigmet - iris file for this ioserviceprovider .
open existing file and populate ncfile with it .
read some global data from sigmet file . the sigmet file consists of records with fixed length = 6144 bytes .
read stationname strings
define dimensions variables attributes in ncfile
fill all of the variables / attributes in the ncfile
read data from a top level variable and return a memory resident array .
read data from a top level variable of integer data type and return a memory resident array .
read data from a top level variable and send data to a writablebytechannel .
calculate radial elevation of each ray
calculate distance between sequential bins in a ray
calculate azimuth of a ray
calculate data values from raw ingest data
calculate time as hh : mm : ss
calculate of nyquist velocity
use the builder to make the vertical transform function
partitions can be removed ( ! )
write equivilent uncompressed version of the file .
set the debug flags
set how indexes are used for both open and sync
open the service provider for reading .
read the data for the variable
read one yx array
is this xy level missing?
the goal of parse () is to extract info from the underlying httprequest and cache it in this object . <p > in particular the incoming url needs to be decomposed into multiple pieces . certain assumptions are made : 1 . every incoming url is of the form ( a ) http ( s ) : // host : port / d4ts / or ( b ) http ( s ) : // host : port / d4ts / <datasetpath > ?query case a indicates that the front page is to be returned . case b indicates a request for a dataset ( or dsr ) and its value is determined by its extensions . the query may be absent . we want to extract the following pieces . 1 . ( in uri parlance ) the scheme plus the authority : http : // host : port 3 . the return type : depending on the last extension ( e . g . . txt ) . 4 . the requested value : depending on the next to last extension ( e . g . . dap ) . 5 . the suffix path specifying the actual dataset : datasetpath with return and request type extensions removed . 6 . the url path = servletpath + datasetpath . 7 . the query part .
get the x y bounding box in projection coordinates .
get the lat / lon coordinates of the midpoint of a grid cell using the x y indices
get horizontal bounding box in lat lon coordinates .
this reports how well different compression schemes would work on the specific data . should be renamed
call this when you have set all the sequence lengths .
flatten the structures into a 1d array of structures of length gettotalnumberofstructures () .
blank fill sbuff with blanks until position tabstop .
create a new string by padding the existing one with blanks to specified width . do nothing if length is already greater or equal to width .
format an integer value .
format a long value .
double value formatting with minimum number of significant figures in a specified width . this will try to do a reasonable job of getting a representation that has min_sigfig significant figures in the specified width . right now all it does is call d ( double d int min_sigfig ) and left pad out to width chars .
nicely formatted representation of bytes eg turn 5 . 636e7 into
show the value of a double to the significant figures
show the value of a double with specified number of decimal places
write the information as an xml document
write the information as an xml document
create the dataset description xml document from this griddataset
create the grid form xml document from this griddataset . used to create the grid html form cause i dont know xslt
/ * private list getdimensions ( ucar . nc2 . dt . griddataset gds ) { hashset dimhash = new hashset () ; list grids = gds . getgrids () ; for ( int i = 0 ; i < grids . size () ; i ++ ) { geogrid grid = ( geogrid ) grids . get ( i ) ; list dims = grid . getdimensions () ; for ( int j = 0 ; j < dims . size () ; j ++ ) { dimension dim = ( dimension ) dims . get ( j ) ; dimhash . add ( dim ) ; } } list list = arrays . aslist ( dimhash . toarray () ) ; collections . sort ( list ) ; return list ; }
display name plus the dimensions
/ * private element writecoordsys ( gridcoordsystem cs ) { element cselem = new element ( coordsys ) ; cselem . setattribute ( name cs . getname () ) ; list axes = cs . getcoordinateaxes () ; for ( int i = 0 ; i < axes . size () ; i ++ ) { coordinateaxis axis = ( coordinateaxis ) axes . get ( i ) ; element axiselem = new element ( axisref ) ; axiselem . setattribute ( name axis . getname () ) ; cselem . addcontent ( axiselem ) ; } list cts = cs . getcoordinatetransforms () ; for ( int j = 0 ; j < cts . size () ; j ++ ) { coordinatetransform ct = ( coordinatetransform ) cts . get ( j ) ; element elem = new element ( coordtransref ) ; elem . setattribute ( name ct . getname () ) ; cselem . addcontent ( elem ) ; } return cselem ; }
debug
perform sanity checks on a slice and repair where possible .
compute the number of elements in the slice . note that this is different from getstop () because stride is taken into account .
convert this slice to a string suitable for use in a constraint
take two slices and compose src wrt target assume neither argument is null . this code should match ucar . ma2 . section in thredds and dceconstraint . c in the netcdf - c library .
map ith element of one range wrt a target range
provide a simple dump of binary data
dump the contents of a buffer from 0 to position
find the earthellipsoid that matches this name .
find the earthellipsoid that matches this epsg id .
/ * message datacol { string name = 1 ; // fullname for top shortname for member datatype datatype = 2 ; section section = 3 ; bool bigend = 4 ; uint32 version = 5 ; bool isvlen = 7 ; uint32 nelems = 9 ;
///////////////////////////////////////////////////////////////////////////////////////////////////
top level vlen
vlen inside a structure
extract all a - href contained urls from the given url and return in list
extract text content from the given url and return in string
workaround for htmleditorkit . parser cant deal with content - encoding
look dataoutputstream uses big - endian
create the dataset description xml document from this griddataset
/ * private element writecoordsys ( gridcoordsystem cs ) { element cselem = new element ( coordsys ) ; cselem . setattribute ( name cs . getname () ) ; list axes = cs . getcoordinateaxes () ; for ( int i = 0 ; i < axes . size () ; i ++ ) { coordinateaxis axis = ( coordinateaxis ) axes . get ( i ) ; element axiselem = new element ( axisref ) ; axiselem . setattribute ( name axis . getname () ) ; cselem . addcontent ( axiselem ) ; } list cts = cs . getcoordinatetransforms () ; for ( int j = 0 ; j < cts . size () ; j ++ ) { coordinatetransform ct = ( coordinatetransform ) cts . get ( j ) ; element elem = new element ( coordtransref ) ; elem . setattribute ( name ct . getname () ) ; cselem . addcontent ( elem ) ; } return cselem ; }
add all ; replace old if has same name
remove an attribute by name .
remove an attribute by name ignoring case
get offsets from firstdate in units of timeunit
add an actionsource listener
add an actionvalue listener public void addactionvaluelistener ( actionvaluelistener l ) { lm . addlistener ( l ) ; } remove an actionvalue listener public void removeactionvaluelistener ( actionvaluelistener l ) { lm . removelistener ( l ) ; }
httpsessionattributelistener
use factory to obtain a esrishapefilerenderer . this caches the esrishapefile for reuse . <p / > implementation note : should switch to weak references .
read the value ( parameters are ignored ) .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
see if either coordinate is + / - infinite . this happens sometimes in projective geometry .
see if either coordinate in <code > pt< / code > is + / - infinite . this happens sometimes in projective geometry .
computes the shape of the largest possible <b > contiguous< / b > chunk starting at { @link #getcurrentcounter () } and with { @code numelems < = maxchunkelems } .
/ * public void setvalue ( nativelong value ) { getpointer () . setnativelong ( 0 value ) ; }
create a java . util . date from this udunits string .
create a java . util . date from a udunit or iso string .
get the origin date .
get the equivalent java . util . date .
create a date from this base unit and the given value .
create the equivalent value from this base unit and the given date . inverse of makedate .
make a standard gmt string representation from this unit and given value .
get the grid spacing in kilometers
add the dimensions associated with this coord sys to the netcdf file
add the variables to the netcdf file
add a coordinate axis
add a gaussian lat axis
make a projection and add it to the netcdf file
add the gds params to the variable as attributes
add coordinate system variable
make a lambertconformalconic projection
make a polarstereographic projection
make a mercator projection
rotatedlatlon
make a space view orthographic projection
make a eumetsat msg normalized geostationary projection projection . fake coordinates for now then see if this can be generalized .
curvilinearaxis
calculate the dx and dy from startx starty and projection .
calculate dx dy lat lon grid note : this assumes lo1 < lo2 and dx is positive going east
///////////////////////////////////////////////////////////////////////////
read a dataset element
read a dataset scan element
}
/ * metadataconverterif
this is only called for thredddsmetadata
write the catalog as an xml document to the specified stream .
/ * protected void writecat6inheritedmetadata ( element elem threddsmetadata tmi ) { if (( tmi . getdatatype () == null ) && ( tmi . getservicename () == null ) && ( tmi . getauthority () == null ) && ( tmi . getproperties () . size () == 0 )) return ;
get the type for the first level of this gridrecord
check if this is a valid file for this ioserviceprovider . you must make this method thread safe ie dont keep any state .
open existing file and populate ncfile with it . this method is only called by the netcdffile constructor on itself . the provided netcdffile object will be empty except for the location string and the ioserviceprovider associated with this netcdffile object .
add the global attributes .
read data from a top level variable and return a memory resident array . this array has the same element type as the variable and the requested shape .
writes an array of bytes to the compressed output stream . this method will block until all the bytes are written .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl . <p / > <h2 > important note< / h2 > this method overrides the basetype method of the same name and type signature and it significantly changes the behavior for all versions of <code > printval () < / code > for this type : <b > <i > all the various versions of printval () will only print a value or a value with declaration if the variable is in the projection . < / i > < / b > <br > <br > in other words if a call to <code > isproject () < / code > for a particular variable returns <code > true< / code > then <code > printval () < / code > will print a value ( or a declaration and a value ) . <br > <br > if <code > isproject () < / code > for a particular variable returns <code > false< / code > then <code > printval () < / code > is basically a no - op . <br > <br >
the relops interface defines how each type responds to relational operators . most ( all? ) types will not have sensible responses to all of the relational operators ( e . g . dint won t know how to match a regular expression but dstring will ) . for those operators that are nonsensical a class should throw invalidoperatorexception .
server - side serialization for opendap variables ( sub - classes of <code > basetype< / code > ) . this does not send the entire class as the java <code > serializable< / code > interface does rather it sends only the binary data values . other software is responsible for sending variable type information ( see <code > dds< / code > ) . <p / > writes data to a <code > dataoutputstream< / code > . this method is used on the server side of the opendap client / server connection and possibly by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
sets the unencoded name of the class instance .
write the variable s declaration in a c - style syntax . this function is used to create textual representation of the data descriptor structure ( dds ) . see <em > the opendap user manual< / em > for information about this structure .
print the variable s declaration . same as <code > printdecl ( os space true ) < / code > .
print the variable s declaration using <code > outputstream< / code > .
print the variable s declaration using <code > outputstream< / code > .
returns a clone of this <code > basetype< / code > . see dapnode . clonedag .
wml2 : collection / wml2 : observationmember / om : om_observation / om : resulttime / gml : timeinstant
tries to find the coordinate variable of the specified type .
tries to find the coordinate variable of the specified type which has the specified dimension as its firsst dimension
convert an errorresponse to the equivalent xml
convert an errorresponse to the equivalent dapexception .
return the list of dimensions that were created
make a new variable out of the list in values
create new variables as sections of ncvar
construct time coordinate from reftime variable
shave n bits off the float
write grib file to a netcdf4 file . experimental .
retrieve the set of enhancements that is associated with the given string . <p / > <table border = 1 > <tr > <th > string< / th > <th > enhancements< / th > < / tr > <tr > <td > all< / td > <td > convertenums convertunsigned applyscaleoffset convertmissing coordsystems< / td > < / tr > <tr > <td > none< / td > <td > &lt ; empty&gt ; < / td > < / tr > <tr > <td > convertenums< / td > <td > convertenums< / td > < / tr > <tr > <td > convertunsigned< / td > <td > convertunsigned< / td > < / tr > <tr > <td > applyscaleoffset< / td > <td > applyscaleoffset< / td > < / tr > <tr > <td > convertmissing< / td > <td > convertmissing< / td > < / tr > <tr > <td > coordsystems< / td > <td > coordsystems< / td > < / tr > <tr > <td > incompletecoordsystems< / td > <td > coordsystems< / td > < / tr > <tr > <td > true< / td > <td > alias for all < / td > < / tr > <tr > <td > scalemissingdefer< / td > <td > alias for none < / td > < / tr > <tr > <td > alldefer< / td > <td > convertenums coordsystems< / td > < / tr > <tr > <td > scalemissing< / td > <td > convertunsigned applyscaleoffset convertmissing< / td > < / tr > < / table >
enable file caching . call this before calling acquirefile () . when application terminates call netcdfdataset . shutdown () .
make netcdffile into netcdfdataset with given enhance mode
factory method for opening a dataset through the netcdf api and identifying its coordinate variables .
factory method for opening a dataset through the netcdf api and identifying its coordinate variables .
factory method for opening a dataset through the netcdf api and identifying its coordinate variables .
/ * enhancement use cases 1 . open netcdfdataset ( enhance ) . 2 . ncml - must create the netcdfdataset and enhance when its done .
same as opendataset but file is acquired through the file cache with defaultenhancemode without the need of setting the enhancemode via the signature . you still close with netcdfdataset . close () the release is handled automatically . you must first call initnetcdffilecache () for caching to actually take place .
/ * static public netcdfdataset acquiredataset ( filefactory fac string location set<enhance > enhancemode int buffer_size ucar . nc2 . util . canceltask canceltask object iospmessage ) throws ioexception {
factory method for opening a netcdffile through the netcdf api .
factory method for opening a netcdffile through the netcdf api . may be any kind of file that can be read through the netcdf api including opendap and ncml . <p > <p > this does not necessarily return a netcdfdataset or enhance the dataset ; use netcdfdataset . opendataset () method for that .
same as openfile but file is acquired through the file cache . you still close with netcdffile . close () the release is handled automatically . you must first call initnetcdffilecache () for caching to actually take place .
same as openfile but file is acquired through the file cache . you still close with netcdffile . close () the release is handled automatically . you must first call initnetcdffilecache () for caching to actually take place .
/ * open or acquire a netcdffile .
//////////////////////////////////////////////////////////////////////////////////
clear coordinate system metadata to allow them to be redone
retrieve the coordinateaxis with the specified axis type .
retrieve the coordinateaxis with the specified type .
retrieve the coordinatesystem with the specified name .
retrieve the coordinatetransform with the specified name .
close all resources ( files sockets etc ) associated with this dataset . if the underlying file was acquired it will be released otherwise closed .
////////////////////////////////////
add a coordinateaxis to the dataset by turning the variableds into a coordinateaxis ( if needed ) . also adds it to the list of variables . replaces any existing variable and coordinateaxis with the same name .
is this enhancement already done ?
generate the list of values from a starting value and an increment . will reshape to variable if needed .
set the data values from a list of strings .
make a 1d array from a list of strings .
show debug / underlying implementation details
/ * debugging : get the information from parsing
debugging
look : can we use cfpointwriter . commandline for cli parsing instead? would that break existing scripts?
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
when we dont know how many in the iteration
compute the linear index from the current odometer indices .
make mfileos7 if file exists otherwise return null
return the known servicetype that matches the given name ( ignoring case ) or null if the name is unknown .
return a servicetype that matches the given name by either matching a known type ( ignoring case ) or creating an unknown type .
/ * public void setcollection ( string filename ) throws ioexception { if ( filename . endswith ( gribcollection . idx_ext )) { openindex ( filename ) ; } else { opencollection ( filename ) ; } }
/ * public boolean writeindex ( formatter f ) throws ioexception { mcollection dcm = scancollection ( spec f ) ;
/ * private void checkruntimes ( formatter f ) { map<date datecount > runs = new hashmap<date datecount > () ; list<grib2parameterbean > params = param2beantable . getbeans () ; for ( grib2parameterbean pb : params ) { list<grib2recordbean > records = pb . getrecordbeans () ; for ( grib2recordbean record : records ) { date d = record . getbasetime () ; datecount dc = runs . get ( d ) ; if ( dc == null ) { dc = new datecount ( d ) ; runs . put ( d dc ) ; } dc . count ++ ; } }
////////////////////////////
get a list of all the features in the shapefile that intersect the specified bounding box . this requires testing every feature in the list created at construction so it s faster to just give a bounding box o the constructor if you will only do this once .
discretize elements of array to a lower resolution . for example if resolution = 100 . the value 3 . 14159265358979 will be changed to 3 . 14 .
_more_
create a netcdfdataset out of this netcdffile adding coordinates etc .
add all the content from another threddsmetadata
set specified type of documentation
remove all instances of specified type of documentation
/////////////////
how many more bytes are in this segment ?
convert a time unit to a calendarperiod grib1 and grib2 are the same ( ! )
prints the value of all variables in this vector . this method is primarily intended for debugging opendap applications and text - based clients such as geturl .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
write a subset of the data to a <code > dataoutputstream< / code > .
get the input stream to the given resource
is this my file?
/ * static public structuredata make ( string name string value ) { structuremembers members = new structuremembers ( ) ; structuremembers . member m = members . addmember ( name null null datatype . string new int [] { 1 } ) ; structuredataw sw = new structuredataw ( members ) ; array dataarray = array . factory ( datatype . string new int [] { 1 } ) ; dataarray . setobject ( dataarray . getindex () value ) ; sw . setmemberdata ( m dataarray ) ; return sw ; }
catalogcrawler . listener
register a class that implements a convention .
register a class that implements a convention .
breakup list of convention names in the convention attribute in cf compliant way .
build a list of conventions
get a coordsysbuilder whose job it is to add coordinate information to a netcdfdataset .
heres where the work is to identify coordinate axes and coordinate systems .
identify coordinate axes set varprocess . iscoordinateaxis = true . default is to look for those referenced by _coordinateaxes attribute . note coordinate variables are already identified .
identify coordinate systems set varprocess . iscoordinatesystem = true . default is to look for those referenced by _coordinatesystems attribute .
identify coordinate transforms set varprocess . iscoordinatetransform = true . default is to look for those referenced by _coordinatetransforms attribute ( or has a _coordinatetransformtype attribute done in varprocess constructor )
take previously identified coordinate axis and coordinate variables and make them into a coordinateaxis . uses the getaxistype () method to figure out the type if not already set .
take all previously identified coordinate systems and create a coordinatesystem object .
assign explicit coordinatesystem objects to variables .
make implicit coordinatesystem objects for variables that dont already have one by using the variables list of coordinate axes and any coordinatevariables for it . must be at least 2 axes . all of a variable s _coordinate variables_ plus any variables listed in a * __coordinateaxes_ * or * _coordinates_ * attribute will be made into an * _implicit_ * coordinate system . if there are at least two axes and the coordinate system uses all of the variable s dimensions it will be asssigned to the data variable .
if a variable still doesnt have a coordinate system use hueristics to try to find one that was probably forgotten . examine existing cs . create a subset of axes that fits the variable . choose the one with highest rank . it must have x y or lat lon . if so add it .
does this axis fit this variable . true if all of the dimensions in the axis also appear in the variable . if char variable last dimension is left out .
take all previously identified coordinate transforms and create a coordinatetransform object by calling coordtransbuilder . makecoordinatetransform () .
assign coordinatetransform objects to coordinate systems .
track coordinate variables
munge this catalog so the given dataset is the top catalog .
}
munge this catalog to remove any dataset that doesnt pass through the filter .
unread catalogrefs are always kept .
remove marked datasets
finish constructing after all elements have been added or modified . this routine will do any needed internal consistency work . its ok to call multiple times .
this converts a string [ units ] since [ isodate ] ( e . g . minutes since 1985 - 01 - 01 ) into a baseseconds ( seconds since 1970 - 01 - 01 ) and a factor ( minutes returns 60 ) . <br > so simplistically epochseconds = storedtime * factor + baseseconds . <br > or simplistically storedtime = ( epochseconds - baseseconds ) / factor .
this returns the factor to multiply by units data to get seconds data ( e . g . minutes returns 60 ) . this is used for part of dealing with udunits - style minutes since 1970 - 01 - 01 - style strings .
this parses n int values from s and stores results in resultsn ( or leaves items in resultsn untouched if no value available ) .
this converts an iso date time string ( [ - ] yyyy - mm - ddthh : mm : ss . ssszz : zz ) into a gregoriancalendar object . <br > it is lenient ; so jan 32 is converted to feb 1 ; <br > the t may be any non - digit . <br > the time zone can be omitted . <br > the parts at the end of the time can be omitted . <br > if there is no time the end parts of the date can be omitted . year is required . <br > this tries hard to be tolerant of non - valid formats ( e . g . 1971 - 1 - 2 1971 - 01 ) <br > as of 11 / 9 / 2006 no longer true : if year is 0 .. 49 it is assumed to be 2000 .. 2049 . <br > as of 11 / 9 / 2006 no longer true : if year is 50 .. 99 it is assumed to be 1950 .. 1999 . <br > if the string is too short the end of 1970 - 01 - 01t00 : 00 : 00 . 000z will be added ( effectively ) . <br > if the string is too long the excess will be ignored . <br > if a required separator is incorrect it is an error . <br > if the date is improperly formatted it returns null . <br > timezone z or is treated as - 00 : 00 ( utc / zulu time ) <br > timezones : e . g . 2007 - 01 - 02t03 : 04 : 05 - 01 : 00 is same as 2007 - 01 - 02t04 : 04 : 05
main .
static methods
servlet api ( selected )
invoked on first get so that everything is available especially spring stuff .
////////////////////////////////////////////////
for bufrmessageviewer
///////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
add value to the named counter . add counter if it doesnt already exist .
gets an instance of this database .
adds a prefix to the database .
tests this class .
for other behavior override this ; use comparexxx routines .
for use by the subclass
parser specific methods
attribute map utilities
add any reserved xml attributes to a node unchanged
attribute map utilities
attribute construction
abstract action definitions
this is called for <value > ... < / value >
/ * ( non - javadoc )
determine if a valid date range was specified
iterator interface extended
returns the <code > attribute< / code > which matches name .
returns the <code > attribute< / code > which matches name .
adds an attribute to the table . if the given name already refers to an attribute and the attribute has a vector value the given value is appended to the attribute vector . calling this function repeatedly is the way to create an attribute vector . <p / > the function throws an exception if the attribute is a container or if the type of the input value does not match the existing attribute s type and the <code > check< / code > parameter is true . use the <code > appendcontainer< / code > method to add container attributes .
adds an attribute to the table . if the given name already refers to an attribute and the attribute has a vector value the given value is appended to the attribute vector . calling this function repeatedly is the way to create an attribute vector . <p / > the function throws an exception if the attribute is a container or if the type of the input value does not match the existing attribute s type . use the <code > appendcontainer< / code > method to add container attributes .
create and append an attribute container to the table . a container is another <code > attributetable< / code > object .
create and append an attribute container to the table . a container is another <code > attributetable< / code > object .
add an alias to the current table . this method is used by the das parser to build aliases for the das . and the ddsxmlparser to add them to the ddx <p / > the new ( 9 / 26 / 02 ) dds requires the use of <code > addalias ( string string string ) < / code > and is the preffered way of representing the das information .
delete the attribute named <code > name< / code > . if the attribute has a vector value delete the <code > i< / code > th element of the vector .
print the attribute table on the given <code > printwriter< / code > .
print the attribute table on the given <code > outputstream< / code > .
returns a clone of this <code > attributetable< / code > . see dapnode . clonedag ()
subcenters
gen process
/ levels
returns { @code true } if this point is nearly equal to { @code that } . the near equality of points is determined using { @link misc#nearlyequals ( double double double ) } with the specified maxreldiff .
given a relative path as an array of path segments ( see { @link #getpathsegments ( string ) } return the path relative to the first path segment .
register a dsp using its class string name .
register a dsp class .
see if a specific dsp is registered
unregister dsp .
lazy instantiation .
get the time interval in units of gr . getpds () . gettimeunit ()
get interval size in units of hours . only use in gribvariable to decide on variable identity when intvmerge = false .
if this has a time interval coordinate get time interval
unit of vertical coordinate . from grib2 code table 4 . 5 . only levels with units get a dimension added
compute inferred information
recursive helper
parse an fqn and use it to trace to a specific object in a dataset . note that this is quite tricky in the face of backslash escapes . because of backslash escapes we cannot use the string . split function because it does appear to be possible to write a regexp that handles preceding backslashes correctly . instead we must parse character by character left to right . traversal into structs : in theory a map variable could point to a field of a structure . however in practice this will not work because we would need a specific instance of that field which means including dimension indices must be included starting from some top - level variable . we choose for now to make that illegal until such time as there is a well - defined meaning for this . note : this assumes the fqn is absolute ( i . e . starts with / ) .
sort the nodelist into prefix left to right order
sort helper
compare 2 tables print report .
stuff for iosp
debugging
check if this is a valid file for this ioserviceprovider .
open existing file and populate ncfile with it .
read data from a top level variable and return a memory resident array . this array has the same element type as the variable and the requested shape .
find first variable with given attribute name
find first variable with given attribute name and value . if not found search one level into structures .
find first variable with given attribute name and value
find first member variable in this struct with given attribute name and value
find structure variable of rank 2 with the 2 given dimensions ( or ) find structure variable of rank 1 with the 1 given dimension
find first nested structure
does this dataset have a record structure? netcdf - 3 specific
translate key to value
turn the key into a string and return the corresponding featuretype if any .
find the variable pointed to by key
find the dimension pointed to by key
find the dimension pointed to by key
get the coordinate value at the i j index .
larger than you would ever expect
get the coordinate values as a 1d double array in canonical order .
create a new coordinateaxis2d as a section of this coordinateaxis2d .
normal case : do something reasonable in deciding on the edges when we have the midpoints of a 2d coordinate .
experimental : for wrf rotated ( nmm e ) grids
experimental : for wrf rotated ( nmm e ) grids
bounds calculations
return index if only one match if no matches return - 1 if > 1 match return - nhits
return index of closest value to target
/ * private static void doit2 ( string spec string timepart formatter errlog ) { collectionspecparser specp = new collectionspecparser ( spec timepart errlog ) ; system . out . printf ( spec = %s timepart = %s%n%s%n spec timepart specp ) ; string err = errlog . tostring () ; if ( err . length () > 0 ) system . out . printf ( %s%n err ) ; system . out . printf ( ----------------------------------- %n ) ; }
sets the system of units . this must be called before any call to <code > instance () < / code > .
getname is deprecated because as the code below shows it has no consistent meaning . sometimes it returns the short name sometimes it returns the full name .
netcdfdataset can end up wrapping a variable in multiple wrapping classes ( e . g . variableds ) . goal of this procedure is to get down to the lowest level variable instance
add an action to the popup menu . note that the menuname is made the name value of the action .
add an action to the popup menu with an icon . note that the menuname is made the name value of the action .
add an action to the popup menu with an icon . note that the menuname is made the name value of the action .
add an action to the popup menu using a jcheckboxmenuitem . fetch the toggle state using : <pre > boolean state = ( boolean ) act . getvalue ( bamutil . state ) ; < / pre >
find the longest match .
return the known metadatatype that matches the given name ( ignoring case ) or null if the name is unknown .
return a metadatatype that matches the given name by either matching a known type ( ignoring case ) or creating an unknown type .
reading
all the work is here so can be called recursively
/ * read data subset from file for a variable return array or java primitive array .
recursive
/ * public static int setoffsets ( structuremembers members ) { int offset = 0 ; for ( structuremembers . member m : members . getmembers () ) { m . setdataparam ( offset ) ; offset + = m . getsizebytes () ;
/ * read data subset from file for a variable create primitive array .
old way
create a netcdfdataset out of this netcdffile adding coordinates etc .
old
////////////////////////////////////////////////////////////////////////////////////////////
sort specific
testing 1 - 2 - 3
finds the first occurrence of match in data .
/ * finds the first occurrence of match in data . @param data search in this byte block @param start start at data [ start ] @param max end at data [ start + max ] @return index into block of first match else - 1 if not found .
///////////////////////////////////////////////
this method removes the least popular picture ( s ) in the cache . it first removes those pictures which have been suggested for removal . and then it picks any it can find as many pictures are removed as nescessary untill there are less pictures in the cache than the settings . maxcache specifies . ( if maxcache is 0 then the enumeration finds no elements and we don t get an endless loop .
store an image in the cache
method to inspect the cache
method to stop all background loading
method to stop all background loading except the indicated file . returns whether the image is already being loaded . true = loading in progress false = not in progress .
listeners will receive columnadded () / columnremoved () event
removes <code > column< / code > from this column model . posts <code > columnremoved< / code > event . will do nothing if the column is not in this model .
moves the column from <code > oldindex< / code > to <code > newindex< / code > . posts <code > columnmoved< / code > event . will not move any columns if <code > oldindex< / code > equals <code > newindex< / code > .
returns an <code > enumeration< / code > of all the columns in the model .
returns the <code > tablecolumn< / code > object for the column at <code > columnindex< / code > .
adapted from jtable . createdefaultcolumnsfrommodel () .
static factory methods for creating httpmethod instances
common method creation code so we can isolate mocking
////////////////////////////////////////////////////////////////////////////////////////////
/ * extend variable { repeated partitionvariable partition = 100 ; repeated parameter vparams = 101 ; // not used yet }
/ * message partition { required string name = 1 ; // name is used in tds - eg the subdirectory when generated by timepartitioncollections required string filename = 2 ; // the gribcollection . ncx2 file required string directory = 3 ; // top directory optional uint64 lastmodified = 4 ; }
return an integer type value ( including long but not floats )
return a float type value
return an integer in range 1 .. max inclusive .
close all resources ( files sockets etc ) associated with this file .
do a bulk read on a list of variables and return a corresponding list of array that contains the results of a full read on each variable . todo : optimize to make only a single server call and cache the results .
primary read entry point . this is the primary implementor of variable . read .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
filesystem can t be re - created either .
this is the old gempak table not as precise
//////////////////////////////////
debug
get the 1d vertical coordinate array for this time step and point
used by coordinatend . makesparsearray ; not used by coordinatetime2d
////////////////////////////////////////////
reminder for subclasses to set this
convert cloud height to meters
/ * class fxy enelementname bufr_unit bufr_scale bufr_referencevalue bufr_datawidth_bits crex_unit crex_scale crex_datawidth 20 20009 general weather indicator ( taf / metar ) code table 0 0 4 code table 0 2
here is where agg variables get read
rest of stuff for construction / deserialization
set the number of colors in the colorscale .
/ * get the color at the given index or the missing data color .
set the data min / max interval . the color intervals are set based on this . a propertychangeevent is sent when this is called . currently the intervals are calculated in the following way ( where incr = ( max - min ) / ( n - 2 )) : <pre > <p / > edge data interval 0 min value < = min 1 min + incr min < = value < min + incr 2 min + 2 * incr min + incr < = value < min + 2 * incr ith min + i * incr min + ( i - 1 ) * incr < = value < min + i * incr n - 2 max min + ( n - 3 ) * incr < = value < max n - 1 max max < value n value = missingdatavalue < / pre >
prints the value of all variables in this vector . this method is primarily intended for debugging opendap applications and text - based clients such as geturl .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
/ * set the bounds of the world coordinates . the point ( world . getx () world . gety () ) is mapped to the lower left point of the screen . the point ( world . getx () + world . width () world . gety () + world . height () ) is mapped to the upper right corner . therefore if coords decrease as you go up world . height () should be negetive .
user must get this graphics2d and draw into it when panel needs redrawing
system - triggered redraw .
map world coords to screen coords .
given a session url authscope and a method url authscope indicate it the are compatible as defined as follows . the method authscope is <i > compatible< / i > with the session authscope if its host + port is the same as the session s host + port and its scheme is compatible where e . g . http is compatible with https . the scope realm is ignored .
given a session url authscope and a method url authscope return a new authscope that is the upgrade / merge of the other two . here upgrade changes the scheme ( only ) to move http - > https . assumes authscopecompatible () is true .
create an authscope from a uri ; remove any principal
compares gds for duplicates
indicates if this factor is the reciprocal of another factor .
wml2 : defaultpointmetadata / wml2 : defaulttvpmeasurementmetadata
see if the service base is reletive
gather context information for the given http request and return a log message appropriate for logging at the start of the request . <p / > <p > the following context information is gathered : <ul > <li > id - an identifier for the current thread ; < / li > <li > host - the remote host ( ip address or host name ) ; < / li > <li > userid - the id of the remote user ; < / li > <li > starttime - the system time in millis when this request is started ( i . e . when this method is called ) ; and< / li > <li > request - the http request e . g . get / index . html http / 1 . 1 . < / li > < / ul > <p / > <p > call this method at the start of each httpservlet doxxx () method ( e . g . doget () doput () ) or spring mvc controller handle () method .
gather context information for the current non - request thread and return a log message appropriate for logging . <p / > <p > the following context information is gathered : <ul > <li > id - an identifier for the current thread ; and< / li > <li > starttime - the system time in millis when this method is called . < / li > < / ul > <p / > <p > call this method only for non - request servlet activities e . g . during init () or destroy () .
api
return a catalog for the given directory .
find which index holds the value want
create an invmetadata content object from an xml document at a named url . the content object is an arraylist of cataloggenconfig instances .
create an invmetadata content object from an org . w3c . dom . element . the content object is an arraylist of cataloggenconfig instances .
serialize the invmetadata content object to a org . w3c . dom . element
validate the content object .
given a metadata jdom element return metadata content object ( arraylist of cataloggenconfig ) . <p / > from the given metadata jdom element build ( and return ) an arraylist of cataloggenconfig instances .
return a cataloggenconfig when given a cataloggenconfig jdom element .
return a datasetsource when given a datasetsource jdom element .
return a datasetnamer when given a datasetnamer jdom element .
return a datasetfilter when given a datasetfilter jdom element .
return a resultservice when given a resultservice jdom element .
create a cataloggenconfig jdom element
create a datasetsource jdom element
create a datasetnamer jdom element
create a datasetfilter jdom element
create a resultservice jdom element
return the value of the named flag . if it doesnt exist it will be added to the store and the menu with a value of false .
construct cascading pull - aside menus using the values of the debug flags in the preferences object .
recursive menu adding
add parameters from the table
make a parameter from the tokens
get the parameter for the given name
test
read in the bytes from the given inputstream and construct and return a string . closes the inputstream argument .
read the bytes in the given input stream .
get the input stream to the given resource
wml2 : defaultpointmetadata / wml2 : defaulttvpmeasurementmetadata / wml2 : uom
_more_
_more_
_more_
but we can define a stronger contract .
make the level values from the specifications
replace the ensemble template parameter in a filename
set extra information used by station obs datasets .
this reads through all the records in the dataset and constructs a list of recordpointobs or recordstationobs . it does not cache the data . <p > if stnidvname is not null its a stationdataset then construct a station hashmap of stationimpl objects . add the recordstationobs into the list of obs for that station .
register for propertychange events when the value of the field changes . when accept () is called you will get a new propertychangeevent ( this fldname oldvalue newvalue ) where the oldvalue newvalue will be string integer boolean etc .
see if edit value is valid put error message in buff .
get current value from editcomponent save to store . if different from old value fire propertychangeevent . return false if invalid format add error message to buff if not null .
see if this value is different from current accepted value ( using equals () ) ; if so set old value to accepted value then accepted value to this value .
/ * get value from store put value into editcomponent
the value in the store has changed : update the edit component send event if its different from previous
send propertychangeevent
an integer input field with an associated cdm . units label .
/ * this dorks with double . tostring () :
read the bit map array .
/ * message catalog { uint64 catid = 1 ; // sequence no string catlocation = 2 ; bool isroot = 3 ; uint64 lastread = 4 ; }
find the known dataformattype that matches the given name ( ignoring case ) or null if the name is unknown .
return a dataformattype for the given name by either matching a known type ( ignoring case ) or creating an unknown type .
gml : point
allow calling from outside
/ * 1 ) single runtime 1a timeoffset 1b time or timerange 1c none = constant runtime dataset 2 ) multiple runtimes 2a timeoffset = constant offset dataset 2b time ( not range ) = constant forecast dataset
returns a string representation of the variables value . this is really foreshadowing functionality for server types but as it may come in useful for clients it is added here . simple types ( example : dfloat32 ) will return a single value . dconstuctor and dvector types will be flattened . dstrings and durl s will have double quotes around them .
debugging flags . this is a way to decouple setting flags from particular implementations .
create the canonical form of the url . if the urlname starts with http : or https : change it to start with dods : otherwise leave it alone .
/ * parse the dds creating a tree of dodsv objects private arraylist parsedds ( dds dds ) throws ioexception { arraylist dodsvlist = new arraylist () ;
go thru the variables / structure - variables and their attributes and move to the proper groups .
utility to decompose a name
////////////////////////////////////////////////////////////////////////////////////////////
recursively make new variables : all new variables come through here
make a structure into a group if its scalar and all parents are groups
/ * private void addattributes ( string tablename attributetable atttable ) {
checks to see if this is netcdf char array .
if an equivilent shared dimension already exists use it else add d to shared dimensions . equivilent is same name and length .
construct list of dimensions to use
full name
get the dods data class corresponding to the netcdf data type . this is the inverse of converttonctype () .
get the netcdf data type corresponding to the dods data type . this is the inverse of converttododstype () .
get the netcdf data type corresponding to the dods basetype class . this is the inverse of converttododstype () .
get whether this is an unsigned type .
this does the actual connection to the opendap server and reading of the data . all data calls go through here so we can add debugging .
make a single call to the dods server to read all the named variable s data in one client / server roundtrip .
/ * this is for reading variables that are members of structures protected array readmemberdata ( ucar . nc2 . variable v section section boolean flatten ) throws ioexception invalidrangeexception { stringbuffer buff = new stringbuffer ( 100 ) ; buff . setlength ( 0 ) ;
debugging
get a gif file make it into an imageicon .
get a gif file make it into an image .
get a gif file make it into a cursor .
open a resource as a stream . first try classloader . getresourceasstream () . if that fails try a plain old fileinputstream () .
test
read data subset from randomaccessfile create primitive array of size layout . gettotalnelems . reading is controlled by the layout object .
read data subset from randomaccessfile place in given primitive array . reading is controlled by the layout object .
read data subset from positioningdatainputstream create primitive array of size layout . gettotalnelems . reading is controlled by the layout object .
read data subset from positioningdatainputstream place in given primitive array . reading is controlled by the layout object .
read data subset from bytebuffer create primitive array of size layout . gettotalnelems . reading is controlled by the layout object .
read data subset from bytebuffer place in given primitive array . reading is controlled by the layoutbb object .
copy data to a channel . used by ncstream . not doing structures correctly yet .
create 1d primitive array of the given size and type
create 1d primitive array of the given size and type fill it with the given value
convert byte array to char array assuming utf - 8 encoding
convert char array to byte array assuming utf - 8 encoding
convert byte array to char array
section reading for member data
look could be used in createview ??
/ * package
get the index th structuredata ( structuredataa ) object we need instances of structuredata to give to the user . we use structuredataa so we can centralize everything in this class . the total number of structuredata objects is dimsize .
get member databuffer of type string or char .
non - atomic cases
key interface method coming in from structuredataa .
utilities
compute the structuremembers object from a dapstructure . may need to recurse if a field is itself a structure
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl .
add this as a dimension to a netcdf file
test
construct a crawlabledataset for the given path using the crawlabledataset implementation indicated by the given class name .
normalize the given path so that it can be used in the creation of a crawlabledataset . this method can be used on absolute or relative paths .
implement gisfeature methods :
this is where persist () reads / writes files
add a nested dataset specified by an explicit netcdf element . enhance is handled by the reader so its always false here .
add a dataset scan
experimental
all elements are processed finish construction
make the list of datasets from explicit and scans .
open one of the nested datasets as a template for the aggregation dataset .
dataset factory so subclasses can override
all non - agg variables use a proxy to acquire the file before reading . if the variable is caching read data into cache now . if not caching variableenhanced . setproxyreader () is called .
this tracks dataset elements that have resource control attributes
add a point to the end of the line .
sets the previous line which makes up the multiline which this line is a part of . if prev is a cfline automatically connect the other line to this line as well .
sets the previous line which makes up the multiline which this line is a part of . if prev is a cfline automatically connect the other line to this line as well .
given a dataset variable and index automatically populates this line and returns it . if not found returns null .
gets the upper bounding box coordinate on the line .
gets the lower bounding box coordinate on the line .
validate this datasetfilter object . return true if valid false if invalid .
test whether the given dataset matches the filter criteria .
given a dataset and a group of filters return true if the group of filters indicates that the dataset should be accepted false if it should be rejected . <p / > to make filtering out a set of datasets as easy as allowing a set of datasets datasetfilter provides a dataset reject mode as well as a dataset accept mode . rejection of a dataset by any filter overrides acceptance by any number of filters . therefore to be accepted by the group a dataset needs to be accepted by at least one filter however rejection by a single filter will cause rejection by the group . <p / > if the filter group is empty the dataset will be accepted .
fdpoint remains open .
double - check idiom for lazy initialization of instance fields . see effective java 2nd ed p . 283 .
parse a constraint expression . variables in the projection are marked as such in the ceevaluator s serverdds instance . the selection subexpression is then parsed and a list of clause objects is built . <p / > the parser is located in opendap . servers . parsers . ceparser .
convenience wrapper for parseconstraint .
this function sends the variables described in the constrained dds to the output described by <code > sink< / code > . this function calls <code > parse_constraint () < / code > <code > basetype :: read () < / code > and <code > serverio :: serialize () < / code > .
evaluate all of the clauses in the clause vector .
mark all the variables in the dds either as part of the current projection ( when <code > state< / code > is true ) or not ( <code > state< / code > is false ) . this is a convenience function that provides a way to clear or set an entire dataset described by a dds with respect to its projection .
print all of the clauses in the clause vector .
amend the given netcdffile with metadata from hdf - eos structmetadata . all variables named structmetadata . n where n = 1 2 3 ... are read in and their contents concatenated to make the structmetadata string .
amend the given netcdffile with metadata from hdf - eos structmetadata
convert to shared dimensions
look if the wanted dimension is in the unknowndims list .
look for a group with the given name . recurse into subgroups if needed . breadth first
get inline content as a string else null if there is none
get the standard url with resolution if the url is reletive . catalog . resolveuri ( getunresolvedurlname () )
construct the standard thredds access uri for this dataset access method resolve if the uri is relative .
********************************************************************** parse the . ini file indicated by the <code > private string inifile< / code > .
********************************************************************** get the list of properties for the section <code > sectionname< / code > .
********************************************************************** get the named property from the current section .
********************************************************************** prints the inifile .
********************************************************************** set the section of the inifile that you wish to work with . this is persistent for the life of the object or until it s set again .
construct input fields based on projection class
changed 4 / 28 / 10 dmh : legal dods names are not same as legal javascript names so translate .
/ * void wwwoutput :: write_variable_entries ( das &das dds &dds ) { this writes the text variables : and then sets up the table so that the first variable s section is written into column two . _os << \ <tr > <td align = \ right \ valign = \ top \ > <h3 > <a href = \ dods_form_help . html#dataset_variables \ > variables : < / a > < / h3 > <td > ;
/ * void wwwoutput :: write_variable_attributes ( basetype * btp das &das ) { attrtable * attr = das . get_table ( btp - > name () ) ; don t write anything if there are no attributes . if ( !attr ) return ;
wml2 : collection / wml2 : observationmember / om : om_observation / om : featureofinterest / wml2 : monitoringpoint / sams : shape
adds the specified component to the layout using the specified constraint object .
invalidates the layout indicating that if the layout manager has cached information it should be discarded .
removes the specified component from the layout .
calculates the preferred size dimensions for the specified container given the components it contains . @param parent the container to be laid out
calculates the minimum size dimensions for the specified container given the components it contains .
lays out the specified container .
determine if this coordinatesystem can be made into a radialcoordsys .
determine if the coordinatesystem cs can be made into a gridcoordsys for the variable v .
get the maximum radial distance in km .
get the units of calendar time . to get a date from a time value call dateunit . getstandarddate ( double value ) . to get units as a string call dateunit . getunitsstring () .
debug
reads data for the given point ( earthlocation ) and if bounded is true returns data for the closest point within the grid for points outside of the grid
/ * ///////////////////////////////////////////////////// uses apache httpcomponents
uses apache commons httpclient
uses java . net
transform geographic earth coordinates to satellite view angle coordinate system also known as the intermediate coordinate system in cgms normalized geostationary projection .
transform satellite view angle coordinates known as the intermeidate coordinates in the cgms normalized geostationary projection to geographic earth coordinates .
transform view angle coordinates in the goes scan geometry frame to view angle coordinates in the geos scan geometry frame .
transform fractional fgf coordinates to ( longitude latitude ) .
transform fractional fgf coordinates to ( lamda theta ) radians .
transform integer fgf coordinates to ( longitude latitude ) of pixel center the ( i j ) pixel zero - based refers to the pixel center .
transform earth coordinates ( lon lat ) to fractional fgf coordinates .
transform pixel center earth coordinates ( lon lat ) to integer fgf coordinates .
transform ( lamda theta ) in radians to fractional fgf coordinates .
find sweep_angle_axis associated with a scan geometry
find scan geometry associated with sweep_angle_axis
set the list of runtime coordinates ; add any that are not already present and make an empty coordinatetimeabstract for it
open a ucar . nc2 . dt . pointobsdataset write out in cf point format .
write data from a ucar . nc2 . dt . pointobsdataset into cf point format .
open a ucar . nc2 . ft . pointfeaturecollection write out in cf point format .
write a ucar . nc2 . ft . pointfeaturecollection in cf point format .
get member data array of any type as an array . for more efficiency use getscalarxxx ( member ) or getjavaarrayxxx ( member ) is possible .
get member data array of any type as an object eg float double string etc .
get member data array of any type as an object eg float double string etc .
get scalar value as a float with conversion as needed . underlying type must be convertible to float .
get string value from rank 0 string or rank 1 char member array .
get member data of type structure .
get member data of type structure .
get arraysequence for a member of type sequence .
debugging
get the full heirarchical name of the dataset which has all parent collection names .
if this dataset has an authority and an id then the concatenation of them is the globally unique id .
get access element of the specified service type for this dataset . if more than one get the first one .
get access element that matches the given access standard url . match on a . getstandardurlname () .
find an immediate child dataset by its name .
get containing catalog .
get the metadata elements of the specified type .
find the named service declared in this dataset or one of its parents .
return the resource control value which indicates that only users with proper permission can access this resource . <p / > ??? not sure if the value indicates anything or just set or not set .
get variables from the specified vocabulary
private latlonpointimpl origin ; // why are we keeping this?
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert lat / lon coordinates to projection coordinates .
convert lat / lon coordinates to projection coordinates .
test
find all catalogref elements in the dataset tree formed by the given dataset list .
escape the characters necessary for a path to be valid for a url
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and point
add 1 to the size of the array for the given dimension . use linear average and interpolation to fill in the values .
add one element to the array by linear interpolation and extrapolation at the ends .
copy constructor - avoid clone !!
precalculate some stuff
compute the rho parameter
compute theta
get the scale at the given lat .
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert lat / lon coordinates to projection coordinates .
convert lat / lon coordinates to projection coordinates .
test
returns a string representation of the variables value . this is really foreshadowing functionality for server types but as it may come in useful for clients it is added here . simple types ( example : dfloat32 ) will return a single value . dconstuctor and dvector types will be flattened . dstrings and durl s will have double quotes around them .
/ * <xs : element ref = dc : title / > <xs : element ref = dc : creator / > <xs : element ref = dc : subject / > <xs : element ref = dc : description / > <xs : element ref = dc : publisher / > <xs : element ref = dc : contributor / > <xs : element ref = dc : date / > <xs : element ref = dc : type / > <xs : element ref = dc : format / > <xs : element ref = dc : identifier / > <xs : element ref = dc : source / > <xs : element ref = dc : language / > <xs : element ref = dc : relation / > <xs : element ref = dc : coverage / > <xs : element ref = dc : rights / > <! -- controlled vocabulary from dcmitype -- > <xs : element ref = dcmitype : dcmitype / >
testing
is this a valid file?
open the service provider for reading .
get the detail information
make a structure for the part
make the missing variable
make a variable from a gempakparmaeter
add on global attributes for all types
get the size of a particular station variable
make the station variables from a representative station
get a 1darray for the type and length
make a station variable
compute post - reduction state .
/ * return yystr after stripping away unnecessary quotes and backslashes so that it s suitable for yyerror . the heuristic is that double - quoting is unnecessary unless the string contains an apostrophe a comma or backslash ( other than backslash - backslash ) . yystr is taken from yytname .
/ * -------------------------------- . | print this symbol on yyoutput . | --------------------------------
parse input from the scanner that was specified at object construction time . return whether the end of the input was reached successfully .
generate an error message .
report on the debug stream that the rule yyrule is going to be reduced .
/ * the parse function allows the specification of a new stream in case one is reusing the parser
this parses then fills in the evaluator from the ast
compares this prefix against another prefixsymbol . the sort keys are decreasing length ( major ) and increasing lexicality ( minor ) .
compares this prefix against a string . the sort keys are decreasing length ( major ) and increasing lexicality ( minor ) .
read the dmr trimmed .
read an error chunk
reads the next byte of databuffer from the input stream . the value byte is returned as an <code > int< / code > in the range <code > 0< / code > to <code > 255< / code > . if no byte is available because the end of the stream has been reached the value <code > - 1< / code > is returned . this method blocks until input databuffer is available the end of the stream is detected or an exception is thrown . <p > operates by loading chunk by chunk . if an error chunk is detected then return errorexception ( which is a subclass of ioexception ) .
reads up to len databuffer of databuffer from the input stream into an array of databuffer . an attempt is made to read as many as len databuffer but a smaller number may be read . the number of databuffer actually read is returned as an integer .
read the size + flags header from the input stream and use it to initialize the chunk state
/ * <exp_codeflagtables_e > <no > 837< / no > <fxy > 002119< / fxy > <elementname_e > instrument operations< / elementname_e > <codefigure > 0< / codefigure > <entryname_e > intermediate frequency calibration mode ( if cal ) < / entryname_e > <status > operational< / status > < / exp_codeflagtables_e >
udunits
old version using dateformatter @param iso iso 8601 date string @return equivilent date
convert an iso formatted string to a calendardate . @param calt calendar may be null for default calendar ( calendar . getdefault () ) @param iso iso 8601 date string <pre > possible forms for w3c profile of iso 8601 year : yyyy ( eg 1997 ) year and month : yyyy - mm ( eg 1997 - 07 ) complete date : yyyy - mm - dd ( eg 1997 - 07 - 16 ) complete date plus hours and minutes : yyyy - mm - ddthh : mmtzd ( eg 1997 - 07 - 16t19 : 20 + 01 : 00 ) complete date plus hours minutes and seconds : yyyy - mm - ddthh : mm : sstzd ( eg 1997 - 07 - 16t19 : 20 : 30 + 01 : 00 ) complete date plus hours minutes seconds and a decimal fraction of a second yyyy - mm - ddthh : mm : ss . stzd ( eg 1997 - 07 - 16t19 : 20 : 30 . 45 + 01 : 00 )
does not handle non - standard calendars
wml2 : measurementtvp
reads a url or file in as a table .
reads an input stream containing lines of ascii in fixed width format . breaks each line into a set of fields ( space or comma delimited ) which may be string integer or double .
copy contents of src to target . skip ones that already exist ( by name ) . dimensions and variables are replaced with equivalent elements but unlimited dimensions are turned into regular dimensions . attribute doesnt have to be replaced because its immutable so its copied by reference .
transfer the objects in src group to the target group
copy attributes from src to target skip ones that already exist ( by name )
copy attributes from src to target skip ones that already exist ( by name )
find the group in newfile that corresponds ( by name ) with oldgroup
stn file must be in the same directory or one up
if a dat file
//////////////////////////////////////////////////////////////////
/////////////////////////////
finds the first instance of c at or after fromindex ( 0 .. ) in carray .
this includes hiascii / iso latin 1 / iso 8859 - 1 but not extensive unicode characters . letters are a .. z a .. z and #192 .. #255 ( except #215 and #247 ) . for unicode characters see java lang spec pg 14 .
returns a string where all occurences of <tt > oldch< / tt > have been replaced with <tt > newch< / tt > . this doesn t throw exceptions if bad values .
convert a string to an int . leading or trailing spaces are automatically removed . this accepts hexadecimal integers starting with 0x . leading 0 s ( e . g . 0012 ) are ignored ; number is treated as decimal ( not octal as java would ) . floating point numbers are rounded . this won t throw an exception if the number isn t formatted right . to make a string from an int use + i integer . tohexstring or integer . tostring ( i radix ) .
convert a string to a double . leading or trailing spaces are automatically removed . this accepts hexadecimal integers starting with 0x . whole number starting with 0 ( e . g . 012 ) is treated as decimal ( not octal as java would ) . this won t throw an exception if the number isn t formatted right .
this converts string representation of a long . leading or trailing spaces are automatically removed . this * doesn t * round . so floating point values lead to long . max_value .
this converts a double to a rational number ( m * 10^t ) . this is similar to math2 . mantissa and math2 . intexponent but works via string manipulation to avoid roundoff problems ( e . g . with 6 . 6260755e - 24 ) .
gets the beginning index of a geometry s points given the index of the geometry within the array .
gets the ending index of a geometry s points given the index of the geometry within the array .
************************************************************************ default handler for opendap ascii requests . returns opendap dap2 data in comma delimited ascii columns for ingestion into some not so opendap enabled application such as ms - excel . accepts constraint expressions in exactly the same way as the regular opendap dataserver .
throw exception if failure
throw exception if failure
creates seperate collection and index for each runtime .
see if edit value is valid put error message in buff .
get current value from editcomponent
set current value of editcomponent
return the string of entity id for the dorade image file
_more_
name : xyzell <p / > call xyzell ( a b xstat xstell ) <p / > purpose : computation of ellipsoidal coordinates xstell given the cartesian coordinates xstat <p / > parameters : in : a : semi - major axis of the reference r * 8 ellipsoid in meters b : semi - minor axis of the reference r * 8 ellipsoid in meters dxell ( 3 ) : translation components from the r * 8 origin of the cart . coord . system ( x y z ) to the center of the ref . ellipsoid ( in metres ) scell : scale factor between ref . ellipsoid r * 8 and wgs - 84 xstat ( 3 ) : cartesian coordinates ( m ) r * 8 out : xstell ( 3 ) : ellipsoidal coordinates r * 8 xstell ( 1 ) : ell . latitude ( radian ) xstell ( 2 ) : ell . longitude ( radian ) xstell ( 3 ) : ell . height ( m ) <p / > sr called : dmlmtv <p / > remarks : --- <p / > author : m . rothacher <p / > version : 3 . 4 ( jan 93 ) <p / > created : 87 / 11 / 03 12 : 32 last modified : 88 / 11 / 21 17 : 36 <p / > copyright : astronomical institute 1987 university of berne switzerland
---------------------------------------------------------------------- gast . f <p / > this subroutine computes the greenwich apparent siderial time angle given a utc date and time . <p / > parameter input parameters : inputs :
jday calculates the julian day number ( jd ) from the gregorian month day and year ( m d y ) . ( not valid before 10 / 15 / 1582 )
this subroutine is to transform the locations and velocities of the gps and leo satellites from the celestial inertial reference frame to the earth centered greenwich reference frame . the dummy arguments iyear month and iday are the calender year month and day of the occultation event . the dummy arguments ihour minute and sec are the utc time . reference : astronomical alamanus 1993 <p / > modified subroutine from dasheng s code .
---------------------------------------------------------------------- file spin . f <p / > this subroutine rotates vector v1 around vector vs at angle a . v2 is the vector after the rotation . <p / > <p / > parameter input parameters : v1 - vector to be rotated vs - vector around which to rotate v1 a - angle of rotation output parameters : v2 - output vector <p / > s . v . sokolovskiy url : svn : // ursa . cosmic . ucar . edu / trunk / src / roam / spin . f $ $id : spin . f 10129 2008 - 07 - 30 17 : 10 : 52z dhunt $ -----------------------------------------------------------------------
_more_
comparing api to others
read in lat / lon points one time for this class
clean up strings to be used for unit string
clean up strings to be used in netcdf object names
compare two names from tables trying to ignore superfulous characters .
the given unit is unitless .
return a url ready to use in a generated html page from a url that is either absolute or relative to the webapp context path . that is if relative it is relative to http : // server : port / thredds / . <p / > <p > for simplicity all relative urls are converted to urls that are absolute paths . for instance catalog . xml becomes / thredds / catalog . xml .
input is xml file with just the <featurecollection >
convert this gisfeature to a java . awt . shape using the default coordinate system mapping gisfeature ( x y ) - > screen ( x y ) . look still have to crossseam ()
convert this gisfeature to a java . awt . shape . the data coordinate system is assumed to be ( lat lon ) use the projection to transform points so project . latlontoproj ( gisfeature ( x y )) - > screen ( x y ) .
convert this gisfeature to a java . awt . shape . the data coordinate system is in the coordinates of dataproject and the screen is in the coordinates of displayproject . so : displayproject . latlontoproj ( dataproject . projtolatlon ( gisfeature ( x y ))) - > screen ( x y ) .
/ * taken from http : // www . nssl . noaa . gov / projects / mrms / operational / tables . php
use a factory so we can debug constructor calls
manage the compound id for variables
parse the dds creating a tree of dodsv objects . the root node is only a container ie it has no basetype . the darray object ( which has the dimension info ) becomes a field of the dodsv rather than being in the tree .
recursively build the dodsv tree . 1 ) put all variables into a dodsv 2 ) unravel dconstructors ( dsequence dstructure dgrid ) 3 ) for darray we put variable = elemtype and store the darray seperately not in the heirarchy .
parse the dds creating a tree of dodsv objects . the root node is only a container ie it has no basetype . the darray object ( which has the dimension info ) becomes a field of the dodsv rather than being in the tree .
recursively build the dodsv tree . 1 ) put all variables into a dodsv 2 ) unravel dconstructors ( dsequence dstructure dgrid ) 3 ) for darray we put variable = elemtype and store the darray seperately not in the heirarchy .
parse the das assign attribute tables to the dodsv objects . nested attribute tables are supposed to follow the tree we construct with dodsv so its easy to assign to correct dodsv .
search the immediate children for a basetype with given name .
find the dodsv object in the datavlist corresponding to the ddsv
return a child by index
//////////////////////////////////////////////////////////////////////////////
get the shape : length of variable in each dimension . a scalar ( rank 0 ) will have an int [ 0 ] shape .
get the parent group .
get the ith dimension .
find the index of the named dimension in this variable .
get the unit string for the variable . looks for the cdm . units attribute value
get shape as a section object .
create a new variable that is a logical subsection of this variable . no data is read until a read method is called on it .
create a new variable that is a logical subsection of this variable . no data is read until a read method is called on it .
create a new variable that is a logical slice of this variable by fixing the specified dimension at the specified index value . this reduces rank by 1 . no data is read until a read method is called on it .
create a new variable that is a logical view of this variable by eliminating the specified dimension ( s ) of length 1 . no data is read until a read method is called on it .
public by accident .
read a section of the data for this variable and return a memory resident array . the array has the same element type as the variable and the requested shape . note that this does not do rank reduction so the returned array has the same rank as the variable . use array . reduce () for rank reduction . <p / > <code > assert ( origin [ ii ] + shape [ ii ] * stride [ ii ] < = variable . shape [ ii ] ) ; < / code > <p / >
read a section of the data for this variable from the netcdf file and return a memory resident array .
read a section of the data for this variable from the netcdf file and return a memory resident array . the array has the same element type as the variable and the requested shape . note that this does not do rank reduction so the returned array has the same rank as the variable . use array . reduce () for rank reduction . <p / > if the variable is a member of an array of structures this returns only the variable s data in the first structure so that the array shape is the same as the variable . to read the data in all structures use ncfile . readsectionspec () . <p / > note this only allows you to specify a subset of this variable . if the variable is nested in a array of structures and you want to subset that use netcdffile . read ( string sectionspec boolean flatten ) ;
get the value as a string for a scalar variable . may also be one - dimensional of length 1 . may also be one - dimensional of type char which wil be turned into a scalar string .
non - structure - member variables .
public by accident do not call directly .
assume filled validated section
public by accident do not call directly .
/ * structure - member variable ; section has a range for each array in the parent stuctures ( s ) and for the variable . private array _readmemberdata ( list<range > section boolean flatten ) throws ioexception invalidrangeexception { / * variable usevar = ( iovar ! = null ) ? iovar : this ; netcdffile usefile = ( ncfileio ! = null ) ? ncfileio : ncfile ; return usefile . readmemberdata ( usevar section flatten ) ; }
get the display name plus the dimensions eg float name ( dim1 dim2 )
get the display name plus the dimensions eg float name ( dim1 dim2 )
get the display name plus the dimensions eg name ( dim1 dim2 )
add display name plus the dimensions to the stringbuffer
add display name plus the dimensions to the stringbuffer
cdl representation of a variable .
string representation of variable and its attributes .
set the data type
set the shape with a list of dimensions . the dimensions may be shared or not . dimensions are in order slowest varying first . send a null for a scalar . technically you can use dimensions from any group ; pragmatically you should only use dimensions contained in the variable s parent groups .
use when dimensions have changed to recalculate the shape .
set the dimensions using the dimensions names . the dimension is searched for recursively in the parent groups .
reset the dimension array . anonymous dimensions are left alone . shared dimensions are searched for recursively in the parent groups .
set the dimensions using all anonymous ( unshared ) dimensions
replace a dimension with an equivalent one .
will this variable be cached when read . set externally or calculated based on total size < sizetocache . <p > this will always return { @code false } if { @link #permitcaching caching isn t permitted } .
set the data cache
get list of dimensions including parents if any .
calculate if this is a classic coordinate variable : has same name as its first dimension . if type char must be 2d else must be 1d .
you must set earthlocation before you call this .
call after adding all runs
//////////////////////////////////////
get all datasets contained directly in this catalog
a path is a synthetic path if it ends in . dmr or . syn
provide an extra api for use in testing
track generic cdmnode < - > dapnode
track variable < - > dapvariable
track variable < - > dapstructure
track variable < - > dapsequence
extract the metadata from the netcdfdataset and build the dmr .
actions
declaration builders
/ * create a sequence from a variable with a variable length last dimension . suppose we have cdm equivalent to this : t var [ d1 ] ... [ dn ]] [ * ] we convert to the following <sequence name = var > <t name = var / > <dim name = d1 / > ... <dim name = dn / > < / sequence >
walk this variable including fields to construct sequence types for any contained vlen dimensions
assign dimensions to a variable
unfortunately the cdm iosp does not actually use the declared enums . rather for every enum type d variable a new enum decl is defined . so we need to find the original enum decl that matches the variable s enum .
////////////////////////////////////////////////
strip vlen dimensions from a set of dimensions
some attributes that are added by the netcdfdataset need to be kept out of the dmr . this function defines that set .
/////////////
prints the original string representation of this clause . for use in debugging .
gml : description
open the file and extract bufr messages
convert one message ino a netcdfdataset and print data
iterate through the observations
private arrayint . d1 parentarray = new arrayint . d1 ( 1 ) ;
write a ucar . nc2 . ft . pointfeaturecollection in cf point format .
open a ucar . nc2 . dt . pointobsdataset write out in cf point format .
get handles the case where its a remote url ( dods or http )
post handles uploaded files
///////////////////////////////////////////////////////////////////////////////////
get the affine transform based on screen size and world bounding box
calculate if we want to rotate based on aspect ratio
calculate an affine transform based on the display size parameters - used for printing . @param rotate should the page be rotated? @param displayx upper right corner of display area @param displayy upper right corner of display area @param displaywidth display area @param displayheight display area
get current maparea .
convert a world coordinate to a display point
convert screen rectangle to a projection ( world ) rectangle
convert a projection ( world ) rectangle to a screen rectangle
call this to change the center of the screen s world coordinates . deltax deltay in display coordinates
call this to zoom into a subset of the screen . startx starty are the upper left corner of the box in display coords width height the size of the box in display coords
adjust bounding box to fit inside the screen size
add a listener .
remove a listener .
send an event to all registered listeners . if an exception is thrown remove the listener from the list
send an event to all registered listeners except the named one .
ncdump that parses a command string .
ncdump parsing command string file already open .
ncdump - like print of netcdf file .
ncdump - like print of netcdf file .
ncdump - like print of netcdf file .
print all the data of the given variable .
print a section of the data of the given variable .
print contents of a structuredata .
print array as undifferentiated sequence of values .
print array to printwriter
write the ncml representation for a file . note that ucar . nc2 . dataset . ncmlwriter has a jdom implementation for complete ncml . this method implements only the core ncml for plain ole netcdf files .
main program . <p > <strong > ucar . nc2 . ncdumpw filename [ - cdl | - ncml ] [ - c | - vall ] [ - v varname1 ; varname2 ; .. ] [ - v varname ( 0 : 1 : 12 ) ] < / strong > <p > where : <ul > <li > filename : path of any cdm readable file <li > cdl or ncml : output format is cdl or ncml <li > - vall : dump all variable data <li > - c : dump coordinate variable data <li > - v varname1 ; varname2 ; : dump specified variable ( s ) <li > - v varname ( 0 : 1 : 12 ) : dump specified variable section < / ul > default is to dump the header info only .
/ * from cf : false_easting ( false_northing ) : the value added to all abscissa ( ordinate ) values in the rectangular coordinates for a map projection . this value frequently is assigned to eliminate negative numbers . expressed in the unit of the coordinate variable identified by the standard name projection_x_coordinate ( projection_y_coordinate ) .
read a variable attribute as a double .
read an attribute as double [ 2 ] . if only one value make second same as first .
add a parameter to a coordinatetransform . make sure that the variable exists . if readdata is true read the data and use it as the value of the parameter otherwise use the variable name as the value of the parameter .
get the earth radius in km from the attribute earth_radius . normally this is in meters convert to km if its > 10 000 . use earth . getradius () as default .
try problem logs
* finish constructing after all elements have been added .
////////////////////////////////////////////////////////////////////////////
datacursor api ( except as implemented in abstractcursor )
support methods
allow specification of basetype to use ; used for enumerations
d4cursor extensions
actions that control the dataset
the actions can then be attached to buttcons menus etc
save all data in the persistentstore
/ * private boolean choosedataset ( string url ) { invdataset invds = new invdatasetimpl ( fname servertype . netcdf ) ; return choosedataset ( invds ) ; }
assume that its done in the event thread
/ * private void drawv ( boolean immediate ) { if ( !startok ) return ; scaledpanel drawarea = vertpanel . getdrawarea () ; graphics2d gv = drawarea . getbufferedimagegraphics () ; if ( gv == null ) return ;
gets parameter table then grib1 parameter based on number .
is this a positiveup verticalcoordinate .
wml2 : collection / wml2 : observationmember / om : om_observation / om : observedproperty
construct the action that is called when this bean s menu item / buttcon is selected . typically this routine is only called once when the bean is added . the action itself is called whenever the menu / buttcon is selected .
convenience routine to make a button with a popup menu attached . to use : <pre > thredds . ui . popupmenu mapbeanmenu = mapbean . makemapselectbutton () ; abstractbutton butt = ( abstractbutton ) mapbeanmenu . getparentcomponent () ; addtomenu ( butt ) ;
converts numeric values from this unit to another unit .
converts numeric values from this unit to another unit .
indicates if numeric values in this unit are convertible with another unit .
returns a label for a quantity in this unit .
wml2 : collection / wml2 : observationmember / om : om_observation / om : featureofinterest / wml2 : monitoringpoint
given a variable name and a beginning index and end index returns a list of polygon ( inclusive on both sides )
given a variable name and a beginning index and end index returns a list of lines ( inclusive on both sides )
given a variable name and a beginning index and end index returns a list of points ( inclusive on both sides )
position file at bitoffset from startpos
read the next nb bits and return an unsigned long .
read the next nb bits and return an signed long .
open a connection to the dods server .
returns the das object from the dataset referenced by this object s url . the das object is referred to by appending . das to the end of a dods url .
returns the dds object from the dataset referenced by this object s url . the dds object is referred to by appending . dds to the end of a opendap url .
use some sense when assembling the ce . since this dconnect object may have constructed using a ce any new ce will have to be integrated into it for subsequent requests . try to do this in a sensible manner!
alternate interface to getcompletece ( string ce )
returns the dds object from the dataset referenced by this object s url . the dds object is referred to by appending . ddx to the end of a opendap url . the server should send back a ddx ( a dds in xml format ) which will get parsed here ( locally ) and a new dds instantiated using the ddsxmlparser .
returns the datadds object from the dataset referenced by this object s url . the dds object is referred to by appending . ddx to the end of a opendap url . the server should send back a ddx ( a dds in xml format ) which will get parsed here ( locally ) and a new dds instantiated using the ddsxmlparser .
returns the datadds object from the dataset referenced by this object s url . the dds object is referred to by appending . ddx to the end of a opendap url . the server should send back a ddx ( a dds in xml format ) which will get parsed here ( locally ) and a new dds instantiated using the ddsxmlparser .
returns the data object from the dataset referenced by this object s url given the constraint expression ce . note that the data object is really just a dds object with data bound to the variables . the dds will probably contain fewer variables ( and those might have different types ) than in the dds returned by getdds () because that method returns the entire dds ( but without any data ) while this method returns only those variables listed in the projection part of the constraint expression . <p > note that if ce is an empty string then the entire dataset will be returned unless a sticky ce has been specified in the constructor .
returns the data object from the dataset referenced by this object s url given the constraint expression ce . note that the data object is really just a dds object with data bound to the variables . the dds will probably contain fewer variables ( and those might have different types ) than in the dds returned by getdds () because that method returns the entire dds ( but without any data ) while this method returns only those variables listed in the projection part of the constraint expression . <p > note that if ce is an empty string then the entire dataset will be returned unless a sticky ce has been specified in the constructor .
does the line between these two points cross the projection seam .
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint
returns the points at which { @code projbb } intersects the map edge .
returns the points at which the line { @code x = x0 } intersects the map edge .
returns the points at which the line { @code y = y0 } intersects the map edge .
reference date ( octet 13 - 17 ) . reference time of data  date and time of start of averaging or accumulation period .
/ * ncep appendix c manual 388 http : // www . nco . ncep . noaa . gov / pmb / docs / on388 / appendixc . html states that if the pds is > 28 bytes and octet 41 == 1 then it s an ensemble an product .
: title = wpdn data : selected by ob time : time range from 1207951200 to 1207954800 ;
this code tweaks our catalog output to match .
present and 14 days .
wml2 : collection / wml2 : observationmember / om : om_observation / om : phenomenontime
check basic dmsp file validity of given random access file .
read the header information from the file into name / value pairs .
parse the file header information about the file ( e . g . file id dataset id record size number of records ) and create netcdf attributes and dimensions where appropriate .
parse the processing / history information from the header .
parse the satellite information from the header .
parse the sensor information from the header .
return a string containing the header name / value pairs .
read an xml document from a url and return the root element .
make sure that text is xml safe
check if this is a valid file for this ioserviceprovider .
open existing file and populate ncfile with it . this method is only called by the netcdffile constructor on itself . the provided netcdffile object will be empty except for the location string and the ioserviceprovider associated with this netcdffile object .
add the global attributes .
read all the data and return the number of strokes
read all the data and return the number of strokes
read data from a top level variable and return a memory resident array . this array has the same element type as the variable and the requested shape .
given a string that contains www escape sequences translate those escape sequences back into ascii characters . return the modified string .
define the definitive url constraint expression escape function .
define the definitive url constraint expression unescape function .
define the definitive url backslash unescape function .
define the definitive url backslash escape function .
make lightning variables @param ncfile the netcdf file @param group the group ( may be null ) @param seq the sequence to add to @param name variable name @param datatype the data type @param dims dimenstion names @param longname the long_name attribute value ( a description ) @param cfname the cf standard_name attribute value ( may be null ) @param units the units attribute value ( if null not added ) @param type coordinate axis type units ( if null not added )
add the global attributes . specific implementations should call super and then add their own .
res . setheader ( content - disposition attachment ; filename = + path + . nc ) ;
write the variable s declaration in a c - style syntax . this function is used to create textual representation of the data descriptor structure ( dds ) . see <em > the opendap user manual< / em > for information about this structure .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl . <p / > <h2 > important note< / h2 > this method overrides the basetype method of the same name and type signature and it significantly changes the behavior for all versions of <code > printval () < / code > for this type : <b > <i > all the various versions of printval () will only print a value or a value with declaration if the variable is in the projection . < / i > < / b > <br > <br > in other words if a call to <code > isproject () < / code > for a particular variable returns <code > true< / code > then <code > printval () < / code > will print a value ( or a declaration and a value ) . <br > <br > if <code > isproject () < / code > for a particular variable returns <code > false< / code > then <code > printval () < / code > is basically a no - op . <br > <br >
set the state of this variable s projection . <code > true< / code > means that this variable is part of the current projection as defined by the current constraint expression otherwise the current projection for this variable should be <code > false< / code > .
server - side serialization for opendap variables ( sub - classes of <code > basetype< / code > ) . this does not send the entire class as the java <code > serializable< / code > interface does rather it sends only the binary data values . other software is responsible for sending variable type information ( see <code > dds< / code > ) . <p / > writes data to a <code > dataoutputstream< / code > . this method is used on the server side of the opendap client / server connection and possibly by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
set the projection information for this dimension . the internal <code > darray< / code > is retrieved and then the <code > darraydimension< / code > associated with the <code > dimension< / code > specified is retrieved and the <code > start< / code > <code > stride< / code > and <code > stop< / code > parameters are passed to its <code > setprojection () < / code > method .
gets the <b > start< / b > value for the projection of the <code > dimension< / code > indicated . the parameter <code > dimension< / code > is checked against the instance of the <code > sdarray< / code > for bounds violation .
write the variable s declaration in a c - style syntax . this function is used to create textual representation of the data descriptor structure ( dds ) . see <em > the opendap user manual< / em > for information about this structure .
returns the short resulting from swapping 2 bytes at a specified offset in a byte array .
returns the int resulting from reversing 4 bytes at a specified offset in a byte array .
returns the double resulting from reversing 8 bytes at a specified offset in a byte array .
returns the float resulting from reversing 4 bytes of a specified float .
returns the double resulting from reversing 8 bytes of a specified double .
convert a short to an array of 2 bytes .
convert an int to an array of 4 bytes .
convert a long to an array of 8 bytes .
read the data { @link ucar . ma2 . array } from the variable at the specified time index if applicable . if the variable does not have a time dimension the data array will have the same rank as the variable . if the variable has a time dimension the data array will have rank - 1 .
create a subset of this verticaltransform .
current version
///////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////
////////////////////////////////////////////////////
write the xml representation to a string .
create the xml representation of the griddatasetinv
construct a griddatasetinv from its xml representation
/ * reset the lexer
entry point for the scanner . returns the token identifier corresponding to the next token and prepares to return the semantic value of the token .
entry point for error reporting . emits an error in a user - defined way .
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and the specified x y index for lat - lon point .
make the c array
make height from the given data . <br > old equationn : height ( x y z ) = eta ( x y ) * ( 1 + s ( z )) + depth_c * s ( z ) + ( depth ( x y ) - depth_c ) * c ( z ) <p / > <p / > / * - sachin 03 / 23 / 09 the new corrected equation according to hernan arango ( rutgers ) height ( x y z ) = s ( x y z ) + eta ( x y ) * ( 1 + s ( x y z ) / depth ( x y ) ) <p / > where s ( x y z ) = depth_c * s ( z ) + ( depth ( x y ) - depth_c ) * c ( z ) /
initiate the response with an xml file with an xml header
write the features from the featurelist . for each feature write its attributes
add levels from the gridrecords
match levels
add dimensions to the netcdf file
add this coordinate system to the netcdf file
find the coordinate transform
get the index of a particular gridrecord
be sure to call this when your application exits otherwise your process may not exit without being killed .
default diskcache2 strategy : use $user_home / . unidata / cache / no scouring alwaysusecache = false mimics default diskcache static class
/ * set the cache root directory . create it if it doesnt exist . normally this is set in the constructor .
get a file in the cache corresponding to the filelocation . file may or may not exist . if filelocation has / in it and cachepathpolicy == nesteddirectory the nested directories will be created .
get the named file . if exists or iswritable return it . otherwise get corresponding file in the cache directory .
returns { @code true } if we can write to the file .
looking for an existing file in cache or no
create a new uniquely named file in the root directory . mimics file . createtempfile ()
make the cache filename
show cache contents for debugging .
remove any files or directories whose last modified time greater than persistminutes
this method has the standard behavior when this object has been created using the standard constructors . otherwise it uses currenttoken and expectedtokensequences to generate a parse error message and returns it . if this object has been created due to a parse error and you do not catch it ( it gets thrown from the parser ) then this method is called during the printing of the final stack trace and hence the correct error message gets displayed .
////////////////////////////////////////////// tablemodellistener ////////////////////////////////////////////////
/////////////////////////////////////////// tablecolumnmodellistener /////////////////////////////////////////////
calculate the bearing between the 2 points . see calculatebearing below .
calculate the bearing between the 2 points . see calculatebearing below . uses default earth object .
computes distance ( in km ) azimuth ( degrees clockwise positive from north 0 to 360 ) and back azimuth ( degrees clockwise positive from north 0 to 360 ) from latitude - longituide point pt1 to latitude - longituide pt2 . uses default earth object .
computes distance ( in km ) azimuth ( degrees clockwise positive from north 0 to 360 ) and back azimuth ( degrees clockwise positive from north 0 to 360 ) from latitude - longituide point pt1 to latitude - longituide pt2 . <p > algorithm from u . s . national geodetic survey fortran program inverse subroutine inver1 by l . pfeifer and john g . gergen . see http : // www . ngs . noaa . gov / tools / inv_fwd / inv_fwd . html <p > original documentation : <br > solution of the geodetic inverse problem after t . vincenty <br > modified rainsford s method with helmert s elliptical terms <br > effective in any azimuth and at any distance short of antipodal <br > standpoint / forepoint must not be the geographic pole < / p > reference ellipsoid is the wgs - 84 ellipsoid . <br > see http : // www . colorado . edu / geography / gcraft / notes / datum / elist . html <p / > requires close to 1 . 4 e - 5 seconds wall clock time per call on a 550 mhz pentium with linux 7 . 2 .
test the calculations - forward and back
calculate a position given an azimuth and distance from another point .
calculate a position given an azimuth and distance from another point . uses default earth .
calculate a position given an azimuth and distance from another point . see details below . uses default earth .
calculate a position given an azimuth and distance from another point . <p / > <p / > algorithm from national geodetic survey fortran program forward subroutine dirct1 by stephen j . frakes . http : // www . ngs . noaa . gov / tools / inv_fwd / inv_fwd . html <p > original documentation : <pre > solution of the geodetic direct problem after t . vincenty modified rainsford s method with helmert s elliptical terms effective in any azimuth and at any distance short of antipodal < / pre >
method to invoke with a filename or url of a picture that is to be loaded a new thread . this is handy to update the screen while the loading chuggs along in the background .
method to invoke with a filename or url of a picture that is to be loaded in the main thread .
loads a picture from the url in the imageurl object into the sourcepicturebufferedimage object and updates the status when done or failed .
this method can be invoked to stop the current reader
this method can be invoked to stop the current reader except if it is reading the desired file . it returns true is the desired file is being loaded . otherwise it returns false .
return the size of the image or zero if there is none
method to register the listening object of the status events
method to register the listening object of the status events
method that sets the status of the scalablepicture object and notifies intereasted objects of a change in status ( not built yet ) .
sets the buffered image . unusual method use with care .
construct the standard thredds access uri for this dataset access method resolved agaisnt the parent catalog if the uri is relative .
for associated fields
transfer info from the proto message to another message with the exact same structure .
count the bits used by the data in this dd and its children only accurate for not compressed and not variable length
look need different hashcode reader assumes using object id
has to use hashcode2 so cant use list . hashcode ()
load the dbase file header .
load the dbase file data .
extract the data for a given field by name .
extract the double array of data for a field by name .
extract the string array of data for a field by name .
extract the boolean array of data for a field by name .
get the name of a field by column number .
get a list of all the field names in the dbase file
test program dumps a dbase file to stdout .
attributes are not allowed on some node types
this may occur after initial construction
used by abstractdsp to suppress certain attributes .
closest containing group
closest containing group structure sequence
set the parent dapnode ; may sometimes be same as container but not always ( think attributes or maps ) . invariant : parent must be either a group or a variable . we can infer the container so set that also .
here escaped means backslash escaped short name
compute the path upto and including some specified containing node ( null = > root ) the containing node is included as is this node .
get the transitive list of containers not including this node
get the transitive list of containing groups possibly including this node
compute the fqn of this node
misc . methods
typeddatasetfactoryif
_more_
_more_
compilation
build the data from the incoming serial data note that some dsp s will not use
not tested
get the object that has the specified key . this returns the object itself not a copy so if you change the bean and call store . save () any changes to the object will be saved even without calling putbean () . if you want to change the object without saving the changes you must make a copy of the object yourself .
stores an object using simple bean properties . if the exact key and value are already in the storeddefaults ( using equals () to test for equality ) then it is not stored .
stores a collection of beans . the beans are stored using simple bean properties . the collection of beans must all be of the same class .
stores an object using xmlencoder / xmldecoder . use this for arbitrary objects . if the exact key and value are already in the storeddefaults ( using equals () to test for equality ) then it is not stored .
get an arraylist . this returns a copy of the stored list .
implements <tt > abstractpreferences< / tt > <tt > childrennamesspi () < / tt > method . find all children nodes of this node ( or of identically named nodes in storeddefaults )
/ * find all children nodes of named node ( or of identically named nodes in storeddefaults )
/ * find all key names of this node ( or of identically named nodes in storeddefaults )
/ * find all keys of named node ( or of identically named nodes in storeddefaults )
/ * returns the named child of this preference node creating it if it does not already exist . it is guaranteed that name is non - null non - empty does not contain the slash character ( / ) and is no longer than preferences . max_name_length characters . also it is guaranteed that this node has not been removed . ( the implementor needn t check for any of these things . )
/ * gets the value with this keyname if not found look in storeddefaults .
/ * stores the value with this key if not already in storeddefaults .
/ * removes node no effect on storeddefaults
assume key non - null locked node
isolate dependencies here - in case we have a minimal i / o mode where not all fields are available
debugging - do not use
read data array
read data array : use when you want to be independent of the gribrecord
print data from a dsp - optionally constrained
print an arbitrary datavariable using a constraint . <p > handling newlines is a bit tricky so the rule is that the last newline is elided and left for the caller to print . exceptions : ?
print a single structure or sequence or record instance
copy constructor - avoid clone !!
writes an ncml element to a string .
writes an ncml element to an output file .
writes an ncml element to an output stream .
writes an ncml element to a writer .
////////////////////////////////////// element creation ////////////////////////////////////////
enum typedef
only for shared dimensions .
creates a { @code <values > } element from the variable s data .
wml2 : measurementtvp / wml2 : value
make the coordinate transform
get the int array from the variable attribute
vert
shared by all instances
shared by all instances
see http : // www . nco . ncep . noaa . gov / pmb / docs / grib2 / grib2_doc . shtml
need a few test cases : 1 ) anne s tdr case - catalog a collection of tds served data . 2 ) catalog a collection of local data files . 3 )
factory method for constructing a base unit .
factory method for constructing a derived unit .
returns the base unit database of the si .
returns the derived unit database of the si .
returns an instance of the si system of units .
/ *
called by dataroothandler . makedynamiccatalog () when the catref is requested
///////////////////////////////////////////////////////////////////////
given a coordinate interval find what grid element matches it .
same contract as findcoordelement ()
performs a binary search to find the index of the element of the array whose value is contained in the contiguous intervals . irregularpoint // irregular spaced points ( values npts ) edges halfway between coords contiguousinterval // irregular contiguous spaced intervals ( values npts ) values are the edges and there are npts + 1 coord halfway between edges <p > same contract as findcoordelement ()
look not using bounded
look not using bounded
return index if only one match if no matches return - 1 if > 1 match return - nhits
if its a tie use the larger one
////////////////////////////////////////////////////////////
look must handle discon interval different
range must be contained in this range
/ * http : // stackoverflow . com / questions / 24660408 / how - can - i - get - intellij - debugger - to - allow - my - apps - shutdown - hooks - to - run?lq = 1 unfortunately you can t use breakpoints in your shutdown hook body when you use stop button : these breakpoints are silently ignored .
/////////////////////////////////////
/ * public void showtreeviewwindow () { if ( treewindow == null ) { datasettree = new datasettreeview () ; treewindow = new independentwindow ( treeview datasettree ) ; treewindow . seticonimage ( thredds . ui . bamutil . getimage ( netcdfui )) ; treewindow . setbounds ( ( rectangle ) prefs . getbean ( treewindow new rectangle ( 150 100 400 700 ))) ; }
/ * private void showmissingdata ( beantable from ) { variablebean vb = ( variablebean ) from . getselectedbean () ; if ( vb == null ) return ; variable v = vb . vs ; if (( v ! = null ) && ( v . getdatatype () == ucar . nc2 . datatype . structure )) { showmissingstructuredata ( ( structure ) v ) ; } if ( !vb . vs . hasmissing () ) return ;
///////////////////////////////////////////////////////////////
/////////////////////////////////////////////
look through the collection and find what gds templates are used .
///////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////
look through the collection and find what gds templates are used .
open a featuredataset from a url location string . example urls : <ul > <li > http : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : http : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : file : c : / test / data / catalog / addestationdataset . xml#addesurfacedata ( absolute file ) <li > thredds : resolve : resolveurl < / ul >
open a featuredataset from an dataset object deciding on which access to use .
open a featuredataset from an access object .
open a netcdfdataset from a url location string . example urls : <ul > <li > http : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : http : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : file : c : / dev / netcdf - java - 2 . 2 / test / data / catalog / addestationdataset . xml#addesurfacedata ( absolute file ) <li > thredds : resolve : resolveurl < / ul >
find the best access in case theres more than one based on what the cdm knows how to open and use .
add information from the dataset to the netcdfdataset .
look for an access method for an image datatype
works against the accesslist instead of the dataset list so we can remove and try again
works against the accesslist instead of the dataset list so we can remove and try again
///////////////////////////////
unsupportedoperation
isolate dependencies here - in case we have a minimal i / o mode where not all fields are available
read data array by first reading in gribrecord . all sections are read in so scanmode is from the datafile not the index .
/ * read data array : use when you want to be independent of the gribrecord
debugging - do not use
e . g . of server with problem ( 2 - nov - 2006 ) : http : // acdisc . sci . gsfc . nasa . gov / opendap - bin / nph - dods / opendap / giovanni /
reassemble the url using the specified parts
canonicalize a part of a url
}
/ * arw users guide p 3 - 19 <pre > 7 . map_proj_name : character string specifying type of map projection . valid entries are : polar - > polar stereographic lambert - > lambert conformal ( secant and tangent ) mercator - > mercator
pretty much wrf specific
////////////////////////////////////////////////////////////////////////////////////////////
assign coordinatetransform objects to coordinate systems .
a path is file if it has no base protocol or is file :
main entry point
////////////////////////////////////////////////
////////////////////////////////////////////////
/ * object [] convert ( int count object src typenotes basetype ) throws dapexception { boolean isenum = isenumtype ( basetype ) ; boolean isopaque = basetype . isopaque () ; typenotes truetype = basetype ; if ( isenum ) truetype = enumbasetype ( basetype ) ;
finish getting the metadata if necessary . if this is an xlink this will trigger a read of the href the first time called .
returns the value to which the key is mapped in this table .
maps the specified key to the specified value in this table .
removes the key ( and its corresponding value ) from this table . if the key is not in the table do nothing .
return this as a java date object
print a dapdataset : - as dmr - optionally constrained
print an arbitrary dapnode and its subnodes as if it is being sent to a client with optional constraint ; inclusions are determined by the view . <p > handling newlines is a bit tricky because they may be embedded for e . g . groups enums etc . so the rule is that the last newline is elided and left for the caller to print . exceptions : printmetadata printdimrefs printmaps
print info from the node that needs to be in the form of xml attributes
printxmlattributes helper function
special here is not the same as reserved
print the dimrefs for a variable s dimensions . if the variable has a non - whole projection then use size else use the dimension name .
xml escape a dap fqn and converting to &quot ; assumes backslash escapes are in effect for / and .
initialize ; note that the file is reopened here
check to see if this is a valid area file .
read the values for a variable
set the area directory attributes on the variable
set the navigation block attributes on the variable
get a description for a particular area directory entry
get the calibration type from the name
set the long name and units for the calibration type
search for axis by type assign to tableconfig if found . search for lat lon time height .
search for axis by type .
search for axis by type .
search for axis by type and test against a predicate
search for dimension used by axis of given by type .
find the coordinatesystem with the most number of coordinateaxes
find the dependent axis that depend on independentaxis
set the state of this variable s projection . <code > true< / code > means that this variable is part of the current projection as defined by the current constraint expression otherwise the current projection for this variable should be <code > false< / code > .
get the row vector for into which to read a row os data for this sequence . when serving sequence data to clients the prefered method is to read one row of the sequence at a time in to this vector evaluate the constraint expression clauses on the current data and then send it to the client if it satisfies the constraint . the not recomended way is to read the entire sequence into memory prior to sending it ( that would be most inefficient ) .
write the variable s declaration in a c - style syntax . this function is used to create textual representation of the data descriptor structure ( dds ) . see <em > the opendap user manual< / em > for information about this structure .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl . <p / > <h2 > important note< / h2 > this method overrides the basetype method of the same name and type signature and it significantly changes the behavior for all versions of <code > printval () < / code > for this type : <b > <i > all the various versions of printval () will only print a value or a value with declaration if the variable is in the projection . < / i > < / b > <br > <br > in other words if a call to <code > isproject () < / code > for a particular variable returns <code > true< / code > then <code > printval () < / code > will print a value ( or a declaration and a value ) . <br > <br > if <code > isproject () < / code > for a particular variable returns <code > false< / code > then <code > printval () < / code > is basically a no - op . <br > <br >
set the state of this variable s projection . <code > true< / code > means that this variable is part of the current projection as defined by the current constraint expression otherwise the current projection for this variable should be <code > false< / code > .
set the read property . a normal variable is read using the <code > read () < / code > method . once read the <em > read< / em > property is <code > true< / code > . use this function to manually set the property value . by default this property is false .
server - side serialization for opendap variables ( sub - classes of <code > basetype< / code > ) . this does not send the entire class as the java <code > serializable< / code > interface does rather it sends only the binary data values . other software is responsible for sending variable type information ( see <code > dds< / code > ) . <p > <p / > writes data to a <code > dataoutputstream< / code > . this method is used on the server side of the opendap client / server connection and possibly by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
adds a variable to the container .
returns the named variable . <b > note : < / b > in <code > dsequence< / code > this method returns the template variable which holds no data . if you need to get a variable containing data use <code > getrow< / code > or the <code > getvariable< / code > method which takes a row number parameter .
gets the indexed variable . for a dsrquence this returns the <code > basetype< / code > from the <code > index< / code > th column from the internal map <code > vector< / code > .
returns the named variable in the given row of the sequence .
checks for internal consistency . for <code > dsequence< / code > verify that the variables have unique names .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
the old deserialize protocol has a number of limitations stemming from its inability to tell when the sequence is finished . it s really only good for a dataset containing a single sequence or where the sequence is the last thing in the dataset . to handle this we just read single instances until we get an ioexception then stop .
deserialize a single row of the <code > dsequence< / code > .
reads a marker byte from the input stream .
writes a marker byte to the output stream .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
returns a clone of this <code > sequence< / code > . see dapnode . clonedag ()
public api
entity resolution ( ignored )
error handling events
location printing
creates the demo chart .
starting point for the demonstration application .
look can we optimize ??
get the array of available parameter names for this volume .
override superclass
set the list of stations .
looks for the station with given id . if found makes it current . redraws .
redraw the graphics on the screen .
setup needed for all singletrajectoryobsdatatypes . can only be called once .
static methods
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
write the catalog as an xml document to the specified stream .
write the catalog as an xml document to the specified stream .
/ * protected void writecat6inheritedmetadata ( element elem threddsmetadata tmi ) { if (( tmi . getdatatype () == null ) && ( tmi . getservicename () == null ) && ( tmi . getauthority () == null ) && ( tmi . getproperties () . size () == 0 )) return ;
adds a <code > rectangle2d< / code > object to this <code > rectangle2d< / code > . the resulting <code > rectangle2d< / code > is the union of the two <code > rectangle2d< / code > objects .
adds a point specified by the double precision arguments <code > newx< / code > and <code > newy< / code > to this <code > rectangle2d< / code > . the resulting <code > rectangle2d< / code > is the smallest <code > rectangle2d< / code > that contains both the original <code > rectangle2d< / code > and the specified point . <p > after adding a point a call to <code > contains< / code > with the added point as an argument does not necessarily return <code > true< / code > . the <code > contains< / code > method does not return <code > true< / code > for points on the right or bottom edges of a rectangle . therefore if the added point falls on the left or bottom edge of the enlarged rectangle <code > contains< / code > returns <code > false< / code > for that point .
intersects the pair of specified source <code > rectangle2d< / code > objects and puts the result into the specified destination <code > rectangle2d< / code > object . one of the source rectangles can also be the destination to avoid creating a third rectangle2d object but in this case the original points of this source rectangle will be overwritten by this method .
returns { @code true } if this bounding box contains { @code point } .
read the object from the input stream of the serialized object
wrtie the object to the output stream
returns { @code true } if this rectangle is nearly equal to { @code other } . the near equality of corners is determined using { @link projectionpoint#nearlyequals ( projectionpoint double ) } with the specified maxreldiff .
adds all the entries in another unitdbimpl to this database .
adds a unit to the database .
adds an alias for a unit already in the database .
adds a symbol for a unit already in the database .
adds an alias for a unit already in the database .
adds an alias for a unit already in the database .
gets a unit by either name plural or symbol . retrieving the unit by symbol is attempted before retrieving the unit by name because symbol comparisons are case sensitive and hence should be more robust .
adds a unit to the database by name .
adds a unit to the database by symbol .
adds a unique unit to a map ..
////////////////////////////////////////////////
add a set of menuitems to the given jmenu one for each possible l&f . if this platform doesnt support the l&f disable the menuitem .
/ * c ++ implementation static bool name_is_global ( string &name ) { static regex global ( \\ ( . * global . * \\ ) \\ | \\ ( . * opendap . * \\ ) 1 ) ; downcase ( name ) ; return global . match ( name . c_str () name . length () ) ! = - 1 ; }
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
tricky bit of business . recapture the entire record based on drs position . for validation .
side effect is that the new record is in repeatrecord
called if its scalar
look - should modify to use hasnetcdf . setdata ( structuredata ) for efficiency
overrride for array of structures
get the unpacked data values for a selected parameter .
unpack mit / hrd - compressed data into an array of exactly ncells shorts .
map limit circle of this radius from the origin p 173
precalculate some stuff
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert lat / lon coordinates to projection coordinates .
/ * <grib2_22_0_0_template_en > <no > 1451< / no > <title_en > product definition template 4 . 55 - spatio - temporal changing tiles at a horizontal level or horizontal layer at a point in time< / title_en > <octetno > 35< / octetno > <contents_en > type of second fixed surface< / contents_en > <note_en > ( see code table 4 . 5 ) < / note_en > <status > operational< / status > < / grib2_22_0_0_template_en >
/ * find station that contains this point . if it exists make it the selected station . @param pickpt : world coordinates @return station that contains this point or null if none .
open a featuredataset from a url location string . example urls : <ul > <li > http : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : http : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : // localhost : 8080 / test / addestationdataset . xml#surfacehourly <li > thredds : file : c : / test / data / catalog / addestationdataset . xml#addesurfacedata ( absolute file ) <li > thredds : resolve : resolveurl < / ul >
open a featuredataset from an invdataset object deciding on which invaccess to use .
open a featuredataset from an invaccess object .
try to open as a netcdfdataset .
find the best access in case theres more than one based on what the cdm knows how to open and use .
add information from the invdataset to the netcdfdataset .
look for an access method for an image datatype
works against the accesslist instead of the dataset list so we can remove and try again
works against the accesslist instead of the dataset list so we can remove and try again
first one override
only used by partitionbuilder not partitionbuilderfromindex
acquire or construct gribcollection - caller must call gc . close () when done
the children must already exist
factory method that returns a regexpanddurationtimecoverageenhancer instance that will apply the match pattern to the dataset name .
factory method that returns a regexpanddurationtimecoverageenhancer instance that will apply the match pattern to the dataset path .
create an querycapability from an xml document at a named url . check dqc . isvalid dqc . geterrormessages () to see if ok . if disk caching is set cache the dqc and check ifmodifiedsince .
create an querycapability from an inputstream . check dqc . isvalid dqc . geterrormessages () to see if ok .
create an invcatalog from an a jdom document . check dqc . isvalid dqc . geterrormessages () to see if ok .
write the catalog as an xml document to a string .
write the catalog as an xml document to the specified stream .
write the catalog as an xml document to the specified filename .
testing
set the projection information for this dimension . the parameters <code > start< / code > <code > stride< / code > and <code > stop< / code > are checked to verify that they make sense relative to each other and to the size of this dimension . if not an invalid parameterexception is thrown . the general rule is : 0&lt ; = start&lt ; size 0&lt ; stride 0&lt ; = stop&lt ; size start&lt ; = stop .
returns a clone of this <code > array< / code > . see dapnode . clonedag ()
structures must be fixed sized
brings up the indicated picture on the display .
sets the buffered image directly .
multifilies the scale factor so that paint () method scales the image larger . this method calls {
this method sets the desired scaled size of the scalablepicture to the size of the jpanel and fires off a createscaledpictureinthread request if the scalablepicture has been loaded or is ready .
set image to center of panel by putting the coordinates of the middle of the original image into the center to x and center to y varaibles by invoking the setcenterloaction method . this method calls <code > repaint () < / code > directly since no time consuming image operations need to take place .
method that moves the image up by 10% of the pixels shown on the screen . this method calls <code > repaint () < / code > directly since no time consuming image operations need to take place . <p > <img src = .. / scrollup . png border = 0 > <p > @see #scrollup () @see #scrolldown () @see #scrollleft () @see #scrollright ()
method that moves the image down by 10% of the pixels shown on the screen . this method calls <code > repaint () < / code > directly since no time consuming image operations need to take place . <p > <img src = .. / scrolldown . png border = 0 > <p >
method that moves the image left by 10% of the pixels shown on the screen . this method calls <code > repaint () < / code > directly since no time consuming image operations need to take place . works just liks {
method that moves the image right by 10% of the pixels shown on the screen . this method calls <code > repaint () < / code > directly since no time consuming image operations need to take place . works just liks {
method to set the center of the image to the true coordinates in the picture but doesn t call <code > repaint () < / code >
we are overriding the default paintcomponent method grabbing the graphics handle and doing our own drawing here . esentially this method draws a large black rectangle . a drawrenderedimage is then painted doing an affine transformation on the scaled image to position it so the the desired point is in the middle of the graphics object . the picture is not scaled here because this is a slow operation and only needs to be done once while moving the image is something the user is likely to do more often .
method that gets invoked from the scalablepicture object to notify of status changes . the scalablepicture goes through several statusses : uninitialised garbage_collection loading scaling ready error . <p > each status is passed to the listener upon receipt . <p > when the scalablepicture signals that it is ready the legend of the picture is sent to the listener . the method {
this subroutine converts the two integers stored in a grid file into three integers containing the date time and forecast time .
this subroutine converts an integer time array containing the date time and forecast time into a gempak grid time .
this subroutine converts an integer grid forecast time into the character forecast type and time . the forecast type is a ( analysis ) f ( forecast ) g ( guess ) or i ( initialize ) . if the forecast time is less than 100 and the minutes are 00 only hh is returned .
this subroutine converts an integer date ( yymmdd ) and time ( hhmm )
this subroutine converts an integer time array into a standard gempak time . the integers are checked for validity .
this subroutine returns the number of days in the given month . the year must be a full four - digit year .
convert the int bits to a string
convert the int bits to a string
this subroutine translates a numeric value for ivcord into its character value in vcoord .
swap the order of the integers in place .
get a name for the grid packing type
get a name for the data packing type
read the data stream from the given inputstream . in the c ++ version this code was in connect .
debug
print the dataset just read . in the c ++ version this code was in <code > geturl< / code > .
dump the dataset using externalize methods . this should create a multipart mime document with the binary representation of the dds that is currently in memory .
find the tag that matches the code .
method for class testing . <p / > invocation : <pre > java getopts option set arg0 arg1 ... argn < / pre >
open from a url : adde : use addeimage . factory () http : use javax . imageio . imageio . read () file : javax . imageio . imageio . read ()
this assumes you have opened a file . looks in the parent directory .
conmpute the size in databuffer of the daptype wrt to a serialization ; 0 if undefined .
convert an array of one type of values to another type
calculates the sum of the values in the given array .
set the grid scale .
set how much the data may overlap .
clear all the grid cells
check if the given rect intersects an already drawn one . if not set the corresponding cell as marked store object return true meaning ok to draw .
check if the given rect intersects an already drawn object
check if the given point is contained in already drawn object
find the closest marked cell to the given point
with center cell [ x y ] and side of length 2 * perimeter + 1
if out of bbox or cell not marked return max_double
setup needed for all multitrajectoryobsdatatypes .
create the canonical form of the url . if the urlname starts with http : change it to start with cdmremote : otherwise leave it alone .
session may be null if so will be closed on method . close ()
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and point
factory method for creating a new baseunit or obtaining a previously - created one .
tests this class .
called from aggregation fmrc featuredatasetfactorymanager
/ * clean up deleted files in metadata manager protected void deleteold ( map<string mfile > newmap ) { if ( store == null && enablemetadatamanager ) initmm () ; if ( store ! = null ) store . delete ( newmap ) ; }
return the set of leading protocols for a url ; may be more than one . watch out for windows paths starting with a drive letter = > protocol names must all have a length > 1 . watch out for :: each captured protocol is saved without trailing : assume : the protocols must be terminated by the occurrence of / .
///////////////////////////////////////////////////////////////////////////////////
given a location find markers indicated which protocol to use look what use case is this handling ?
given the fragment part of a url see if it parses as name = value pairs separated by & ( same as query part ) .
given a url search the path to look for protocol indicators
check path extension ; assumes no query or fragment
/ * attempt to map a leading url protocol url to a service type ( see thredds . catalog . servicetype ) . possible service types should include at least the following . <ol > <li > opendap ( dap2 protocol ) <li > dap4 ( dap4 protocol ) <li > cdmremote ( remote ncstream ) < / ol >
if the url alone is not sufficient to disambiguate the location then this method will attempt to do a specific kind of request on the server typically a head call using the url . it finds the header content - description and uses it value ( e . g . ncstream or dods etc ) in order to disambiguate .
cdmremote
not sure what other opendap servers do so fall back on check for dds
check for dmr
look compression not used
return last name part of an fqn ; result will be escaped .
return prefix name part of an fqn ; result will be escaped .
walk the specified subtree dir tree to try to locate file|dir named filename . use breadth first search .
walk the specified dir tree to locate file specified by relative path . use breadth first search .
convert path to : 1 . use / consistently 2 . remove any trailing / 3 . trim blanks 4 . be aware of possible windows drive letter
properly extract the byte contents of a bytebuffer
given a dap variable get the path from the top - level variable to and including the given variable such that all but the last element is a structure .
convert paths to null
test a list<slice > against set of dapdimensions to see if the list is whole wrt the dimensions
given an array of strings and a separator and a count concat the first count elements of an array with separator between them . a null string is treated like .
return true if this path appears to start with a windows drive letter
return the set of leading protocols for a url ; may be more than one .
provide a helper function to convert an index object to a slice list .
provide a helper function to convert an offset to a slice list .
given an offset ( single index ) and a set of dimensions compute the set of dimension indices that correspond to the offset .
given an offset ( single index ) and a set of dimensions compute the set of dimension indices that correspond to the offset .
test if a set of slices represent a contiguous region this is equivalent to saying all strides are one
test if a set of slices represent a single position
if a set of slices refers to a single position then return the corresponding index . otherwise throw exception .
read the result of a data request . only one variable at a time .
look
///////////////////////////////////////////////////////////////////
create an xml document from this info
/ * magic_start version sizeindex bufrcdmindexproto ( sizeindex bytes )
/ * create new arraydouble with given indeximpl and backing store . should be private .
copy from javaarray to storage using the iterator : used by factory ( object ) ;
set extra information used by station obs datasets . use stnidvname or stnindexvname .
access it members
////////////////////////////////////////////////////////////////////////////////////
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl . <p / > <h2 > important note< / h2 > this method overrides the basetype method of the same name and type signature and it significantly changes the behavior for all versions of <code > printval () < / code > for this type : <b > <i > all the various versions of printval () will only print a value or a value with declaration if the variable is in the projection . < / i > < / b > <br > <br > in other words if a call to <code > isproject () < / code > for a particular variable returns <code > true< / code > then <code > printval () < / code > will print a value ( or a declaration and a value ) . <br > <br > if <code > isproject () < / code > for a particular variable returns <code > false< / code > then <code > printval () < / code > is basically a no - op . <br > <br >
read ncep mnemonic bufr tables .
read ncep mnemonic bufr tables .
field construction
input is xml file with just the <featurecollection >
read a catalog and extract a featurecollectionconfig from it
add single declaration
we will need to re - order the groups
parse an fqn and use it to trace to a specific object in a dataset . absolute fqn paths are passed to dapdataset . findbyfqn () . relative fqns are assumed to be wrt to the fqn of this node
locate a variable in this group
/ * private boolean compare ( list<dimension > dims1 list<dimension > dims2 ) { if ( dims1 . size () ! = dims2 . size () ) return false ; for ( int i = 0 ; i < dims1 . size () ; i ++ ) { dimension dim1 = dims1 . get ( i ) ; dimension dim2 = dims2 . get ( i ) ; if ( !dim1 . getname () . equals ( dim2 . getname () )) return false ; if ( dim1 . getlength () ! = dim2 . getlength () ) return false ; } return true ; }
return an arraylist of paired objects .
return an arraylist of paired objects .
return an arraylist of paired objects .
check that want is in both list1 and list2 using object . equals ()
/ * the coards standard offers limited support for climatological time . for compatibility with coards time coordinates should also be recognised as climatological if they have a units attribute of time - units relative to midnight on 1 january in year 0 i . e . since 0 - 1 - 1 in udunits syntax and provided they refer to the real - world calendar . we do not recommend this convention because ( a ) it does not provide any information about the intervals used to compute the climatology and ( b ) there is no standard for how dates since year 1 will be encoded with units having a reference time in year 0 since this year does not exist ; consequently there may be inconsistencies among software packages in the interpretation of the time coordinates . year 0 may be a valid year in non - real - world calendars and therefore cannot be used to signal climatological time in such cases .
we assume that coordinate axes get identified by being coordinate variables
the time unit statistical type derived from code table 5 )
///////////////////////////////////////////////////////////////////////////////////
here s where to deal with crossing seam
/ * longitude subset after normalizing to start draw a circle representing longitude values from start to start + 360 . all values are on this circle and are > start . put start at bottom of circle end > start data has values from start counterclockwise to end . wantmin wantmax can be anywhere want goes from wantmin counterclockwise to wantmax . wantmin may be less than or greater than wantmax .
return y x range
calculates the bounding box of this coordinate reference system in projection coordinates . if this crs { @link #isprojection isn t a projection } than { @code null } is returned .
calculates the bounding box of this coordinate reference system in latitude / longitude . this method properly handles coverages that straddle the international date line by deriving its bounding box from the { @link #calcconnectedlatlonboundarypoints ( int int ) connected latitude / longitude boundary } . <p > if this crs { @link #isprojection is a projection } its lat / lon boundary is computed by converting each point in its { @link #calcprojectionboundarypoints () projection boundary } to latitude / longitude using the { @link projection projection } .
calculates the latitude / longitude boundary of this coordinate reference system . the boundary starts at the lower left corner of the coverage -- i . e . { @code ( y [ 0 ] x [ 0 ] ) } -- and consists of the points that lie along the bottom right top and left edges in that order . <p > the { @code maxpointsinyedge } parameter establishes a limit on the number of boundary points that ll be included from the right and left edges . { @code maxpointsinxedge } establishes a similar limit for the bottom and top edges . the size of the returned list will be { @code  2 * maxpointsinyedge + 2 * maxpointsinxedge } . note that the corners are always included regardless of the arguments . if you wish to include all of the points along the edges in the boundary simply choose values for the parameters that are greater than the lengths of the corresponding axes in the crs . { @link integer#max_value } works great . in that case the size of the returned list will be { @code 2 * numxcoords + 2 * numycoords } . <p > if this crs { @link #isprojection is a projection } the lat / lon boundary is computed by converting each point in its { @link #calcprojectionboundarypoints () projection boundary } to latitude / longitude using the { @link projection projection } . <p > points in the boundary will be { @link #connectlatlonpoints connected } . this facilitates proper interpretation of the boundary if it s rendered as a georeferenced polygon particularly when the boundary crosses the international date line .
calculates the boundary of this coordinate reference system in projection coordinates . the boundary starts at the lower left corner of the coverage -- i . e . { @code ( y [ 0 ] x [ 0 ] ) } -- and consists of the points that lie along the bottom right top and left edges in that order . <p > the { @code maxpointsinyedge } parameter establishes a limit on the number of boundary points that ll be included from the right and left edges . { @code maxpointsinxedge } establishes a similar limit for the bottom and top edges . the size of the returned list will be { @code  2 * maxpointsinyedge + 2 * maxpointsinxedge } . note that the corners are always included regardless of the arguments . if you wish to include all of the points along the edges in the boundary simply choose values for the parameters that are greater than the lengths of the corresponding axes in the crs . { @link integer#max_value } works great . in that case the size of the returned list will be { @code 2 * numxcoords + 2 * numycoords } .
returns a list of points that is equivalent to the input list but with longitude values adjusted to ensure that adjacent elements are connected . <p > two points are connected if the absolute difference of their { @link latlonpointimpl#lonnormal normalized longitudes } is { @code 180 } . for example the longitudes { @code 112 } and { @code 124 } are connected . so are { @code 15 } and { @code - 27 } . <p > two points may be disconnected if they lie on opposite sides of the international date line . for example the longitudes { @code 175 } and { @code - 175 } are disconnected because their absolute difference is { @code 350 } which is { @code > 180 } . to connect the two points we adjust the second longitude to an equivalent value in the range { @code [ firstlon  180 ] } by adding or subtracting { @code 360 } . so { @code - 175 } would become { @code 185 } . we perform this adjustment for each pair of adjacent elements in the list . <p > performing the above adjustment will result in longitudes that lie outside of the normalized range of ( { @code [ - 180 180 ] } ) . to be precise if adjustments are necessary all of the longitudes in the returned list will be in either { @code [ - 360 0 ] } or { @code [ 0 360 ] } . consequently adjusted points cannot be returned as { @link latlonpoint } s ; they are returned as { @link latlonpointnonormalize } objects instead . <p > longitudes { @code lon1 } and { @code lon2 } are considered equivalent if { @code lon1 == lon2 + 360 * i } for some integer { @code i } .
returns the { @link #calcconnectedlatlonboundarypoints ( int int ) latitude / longitude boundary } of this coordinate reference system as a polygon in wkt . it is used in the openlayers map in ncss as well as the datasetboundaries endpoint .
provide defaults for a settings map
timeouts
compression
it is convenient to be able to directly set the credentials ( not the provider ) when those credentials are fixed .
interceptors : only supported at global level
extract the sessionid cookie value
set the max number of redirects to follow
enable / disable redirection following default is yes .
should we use sessionid s?
close the session . this implies closing any open methods .
this is the most general case
it is convenient to be able to directly set the credentials ( not the provider ) when those credentials are fixed .
handle authentication and proxy ing
/ * package scope
utilities
if we are testing then track the sessions for kill
/ * only allow if debugging
/ * only allow if debugging
deprecated but here for back compatibility
obsolete
this is the most general case
private dqcfactory dqcfactory = null ;
generate a subclass of index optimized for this array s rank
compute standard strides based on array s shape . ignore vlen
create a new index based on current one except flip the index so that it runs from shape [ index ] - 1 to 0 . leave rightmost vlen alone .
create a new index based on a subsection of this one with rank reduction if dimension length == 1 .
create a new index based on current one by eliminating any dimensions with length one .
create a new index based on current one by eliminating the specified dimension ;
create a new index based on current one except transpose two of the indices .
create a new index based on a permutation of the current indices ; vlen fails .
get an index iterator for traversing the array in canonical order .
get the current element s index into the 1d backing array . vlen stops processing .
set the current counter from the 1d current element currelement = offset + stride [ 0 ] * current [ 0 ] + ...
set the current element s index . general - rank case .
set current element at dimension dim to v
set current element at dimension 0 1 2 to v0 v1 v2
string representation
check if we all time intervals have the same length .
make calendar date range using the first and last ending bounds
initialize this reader . get the grid specific info
read in the stations and times . subclasses should call this during init ()
get the date / time information
get the list of dates
make gempakparameters from the list of
get the station list
make a station from the header info
get the station key names
get the station keys
get the list of dates in this file .
print the list of dates in the file
print the list of dates in the file
find the station index for the specified station id .
get the type for this file
set depth + = n
set depth = n
/ * only call on the root node
/ * public string tostring () { stringbuilder buf = new stringbuilder () ; boolean first = true ; if ( projections ! = null ) for ( astprojection p : projections ) { buf . append (( first ? : ) + p . tostring () ) ; first = false ; } first = true ; if ( selections ! = null ) for ( astclause c : selections ) { buf . append ( c . tostring () ) ; first = false ; } return buf . tostring () ; }
/ * public string tostring () { if ( var ! = null ) return var . tostring () ; else return fcn . tostring () ; }
/ * public string tostring () { stringbuilder buf = new stringbuilder () ; boolean first = true ; buf . append ( fcnname ) ; buf . append ( ( ) ; if ( args ! = null ) for ( astvalue arg : args ) { if ( !first ) buf . append ( ) ; else { first = false ; } buf . append ( arg . tostring () ) ; } buf . append ( ) ) ; return buf . tostring () ; }
/ * public string tostring () { stringbuilder buf = new stringbuilder () ; boolean first = true ; for ( astsegment seg : segments ) { buf . append (( first ? : . ) + seg . tostring () ) ; first = false ; } return buf . tostring () ; }
/ * public string tostring () { stringbuilder buf = new stringbuilder () ; buf . append ( name ) ; if ( slices ! = null ) for ( astslice slice : slices ) { buf . append ( slice . tostring () ) ; } return buf . tostring () ; }
/ * public string tostring () { if ( stride == 1 ) { if ( first == last ) return string . format ( [ %d ] first ) ; else return string . format ( [ %d : %d ] first last ) ; } else return string . format ( [ %d : %d : %d ] first stride last ) ; }
/ * public string tostring () { stringbuilder buf = new stringbuilder () ; if ( constant ! = null ) buf . append ( constant . tostring () ) ; else if ( var ! = null ) buf . append ( var . tostring () ) ; else if ( fcn ! = null ) buf . append ( fcn . tostring () ) ; else assert ( false ) ; return buf . tostring () ; }
/ * public string tostring () { stringbuilder buf = new stringbuilder () ; switch ( tag ) { case stringconst : buf . append ( string . format ( \ %s \ text )) ; break ; case intconst : buf . append ( string . format ( %d intvalue )) ; break ; case floatconst : buf . append ( string . format ( % . 1f floatvalue )) ; break ; default : assert ( false ) ; } return buf . tostring () ; }
/ * public string tostring () { if ( boolfcn ! = null ) { return & + boolfcn . tostring () ; } else { stringbuilder buf = new stringbuilder ( & ) ; buf . append ( lhs . tostring () ) ; buf . append ( operatorstring ( operator )) ; boolean first = true ; if ( rhs . size () > 1 ) buf . append ( { ) ; if ( rhs ! = null ) for ( astvalue value : rhs ) { buf . append (( first ? : ) + value . tostring () ) ; first = false ; } if ( rhs . size () > 1 ) buf . append ( } ) ; return buf . tostring () ; } }
assume first dimension is time series
/ *
create a gbx9 index from a single grib1 or grib2 file . use the existing index if it already exists .
called from aggregation fmrc featuredatasetfactorymanager
add a directory scan to the collection
compute if synchronous scan is needed . true if recheck is true and enough time has elapsed .
only called from synch methods
set debugging flags
specify which variable will get written
write the input file to the output file .
/ * package
///////////////////////
write the information as an xml document
create an xml document from this info
debug
///////////////////////////////////////////// marshalling ///////////////////////////////////////////////
validates an xml doc . if the validation fails the exception contains a detailed list of errors .
convert this multislice to a string suitable for use in a constraint
copy () doesnt work because convert gets called twice
set the structure to wrap .
regular variables .
section of regular variable
is conversion needed?
3 ) variable with cached data added to structureds through ncml
/ * convert original structuredata to one that conforms to this structure
the wrapper structuremembers must be converted to correspond to the wrapper structure
look for the top variable that has an orgvar with the wanted orgname
verify that the variable has data in the data array
do not use directly . public by accident . recalc any enhancement info
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
return null means request has been handled and calling routine should exit without further processing
check if this is making a request for a restricted dataset and if so if its allowed .
datasetsource
prints the original string representation of this clause . for use in debugging .
is this a valid file?
read the data for the variable
read in the data for the variable . in this case it should be a structure . the section should be rank 2 ( station time ) .
create an empty arraysequence for missing data
create an arraysequence to hold the data
build the netcdf file
build a standard station structure
make a sequence for the part
add the vertical coordinate variables if necessary
this allows the possibility of reading a catalog in another thread . the default implementation does not do that but a subclass may override and implement . if the catalog is read successfully it is passed on to the callback .
create an invcatalog from an xml document at a named uri . failures and exceptions are handled by causing validate () to fail . therefore be sure to call validate () before trying to use the invcatalog object .
read an invcatalog from an a uri . failures and exceptions are handled by causing validate () to fail . therefore be sure to call validate () before trying to use the invcatalog object .
create an invcatalog by reading catalog xml from a string .
create an invcatalog by reading catalog xml from a stringreader .
create an invcatalog from an inputstream . failures and exceptions are handled by causing validate () to fail . therefore be sure to call validate () before trying to use the invcatalog object .
create an invcatalog from a jdom document . failures and exceptions are handled by causing validate () to fail . therefore be sure to call validate () before trying to use the invcatalog object .
write the invcatalogimpl to the outputstream as a invcatalog 1 . 0 document .
/ * write the catalog as an xml document to the specified filename .
write the catalog as an xml document to a string .
find the metadataconverterif registered for this key
testing
returns the identifiers associated with the dimensionless derived unit .
multiplies this derived unit by another .
divides this derived unit by another .
converts numerical values from this unit to the derived unit . obviously the numerical values are unchanged .
indicates if values in this unit are convertible with another unit .
tests this class .
checks the type of the simple geom and calls the appropriate method to build the xml
takes in a point and writes its xml
takes in a line and iterates through all its points writing the poslist to xml
takes in a polygon checks whether it is an interior or exterior ring and writes the corresponding xml . iterates through all linked polygons
parser api
xml attribute utilities
attribute construction
return the subnodes of a node with non - element nodes suppressed
recursive descent parser
pass reserved xml attributes unchanged
gets the subset string to be used in netcdffile . read given a variable and some indicies . useful for subsetting timeseries
turn any arraystructure into a arraystructurema
set the data array for this member .
create an arraystructure for a structure . allow nested structures . create the data arrays and an iterator .
returns a polygon given a variable name and the geometric index . if the polygon is not found it will return null . if the polygon is a part of the multi - polygon it will return the head ( the first polygon in the series which constitutes the multi - polygon ) .
returns a line given a variable name and the geometric index . if the line is not found it will return null . if the line is a part of the multi - line it will return the head ( the first line in the series which constitutes the multi - line ) .
returns a point given a variable name and the geometric index . if the point is not found it will return null . if the point is a part of the multi - point it will return the head ( the first point in the series which constitutes the multi - point ) .
given a variable name returns the geometry type which that variable is associated with . if the variable has no simple geometry information null will be returned .
make a station from the station data structure .
recursive ast walker ; compilation of filters is done elsewhere .
convert field references in a filter
process a dim redefinition
package private . use array . factory ()
/ * create new arrayobject with given indeximpl and backing store . should be private .
create new array with given indeximpl and the same backing store
copy from javaarray to storage using the iterator : used by factory ( object ) ;
returns { @code true } if this rectangle is nearly equal to { @code other } . the near equality of corners is determined using { @link latlonpoint#nearlyequals ( latlonpoint double ) } with the specified maxreldiff .
determine if the given lat / lon point is contined inside this rectangle .
determine if this bounding box is contained in another latlonrect .
extend the bounding box to contain this point
extend the bounding box to contain the given rectangle
create the instersection of this latlon with the given one
return a string representation of this object . <pre > lat = [ - 90 . 00 90 . 00 ] lon = [ 0 . 00 360 . 00< / pre >
add elements of two arrays together allocating the result array . the result type and the operation type are taken from the type of a .
add elements of two arrays together as doubles place sum in the result array . the values from the arrays a and b are converted to double ( if needed ) and the sum is converted to the type of result ( if needed ) .
check that two arrays are conformable .
check that two array shapes are conformable . the shapes must match exactly except that dimensions of length 1 are ignored .
convert original array to desired type
copy using iterators . will copy until !from . hasnext () .
copy array a to array result the result array will be in canonical order the operation type is taken from the type of a .
copy array a to array result as doubles the values from the arrays a are converted to double ( if needed ) and then converted to the type of result ( if needed ) .
copy array a to array result as floats the values from the arrays a are converted to float ( if needed ) and then converted to the type of result ( if needed ) .
copy array a to array result as longs the values from the array a are converted to long ( if needed ) and then converted to the type of result ( if needed ) . @param result copy to here @param a copy from here
copy array a to array result as integers the values from the arrays a are converted to integer ( if needed ) and then converted to the type of result ( if needed ) .
copy array a to array result as shorts the values from the array a are converted to short ( if needed ) and then converted to the type of result ( if needed ) .
copy array a to array result as char the values from the array a are converted to char ( if needed ) and then converted to the type of result ( if needed ) .
copy array a to array result as bytes the values from the array a are converted to byte ( if needed ) and then converted to the type of result ( if needed ) .
copy array a to array result as bytes the array a and result must be type boolean
copy array a to array result as an object the array a and result must be type object
find min and max value in this array getting values as doubles . skip double . nan .
set all the elements of this array to the given double value . the value is converted to the element type of the array if needed .
sum all of the elements of array a as doubles . the values from the array a are converted to double ( if needed ) .
sum all of the elements of array a as doubles . the values from the array a are converted to double ( if needed ) .
calculate the scale / offset for an array of numbers . <pre > if signed : then max value unpacked = 2^ ( n - 1 ) - 1 packed min value unpacked = - ( 2^ ( n - 1 ) - 1 ) packed note that - 2^ ( n - 1 ) is unused and a good place to map missing values by solving 2 eq in 2 unknowns we get : scale = ( max - min ) / ( 2^n - 2 ) offset = ( max + min ) / 2 if unsigned then max value unpacked = 2^n - 1 packed min value unpacked = 0 packed and : scale = ( max - min ) / ( 2^n - 1 ) offset = min one could modify this to allow a holder for missing values . < / pre >
returns true if the specified arrays have the same size signedness and <b > approximately< / b > equal corresponding elements . { @code float } elements must be within { @link misc#defaultmaxrelativedifffloat } of each other as determined by { @link misc#nearlyequals ( double double double ) } . similarly { @code double } elements must be within { @link misc#defaultmaxrelativediffdouble } of each other . <p > { @link #equals ( array array ) } is an alternative to this method that requires that corresponding elements be <b > exactly< / b > equal . it is suitable for use in { @link object#equals } implementations whereas this method isn t .
/ * @override public list<calendardate > getcalendardates () { if ( gettimeaxis () ! = null ) return gettimeaxis () . getcalendardates () ;
turn configcatalog into a mutable catalogbuilder so we can mutate
returns the <code > attributetable< / code > with the given name .
returns the <code > attributetable< / code > with the given name .
this method searchs through the <code > das< / code > for alias members . when an alias is found the method attempts to resolve it to a specific attribute . <p / > this method is invoked by <code > parse ( inputstream is ) < / code > and is used to search for aliases in attributetables found in the das . <p / > if you are building a das from it s api it is important to call this method prior to returning said das to an application . if this call is not made aliases will not work correctly .
this method recursively searchs through the passed <code > attributetable< / code > parameter at for alias members . when an alias is found the method attempts to resolve it to a specific attribute . <p / > this method gets called is invoked by <code > reolvealiases ( basetype bt ) < / code > and is used to search for aliases in attributetables found in a basetypes attributes . <p / > this method manipulates the global variable <code > currentbt< / code > .
this method attempts to resolve the past alias to a specific attribute in the dds . it does this by : <ul > <li > 1 ) tokenizing the alias s variable and attribute fields ( see <code > alias< / code > ) < / li > <li > 2 ) evaluating the tokenized fields to determine if the alias is defined in terms of a relative or absolute path < / li > <li > 3 ) searching the das or the currentat ( depending on results of 2 ) for the target attribute < / li > <li > 4 ) setting the aliases intrnal reference to it s attribute < / ul > <p / > if an attribute matching the definition of the alias cannot be located an exception is thrown
this method executes a ( recursive ) search of the <code > attributetable< / code > parameter <b > at< / b > for an <code > attribute< / code > whose name resolves to the vector of names contained in the <code > vector< / code > parameter <b > anames< / b > . an attribute is considered a match if each of it s node names in the hierarchy of attributetables contained in the one passed as parameter <b > at< / b > matches ( equals ) the corresponding name in the vector <b > anames< / b > .
returns a clone of this <code > attribute< / code > . see dapnode . clonedag ()
/ * code table 6  data representation type code figure meaning 0 latitude / longitude grid  equidistant cylindrical or plate carre projection 1 mercator projection 2 gnomonic projection 3 lambert conformal secant or tangent conic or bi - polar projection 4 gaussian latitude / longitude grid 5 polar stereographic projection 6 universal transverse mercator ( utm ) projection 7 simple polyconic projection 8 albers equal - area secant or tangent conic or bi - polar projection 9 millers cylindrical projection 10 rotated latitude / longitude grid 1112 reserved 13 oblique lambert conformal secant or tangent conic or bi - polar projection 14 rotated gaussian latitude / longitude grid 1519 reserved 20 stretched latitude / longitude grid 2123 reserved 24 stretched gaussian latitude / longitude grid 2529 reserved 30 stretched and rotated latitude / longitude grids 3133 reserved 34 stretched and rotated gaussian latitude / longitude grids 3549 reserved ^ 50 spherical harmonic coefficients 5159 reserved 60 rotated spherical harmonic coefficients 6169 reserved 70 stretched spherical harmonics 7179 reserved 80 stretched and rotated spherical harmonic coefficients 8189 reserved 90 space view perspective or orthographic 91191 reserved 192254 reserved for local use
signed
************************************************************************ default handler for opendap directory requests . returns an html document with a list of all datasets on this server with links to their dds das information and html responses .
create a projectionimpl from the projection
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
///////////////////////////////////////////////////////////////////////////////////
define the definitive opendap identifier unescape function .
define the definitive url unescape function .
decode all of the parts of the url including query and fragment
backslash escape a string
backslash unescape a string
tokenize an escaped name using . as delimiter skipping \ .
find first occurence of char c in escapedname excluding escaped c .
given a backslash escaped name convert to a dap escaped name
given a dap ( attribute ) string insert backslashes before and / characters . this code also escapes control characters although the spec does not call for it ; make that code conditional .
given a cdm string insert backslashes before <toescape > characters .
support methods
read a top - level scalar atomic variable
nc4cursor extensions
utilities
given a field ref compute the true offset with respect to it top - level containing structure / record
given a cursor get a list of containing cursors with the following constraints . 1 . the first element in the path is a top - level variable . 2 . the remaining elements are the enclosing compound variables 3 . the last element is the incoming cursor .
if the basetype is sequence ( = > isvlen () ) then return the type of the first field of this sequence . otherwise return null .
{
convenience method for searching below <code > container< / code > in the component hierarchy and return nested components that are instances of class <code > clazz< / code > it finds . returns an empty list if no such components exist in the container . <p > invoking this method with a class parameter of jcomponent . class will return all nested components . <p > this method invokes getdescendantsoftype ( clazz container true )
convenience method for searching below <code > container< / code > in the component hierarchy and return nested components that are instances of class <code > clazz< / code > it finds . returns an empty list if no such components exist in the container . <p > invoking this method with a class parameter of jcomponent . class will return all nested components .
convenience method that searches below <code > container< / code > in the component hierarchy and returns the first found component that is an instance of class <code > clazz< / code > and has the bound property value . returns { @code null } if such component cannot be found .
convenience method that searches below <code > container< / code > in the component hierarchy in a depth first manner and returns the first found component of class <code > clazz< / code > having the bound property value . <p > returns { @code null } if such component cannot be found . <p > this method invokes getdescendantofclass ( clazz container property value true )
convenience method that searches below <code > container< / code > in the component hierarchy in a depth first manner and returns the first found component of class <code > clazz< / code > having the bound property value . <p > returns { @code null } if such component cannot be found .
convenience method for mapping a container in the hierarchy to its contained components . the keys are the containers and the values are lists of contained components . <p > implementation note : the returned value is a hashmap and the values are of type arraylist . this is subject to change so callers should code against the interfaces map and list .
convenience method for retrieving a subset of the uidefaults pertaining to a particular class .
convenience method for retrieving a subset of the uidefaults pertaining to a particular class .
convenience method for retrieving the uidefault for a single property of a particular class .
convenience method for obtaining most non - null human readable properties of a jcomponent . array properties are not included . <p > implementation note : the returned value is a hashmap . this is subject to change so callers should code against the interface map .
convenience method to obtain the swing class from which this component was directly or indirectly derived .
the goal here is to process the serialized databuffer and locate top - level variable positions in the serialized databuffer . access to non - top - level variables is accomplished on the fly .
compile a structure array .
compile a structure instance .
compile a sequence array .
compile a sequence as a set of records .
utilities
reads <code > n< / code > little - endian doubles from a random access file . <p / > <p > this method is provided for speed when accessing a number of consecutive values of the same type .
read a long in little endian format
reads <code > n< / code > little - endian longs from a random access file . <p / > <p > this method is provided for speed when accessing a number of consecutive values of the same type .
/ * protected variable findvariablewithstandardnameandnotdimension ( netcdfdataset ds string standard_name dimension outer formatter errlog ) { for ( variable v : ds . getvariables () ) { string stdname = ds . findattvalueignorecase ( v cf . standard_name null ) ; if (( stdname ! = null ) && stdname . equals ( standard_name ) && v . getrank () > 0 && !v . getdimension ( 0 ) . equals ( outer )) return v ; } return null ; }
read in the index index raf already open ; return null on failure
add listener : action event sent if apply button is pressed
remove listener
call field . accept () on all fields . this puts any edits into the store and fires propertychangeevents if any values change and sends an actionevent to any listeners .
find the field with the specified name .
get current value of the named field
set the current value of the named field
add a field created by the user .
add a boolean field as a checkbox .
add a field that edits a date
add a field that edits a double
add a field that edits an integer
add a password text field .
add a text field .
add a text combobox field .
add a textarea field .
add a heading at the specified row . this spans all columns
add a component .
add a seperator after the last field added .
call when finished adding components to the prefpanel .
thanks to heinz m . kabutz
read the value ( parameters are ignored ) .
get the cell spacing . an exception is thrown if the cell spacing is not constant .
returns the array of factor - s constituting this dimension .
multiplies this dimension by another dimension .
raises this dimension to a power .
indicates if this dimension is the reciprocal of another dimension .
indicates if this dimension is dimensionless . a dimension is dimensionless if it has no factor - s or if all factor - s are themselves dimensionless .
wml2 : collection / wml2 : observationmember
/ * notify all listeners that have registered interest for notification on this event type . the event instance is lazily created using the parameters passed into the fire method .
/ * notify all listeners that have registered interest for notification on this event type . the event instance is lazily created using the parameters passed into the fire method .
/ * notify all listeners that have registered interest for notification on this event type . the event instance is lazily created using the parameters passed into the fire method .
persist info ( ncoords coordvalues ) from joinexisting since that can be expensive to recreate .
read info from the persistent xml file if it exists
has the name getcachename ()
make a key from ( center subcenter version ) that provides correct sort order .
get a grib1paramtables object optionally specifying a parameter table or lookup table specific to this dataset .
get a grib1tables object optionally specifiying a parameter table in xml specific to this dataset .
debugging only
add all tables in list to standard tables
add table to standard tables for a specific center subcenter and version .
multiply this unit by another unit .
divide this unit by another unit .
raise this unit to a power .
converts values in this unit to the equivalent values in the convertible derived unit .
converts values in the convertible derived unit to the equivalent values in this unit .
is this a valid file?
open the service provider for reading .
make the netcdf file
read the data for the variable
initialize the unit table . this is used if there are no units in the file .
create a vertical dimension variable based on the info . based on visad . data . vis5d . vis5dverticalsystem .
add lat / lon variables to the file
read and set the descriptor name size and endianness and return the entire contents of the descriptor ( including the name and size ) as a byte array . the file position will be left at the beginning of the next descriptor ( or at the end of file ) .
skip the current dorade descriptor in the file leaving the file position at the beginning of the next descriptor ( or at the end of file ) .
return the name of the dorade descriptor at the current location in the file . the current location will not be changed .
determine if the given dorade sweepfile contains little - endian data ( in violation of the dorade definition ... ) .
unpack a two - byte integer from the given byte array .
unpack a four - byte integer from the given byte array .
unpack a four - byte ieee float from the given byte array .
unpack an eight - byte ieee float from the given byte array .
get the default verbose state for new <code > doradedescriptor< / code > - s of the given name .
gets an instance of this database .
adds a derived unit to the database .
adds a derived unit to the database .
adds an alias for a unit to the database .
adds a symbol for a unit to the database .
tests this class .
/ try to figure out if we need to add file : to the location when writing
this augments uri . resolve () by also dealing with file : uris . if baseuri is not a file : scheme then uri . resolve is called . otherwise the last / is found in the base and the ref is appended to it . <p > for file : baseurls : only reletive urls not starting with / are supported . this is apparently different from the behavior of uri . resolve () so may be trouble but it allows ncml absolute location to be specified without the file : prefix . <p / > example : <pre > base : file : // my / guide / collections / designfaq . ncml ref : sub / my . nc resolved : file : // my / guide / collections / sub / my . nc < / pre >
factory method for creating a unit converter .
writing data
add listener : listselectionevent sent when a new row is selected
remove listener
set the data as a collection of structuredata .
set the data as a collection of pointfeature .
draws all the features that are within the graphics clip rectangle using the previously set displayprojection .
get the set of shapes to draw convert projections if need be
wml2 : collection / wml2 : metadata / wml2 : documentmetadata
time ( nruns ntimes ) - > time ( ntimes ) with dependent reftime ( ntime ) coordinate
/ * non unique time case 3 ) time ( nruns ntimes ) with reftime ( nruns )
only for the 2d times
only for the 2d times
//////////////////////////////////////////////////////////////////////////////////////////////
look - needs to be a directory or maybe an mfile collection
process all the bytes in the stream
read into dest byte array until buffer is full or end of stream
read into new buffer until buffer is full or end of stream
read into new buffer until buffer is full or end of stream
get more bytes into buffer . stop when endsequence is found .
reads up to len bytes of data from this input stream into an array of bytes . this method blocks until some input is available .
skips over and discards n bytes of data from the input stream .
reading
tests this class .
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and point
match levels
add this coord as a dimension to the netcdf file
add this coord as a variable in the netcdf file
get the coordinate index for the record
checking the file
open the file and read the header part
read the data for each variable passed in
all the work is here so can be called recursively
read data from encoded values and run len into regular data array
take advantage of the work already done by netcdfdataset
turn variable into opendap variable
returns a clone of this <code > ?< / code > . see basetype . clonedag ()
called by navigation
set the map area .
set the map area by converting latlonrect to a projectionrect .
set the center point of the maparea
set the projection change the map area to the projection s default .
add all of the toolbar s actions to a menu .
from panning so wait delay msecs before doing the redraw .
sets whether the user can zoom / pan on this navigatedpanel . default = true .
note : i believe that the repaintmanager is not used on jpanel subclasses ???
system - triggered redraw .
user must get this graphics2d and draw into it when panel needs redrawing
this calculates the affine transform that maps the current map area ( in projection coordinates ) to a display area ( in arbitrary units ) . @param rotate should the page be rotated? @param displayx upper right corner of display area @param displayy upper right corner of display area @param displaywidth display area @param displayheight display area
when component resizes we need a new buffer
draw and drawg are like paintimmediately ()
set the currently selected variable .
todo : add index range checks
convert int base to index based
get the array element at a specific dap4 index as a double
get the array element at a specific dap4 index as an object
return the string of sector for the gini image file
return the channel id for the gini image file
return the channel id for the gini image file
return the channel id for the gini image file
read a scaled 3 - byte integer from file and convert to double
convenience function ; look up parameter by name ignoring case .
iterator api overrides
compute the total number of elements .
parse the ctl file
swap the byte order from the system default
get the number of timesteps per file and the starting offset
get the file name for the particular time and ensemble index
get the list of filenames
get the path to the data descriptor file
get the full path for a given filename
add a chsub
////////////////////////////////////////////////////////////////////////////////////////////////
///////////////////////////////////////////
calculate the offset in units of timeunit from the given reference date?
/ * create new arrayboolean with given indeximpl and backing store . should be private .
copy from javaarray to storage using the iterator : used by factory ( object ) ;
check if this file is a nids / tdwr file
read the header of input file and parsing the wmo part
read the compressed data
read and parse the header of the nids / tdwr file
construct a dataset for special graphic symbol packet with code 12 13 and 14
construct a dataset for special symbol packet with code 25
check level iii file header
construct a dataset for vector arrow data packet with code 5
construct a dataset for text and special symbol packets with code 1 2 and 8
construct a dataset for linked vector packet and unlinked vector packet
construct a dataset for nids digital precipitation array
construct a raster dataset for nids raster products ;
construct a radial dataset for nids radial products ;
for level3 176 product
for level3 176 product
for level3 176 product
for level3 176 product
for level3 176 product
construct a generic radial dataset for dualpol radial products ;
get the table to calibrate data value
get the calibrate data values for tdwr data
get the calibrate data values for tdwr data
get the calibrate data values for dualpol data
get the calibrate data values for tdwr data
adding new variable to the netcdf file
adding new parameter to the netcdf file
misc
parsing the product information into netcdf dataset
uncompress the tdwr products
/ * * name : read_dividlen * * purpose : read divider id header from nexrad level iii product *
/ * * name : read_msghead * * purpose : read message header from nexrad level iii product * *
get unsigned integer from byte array
get signed integer from bytes
/ * * name : read_proddesc * * purpose : read product description header from nexrad level iii product * *
this converts a byte array to another primitive array
this converts a byte array to a wrapped primitive ( byte short integer double float long )
name : iszlibed
/ * * name : isencrypt * * purpose : check a two - byte sequence to see if it indicates the start of * an encrypted image . *
/ * * name : getzlibednexr * * purpose : read bytes from a nexrad level iii product into a buffer * this routine reads compressed image data for level iii formatted file . * we referenced mcidas getnexrline function
/ * * name : code_lookup * * purpose : derive some derivable metadata *
/ * product id table
/ * product resolution
/ * product level tabel
////////////////////////////////////////////////////////
primary controller entry point
process a dsr request . *
process a dmr request .
process a datadmr request . note that if this throws an exception then it has not yet started to output a response . it a response had been initiated then the exception would produce an error chunk . <p > *
utility methods
merge the servlet inputs into a single object for easier transport as well as adding value .
generate an error based on the parameters
set special attribute : endianness : overwrite exiting value
set special attribute : constraint : overwrite exiting value
set the anchor point .
erase the last rectangle and draw a new one from the anchor point to this point .
last point done with drawing .
last point done with drawing .
get current bounds
get previous bounds
parse the text in w3c profile of iso 8601 format . @param text parse this text @return equivalent date or null if failure @see <a href = http : // www . w3 . org / tr / note - datetime > w3c profile of iso 8601< / a >
parse text in the format yyyy - mm - dd hh : mm : ss
parse text in the format yyyy - mm - dd hh : mm
parse text in the format yyyy - mm - dd t hh : mm : ss
parse text in the format yyyy - mm - dd t hh : mm
parse text in the format yyyy - mm - dd
standard date format = yyyy - mm - dd hh : mm : ssz
change shape of the data variables
even if javabits is 64 the limit on an array size is integer . max_value .
safely rounds a double to an int . ( math . round but rounds to a long and not safely . )
see http : // www . nco . ncep . noaa . gov / pmb / docs / grib2 / grib2_doc . shtml
convert 2 bytes into a signed integer .
convert unsigned bytes into an integer .
convert 3 bytes into a signed integer .
convert 2 bytes into an unsigned integer .
convert 3 bytes into an unsigned integer .
convert 4 bytes into a float value .
convert 4 bytes to a float .
convert 8 bytes into a signed long .
count number of bits on in bitmap
lon naught ??
precalculate some stuff
create a wks string
get the scale at the given lat .
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert lat / lon coordinates to projection coordinates .
convert projection coordinates to lat / lon coordinate .
escape selected characters in a string using xml entities
escape control chars plus selected other characters in a string using backslash the definitive list is in netcdf - c / ncgen / ncgen . l .
remove backslashed characters in a string
split a string with respect to a separator character and taking backslashes into consideration .
clean up a string : currently means : 1 . strip off everything after the first nul character
//////////////////////////////////////////////////////////////////
factory method
scan has been done create fmrcinv
the ones that dont start with thredds
this implementation requires the path to be relative to the root directory and a descendant of the root directory . it also requires the relative path at each path segment to be a descendant of the root directory i . e . it cannot start with .. / or contain .. / path segments such that once normalized it would start with .. / ( e . g . dir1 / .. / .. / dir2 once normalized would be .. / dir2 ) .
returns the number of variables contained in this object . for simple and vector type variables it always returns 1 . to count the number of simple - type variable in the variable tree rooted at this variable set <code > leaves< / code > to <code > true< / code > .
adds a variable to the container .
gets the indexed variable . for a dgrid the index 0 returns the <code > darray< / code > and indexes 1 and higher return the associated map <code > vector< / code > s .
checks for internal consistency . for <code > dgrid< / code > verify that the map variables have unique names and match the number of dimensions of the array variable .
coverity [ call_super ]
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
how many prohected components of this grid object?
when projected ( using whatever the current constraint provides in the way of a projection ) am i still a grid?
returns a clone of this <code > dgrid< / code > . see dapnode . clonedag ()
make the level values from the specifications
parser primary actions
selection actions
parser list support
return record header time as a calendardate
make a section of an arraystructurebb
makes a document for a file . <p / > the document has three fields : <ul > <li > <code > path< / code > -- containing the pathname of the file as a stored untokenized field ; <li > <code > modified< / code > -- containing the last modified date of the file as a field as created by <a href = lucene . document . datetools . html > datetools< / a > ; and <li > <code > contents< / code > -- containing the full contents of the file as a reader field ;
index all text files under a directory .
deserialize the grib1record object
look what about extending an index ??
this implementation requires a relative path . the relative path may not start with .. / or once normalized start with .. / . here normalized means that . / and path / .. segments are removed e . g . dir1 / .. / .. / dir2 once normalized would be .. / dir2 .
do we think this is a m3io file .
intend to use epsg system parameters
///////////////////////////////////////////////////////////////////////
open the service provider for reading .
read the data for the variable
reacquire any resources like file handles
is this date before the given date . if ispresent always false .
is this date before the given date . if d . ispresent always true else if this . ispresent false .
is this date after the given date . if ispresent always true .
test
when we have a real catalog ( filename ! = catscan )
when we have a catalog built from a directory ( filename == catscan )
return the known collectiontype that matches the given name ( ignoring case ) or null if the name is unknown .
return a collectiontype that matches the given name by either matching a known type ( ignoring case ) or creating an unknown type .
set the i th value of the array .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
add a coordinatesystem to the dataset .
get the description of the variable . default is to look for attributes in this order : cdm . long_name description title standard_name .
set the unit string for this variable . default is to use the cdm . units attribute .
get the unit string for the variable . may be set explicitly else look for attribute cdm . units .
called from tdsinit on spring - managed auto - wired bean
called from init () and from trigger controller
catalogrelpath must be relative to rootdir
does the actual work of reading a catalog .
dirpath = the directory path reletive to the rootdir
dirpath is the directory relative to rootdir directory is absolute
/////////////////////////////////////////////////////////////////////////////////////////////////////////////
test if point lies between two longitudes deal with wrapping .
put longitude into the range [ start start + 360 ] deg
make a nicely formatted representation of a latitude eg 40 . 34n or 12 . 9s .
make a nicely formatted representation of a longitude eg 120 . 3w or 99 . 99e .
compares this base quantity to another base quantity .
tests this class .
get the currently selected invdataset .
set the currently selected invdataset .
create the treepath corresponding to the given treenode .
open all nodes of the tree .
set the invcatalog to display . the catalog is read asynchronously and displayed if successfully read . you must use a propertychangeeventlistener to be notified if successful .
set the catalog to be displayed . if ok then a catalog propertychangeevent is sent .
debug
debugging only
look for aliases .
look for an coord_axis or coord_alias attribute
bigendian
writes an int in a variable - length format . writes between one and five bytes . smaller values take fewer bytes . negative numbers are not supported .
writes an long in a variable - length format . writes between one and nine ( ? ) bytes . smaller values take fewer bytes . negative numbers are not supported .
writes a string . ( vlen ) [ char ]
writes a sequence of utf - 8 encoded characters from a string .
private char [] chars ;
reads utf - 8 encoded characters into an array .
read data from this record .
we are running with only ncx index files no data
/ * <! -- c : / data / dt2 / station / ndbc . nc -- > <stationfeature > <stationid > : station < / stationid > <stationdesc > : description < / stationdesc > <coordaxis type = lat > lat< / coordaxis > <coordaxis type = lon > lon< / coordaxis > <coordaxis type = height > 0< / coordaxis > <table dim = time > <coordaxis type = time > time< / coordaxis > < / table > < / stationfeature >
get the 3d vertical coordinate array for this time step .
get the 1d vertical coordinate array for this time step and point
add a member .
remove the given member
get the names of the members .
find the member by its name .
read the bitmap array when needed return null if none .
set the state from the last saved in the preferencesext .
save state to the preferencesext .
get the currently selected rows .
set the current selection to this row .
this array translates the column index to the model index
///////////////////////////////////////////////////////////////////////////////
/ * copy constructor . this makes a local copy of all the data in the from strucuredata . @param from copy from here
get member data array of any type as an array .
get member data of type double .
get java double array for a member of type double .
get member data of type float .
get java float array for a member of type float .
get member data of type byte .
get java byte array for a member of type byte .
get member data of type int .
get java int array for a member of type int .
get member data of type short .
get java short array for a member of type short .
get member data of type long .
get java long array for a member of type long .
get member data of type char .
get java char array for a member of type char .
get string value from rank 0 string or rank 1 char member array .
get member data of type structure .
write all harvestable datasets to dif records that have at least the minimum metadata . call isdatasetuseable () to find out .
write a dif record for a specific dataset
see if a dataset is harvestable to a dif record .
utility routine to keep list of objects small . add fldvalue to the fldname list in flds . fldvalue may be a list or an object . if no list just keep the object without creating a list ( common case ) . otherwise add it to the existing list .
make an immutable copy without changin datasetbuilder
transfer all metadata optionally also inheritable metadata from parents
place directly into flds ( not in this . tmi ) look why not into tmi ?? look put into tmi see what breaks!
get the inheritable threddsmetadata object . if doesnt exist create new empty one
add in a new product
/ * is this a time interval variable
make the netcdf variable . if vname is not already set use usename as name
debugging
dump out the missing data
dump out the missing data as a summary
find the grid record for the time and level indices canonical ordering is ens time level
dump this variable
make a long name for the variable
register a class that implements a typeddatasetfactoryif .
register a class that implements a typeddatasetfactoryif .
open a dataset as a typeddataset .
open a dataset as a typeddataset .
wml2 : defaultpointmetadata
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
spacing
calendardate double [ 2 ] or double
only for longitude only for regular ( do we need a subclass for longitude 1d coords ??
look incomplete handling of subsetting params
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
figure out what kind of netcdf - related file we have . constraint : leave raf read pointer to point just after the magic number .
not quite memcmp
returns a string representation of the variables value . this is really foreshadowing functionality for server types but as it may come in useful for clients it is added here . simple types ( example : dfloat32 ) will return a single value . dconstuctor and dvector types will be flattened . dstrings and durl s will have double quotes around them .
print an array . this is a private member function .
dsp extensions
it is common to want to parse a dmr text to a dapdataset so provide this utility .
walk the dataset tree and remove selected attributes such as _unsigned
some attributes that are added by the netcdfdataset need to be kept out of the dmr . this function defines that set .
parse the given date string ( starting at the first numeric character ) using the given date format string ( as described in java . text . simpledateformat ) and return a date .
parse the given date string starting at a position given by the offset of the demark character in the dateformatstring . the rest of the dateformatstring is the date format string ( as described in java . text . simpledateformat ) . <pre > example : datestring = wrfout_d01_2006 - 07 - 06_080000 . nc dateformatstring = wrfout_d01_#yyyy - mm - dd_hhmm < / pre > this simply counts over wrfout_d01_ number of chars in datestring then applies the remaining dateformatstring .
parse the given date string ( between the demarcation characters ) using the given date format string ( as described in java . text . simpledateformat ) and return a date . <pre > example : datestring = / data / anything / 2006070611 / wrfout_d01_2006 - 07 - 06_080000 . nc dateformatstring = #wrfout_d01_#yyyy - mm - dd_hhmm would extract the date 2006 - 07 - 06t08 : 00
parse the given date string ( starting at the given startindex ) using the given date format string ( as described in java . text . simpledateformat ) and return a date . assumes timezone is gmt .
use regular expression capture group replacement to construct a date string and return the date that is obtained by parseing the constructed date string using the date format string yyyy - mm - dd t hh : mm .
the same as getdateusingregexp () except the date format string to be used must be specified .
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
only one message per coordinatepartitionunionizer instance
split a <value > ... < / value > into its component strings . generally type checking is not performed . string quotes are obeyed and backslash escapes are removed .
reading
all the work is here so can be called recursively
for the compressed data read all out into a array and then parse into requested
/ * * name : getginiline * * purpose : extract a line of data from a gini image * * parameters : * buf - buffer containing image data * * returns : * success == 1 * failure == 0 * *
some weird adjustment for la1 and la2 .
_more_
parse a section specification string . these have the form : <pre > section specification : = selector | selector . selector selector : = varname [ ( dims ) ] varname : = escaped_string <p / > dims : = dim | dim dims dim : = : | slice | start : end | start : end : stride slice : = integer start : = integer stride : = integer end : = integer escaped_string : must escape characters = . ( < / pre > <p / > nonterminals are in lower case terminals are in upper case literals are in single quotes . optional components are enclosed between square braces [ and ] .
parse variable name and index selector out of the selector string . variable name must be escaped
make section specification string from a range list for a variable .
is the point ( lat lon ) contained in the ( row col ) rectangle ?
/ * http : // mathforum . org / library / drmath / view / 54386 . html
/ * choose x y such that ( matrix multiply ) :
we think its got to be in one of the 9 boxes around rectindex
make the <code > coordinatetransform< / code > from the dataset
calling close will force the method to close and will force any open stream to terminate . if the session is local then that too will be closed .
create a request add headers and content then send to httpsession to do the bulk of the work .
debug only
///////////////////////////////////////////////////////////////////////////////
////////////////////////////////////////////////////////////////////////////////
//
//
//
for stations figure out the encoding
identify ragged array representations for single nests ( station profile trajectory )
identify ragged array representations for double nests ( timeseries profile timeseries trajectory ) <p / > this uses the contiguous ragged array representation for each profile ( 9 . 5 . 43 . 3 ) and the indexed ragged array representation to organise the profiles into time series ( 9 . 3 . 54 ) . the canonical use case is when writing real - time data streams that contain profiles from many stations arriving randomly with the data for each entire profile written all at once .
for station and stationprofile not flat
///////////////////////////////////////////////////////////////////////////////
the inner table of structure ( outer inner ) and middle table of structure ( outer middle inner )
the inner table of structure ( outer middle inner )
class i don t understand enough of the code base to anticipate implementation artifacts .
added 5 - 30 - 2006 to allow for resetting of the input used by this object . this saves in memory allocation costs
reads the stream .
call this from awt event thread . the task is run in a background thread .
misc .
convert a uri string to an instance of java . net . uri . the critical thing is that this procedure can handle backslash escaped uris as well as %xx escaped uris .
remove selected fields from a uri producing a new uri
convert a zero - length string to null
join two string together to form proper path without trailing slash
convert path to use / consistently and to remove any trailing /
convert path to remove any leading / or drive letter assumes canonical .
support function
convert path to add a leading / ; assumes canonical .
accept datasets whose last modified date is at least the last modified limit of milliseconds in the past .
////////////////////////////////////////////////////////
for making partition collection
the files that comprise the collection . actual paths including the grib cache if used .
public by accident do not use
get index filename
set from gribcollectionbuilderfromindex . readfromindex ()
stuff for filecacheable
coverity [ call_super ]
number of nested fields
open an existing netcdf file for writing data . cannot add new objects you can only read / write data to existing variables . setting fill = false is more efficient use when you know you will write all data .
create a new netcdf file put it into define mode . make calls to addxxx () then when all objects are added call create () . you cannot read or write data until create () is called . setting fill = false is more efficient use when you know you will write all data .
add a dimension to the file . must be in define mode .
add a dimension to the file . must be in define mode .
rename a dimension . must be in define mode .
add a global attribute to the file . must be in define mode .
add a global attribute of type string to the file . must be in define mode .
add a global attribute of type array to the file . must be in define mode .
delete a global attribute . must be in define mode .
rename a global attribute . must be in define mode .
add a variable to the file . must be in define mode .
add a variable to the file . must be in define mode .
add a variable to the file . must be in define mode .
add a variable with datatype = string to the file . must be in define mode . the variable will be stored in the file as a char variable . a new dimension with name varname_strlen is automatically added with length max_strlen .
rename a variable . must be in define mode .
add an attribute to the named variable . must be in define mode .
add an attribute of type string to the named variable . must be in define mode .
add an attribute of type array to the named variable . must be in define mode .
delete a variable attribute . must be in define mode .
rename a variable attribute . must be in define mode .
update the value of an existing attribute . attribute is found by name which must match exactly . you cannot make an attribute longer or change the number of values . for strings : truncate if longer zero fill if shorter . strings are padded to 4 byte boundaries ok to use padding if it exists . for numerics : must have same number of values .
after you have added all of the dimensions variables and attributes call create () to actually create the file . you must be in define mode . after this call you are no longer in define mode .
rewrite entire file
write data to the named variable origin assumed to be 0 . must not be in define mode .
write data to the named variable . must not be in define mode .
write string data to a char variable origin assumed to be 0 . must not be in define mode .
write string data to a char variable . must not be in define mode .
close the file .
add a variable to the file . must be in define mode .
initialize the file read in all the metadata ( ala dm_open )
initialize this reader . get the grid specific info
set the file subtype .
print the list of dates in the file
run the program
writes headers and bounding box
in the wfs specification for getfeature each feature type is its own member and so writemembers add each member to the fileoutput
write stationobsdataset xml document
write stationcollection xml document
create an xml document from this info
create an xml document from this info
debug
write the dsr ; do not bother to cache .
cache the dmr . what it really does is cache the dmr and write it at the point where it is needed ; either in close () if writing the dmr only or in writechunk () if writing data as well .
output the specifiedd dmr or dsr or ... but xml only .
write an error chunk . if mode == dmr then replaces the dmr else reset the current chunk thus losing any partial write .
write out the current chunk ( with given set of flags ) .
closes this output stream and releases any system resources associated with this stream . except the underlying stream is not actually closed ; that is left to the servlet level
overload flush to also write out the dmr
writes len bytes from the specified byte array starting at offset off to this output stream . <p > if this write fills up the chunk buffer then write out the buffer and put the remaining bytes into the reset buffer .
needed for constructcopy
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
/ * roszelld@usgs . gov m transforming coordinates ( which are in utm zone 17n projection ) to lat / lon .
got to use this or subclass readobservations ()
look at config and decide if tasks need to be started
is want contained in this range?
create a new range by composing a range that is reletive to this range . revised 2013 / 04 / 19 by dennis heimbigner to handle edge cases . see the commentary associated with the netcdf - c file dceconstraints . h function dceslicecompose () .
create a new range by compacting this range by removing the stride . first = first / stride last = last / stride stride = 1 .
get ith element
get the index for this element : inverse of element
create a new range by intersecting with a range using same interval as this range . note : we dont yet support intersection when both ranges have strides
determine if a given range intersects this one . note : we dont yet support intersection when both ranges have strides
create a new range shifting this range by a constant factor .
create a new range by making the union with a range using same interval as this range . note : no strides
find the first element in a strided array after some index start . return the smallest element k in the range such that <ul > <li > k > = first <li > k > = start <li > k < = last <li > k = element of this range < / ul >
package private . use array . factory ()
copy from javaarray to storage using the iterator : used by factory ( object ) ;
read data subset from file for a variable create primitive array .
read data subset from file for a variable to writablebytechannel . will send as bigendian since thats what the underlying file has .
write data to a file for a variable .
/ * <! -- c : / data / dt2 / station / madis2 . sao -- > <stationcollection > <table dim = maxstaticids limit = nstaticids > <lastlink > lastrecord< / lastlink >
read the data values ( parameters are ignored ) . use the start stop and stride values that were set by the constraint evaluator .
writes data to a <code > dataoutputstream< / code > . this method is used on the server side of the opendap client / server connection and possibly by gui clients which need to download opendap data manipulate it and then resave it as a binary file .
write a subset of the data to a <code > dataoutputstream< / code > .
create a new primitive vector using a subset of the data .
returns a clone of this <code > booleanprimitivevector< / code > . see dapnode . clonedag ()
/ * type info codes from hntdefs . h #define dfnt_uchar8 3 #define dfnt_char8 4 #define dfnt_float32 5 #define dfnt_float64 6
return sorted catalogs
accessors
file loader
urlmap api
delete old databases
set the grid nav block values
set the parameters for the gds . todo add the following : the following simple map projections may be specified :
seems to handle swath as well ??
write swath grid data to the geotiff file .
interpolate the swath data to regular grid
get lat lon information from the swath
used by h5tiledlayout
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert lat / lon coordinates to projection coordinates .
convert lat / lon coordinates to projection coordinates .
this returns true when the line between pt1 and pt2 crosses the seam . when the cone is flattened the seam is lon0 + - 180 .
make a double array out of an int array
/////////////////////////////////////////////////////////
supported for backwards compatibility . we prefer that datasetboundaries . wkt or datasetboundaries . json are used .
checks that all the requested vars exist . if all fills out the param . vars with all grid names throws exception if some of the variables in the request are not contained in the dataset
returns true if all the variables have the same vertical axis ( if they have an axis ) . could be broadened to allow all with same coordinate unites? coordinate value??
construct a stereographic projection using latitude of true scale and calculating scale factor . <p > since the scale factor at lat = k = 2 * k0 / ( 1 + sin ( lat )) [ snyder working manual p157 ] then to make scale = 1 at lat set k0 = ( 1 + sin ( lat )) / 2
calculate polar stereographic scale factor based on the natural latitude and longitude of the original ref : ogp surveying and positioning guidance note number 7 part 2 april 2009 http : // www . epsg . org added by qun he <qunhe@unc . edu >
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert projection coordinates to lat / lon coordinate .
convert lat / lon coordinates to projection coordinates .
find the datasetsourcestructure that matches this name .
to work under intellij .
fill in the netcdf file
make coordinate system without missing data - means that we have to make a coordinate axis for each unique set of time or vertical levels .
make a vertical dimensions
read the header and populate the ncfile
finish constructing after all elements have been added . this does the inheritence thing this can be called again if new elements are added .
look for invmetadata elements in the parent that need to be added to the public metadata of this dataset . recurse up through all ancestors .
take all elements from tmd and add to the public metadata of this dataset . for invmetadata elements only add if inheritall || invmetadata . isinherited () .
transfer all inheritable metadata from fromds to the local metadata of this dataset . called by invdatasetscan to transfer inheritable metaddata to the nested catalogref
transfer inherited metadata consolidating it into target
put metadata into canonical form . all non - inherited thredds metadata put into single metadata element pointed to by getlocalmetadata () . all inherited thredds metadata put into single metadata element pointed to by getlocalmetadatainherited () . this is needed to do reliable editing .
look these are wrong
add a nested dataset at the location indicated by index .
remove the given dataset element from this dataset if it is in the dataset .
replace the given dataset if it is a nesetd dataset .
add a service to this dataset .
remove a service from this dataset .
set the list of services attached specifically to this dataset . discard any previous servies .
remove the given invmetadata from the set of metadata local to this dataset .
look up the user property having the given key
write an html representation of the given dataset . <p > with datasetevents catrefevents = true this is used to construct an html page on the client ( eg using htmlpage ) ; the client then detects url clicks and processes . <p > with datasetevents catrefevents = false this is used to construct an html page on the server . ( eg using htmlpage ) ; the client then detects url clicks and processes .
resolve reletive urls against the catalog url .
validate this datasetnamer object . return true if valid false if invalid .
try to name the given dataset .
try to name the given dataset .
get list of data descriptors as strings
initialize
/ * difficult thing is to return the extra line assocated with the previous good log we do this by not returning until we get a match on the next log . we have to rewind .
constructs the full server uri from a request
processes getcapabilities requests .
processes getfeature requests .
checks request parameters for errors . will send back an xml exception if any errors are encountered .
a handler for wfs based http requests that sends to other request handlers to handle the request .
a path is a dap4 path if at least one of the following is true . 1 . it has dap4 : as its leading protocol 2 . it has #protocol = dap4 in its fragment
open a connection and make a request for the ( possibly constrained ) dmr .
provide a method for getting the capabilities document .
utilities
////////////////////////////////////// crawlabledatasetfile ////////////////////////////////////////
returns the size of the dataset in bytes . will be zero if this dataset is a collection or non - existent .
returns the date that the dataset was last modified . will be null if the dataset is a collection or non - existent .
exception handlers
unit testing
generator
node specific generators
given a dataset variable and index automatically populates this point and returns it . if not found returns null .
return the file path dealing with leading and trailing path seperators ( which must be a slash ( / )) for the given directory and file paths . <p / > note : dealing with path strings is fragile . todo : switch from using path strings to java . io . files .
write a file to the response stream .
write a file to the response stream . handles range requests .
write a file to the response stream . handles range requests .
send given content string as the http response .
set the proper content length for the string
return the request url relative to the server ( i . e . starting with the context path ) .
forward this request to the catalogservices servlet ( / catalog . html ) .
this is the server part eg http : // motherlode : 8080
the request base as a uri
servletpath + pathinfo
the entire request including query string
return the value of the given parameter for the given request . should only be used if the parameter is known to only have one value . if used on a multi - valued parameter the first value is returned .
show details about the request
/ * static public void showsession ( httpservletrequest req printstream out ) {
/ * static private string getserverinfoname ( string serverinfo ) { int slash = serverinfo . indexof ( / ) ; if ( slash == - 1 ) return serverinfo ; else return serverinfo . substring ( 0 slash ) ; }
///////////////////////////////////////////////////////////////////////
save persistent state .
wrap this in a jdialog component .
write a file directory .
/ * create new arrayfloat with given indeximpl and backing store . should be private .
copy from javaarray to storage using the iterator : used by factory ( object ) ;
wml2 : measurementtvp / wml2 : time
wml2 : collection / wml2 : observationmember / om : om_observation / om : phenomenontime / gml : timeperiod / gml : beginposition
wml2 : collection / wml2 : observationmember / om : om_observation / om : phenomenontime / gml : timeperiod / gml : endposition
wml2 : collection / wml2 : observationmember / om : om_observation / om : resulttime / gml : timeinstant / gml : timeposition
///////////////////////////////////////////////
not used yet
track nested tables .
total bits of this table and all subtables
/ * ! grib2 parameter table ! !d# = discipline number !ct# = category number ( octet 10 code table 4 . 2 ) !id# = parameter number ( octet 11 ) !pd# = product definition template number ( octet 8 - 9 code table 4 . 0 ) ! ! temperature !d# ct# id# pd# name units gnam scale missing hzremap direction !23|123|123|123|12345678901234567890123456789012|12345678901234567890|123456789012|12345|123456 . 89|12345678|1234567890 1 2 3 4 5 6 7 8 9 10 11 12 0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890 000 000 000 000 temperature k tmpk 0 - 9999 . 00 0 0 000 000 000 019 temperature below normal % ptbn 0 - 9999 . 00 0 0 000 000 000 029 temperature near normal % ptnn 0 - 9999 . 00 0 0 000 000 000 039 temperature above normal % ptan 0 - 9999 . 00 0 0 000 000 001 000 virtual temperature k tvrk 0 - 9999 . 00 0 0 000 000 002 000 potential temperature k thta 0 - 9999 . 00 0 0 000 000 003 000 equivalent potential temp k thte 0 - 9999 . 00 0 0 000 000 004 008 maximum temperature k tmxk 0 - 9999 . 00 0 0 000 000 005 008 minimum temperature k tmnk 0 - 9999 . 00 0 0 000 000 006 000 dew point temperature k dwpk 0 - 9999 . 00 0 0 000 000 007 000 dew point depression k dpdk 0 - 9999 . 00 0 0 000 000 008 000 lapse rate k m ** - 1 laps 0 - 9999 . 00 0 0 000 000 009 000 temperature anomaly k tmpka 0 - 9999 . 00 0 0 000 000 010 000 latent heat net flux w m ** - 2 fxlh 0 - 9999 . 00 0 0 000 000 011 000 sensible heat net flux w m ** - 2 fxsh 0 - 9999 . 00 0 0 000 000 012 000 heat index k heat 0 - 9999 . 00 0 0 000 000 013 000 wind chill factor k chill 0 - 9999 . 00 0 0 !000 000 014 000 minimum dew point depression k ???? 0 - 9999 . 00 0 0 !000 000 015 000 virtual potential temperature k ???? 0 - 9999 . 00 0 0 ! ! moisture !d# ct# id# pd# name units gnam scale missing hzremap direction !23|123|123|123|12345678901234567890123456789012|12345678901234567890|123456789012|12345|123456 . 89|12345678|1234567890 000 001 000 000 specific humidity kg kg ** - 1 spfh 0 - 9999 . 00 0 0
append this line to the bottom of the jtextarea . a newline is added and jtextarea is scrolled to bottom ; remove lines at top if needed .
/ * this is part of the lexer interface
entry point for error reporting . emits an error in a user - defined way .
system . out . println ( drag : + deltax + + deltay ) ; }
accessors
create an xml document for the stations in this dataset possible subsetted by bb . must be a station dataset .
create the capabilities xml document for this dataset
package private . use array . factory ()
copy from javaarray to storage using the iterator : used by factory ( object ) ;
package private : mostly for iterators
coord based record finding . note only one record at a time
get the ith coordinate
dmrfactory api
add the item to the top of the list . if it already exists move it to the top .
use this to obtain the list of items .
get the 3d vertical coordinate array for this time step .
look this could be a problem
return ith slice
compute the total number of elements .
iterator api
return - 1 if we have completed .
http : // www . nco . ncep . noaa . gov / pmb / docs / on388 / table5 . html
public so can be called from grib2
/////////////////////////////////////// levels
/ * magic_start version sizerecords sparsearray s ( sizerecords bytes ) sizeindex gribcollectionindex ( sizeindex bytes )
/ * message record { uint32 fileno = 1 ; // which grib file ? key into gc . filemap uint64 pos = 2 ; // offset in grib file of the start of entire message uint64 bmspos = 3 ; // use alternate bms if non - zero uint32 drsoffset = 4 ; // offset of drs from pos ( grib2 only ) }
/ * <xsd : element name = datasetscan substitutiongroup = dataset > <xsd : complextype > <xsd : complexcontent > <xsd : extension base = datasettype > <xsd : sequence > <xsd : element ref = filter minoccurs = 0 maxoccurs = 1 / > <xsd : element ref = namer minoccurs = 0 maxoccurs = 1 / > <xsd : element ref = sort minoccurs = 0 maxoccurs = 1 / > <xsd : element ref = addlatest minoccurs = 0 maxoccurs = 1 / > <xsd : element ref = addproxies minoccurs = 0 maxoccurs = 1 / > <xsd : element name = adddatasetsize minoccurs = 0 maxoccurs = 1 / > <xsd : element ref = addtimecoverage minoccurs = 0 maxoccurs = 1 / > < / xsd : sequence >
/ * <xsd : element name = filter > <xsd : complextype > <xsd : choice > <xsd : sequence minoccurs = 0 maxoccurs = unbounded > <xsd : element name = include type = filterselectortype minoccurs = 0 / > <xsd : element name = exclude type = filterselectortype minoccurs = 0 / > < / xsd : sequence > < / xsd : choice > < / xsd : complextype > < / xsd : element >
/ * <xsd : element name = namer > <xsd : complextype > <xsd : choice maxoccurs = unbounded > <xsd : element name = regexponname type = namerselectortype / > <xsd : element name = regexponpath type = namerselectortype / > < / xsd : choice > < / xsd : complextype > < / xsd : element >
/ * <xsd : element name = sort > <xsd : complextype > <xsd : choice > <xsd : element name = lexigraphicbyname > <xsd : complextype > <xsd : attribute name = increasing type = xsd : boolean / > < / xsd : complextype > < / xsd : element > <xsd : element name = crawlabledatasetsorterimpl minoccurs = 0 type = userimpltype / > < / xsd : choice > < / xsd : complextype > < / xsd : element >
/ * <xsd : element name = addtimecoverage > <xsd : complextype > <xsd : attribute name = datasetnamematchpattern type = xsd : string / > <xsd : attribute name = datasetpathmatchpattern type = xsd : string / > <xsd : attribute name = starttimesubstitutionpattern type = xsd : string / > <xsd : attribute name = duration type = xsd : string / > < / xsd : complextype > < / xsd : element >
all cdmrfeaturedatasets must return their featuretype - use as a fail - fast test of the endpoint
set the value type of the option switch to the type passed
wml2 : collection / wml2 : observationmember / om : om_observation / om : phenomenontime / gml : timeperiod
constructs a grib1gds object from a pds and predefined tables .
21 - 26 61 - 64 : international exchange and family of services ( fos ) grids . so may be more general than ncep
copy all bytes from in and throw them away .
copy all bytes from in and throw them away .
copy all bytes from in to out specify buffer size
read the contents from the inputstream and place into a string with any error messages put in the return string .
read the contents from the inputstream and place into a byte array with any error messages put in the return string .
wite the contents from the string to a stream
copy one file to another .
copy one file to another .
copy file to output stream
copy file to output stream
copy file to output stream specify internal buffer size
copy part of a randomaccessfile to output stream specify internal buffer size
copy an entire directory tree .
read the file and place contents into a byte array with any error messages put in the return string .
read the contents from the named file and place into a string assuming utf - 8 encoding .
write string contents to a file using utf - 8 encoding .
write byte [] contents to a file .
write contents to a file using utf - 8 encoding .
copy input stream to file . close input stream when done .
copy contents of url to output stream specify internal buffer size . request gzip encoding
turns a parseexception into a opendap dap2 error and sends it to the client .
sends a opendap dap2 error to the client .
sends an error to the client . fix : the problem is that if the message is already committed when the ioexception occurs the headers dont get set .
sends a opendap dap2 error ( type unknown error ) to the client and displays a message on the server console .
handler for the client s ddx request . requires the getddx () method implemented by each server localization effort . <p > <p > once the ddx has been parsed and constrained it is sent to the requesting client .
handler for the client s data request . requires the getdds () method implemented by each server localization effort . <p > <p > once the dds has been parsed the data is read ( using the class in the localized server factory etc . ) compared to the constraint expression and then sent to the client .
handler for the client s directory request . <p > returns an html document to the client showing ( a possibly pseudo ) listing of the datasets available on the server in a directory listing format . <p > the bulk of this code resides in the class opendap . servlet . getdirhandler and documentation may be found there .
sends an html document to the client explaining that they have used a poorly formed url and then the help page ...
handler for opendap info requests . returns an html document describing the contents of the servers datasets . <p > the bulk of this code resides in the class opendap . servlet . getinfohandler and documentation may be found there .
handler for opendap . html requests . returns the opendap web interface ( aka the interface from hell ) to the client . <p > the bulk of this code resides in the class opendap . servlet . gethtmlinterfacehandler and documentation may be found there .
handler for opendap catalog . xml requests .
to be overridden by servers that implement catalogs
handler for opendap status requests ; not publically available used only for debugging
handler for opendap status requests ; not publically available used only for debugging
to be overridden by servers that implement status report
this is a bit of instrumentation that i kept around to let me look at the state of the incoming <code > httpservletrequest< / code > from the client . this method calls the <code > get * < / code > methods of the request and prints the results to standard out .
handles incoming requests from clients . parses the request and determines what kind of opendap response the client is requesting . if the request is understood then the appropriate handler method is called otherwise an error is returned to the client . <p > this method is the entry point for <code > dtsservlet< / code > .
**************************************************************************
prints the bad url page page to the passed printwriter
reference reference or base time as dare .
add an entity for resolution . specify a local resource and / or a url . look for the local resource first .
we read the dtd / schema locally if we can .
look probably desnt work
optionally read in all messages return as list<ncmess >
read an ncml file from a string and construct a ncmlcollectionreader from its scan or scanfmrc element .
read an ncml file from a url location and construct a ncmlcollectionreader from its scan or scanfmrc element .
replace any char not alphanumeric or in allowchars by replacechar .
break the given text into lines respecting word boundaries ( blank space ) .
delete any non - printable characters
remove any char not alphanumeric or in okchars .
remove all but printable ascii
transform embedded space to _
count number of chars that match in two strings starting from front .
pad the given string with padstring on the left up to the given length .
pad the given string with padstring on the right up to the given length .
remove all occurrences of the substring sub in the string s .
remove all occurrences of the character c in the string s .
remove all occurrences of the character c at the end of s .
remove any whitespace ( ie . character . iswhitespace ) from the input string .
collapse continuous whitespace into one single .
replace any char out in s with in .
replace all occurrences of any char in replacechar with corresponding string in replacewith
replaces all occurrences of pattern in string with value
replace all occurrences of orgreplace with orgchar ; inverse of replace () .
find all occurrences of the match in original and substitute the subst string .
escape any char not alphanumeric or in okchars . escape by replacing char with %xx ( hex ) .
this finds any %xx and converts to the equivalent char . inverse of escape () .
find all occurences of match strings in original and substitute the corresponding subst string .
remove any of the characters in out from sb
replace any string out in sb with char in .
replace any of the characters from out with corresponding character from in
find all occurences of the match in original and substitute the subst string directly into the original .
remove bad char from beginning or end of string
old school : used by fmrc and point
called by eventbus this is where the trigger comes in
/////////////////////////////////////////////////
a request has come in check that the state has been initialized . this is called from the request thread .
collection was changed update internal objects . called by collectionupdater trigger via handlecollectionevent so in a quartz scheduler thread
/////////////////////////////////////////////////////////////////////////////////////////////////
make the containing catalog of this feature collection http : // server : port / thredds / catalog / path / catalog . xml
this catalog lists the individual files comprising the collection .
get the associated grid dataset if any . called by datasethandler . opengriddataset ()
get the dataset named by the path . called by datasethandler . getnetcdffile ()
this says that a file url has to be topdirectory + [ files / + ] + match . remaining
/ * http : // www . unidata . ucar . edu / software / netcdf / docs / bestpractices . html packed data values
/////////////////////////////////////////////
/////////////////////////////////////////////
look through the collection and find what gds and pds templates are used .
/////////////////////////////////////////////////
/////////////////////////////////////////////
/////////////////////////////////////////////
/////////////////////////////////////////////
/////////////////////////////////////////////////////////////////
/////////////////////////////////////////////////////////////////////////////////
get a list of all the nested datasets .
release resources - undo the read of the catalog . this is needed when crawling large catalogs . for modest catalogs that you will repeatedly examine do not use this method .
read the referenced catalog asynchronously if the catalog factory supports it . if it doesnt this method will work equivilently to read () which is called the first time getdatasets () is called . if the catalog is already read in the callback will be called immediately before this method exits .
// proxy
/ * look public thredds . catalog . invcatalog getparentcatalog () { return !useproxy ? super . getparentcatalog () : proxy . getparentcatalog () ; }
/ * public void setlevels ( ucar . nc2 . dataset . grid . gridcoordsys gcs int current ) { this . zaxis = gcs . getverticalaxis () ; if ( zaxis == null ) { slider . setenabled ( false ) ; return ; } set up the slider and conversion slider . setenabled ( true ) ; slider . setinverted ( !gcs . iszpositive () ) ; slider . settooltiptext ( zaxis . getunitstring () ) ; setselectedindex ( current ) ;
************************************************************************ default handler for opendap info requests . returns an html document describing the contents of the servers datasets . <p / > the infocache &lt ; init - param&gt ; element in the web . xml file specifies the designated location for : <ul > <li > . info response override files . < / li > <li > server specific html * files . < / li > <li > dataset specific html * files . < / li > < / ul > <p / > the server specific html * files must be named #servlet# . html where #servlet# is the name of the servlet that is running as the opendap server in question . this name is determined at run time by using the class called class ( this . getclass () . getname () ) . <p / > <p > in the c ++ code the analogy is the per - cgi file names . < / p > <p / > <p / > the dataset specific html * files are located by catenating . html to #name# where #name# is the name of the dataset . if the filename part of #name# is of the form [ a - za - z ] + [ 0 - 9 ] * . * then this function also looks for a file whose name is [ a - za - z ] . html for example if #name# is ... / data / fnoc1 . nc this function first looks for ... / data / fnoc1 . nc . html . however if that does not exist it will look for ... / data / fnoc . html . this allows one per - dataset file to be used for a collection of files with the same root name . < / p > <p / > nb : an html * file contains html without the <html > <head > or <body > tags ( my own notation ) . <p / > <h3 > look for the user supplied server - and dataset - specific html * documents . < / h3 >
************************************************************************ checks the info directory for user supplied override documents for the passed dataset name . if there are overridedocuments present then the contents are read and returned to the caller as a string .
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -
make deep copy from sdata to another structuredata object whose data is self contained
make deep copy from an arraystructure to a arraystructurebb whose data is contained in a bytebuffer
make deep copy to an arraystructurebb whose data is contained in a bytebuffer . use the order of the members in the given structure ; skip copying any not in the structure
make deep copy from a structuredata to a arraystructurebb whose data is contained in a bytebuffer .
make deep copy from a structuredata to a arraystructurebb whose data is contained in a bytebuffer
make deep copy from a structuredata into the given arraystructurebb
only use in gribvariable to decide on variable identity when intvmerge = false . by returning a constant we dont intvmerge = false . problem is we cant reconstruct interval length without reference time which is not in the pds .
create a new coordinateaxis1d as a section of this coordinateaxis1d .
get the list of names to be used for user selection . the ith one refers to the ith coordinate .
///////////////////////////////////////////////// jfilechooser ///////////////////////////////////////////////////
find a tableconfigurer for this dataset if there is one .
create a tableanalyser for this dataset with the given tableconfigurer
for debugging messages
make a nestedtable object for the dataset .
no tableconfig was passed in - gotta wing it
/ * public void showtables ( java . util . formatter sf ) { sf . format ( %ntables%n ) ; for ( nestedtable . table t : tableset ) sf . format ( %s%n t ) ;
create an xml document from this info
//////////////////////////////////////////////////////////////////////////////
is this a valid file?
open the service provider for reading .
open the index and create the netcdf file from that
sync and extend
package private . use array . factory ()
copy from javaarray to storage using the iterator : used by factory ( object ) ;
copy to javaarray from storage using the iterator : used by copytondjavaarray ;
package private : mostly for iterators
************************************************************************ sends a opendap dap2 error to the client .
************************************************************************ sends an error to the client .
************************************************************************ sends a opendap dap2 error ( type unknown error ) to the client and displays a message on the server console .
************************************************************************ default handler for the client s das request . operates on the assumption that the das information is cached on a disk local to the server . if you don t like that then you better override it in your server : ) <p / > <p > once the das has been parsed it is sent to the requesting client .
************************************************************************ sends an html document to the client explaining that they have used a poorly formed url and then the help page ...
************************************************************************ default handler for opendap ascii data requests . returns the request data as a comma delimited ascii file . note that this means that the more complex opendap structures such as grids get flattened ... <p / > <p / > modified 2 / 8 / 07 jcaron to not make a dconnect2 call to itself
************************************************************************ default handler for debug requests ;
************************************************************************ this is a bit of instrumentation that i kept around to let me look at the state of the incoming <code > httpservletrequest< / code > from the client . this method calls the <code > get * < / code > methods of the request and prints the results to standard out .
************************************************************************ prints the opendap server help page to the passed printwriter
write the variable s declaration in xml . this function is used to create the xml representation of the data descriptor structure ( dds ) . see <em > the opendap user manual< / em > for information about this structure .
get the latitude values for the given type .
returns the long resulting from reversing 8 bytes at a specified offset in a byte array .
returns the float resulting from reversing 4 bytes at a specified offset in a byte array .
returns the char resulting from swapping 2 bytes at a specified offset in a byte array .
the attribute coordinates is an alias for _coordinateaxes .
add a parameter to a coordinatetransform . the variable attribute points to a another variable that has the data in it . make sure that atrribute and variable exist . id readdata is true read the data and use it as the value of the parameter otherwise use the name as the value of the parameter .
find the variable with the specified ( short ) name in this group .
find the variable with the specified ( short ) name in this group or a parent group .
retrieve the group with the specified ( short ) name .
retrieve a dimension using its ( short ) name . if it doesnt exist in this group recursively look in parent groups .
retrieve a dimension using its ( short ) name in this group only
attributehelper
find an enumeration typedef using its ( short ) name . if it doesnt exist in this group recursively look in parent groups .
get the common parent of this and the other group . cant fail since the root group is always a parent of any 2 groups .
is this a parent of the other group?
get string with name and attributes . used in short descriptions like tooltips .
set the group s parent group
adds the specified shared dimension to this group .
adds the specified shared dimension to this group but only if another dimension with the same name doesn t already exist .
add a nested group
add an enumeration
add a variable
remove an dimension : uses the dimension hashcode to find it .
remove an attribute : uses the group hashcode to find it .
remove a variable : uses the variable hashcode to find it .
remove a dimension using its name in this group only
remove a variable using its ( short ) name in this group only
make this immutable .
create groups to ensure path is defined
creates a das object from the collection of <code > basetype< / code > variables and their associated <code > attributes< / code > . this das is correctly formed ( vis - a - vis the dap specification ) for this dds .
this method just makes sure that the attribute field in each aliases resolves correctly if there ends up being a looseends attribute table at the top level .
make a helper function for <code > getlooseendstablename< / code > insures that there are no naming conflicts when creating a looseends <code > attributetable< / code >
a helper function for <code > checklooseendstablenameconflict< / code > insures that there are no naming conflicts when creating a looseends <code > attributetable< / code >
builds attributetables ( from basetype variables ) for us in a das created by getdas ()
builds attributetables ( from basetype variables ) for us in a das created by getdas ()
print a das constructed from this dds and it s basetype variables .
removes a variable from the <code > dds< / code > . does nothing if the variable can t be found . if there are multiple variables with the same name only the first will be removed . to detect this call the <code > checksemantics< / code > method to verify that each variable has a unique name .
is the variable <code > var< / code > a vector of dconstructors? return true if it is false otherwise . this mess will recurse into a dvector s template basetype ( which is a basetypeprimivitivevector ) and look to see if that is either a dconstructor or <em > contains< / em > a dconstructor . so the <code > list strucutre { ... } g [ 10 ] ; < / code > should be handled correctly . <p > <p / > note that the list type modifier may only appear once .
returns a reference to the named variable .
look for <code > name< / code > in the dds . start the search using the ctor variable ( or array / list of ctors ) found on the top of the stack <code > compstack< / code > ( for component stack ) . when the named variable is found return the stack compstack modified so that it now contains each ctor - type variable that on the path to the named variable . if the variable is not found after exhausting all possibilities throw nosuchvariable . <p > <p / > note : this method takes the stack as a parameter so that it can be used by a parser that is working through a list of identifiers that represents the path to a variable <em > as well as< / em > a shorthand notation for the identifier that is the equivalent to the leaf node name alone . in the form case the caller helps build the stack by repeatedly calling <code > search< / code > in the latter case this method must build the stack itself . this method is over kill for the first case .
reads a <b > ddx< / b > from the named <code > inputstream< / code > . this method calls a generated parser to interpret an xml representation of a <code > dds< / code > ( aka a <b > ddx< / b > ) and instantiate that <code > dds< / code > in memory . this method does the following : <ul > <li > gets a new <code > ddsxmlparser< / code > using the <code > basetypefactory< / code > held in this ( the <code > dds< / code > ) class . < / li > <li > uses the <code > ddsxmlparser< / code > to parse the ddx waiting in the <code > inputstream< / code > <i > is< / i > . < / li > <li > calls <code > dds . checkforattributenameconflict () < / code > < / li > <li > calls <code > dds . resolvealiases () < / code > < / li > < / ul > <p / > the last two items should be called every time a <code > dds< / code > is populated with variables ( by a parser or through the <code > dds< / code > api ) and prior to releasing it for use to any calling program .
reads a <b > ddx< / b > from the named <code > document< / code > . this method calls a generated parser to interpret an xml representation of a <code > dds< / code > ( aka a <b > ddx< / b > ) and instantiate that <code > dds< / code > in memory . this method does the following : <ul > <li > gets a new <code > ddsxmlparser< / code > using the <code > basetypefactory< / code > held in this ( the <code > dds< / code > ) class . < / li > <li > uses the <code > ddsxmlparser< / code > to parse the ddx waiting in the <code > inputstream< / code > <i > is< / i > . < / li > <li > calls <code > dds . checkforattributenameconflict () < / code > < / li > <li > calls <code > dds . resolvealiases () < / code > < / li > < / ul > <p / > <p / > the last two items should be called every time a <code > dds< / code > is populated with variables ( by a parser or through the <code > dds< / code > api ) and prior to releasing it for use to any calling program .
check the semantics of the <code > dds< / code > . if <code > all< / code > is true check not only the semantics of the <code > dds< / code > itself but also recursively check all variables in the dataset .
print the <code > dds< / code > on the given <code > printwriter< / code > .
before the dds can be used all of the aliases in the various attributetables must be resolved . this means that it is necessary to verify that each alias references an attribute that exists and is not another alias . this is accomplished by searching the dds s variable s attribute holdings for aliases everytime an alias is located a new search begins to find the attribute that the alias is attempting to reference . <p / > this method recursively searchs through the passed <code > basetype< / code > parameter bt for alias members of attributetables and when they are found attempts to resolve them to a specific attribute . <p / > this method gets called at the top level at the parser only after the entire dds has been parsed and built . it s intial invocation get passed the dds ( which is in fact a <code > basetype< / code > ) <p / > <p / > this method manipulates the global variable <code > currentbt< / code > .
this method recursively searchs through the passed <code > attributetable< / code > parameter at for alias members . when an alias is found the method attempts to resolve it to a specific attribute . <p / > this method is invoked by <code > resolvealiases ( basetype bt ) < / code > and is used to search for aliases in attributetables found in a basetypes attributes . <p / > this method manipulates the global variable <code > currentbt< / code > .
this method attempts to resolve the past alias to a specific attribute in the dds . it does this by : <ul > <li > 1 ) tokenizing the alias s attribute field ( see <code > alias< / code > ) < / li > <li > 2 ) evaluating the tokenized field to locate the longest possible variable name represented as a consecutive set of tokens < / li > <li > 2 ) evaluating the the remaining tokenized field to locate the attribute that this alias is attempting to reference< / li > <li > 4 ) setting the aliases internal references for it s variable and it s attribute . < / ul > <p / > if an attribute matching the definition of the alias cannot be located an exception is thrown
this method executes a ( recursive ) search of the <code > dconstructor< / code > parameter <b > dcbt< / b > for a <code > basetype< / code > variable whose name resolves to the vector of names contained in the <code > vector< / code > parameter <b > vnames< / b > . a variable is considered a match if each of it s node names in the hierarchy of containers in the one passed as parameter <b > dcbt< / b > matches ( equals ) the corresponding name in the vector <b > vnames< / b > .
the <code > normalize< / code > method is used to normalize variable and attribute name strings prior to their comparison with the normalized tokens extracted from the variable and name fields in an alias declaration . <p / > the rule for this normalization is as follows : <p / > <ul > <li > the &quot ; ( double quote ) and the \ ( backslash aka escape ) characters must be escaped ( using the \ character ) in the <b > variable< / b > and <b > attribute< / b > fields . < / li > < / ul >
the <code > tokenizealiasfiled () < / code > method is used to tokenize the <b > variable< / b > and the <b > attribute< / b > fields in the alias declaration . it is required that these fields be <b > normalized< / b > in the xml instance document . the rules for this normalization are as follows : <ul > <p / > <li > the &quot ; ( double quote ) and the \ ( backslash aka escape ) characters must be escaped ( using the \ character ) in the <b > variable< / b > and <b > attribute< / b > fields . < / li > <p / > <li > the <b > variable< / b > and <b > attribute< / b > fields must be enclosed in double quotes if their values contain the dot ( . ) character . < / li > <p / > <li > fully qualified <b > variable< / b > and <b > attribute< / b > names always begin with the dot ( . ) character . < / li > < / ul >
prints the peristent representation of the <code > dds< / code > as an xml document . this xml document is know as a <b > ddx< / b > . the ddx can be parsed using the <code > ddsxmlparser< / code >
takes the passed parameter <code > das< / code > and attempts to incorporate it s contents into the attributes of the dds variables . if an <code > attribute< / code > in the <code > das< / code > can t be associated with a variable in a logical manner then it is placed at the top level of the dds . ( basically it becomes a toplevel attribute in the dataset )
a helper methods for ingestdas () .
a helper methods for ingestdas () .
a helper methods for ingestdas () .
check for name conflicts . in the xml representation of the dds it is syntactically possible for a variable container ( dconstructor ) to possess an attribute that has the same name as one of the container variable s member variables . that s a no - no! . check for it here and throw a nice fat exception if we find it .
this a wrapper method for <code > dds . print () < / code > .
this a wrapper method for <code > dds . printxml () < / code > .
returns a clone of this <code > dds< / code > . see dapnode . clonedag ()
look what about extending an index ??
/ * message gribidsection { required uint32 center_id = 1 ; required uint32 subcenter_id = 2 ; required uint32 master_table_version = 3 ; required uint32 local_table_version = 4 ; required uint32 significanceofrt = 5 ; repeated uint32 refdate = 6 [ packed = true ] ; // year month day hour minute second ; required uint32 productionstatus = 7 ; required uint32 processeddatatype = 8 ; }
write griddatatype data to the geotiff file .
write grid data to the geotiff file . grid currently must : <ol > <li > have a 1d x and y coordinate axes . <li > be lat / lon or lambert conformal projection <li > be equally spaced < / ol >
replace missing values with dataminmax . min - 1 . 0 ; return a floating point data array .
replace missing values with 0 ; scale other values between 1 and 255 return a byte data array .
look wtf ?? is this the seam crossing ??
write gridcoverage data to the geotiff file .
search for an aliased coord that may have multiple variables : dimname = alias1 alias2 ; variable alias1 ( dim ) ; variable alias2 ( dim ) ;
given the information on construction writes the necessary exception information .
package private . use array . factory ()
/ * create new arrayint with given indeximpl and backing store . should be private .
copy from javaarray to storage using the iterator : used by factory ( object ) ;
package private : mostly for iterators
begin api override
open gribcollectionimmutable from an existing index file . return null on failure
///////////////////////////////////////////////////////////////////////////////////////////////
this is only used for the top level gribcollection .
find out what kind of index this is
open gribcollectionimmutable from an existing index file . return null on failure
open gribcollectionimmutable from an existing index file . return null on failure
used ( only ) by gribcollectionbuilder
update grib collection if needed
return true if changed exception on failure
return true if changed exception on failure
update all the gbx indices in one directory and the ncx index for that directory
file partition : each file is a collection of grib records and the collection of all files in the directory is a partitioncollection . rewrite the partitioncollection and optionally its children
open gribcollection from config . collectionupdater calls invdatasetfc . update () calls invdatasetfcgrib . updatecollection ()
used by iosps
open a grib collection from a single grib1 or grib2 file . create the gbx9 and ncx2 files if needed .
from a single file read in the index create if it doesnt exist ; return null on failure
create a grib collection / partition collection from an existing ncx2 file . partioncollection . partition . getgribcollection () .
/ indexreader interface
match has different semantics than urlcompare
allow users to add to the default rc
allow users to search the default rc
record some well known parameters
overwrite existing entries
allow for external loading
prints the original string representation of this clause . for use in debugging .
get top level datasets contained directly in this catalog . do not dereference catrefs .
look though all datasets here or under here . do not go into catrefs
sets new projection for subsequent drawing .
we have to deal with both projections and resolution - dependence
make an arraylist of shapes from the given featurelist and current display projection
compares this prefixname with a string .
the given task is run in a background thread . progress is indicated once a second . you cannot call this method again till the task is completed .
update all the grib indices in one directory and the collection index for that directory
look need an option to only scan latest last partition or something
return true if changed exception on failure
/ * look heres a place where one could post process and combine instead of at coverage level . this would benefit iosp ie the netcdf api private void maketime2runtime ( gribcollectionmutable . dataset ds2d boolean iscomplete ) throws ioexception {
/ * magic_start version sizerecords variablerecords ( sizerecords bytes ) sizeindex gribcollectionindex ( sizeindex bytes )
/ * message dataset { required type type = 1 ; repeated group groups = 2 ; }
/ * message group { gds gds = 1 ; // use this to build the horizcoordsys repeated variable variables = 2 ; // list of variables repeated coord coords = 3 ; // list of coordinates repeated uint32 fileno = 4 [ packed = true ] ; // the component files that are in this group key into gc . mfiles }
/ * message variable { uint32 discipline = 1 ; bytes pds = 2 ; // raw pds repeated uint32 ids = 3 [ packed = true ] ; // extra info not in pds ; grib2 id section
/ * message partitionvariable { uint32 groupno = 1 ; uint32 varno = 2 ; uint32 flag = 3 ; uint32 partno = 4 ;
/ * message partition { string name = 1 ; // name is used in tds - eg the subdirectory when generated by timepartitioncollections string filename = 2 ; // the gribcollection . ncx file reletive to gc . string directory = 3 ; // top directory not used uint64 lastmodified = 4 ; int64 length = 5 ; int64 partitiondate = 6 ; // partition date added 11 / 25 / 14 }
look
//////////////
extend result with all the values in the list of enscoord
/ * message record { uint32 fileno = 1 ; // which grib file ? key into gc . filemap uint64 pos = 2 ; // offset in grib file of the start of entire message uint64 bmspos = 3 ; // use alternate bms if non - zero ( grib2 only ) uint32 drsoffset = 4 ; // offset of drs from pos ( grib2 only ) }
/ * message dataset { type type = 1 ; repeated group groups = 2 ;
/ * message group { gds gds = 1 ; // use this to build the horizcoordsys repeated variable variables = 2 ; // list of variables repeated coord coords = 3 ; // list of coordinates repeated int32 fileno = 4 [ packed = true ] ; // the component files that are in this group key into gc . mfiles }
/ * message variable { uint32 discipline = 1 ; bytes pds = 2 ; // raw pds repeated uint32 ids = 3 [ packed = true ] ; // extra info not in pds ; grib2 id section
set the index - th structuredata of this arraystructure .
get the index - th structuredata of this arraystructure .
get member data of any type for a specific record as an array . this may avoid the overhead of creating the structuredata object but is equivilent to getstructure ( recno ) . getarray ( member m ) .
set data for one member over all structures . this is used by variableds to do scale / offset .
extract data for one member over all structures .
member data is itself a structure and may be an array of structures .
get member data array of any type as an object eg float double string structuredata etc .
get scalar value as a float with conversion as needed . underlying type must be convertible to float .
get scalar value as a double with conversion as needed . underlying type must be convertible to double .
get scalar value as an int with conversion as needed . underlying type must be convertible to int .
get scalar member data of type float .
get scalar member data of type byte .
get scalar member data of type short .
get scalar member data of type char .
get member data of type string or char .
get member data of type structure .
get member data of type array of structure .
get member data of type arraysequence
get member data of type arrayobject
experimental
precalculate some stuff
this returns true when the line between pt1 and pt2 crosses the seam . when the cone is flattened the seam is lon0 + - 180 .
force an attribute value ( typically string ) to match a given basetype
/ * get the size of an equivalent java object ; zero if not defined
force a numeric value to be in a specified range only defined for simple integers ( valueclass long ) warning : unsigned values are forced into the signed size but the proper bit pattern is maintained . the term force means that if the value is outside the typed min / max values it is pegged to the min or max value depending on the sign . note that truncation is not used .
peg a value to either the min or max depending on sign .
for removeprefix / path style servlet mappings .
/////////////////////////////////////////////////
_more_
evaluate a filter with respect to a sequence record . assumes the filter has been canonicalized so that the lhs is a variable .
convert the view to a constraint string suitable for use in a url except not url encoded .
recursive helper for tostring / toconstraintstring
reference x match
selection x match <p > evaluate a filter with respect to a sequence record . assumes the filter has been canonicalized .
evaluate a filter with respect to a sequence record .
/ * search the set of variables
locate each unexpanded structure|sequence and : 1 . check that none of its fields is referenced = > do not expand 2 . add all of its fields as leaves note that #2 may end up adding additional leaf structs & / or seqs
locate each structure|sequence and : 1 . check that all of its fields are referenced recursively and not constrained otherwise ignore 2 . contract by removing all of the fields of the structure or sequence . this is intended to be ( not quite ) the dual of expand () ;
recursive helper
count the number of fields of a structure that already in this view .
see if a structure is whole which means that none of its fields is missing from the constraint all of fields use default ( non - constrained ) dimension ) and all of its fields are also whole . this must be done recursively .
compute dimension related information using slicing and redef info . in effect this is where projection constraints are applied <p > assume that the constraint compiler has given us the following info : <ol > <li > a list of the variables to include . <li > a pair ( dapdimension slice ) for each redef <li > for each variable in #1 a list of slices taken from the constraint expression < / ol > <p > two products will be produced . <ol > <li > the variables map will be modified so that the slices properly reflect any original or redef dimensions . <li > a set dimrefs of all referenced original dimensions . < / ol > <p > the processing is as follows <ol > <li > for each redef create a new redef dimension <li > for each variable : <ol > <li > if the variable is scalar do nothing . <li > if the variable has no associated slices then make its new dimensions be the original dimensions . <li > otherwise walk the slices and create new dimensions from them ; use redefs where indicated <li > < / ol > < / ol >
walk all the included variables and accumulate the referenced enums
walk all the included declarations and accumulate the set of referenced groups
static utility for compiling a constraint string
write the variable s declaration in a c - style syntax . this method is used to create textual representation of the data descriptor structure ( dds ) .
returns a clone of this <code > primitivevector< / code > . see dapnode . clonedag ()
/ * 1 ) single runtime 1a timeoffset 1b time or timerange 1c none = constant runtime dataset 2 ) multiple runtimes 2a timeoffset = constant offset dataset 2b time ( not range ) = constant forecast dataset
accept grib2 or ncx files
save all data in the persistentstore
actions that are system - wide
//////////////////////////////////////////////////////////////////
initialize the file read in all the metadata ( ala dm_open )
initialize the file read in all the metadata ( ala dm_open )
initialize the file read in all the metadata ( ala dm_open )
get the byte order for the machine type .
look wtf ?? set the machine type for this system .
read the file header info ( dm_rfil )
read in the row and column keys ( dm_key )
read the headers ( dm_rhda )
read the parts ( dm_rprt )
run the program
find a key with the given name
find the file header with this name
read in the values for the file header
print the part information
find the part with the particular name .
find the part with the particular name .
get the pointer to the data . taken from dm_rdtr
read an integer
read into an array of ints .
read a float
read into an array of ints .
read a string
read the data
read the real ( float ) data
unpack an array of packed integers .
get a bit string for an integer
//////////////////////////////////////////////////////////////////////////////////////////////
//////////////////////////////////////
write ncfile to a writablebytechannel .
parse the ddx waiting in the <code > inputstream< / code > and instantiate all of the member <code > basetype< / code > variables and their associated <code > attributes < / code > into a <code > dds< / code > using the passed <code > basetypefactory< / code >
parse the ddx waiting in the <code > inputstream< / code > and instantiate all of the member <code > basetype< / code > variables and their associated <code > attributes < / code > into a <code > dds< / code > using the passed <code > basetypefactory< / code >
this method recursively travels through the dom tree locating basetype derived nodes and placing them in the dds . the structure of the basetype derived elements in the xml instance document is captured in the dom object that is being parsed . this structure again reflected in the resulting dds .
arrays have special parsing need as their syntax is different from that of a typical basetype derived type or a container type . the array is based on a template variable that can have any structure that can be represented by the opendap data model . with the exception of ( you knew this was comming right? ) of other arrays . ie you can t have arrays of arrays . this caveat is enforced by the xml schema .
builds the template variable for an array . the logic here has a lot in common with the logic in parsebase . i considered trying to refactor the code so that the two methods could utilize the same logic but i bagged it . cie la vie . <p / > arrays of arrays are not allowed this rule should is enforced through the schema validation process .
grids are unusual examples of dconstructor and require special handling when parsing .
a convienience function used for displaying information in _debug mode . prints an xml element s name content ( if any ) and attributes to system . out
/ * builds a new basetype derived type from the passed xml element . <p > this happens in 4 steps : <ul > <li > 1 ) determine the opendap type and vairiable name < / li > <li > 2 ) get an new one of the thing in ( 1 ) < / li > <li > 3 ) parse any attribute tags associated with this opendap type . ( they appear as children of the xml element ) < / li > <li > 4 ) parse any alias tags associated with this opendap type . ( they appear as children of the xml element ) < / li > < / ul >
the name of this method might be a bit misleading . this method is basically a wrapper for the basetypefactory associated with the dds that we are building . <p / > i think it should really be a method of basetypefactory . <p / > something like : <p / > basetypefactory . getnewvariable ( string typestring string name ) <p / > but well basetypefactory is an interface so that s a crappy idea . * sigh *
parse the attribute tags for a given variable element in the xml document . build the appropriate attributes and attributetables and add them to the the current variable s ( currentbt s ) attributetable .
parse all of the alias tags in this element of the xml document . add each one to the correct attribute table .
this method is used to normalize strings prior to their inclusion in xml documents . xml has certain parsing requirements around reserved characters . these reserved characters must be replaced with symbols recognized by the xml parser as place holder for the actual symbol . <p / > the rule for this normalization is as follows : <p / > <ul > <li > the &lt ; ( less than ) character is replaced with &amp ; lt ; <li > the &gt ; ( greater than ) character is replaced with &amp ; gt ; <li > the &amp ; ( ampersand ) character is replaced with &amp ; amp ; <li > the ( apostrophe ) character is replaced with &amp ; apos ; <li > the &quot ; ( double quote ) character is replaced with &amp ; quot ; < / ul >
wml2 : collection / wml2 : observationmember / om : om_observation / om : featureofinterest
convert ids to datadescriptors expand table d
look for replication move replicated items into subtree
/ * try to grab names of compounds ( structs ) if f = 1 is followed by f = 3 eg : 0 - 40 - 20 : gqisflagqualdetailed - quality flag for the system 1 - 01 - 010 : replication 3 - 40 - 2 : ( iasi level 1c band description ) 0 - 25 - 140 : start channel 0 - 25 - 141 : end channel 0 - 25 - 142 : channel scale factor 1 - 01 - 087 : replication 3 - 40 - 3 : ( iasi level 1c 100 channels ) 1 - 04 - 100 : replication 2 - 01 - 136 : operator = change data width 0 - 5 - 42 : channel number 2 - 01 - 000 : operator = change data width 0 - 14 - 46 : scaled iasi radiance 0 - 2 - 19 : satellite instruments 0 - 25 - 51 : avhrr channel combination 1 - 01 - 007 : replication 3 - 40 - 4 : ( iasi level 1c avhrr single scene ) 0 - 5 - 60 : y angular position from centre of gravity 0 - 5 - 61 : z angular position from centre of gravity 0 - 25 - 85 : fraction of clear pixels in hirs fov ...
flatten the compounds ( type 3 ) ; but dont remove bad ones
assume theres only one in effect at a time
///////////////// local time types
get the dataset filename .
print the constrained <code > dds< / code > on the given <code > printwriter< / code > .
is this a valid file?
get the cf feature type
read the data for the variable
read in the data for the variable . in this case it should be a structure . the section should be rank 2 ( station time ) .
read in the data for the record variable . in this case it should be a structure of record dimension . we can handle a subset of the variables in a structure .
build the netcdf file
build a standard station structure
build a ship station structure . here the columns are the stations / reports and the rows ( 1 ) are the reports .
returns the absolute difference between two numbers i . e . { @code |a - b| } .
same as {
returns the relative difference between two numbers i . e . { @code |a - b| / max ( |a| |b| ) } . <p > for cases where { @code a == 0 } { @code b == 0 } or { @code a } and { @code b } are extremely close traditional relative difference calculation breaks down . so in those instances we compute the difference relative to { @link float#min_normal } i . e . { @code |a - b| / float . min_normal } .
check if two numbers are nearly equal with given absolute tolerance .
////////////////////////////////////////////////////////////////////
}
/ * 14 . 1 <bc_tableb_bufr14_1_0_crex_6_1_0 > <sno > 1< / sno > <class > 00< / class > <fxy > 000001< / fxy > <elementname_e > table a : entry< / elementname_e > <elementname_f > table a : entr?e< / elementname_f > <elementname_r > ??????? ? : ???????< / elementname_r > <elementname_s > tabla a : elemento< / elementname_s > <bufr_unit > ccitt ia5< / bufr_unit > <bufr_scale > 0< / bufr_scale > <bufr_referencevalue > 0< / bufr_referencevalue > <bufr_datawidth_bits > 24< / bufr_datawidth_bits > <crex_unit > character< / crex_unit > <crex_scale > 0< / crex_scale > <crex_datawidth > 3< / crex_datawidth > <status > operational< / status > <notestotable_e > notes : ( see ) #bufr14_1_0_crex6_1_0_notes . doc#bc_cl000< / notestotable_e > < / bc_tableb_bufr14_1_0_crex_6_1_0 >
/ * <b_tabled_bufr14_1_0_crex_6_1_0 > <sno > 2647< / sno > <category > 10< / category > <fxy1 > 310013< / fxy1 > <elementname1_e > ( avhrr ( gac ) report ) < / elementname1_e > <fxy2 > 004005< / fxy2 > <elementname2_e > minute< / elementname2_e > <remarks_e > minute< / remarks_e > <status > operational< / status > < / b_tabled_bufr14_1_0_crex_6_1_0 >
/ * message gds { bytes gds = 1 ; // raw gds : grib1sectiongriddefinition or grib2sectiongriddefinition uint32 predefinedgriddefinition = 2 ; // only grib1 ; instead of gds raw bytes ; need center subcenter to interpret }
/ * message coord { gribaxistype axistype = 1 ; int32 code = 2 ; // time unit ; level type string unit = 3 ; repeated float values = 4 ; repeated float bound = 5 ; // only used if interval then = ( value bound ) repeated int64 msecs = 6 ; // calendar date
/ * not currently used
selected consult or iterator overrides for efficiency
parses a unit specification . this method is thread - safe .
sort ray objects in the same sweep according to the ascended azimuth ( from 0 to 360 ) and time .
show me lots of stuff about the passed in object
write a subset of the data to a <code > dataoutputstream< / code > .
a variable is tiled if any of its dimensions are tiled
implements coverting a complete best to a monotonic best . the reftime is not allowed to decrease
convert a latlonpoint to projection coordinates
convert projection coordinates to a latlonpoint note : a new object is not created on each call for the return value .
convert projection coordinates to lat / lon coordinate .
convert lat / lon coordinates to projection coordinates .
does the line between these two points cross the projection seam .
split a latlon rectangle to the equivalent projectionrect using this latlonprojection to split it at the seam if needed .
create a latlon rectangle and split it into the equivalent projectionrect using this latlonprojection . the latlon rect is constructed from 2 lat / lon points . the lon values are considered coords in the latlonprojection and so do not have to be + / - 180 .
look change to responseentity<string >
everything but header data which is binary data and capabilities which is xml
experimental : should be package private
construct the timeseries plot for the list of logs passed in
turn a list into a map
get the value as an array .
retrieve string value ; only call if isstring () is true .
retrieve a numeric value by index . if it s a string it will try to parse it as a double .
write cdl representation into f
set the value as a string trimming trailing zeroes
set the values from a list
set the values from an array
scan the collection and gather information on contained datasets .
generate the catalog for a resolver request of the given proxydatasethandler .
- baseid + / + node . getpath () . substring ( collectionlevel . length ) [ when id added at catalog construction using node info ]
- collectionpath + / + node . getpath () . substring ( collectionlevel . length ) [ when service is absolute ( i . e . relative to collection ) ]
- node . getpath () . substring ( cataloglevel . length ) + / catalog . xml
caller must iter . finish () and out . close () .
put a message on the queue schedule writing if not already scheduled .
returns a string representation of the variables value . this is really foreshadowing functionality for server types but as it may come in useful for clients it is added here . simple types ( example : dfloat32 ) will return a single value . dconstuctor and dvector types will be flattened . dstrings and durl s will have double quotes around them .
deferred creation of components to minimize startup
jump to the appropriate tab based on datatype of invdataset
jump to the appropriate tab based on datatype of invaccess
jump to the appropriate tab based on datatype of threddsdata
handle messages .
set look - and - feel .
must call this method on the event thread .
build an unnamed invcatalog for this datasetsource and return the top - level invdataset . the resultservice for this datasetsource is used to create the invservice for the new invcatalog . each invdataset in the catalog is named with the location of the object they represent on the dataset source .
return a list of the invdatasets contained in the given collection dataset on this datasetsource .
create standard name from list of axes . sort the axes first
prefer smaller ranks in case more than one
find the coordinateaxis that has the given axistype . if more than one return the one with lesser rank .
find the first projectionct from the list of coordinatetransforms .
get the projection for this coordinate system . if islatlon () then returns a latlonprojection . otherwise extracts the projection from any projectionct coordinatetransform .
true if it has x and y coordinateaxis and a coordtransform projection
true if all axes are coordinateaxis1d and are regular
test if all the dimensions in subset are in set
do we have all the axes in the list?
do we have the named axis?
do we have all the dimensions in the list?
do we have all the axes types in the list?
do we have an axes of the given type?
this version of clonedag () is the primary point of cloning . if the src is already cloned then that existing clone is immediately returned . otherwise clonedag ( map ) is called to have the object clone itself . note this is static because it uses no existing state .
this procedure does the actual recursive clone .
************************************************************************ default handler for opendap . html requests . returns an html form and javascript code that allows the user to use their browser to select variables and build constraints for a data request . the dds and das for the data set are used to build the form . the types in opendap . servlet . www are integral to the form generation .
////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////////////////////////////
debug
add listener : listselectionevent sent when a new row is selected
remove listener
get the currently selected bean or null if none selected .
get the currently selected beans . use this for multiple selection
get the currently selected cells . use this for multiple row selection when columnselection is on
set the currently selected cells ( 0 false or null ) . use this for multiple row selection when columnselection is on
set which row is selected .
set which rows are selected . must also call setselectionmode ( listselectionmodel . multiple_interval_selection ) ;
save state to the preferencesext .
notifies the tablemodel that the data in the specified bean has changed . the tablemodel will then fire an event of its own which its listeners will hear ( usually a jtable ) .
restore state from preferencesext
/ * needed to implement array . getelement ()
convert a string to a specified cdmtype note that if en is defined then we attempt to convert the string as enum const
factory method for constructing an unknown unit from a name .
closes this input stream and releases any system resources associated with the stream ; closes the method also .
has v already been added to the set of extra variables?
is v a coordinate axis for this feature type?
find a coord axis of the given type in the table and its parents
use recursion so that parent variables come first
add table join to this cursor level
// station or station_profile
also called from standardpointfeatureiterator
do the conversion and return a nodemap representing the conversion .
create a variable or field
/ * package
/ * package
/ * package
/ * package
dsp api
utilities
create a simpleunit from the given name catch exceptions .
create a simpleunit from the given name allow exceptions .
need subclass access
return true if unitstring1 is compatible to unitstring2 meaning one can be converted to the other . if either unit string is illegal return false .
return true if unitstring1 is convertible to unitstring2
return true if this ucar . units . unit is a date .
return true if the given unit is convertible to a date unit . allowed format is something like : <pre > [ - ] y [ y [ y [ y ]]] - mm - dd [ ( t| ) hh [ : mm [ : ss [ . sss * ]]] [ [ + | - ] hh [[ : ] mm ]]] < / pre >
return true if the given unit is a time unit eg seconds .
get the conversion factor to convert inputunit to outputunit .
convert given value of this unit to the new unit .
return true if unitstring1 is compatible to unitstring2 meaning one can be converted to the other . if either unit string is illegal return false .
is this an instance of an unknownunit?
extract the value can only be called for scaledunit .
generates a clause which which compares subclauses using one of the relative operators supported by the operator class .
generates a clause which invokes a function that returns a boolean value .
generates a clause which invokes a function that returns a basetype .
/ * private void writedatafinish () throws ioexception { arrayint . d1 nextchildarray = new arrayint . d1 ( recno ) ;
////////////////////////////////////////////////////////////////////////////////
adapt a rank 2 array into a java . awt . image . bufferedimage . if passed a rank 3 array take first 2d slice .
///////////////////////////////////////////////
open a catalog and crawl ( depth first ) all the datasets in it . close catalogs and release their resources as you .
crawl a catalog thats already been opened . when you get to a dataset containing leaf datasets do all only the first or a randomly chosen one .
crawl this dataset recursively return all datasets
crawl this dataset recursively . only send back direct datasets
get index file may be in cache directory may not exist
looking for an existing file in cache or not
gml : point / gml : pos
java . net calls this :
http client calls this :
debugging do not use in production . set counters to zero set debugging on
debugging do not use .
close the file and release any associated system resources .
set the position in the file for the next read or write .
get the length of the file . the data in the buffer ( which may not have been written the disk yet ) is taken into account .
copy the contents of the buffer to the disk .
read a byte of data from the file blocking until data is available .
read up to <code > len< / code > bytes into an array at a specified offset . this will block until at least one byte has been read .
read <code > nbytes< / code > bytes at the specified file offset send to a writablebytechannel . this will block until all bytes are read . this uses the underlying file channel directly bypassing all user buffers .
read directly from file without going through the buffer . all reading goes through here or readtobytechannel ;
reads exactly <code > len< / code > bytes from this file into the byte array . this method reads repeatedly from the file until all the bytes are read . this method blocks until all the bytes are read the end of the stream is detected or an exception is thrown .
write a byte to the file . if the file has not been opened for writing an ioexception will be raised only when an attempt is made to write the buffer to the file . <p / > caveat : the effects of seek ( ) ing beyond the end of the file are undefined .
write <code > len< / code > bytes from an array to the file .
read an array of shorts
read an integer at the given position bypassing all buffering .
read an array of ints
read an array of longs
read an array of floats
read an array of doubles
read a string of known length .
read a string of max length zero terminate .
write an array of booleans
write an array of shorts
write an array of chars
write an array of ints
write an array of longs
write an array of floats
write an array of doubles
writes the string to the file as a sequence of bytes . each character in the string is written out in sequence by discarding its high eight bits .
writes the character array to the file as a sequence of bytes . each character in the string is written out in sequence by discarding its high eight bits .
writes a string to the file as a sequence of characters . each character is written to the data output stream as if by the <code > writechar< / code > method .
writes a string to the file using utf - 8 encoding in a machine - independent manner . <p / > first two bytes are written to the file as if by the <code > writeshort< / code > method giving the number of bytes to follow . this value is the number of bytes actually written out not the length of the string . following the length each character of the string is output in sequence using the utf - 8 encoding for each character .
search forward from the current pos looking for a match .
create the selector result string and append .
/ * since none of these are required can only do consistency checks
returns a directorypartition or directorycollection
find the index file using its canonical name
scans first 100 files to decide if its a leaf . if so it becomes a directorycollection else a partitioncollection .
find all children directories . does not recurse . we separate this from the constructor so it can be done on demand public for debugging .
scan for subdirectories make each into a directorybuilder and add as a child
read the list of files from the index
open a netcdf dataset using netcdfdataset . defaultenhancemode plus coordsystems and turn into a griddataset .
open a netcdf dataset using netcdfdataset . defaultenhancemode plus coordsystems and turn into a griddataset .
return griddatatype objects grouped by gridcoordsys . all griddatatype in a gridset have the same gridcoordsystem .
show grids and coordinate systems .
filecacheable
you must call shutdown () to shut down the background threads in order to get a clean process shutdown .
acquire a filecacheable and lock it so no one else can use it . call filecacheable . close when done .
acquire a filecacheable from the cache and lock it so no one else can use it . if not already in cache open it the filefactory and put in cache . <p / > app should call filecacheable . close when done and the file is then released instead of closed . <p / > if cache size goes over maxelement then immediately ( actually in 100 msec ) schedule a cleanup in a background thread . this means that the cache should never get much larger than maxelement unless you have them all locked .
try to find a file in the cache .
look should you remove the entire cacheelement ?
remove all instances of object from the cache
release the file . this unlocks it updates its lastaccessed date . normally applications need not call this just close the file as usual . the filecacheable has to do tricky stuff .
debug
show individual cache entries add to formatter .
add stat report ( hits misses etc ) to formatter .
cleanup the cache bringing it down to minimum number . will close the lru ( least recently used ) ones first . will not close locked files . normally this is done in a background thread you dont need to call . <p / > we have to synchronize because of clearcache ()
convert 4 bytes into a signed integer .
acquire a filecacheable and lock it so no one else can use it . call filecacheable . close () when done .
acquire a filecacheable from the cache and lock it so no one else can use it . if not already in cache open it with filefactory and put in cache . <p / > call filecacheable . close () when done ( rather than filecacheif . release () directly ) and the file is then released instead of closed . <p / > if cache size goes over maxelement then immediately ( actually in 100 msec ) schedule a cleanup in a background thread . this means that the cache should never get much larger than maxelement unless you have them all locked .
try to find a file in the cache .
get cacheelement specified by hashkey . if found update lastused in shadowcache .
/ * if ( disabled . get () ) return ;
release the file . this unlocks it updates its lastaccessed date . filecacheable . close () needs to call this instead of actually closing .
debug
remove all cache entries .
show individual cache entries add to formatter .
/////////////////////////////////////////////////////////////
/ * the parse function allows the specification of a new stream in case one is reusing the parser
determine if this coordinatesystem can be made into a gridcoordsys . optionally for a given variable . this currently assumes that the coordinatesystem : <ol > <li > is georeferencing ( cs . isgeoreferencing () ) <li > x y are 1 or 2 - dimensional axes . <li > z t if they exist are 1 - dimensional axes . <li > domain rank > 1 < / ol >
determine if the coordinatesystem cs can be made into a gridcoordsys for the variable v .
we have to delay making these since we dont identify the dimensions specifically until now
is this a global coverage over longitude ?
true if increasing z coordinate values means up in altitude
given a point in x y coordinate space find the x y index in the coordinate system .
given a point in x y coordinate space find the x y index in the coordinate system . if outside the range the closest point is returned eg 0 or n - 1 depending on if the coordinate is too small or too large .
given a lat lon point find the x y index in the coordinate system .
given a lat lon point find the x y index in the coordinate system . if outside the range the closest point is returned
get the x y bounding box in projection coordinates .
get the lat / lon coordinates of the midpoint of a grid cell using the x y indices
get index ranges for the given lat lon bounding box . for projection only an approximation based on latlon corners . must have coordinateaxis1d or 2d for x and y axis .
///////////////////////////////////////////////////////////////
get the list of level names to be used for user selection . the ith one refers to the ith level coordinate .
return slider indicator position for currently selected item
return item selected by this pixel position
create standard name = topcollectionname + last directory
create standard name = topcollectionname + last directory
this idiom keeps the iterator from escaping so that we can use try - with - resource and ensure directorystream closes . like ++
copy remote files to localdir
pointfeatureiterator . hasnext () doesn t guarantee idempotency but we do .
but we can define a stronger contract .
returns the next point that satisfies the filter or { @code null } if no such point exists .
look maybe combine grib1 grib2 and bufr ??
convert a period string into a calendarperiod . field .
minimize memory use by interning . wacko shit in gribpartitionbuilder timecoordinate whoduhthunk?
convert a udunit period string into a calendarperiod
subtract two dates return difference in units of this period . if not even will round down and log a warning
get the conversion factor of the other calendarperiod to this one
get the duration in milliseconds - +
start + offset = end
is this a valid file?
open the service provider for reading .
open the index and create the netcdf file from that
sync the file
initialize the parameter tables .
add a datarootext to in - memory tree .
find the longest path match .
find the longest dataroot match .
convert a datarootext to a dataroot
finds datasetscan datasetfmrc look for duplicate ids ( give message ) . dont follow catrefs .
return requested calendardaterange .
redo the variables against the shared coordinates
open an existing netcdf file for writing data . fill mode is true . cannot add new objects you can only read / write data to existing variables .
create a new netcdf file with fill mode true .
// use these calls in define mode
add a shared dimension to the file . must be in define mode .
add a shared dimension to the file . must be in define mode .
rename a dimension . must be in define mode .
add a group to the file . must be in define mode . if pass in null as the parent then the root group is returned and the name is ignored . this is how you get the root group . note this is different from other uses of parent group .
add a global attribute to the file . must be in define mode .
add a enumtypedef to the file . must be in define mode .
delete a group attribute . must be in define mode .
rename a group attribute . must be in define mode .
add a variable to the file . must be in define mode .
add a variable to the file . must be in define mode .
add a variable to the file . must be in define mode .
adds a copy of the specified structure to the file ( netcdf4 only ) . do not use yet
add a variable with datatype = string to a netcdf - 3 file . must be in define mode . the variable will be stored in the file as a char variable . a new dimension with name stringvar . getshortname () _strlen is automatically added with length max_strlen as determined from the data contained in the stringvar .
add a variable with datatype = string to the file . must be in define mode . the variable will be stored in the file as a char variable . a new dimension with name varname_strlen is automatically added with length max_strlen .
rename a variable . must be in define mode .
add an attribute to the named variable . must be in define mode .
after you have added all of the dimensions variables and attributes call create () to actually create the file . you must be in define mode . after this call you are no longer in define mode .
set the redefine mode . designed to emulate nc_redef ( redefinemode = true ) and nc_enddef ( redefinemode = false )
rewrite entire file
for netcdf3 only take all unlimited variables and make them into a structure .
// use these calls to write data to the file
write data to the named variable origin assumed to be 0 . must not be in define mode .
write data to the named variable . must not be in define mode .
write string data to a char variable origin assumed to be 0 . must not be in define mode .
write string data to a char variable . must not be in define mode .
close the file .
abort writing to this file . the file is closed .
write xml using the bean properties of the contained object
extract info from underlying feature dataset
/////////////////////////////////////////////////////////////////////////////
//////////////////
look for possible matches of old ( 4 . 2 ) grib names in new ( 4 . 3 ) dataset .
////////////////////////////////////////////////
wml2 : collection / wml2 : observationmember / om : om_observation / om : result / wml2 : measurementtimeseries
multiply this unit by another unit .
divide this unit by another unit .
divide this unit into another unit .
converts a value in this unit to the equivalent value in the convertible derived unit .
converts a value in the convertible derived unit to the equivalent value in this unit .
converts values in the convertible derived unit to the equivalent values in this unit .
convert a datadds into an array for a structure member variable .
convert a datadds into an array for a top level variable ie not a structure member variable .
convert a datadds into an array
datav is an array of dstructure : darray with basetypeprimitivevector whose values are dstructure
convert a dods scalar value
convert a dods scalar value
older opendap servers send netcdf char data as strings of length 1 ( !! )
this is called on tds shutdown and reinit
assumes only one open at a time ; could have metadatamanagers share open databases
see if edit value is valid put error message in buff .
get current value from editcomponent
convert a time udunit string
/ * # code table 4 . 2 - parameter number by product discipline and parameter category 0 0 estimated precipitation ( kg m - 2 ) 1 1 instantaneous rain rate ( kg m - 2 s - 1 ) 2 2 cloud top height ( m ) 3 3 cloud top height quality indicator ( code table 4 . 219 ) 4 4 estimated u - component of wind ( m / s ) 5 5 estimated v - component of wind ( m / s ) 6 6 number of pixel used ( numeric ) 7 7 solar zenith angle ( deg ) 8 8 relative azimuth angle ( deg ) 9 9 reflectance in 0 . 6 micron channel ( % ) 10 10 reflectance in 0 . 8 micron channel ( % ) 11 11 reflectance in 1 . 6 micron channel ( % ) 12 12 reflectance in 3 . 9 micron channel ( % ) 13 13 atmospheric divergence ( / s ) 14 14 cloudy brightness temperature ( k ) 15 15 clear - sky brightness temperature ( k ) 16 16 cloudy radiance ( with respect to wave number ) ( w m - 1 sr - 1 ) 17 17 clear - sky radiance ( with respect to wave number ) ( w m - 1 sr - 1 ) 18 18 reserved 19 19 wind speed ( m / s ) 20 20 aerosol optical thickness at 0 . 635 um 21 21 aerosol optical thickness at 0 . 810 um 22 22 aerosol optical thickness at 1 . 640 um 23 23 angstrom coefficient # 24 - 26 reserved 27 27 bidirectional reflectance factor ( numeric ) 28 28 brightness temperature ( k ) 29 29 scaled radiance ( numeric ) # 30 - 191 reserved # 192 - 254 reserved for local use 255 255 missing
brute force
find the best index for the given lat lon point . @param wantlat lat of point @param wantlon lon of point @param rectindex return ( row col ) index or best guess here . may not be null
reads the contents of { @code inputstream } into a stringarray . each line of input will result in an element in the array . <p / > the specified stream remains open after this method returns .
this adds an item to the array ( increasing size by 1 ) .
this ensures that the capacity is at least mincapacity .
this gets a specified element .
/ *
transform a real longitude and latitude into the rotated longitude ( x ) and rotated latitude ( y ) .
transform a rotated longitude ( x ) and rotated latitude ( y ) into a real longitude - latitude pair .
resets the location being scanned ( do not use this method public by accident ) .
return the crawlabledataset path / location that corresponds to the given dataset path . the given dataset path must start with the datasetscan path for this invdatasetscan if not a null is returned .
return the crawlabledataset for the given path null if this invdatasetscan does not allow ( filters out ) the requested crawlabledataset .
try to build a catalog for the given path by scanning the location associated with this invdatasetscan . the given path must start with the path of this invdatasetscan .
try to build a catalog for the given resolver path by scanning the location associated with this invdatasetscan . the given path must start with the path of this invdatasetscan and refer to a resolver proxydatasethandler that is part of this invdatasetscan .
what is the data type of the aggregation coordinate ?
factory for grib2pds
/ * public double getprobabilitylowerlimit () { return gribnumbers . undefined ; }
null means use reftime
apply scale factor to value return a double result .
write an html representation of the given dataset . <p > with datasetevents catrefevents = true this is used to construct an html page on the client ( eg using htmlpage ) ; the client then detects url clicks and processes . <p > with datasetevents catrefevents = false this is used to construct an html page on the server . ( eg using htmlpage ) ; the client then detects url clicks and processes .
resolve reletive urls against the catalog url .
parse the localconcept files needed to create grib1 tables for use by the cdm .
add the information from a localconcept file to super hashmap localconcepts
clean the string representation of a line in the localconcept file . basic removal of tabs semicolons single quotes etc .
store localconcept information in super hashmap localconcepts
write out grib1 tables based on localconcepts files - these are the tables that the cdm will read .
write the lookuptables . txt file which basically registers all of the new grib1 tables with the cdm
quick prinout to system . out of the different parameter metadata fields
generate grib1 tables for the cdm based on the localconcept files from ecmwf grib - api
//////////////////////////////////////////////////// static //////////////////////////////////////////////////////
todo : this needs testing .
todo : this needs testing .
//////////////////////////////////////////////////////////////////
/////////////////////////////////////////
reads an error description from the named inputstream . this method calls a generated parser to interpret an ascii representation of an <code > error< / code > and regenerate it as a <code > dap2exception< / code > .
print the error message on the given <code > printwriter< / code > . this code can be used by servlets to throw dap2exception to client .
/////////////////////////////////////////////////////////////////////////////////////////////
find the datasetsourcetype that matches this name .
wml2 : collection / wml2 : observationmember / om : om_observation / om : featureofinterest / wml2 : monitoringpoint / gml : identifier
factory method for this abstract class . @param name @param type @param structure @param accesspoint
crawl this datasetsource and generate a new invcatalog return the top - level invdataset .
crawl this datasetsource and generate a new invcatalog with all datasets named sorted and organized as defined by this datasetsource return the newly generated invcatalog .
use the list of dsnamers to name the given list of datasets .
name the datasets contained in the given dataset . the given dataset contains a flat list of datasets .
name the datasets in the given dataset hierarchy using this datasetsource s list of datasetnamers .
method to invoke with a filename or url of a picture that is to be loaded and scaled in a new thread . this is handy to update the screen while the loading chuggs along in the background . make sure you invoked setscalefactor or setscalesize before invoking this method . <p / > step 1 : am i already loading what i need somewhere? if yes - > use it . has it finished loading? if no - > wait for it if yes - > use it else - > load it
synchroneous method to load the image . it should only be called by something which is a thread itself such as the htmldistillerthread . since this intended for large batch operations this bypasses the cache .
stops all picture loading except if the url we desire is being loaded
method that is invoked by the sourcepicturelistener interface . usually this will be called by the sourcepicture telling the scalablepicture that it has completed loading . the scalablepicture should then change it s own status and tell the scalablelisteners what s up .
pass on the update on the loading progress to the listening objects
method that creates the scaled image in the background in it s own thread .
return the size of the scaled image or zero if there is none
return the size of the scaled image as a neatly formatted text or zero if there is none
this static method writes the indicated renderedimage ( bufferedimage ) to the indicated file .
method that sets the status of the scalablepicture object and notifies intereasted objects of a change in status ( not built yet ) .
initialize the file read in all the metadata ( ala dm_open )
initialize this reader . get the grid specific info
get the list of merged parts in this file
print the list of dates in the file
make the header for the text report
this subroutine checks the parts in a sounding data set for the unmerged data types .
check for valid groups
run the program
set the cache root directory . create it if it doesnt exist .
make sure that the current root directory exists .
get a file if it exists . if not get a file that can be written to . if alwaysincache look only in the cache otherwise look in the normal location first then in the cache . <p >
get a file in the cache . file may or may not exist . we assume its always writeable . if it does exist set its lastmodifieddate to current time .
make the cache filename
remove all files with date < cutoff .
remove files if needed to make cache have less than maxbytes bytes file sizes . this will remove files in sort order defined by filecomparator . the first files in the sort order are kept until the max bytes is exceeded then they are deleted .
debug
get the named icon from the default resource ( jar file ) .
get the named image from the default resource ( jar file ) .
make a buttcon = button with an icon
make a buttcon = button with an icon
nb : doesnt add action to menuitem
creates a menuitem using the given action and adds it to the given menu . uses properties that have been set on the action ( see setactionproperties () ) . all are optional except for action . short_description : <pre > action . short_description string menuitem text ( required ) action . small_icon icon the icon to use bamutil . selected_icon icon the icon when selected ( optional ) bamutil . toggle boolean true if its a toggle bamutil . mnemonic integer menu item shortcut bamutil . accel integer menu item global keyboard accelerator < / pre > <br > the action is triggered when the menuitem is selected . enabling and disabling the action does the same for the menuitem . for toggles state is maintained in the action and menuitem state changes when the action state changes . <br > <br > the point of all this is that once you set it up you work exclusively with the action object and all changes are automatically reflected in the ui .
nb : doesnt add action to button
creates an abstractbutton using the given action and adds it to the given container at the position .. uses properties that have been set on the action ( see setactionproperties () ) . all are optional except for action . small_icon : <pre > action . small_icon icon the icon to use ( required ) bamutil . selected_icon icon the icon when selected ( optional ) action . short_description string tooltip bamutil . toggle boolean true if its a toggle < / pre > <br > the action is triggered when the button is selected . enabling and disabling the action does the same for the button . for toggles state is maintained in the action and the button state changes when the action state changes . <br > <br > the point of all this is that once you set it up you work exclusively with the action object and all changes are automatically reflected in the ui .
standard way to set properties for actions . this also looks for an icon <icon_name > sel and if it exists : 1 ) sets selectedicon if its a toggle or 2 ) sets the icon when selected ( optional ) if its not a toggle
standard way to set properties and state for toggle actions . *
look could do better : all and maybe hashset<name >
/ * find the station closest to the specified point . the metric is ( lat - lat0 ) ** 2 + ( cos ( lat0 ) * ( lon - lon0 )) ** 2
contains a bufr table entry
create a coordinate axis from an existing variable .
make a copy with an independent cache .
does the axis have numeric values .
get a string representation
needed by time coordinates
sort the rowlist : note rowlist changed not a copy of it .
replace the rowlist with this one .
remove elem from rowlist update the table . searches for match using object identity ( == )
get the currently selected row .
set the current selection to this row .
increment or decrement the current selection by one row .
for each column get the model index
///////////////////////////////////////////////////////////////////////////////
this .
look fake
set current value - no event
push parse input from external lexer
( re - ) initialize the state of the push parser .
compares elements in a <code > vector< / code > of <code > basetype< / code > s and throw a <code > badsemanticsexception< / code > if there are any duplicate elements .
takes a <code > vector< / code > of <code > basetype< / code > s retrieves their names into an array of <code > string< / code > s and performs a quick sort on that array .
internal recursive method to perform quick sort on name array .
private method to swap two elements in the array
this function escapes non - printable characters and quotes . this is used to make <code > printval< / code > output <code > dstring< / code > data in the same way as the c ++ version . since java supports unicode this will need to be altered if it s desired to print <code > dstring< / code > as utf - 8 or some other character encoding .
make mfileos if file exists otherwise return null
transform a real longitude and latitude into the rotated longitude ( x ) and rotated latitude ( y ) .
transform a rotated longitude ( x ) and rotated latitude ( y ) into a real longitude - latitude pair .
tor s transform algorithm renamed to rotate for clarity
create an xmlstore reading from the specified filename .
create an xmlstore reading from an input stream . because of some peculiariteis you must open the input stream wtice and pass both in .
create a read - only xmlstore reading from the specified resource opened as a resource stream using the xmlstore classloader . this allows you to find files that are in jar files on the application classpath .
convenience routine for creating an xmlstore file in a standard place .
save the current state of the preferences tree to disk using the original filename . the xmlstore must have been constructed from a writeable xml file .
save the current state of the preferences tree to the given outputstream .
write out an atomic variable .
write out a scalar or array structure instance
write out a single structure instance
write out a single or array sequence instance
write out a single sequence of records ( eventually use any filter in the dapvariable )
write out a single record instance .
returns a string representation of the variables value . this is really foreshadowing functionality for server types but as it may come in useful for clients it is added here . simple types ( example : dfloat32 ) will return a single value . dconstuctor and dvector types will be flattened . dstrings and durl s will have double quotes around them .
//////////////////////////////////////
is this a valid bufr file .
get the wmo station id as a string
write the variable s declaration in a c - style syntax . this function is used to create textual representation of the data descriptor structure ( dds ) . see <em > the opendap user manual< / em > for information about this structure .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl .
print an array . this is a private member function .
given a size and a name this function adds a dimension to the array . for example if the <code > darray< / code > is already 10 elements long calling <code > appenddim< / code > with a size of 5 will transform the array into a 10x5 matrix . calling it again with a size of 2 will create a 10x5x2 array and so on .
use this method to squeeze out all of the array dimensions whose size is equal to 1 . <br > many queries that contstrain arrays return an array that has dimensions whose size has been reduced to 1 . in effect that the dimension no longer really exists except as a notational convention for tracking the hyperslab that the array represents . since many clients have difficulty handling n - dimensional arrays this method was added to allow the client to easily squeeze the extra dimensions out of the array .
returns the <code > darraydimension< / code > object for the dimension requested . it makes sure that the dimension requested exists .
returns a clone of this <code > array< / code > . see dapnode . clonedag ()
compare 2 tables print report .
set the state of this variable s projection . <code > true< / code > means that this variable is part of the current projection as defined by the current constraint expression otherwise the current projection for this variable should be <code > false< / code > .
<p / > server - side serialization for opendap variables ( sub - classes of <code > basetype< / code > ) . this does not send the entire class as the java <code > serializable< / code > interface does rather it sends only the binary data values . other software is responsible for sending variable type information ( see <code > dds< / code > ) . < / p > <p > writes data to a <code > dataoutputstream< / code > . this method is used on the server side of the opendap client / server connection and possibly by gui clients which need to download opendap data manipulate it and then re - save it as a binary file . < / p > <h2 > caution : < / h2 > when serializing arrays of sequences ( children of dsequence ) it is crucial that it be handled with great care . sequences have been implemented so that only one instance ( or row if you will ) is retained in memory at a given time . in order to correctly serialize an array of sequences the read () method for the array must create an instance of the sequence for each member of the array typically by repeatedly cloning the template variable in the primitivevector . the important next step is to not attempt to read any data into the sequences from within the read () method of the parent array . the sequence s data will get read and constraint expressions applied when the serialze () method of the array calls the serialize method of the sequence . good luck!
set the projection information for this dimension . the <code > darraydimension< / code > associated with the <code > dimension< / code > specified is retrieved and the <code > start< / code > <code > stride< / code > and <code > stop< / code > parameters are passed to its <code > setprojection () < / code > method .
method to read an entry from the data stream . the stream is assumed to be in the right spot for reading . this method should be called from something controlling the reading of the entire file .
method to retrieve data for this field
/ * param table : <grib2_22_0_0_codeflag_exp_en > <no > 524< / no > <title_en > code table 4 . 2 - parameter number by product discipline and parameter category< / title_en > <subtitle_en > product discipline 0 - meteorological products parameter category 1 : moisture< / subtitle_en > <codeflag > 101< / codeflag > <meaningparameterdescription_en > specific number concentration of snow< / meaningparameterdescription_en > <unitcomments_en > kg - 1< / unitcomments_en > <elementdescription_en > number of particles per unit mass of air< / elementdescription_en > <status > operational< / status > < / grib2_22_0_0_codeflag_exp_en >
read a ncml variable element and nested elements when it creates a new variable .
/ * code table code table 5 . 0 - data representation template number ( 5 . 0 ) 0 : grid point data - simple packing 1 : matrix value at grid point - simple packing 2 : grid point data - complex packing 3 : grid point data - complex packing and spatial differencing 4 : grid point data - ieee floating point data 40 : grid point data - jpeg 2000 code stream format 41 : grid point data - portable network graphics ( png ) 50 : spectral data - simple packing 51 : spherical harmonics data - complex packing 61 : grid point data - simple packing with logarithm pre - processing 200 : run length packing with level values 65535 : missing
grid point data - simple packing
/ * data template 7 . 2  grid point data  complex packing note : for most templates details of the packing process are described in regulation 92 . 9 . 4 . octet no . contents 6xx ng group reference values ( x1 in the decoding formula ) each of which is encoded using the number of bits specified in octet 20 of data representation template 5 . 0 . bits set to zero shall be appended as necessary to ensure this sequence of numbers ends on an octet boundary [ xx + 1 ] yy ng group widths each of which is encoded using the number of bits specified in octet 37 of data representation template 5 . 2 . bits set to zero shall be appended as necessary to ensure this sequence of numbers ends on an octet boundary [ yy + 1 ] zz ng scaled group lengths each of which is encoded using the number of bits specified in octet 47 of data representation template 5 . 2 . bits set to zero shall be appended as necessary to ensure this sequence of numbers ends on an octet boundary ( see note 14 of data representation template 5 . 2 ) [ zz + 1 ] nn packed values ( x2 in the decoding formula ) where each value is a deviation from its respective group reference value
/ * from wgrib unpk_complex () :
/ * data template 7 . 3  grid point data  complex packing and spatial differencing note : for most templates details of the packing process are described in regulation 92 . 9 . 4 . octet no . contents 6ww first value ( s ) of original ( undifferenced ) scaled data values followed by the overall minimum of the differences . the number of values stored is 1 greater than the order of differentiation and the field width is described at octet 49 of data representation template 5 . 3 ( see note 1 ) [ ww + 1 ] xx ng group reference values ( x1 in the decoding formula ) each of which is encoded using the number of bits specified in octet 20 of data representation template 5 . 0 . bits set to zero shall be appended where necessary to ensure this sequence of numbers ends on an octet boundary [ xx + 1 ] nn same as for data representation template 7 . 2
grid point data - jpeg 2000 code stream format
grid point data - jpeg 2000 code stream format
code taken from esupport ticket zvt - 415274
ported from https : // github . com / erdc - cm / grib_api / blob / master / src / grib_accessor_class_data_g1second_order_general_extended_packing . c
look might be wrong for a quasi regular ( thin ) grid ??
abstractcursor abstract methods
support methods
write a netcdf - 3 file from a subset of a grid dataset
write a netcdf - 3 file from a subset of a grid dataset as long as it doesnt exceed a certain file size .
write a cf compliant netcdf - 3 file from any gridded dataset .
process the coordinate transformations ( formula_terms ) and adds the variables needed for performing that transformation to the list of variables in the new file . also subsets the grids variables if needed .
set the list of stations .
set selected station based on the sttion id .
find station that contains this point . if it exists make it the selected station .
find station closest to this point . make it the selected station .
get the selected station .
//////////////////////////////////////////////////////////////////////////
/ * message dataroot { required string urlpath = 1 ; required string dirlocation = 2 ; required dataroottype type = 3 ; optional string catlocation = 4 ; // omit for simple dataset root }
type { datasetroot datasetscan catalogscan featurecollection }
set the parameters for the gds
get the name for the projection type
public void exit () { listen . exit () ; }
////////////////////////////////////////////
erase the last rectangle and shift the rectangle and redraw deltax deltay : position from original position
/ * private void compare ( message m1 message m2 formatter f ) { formatter f1 = new formatter () ; formatter f2 = new formatter () ; m1 . dump ( f1 ) ; m1 . dump ( f2 ) ;
////////////////////////////////////////////////////////////////////////////////////////////////////////////////
get all the stations within a bounding box .
find a station by name
get all data for this station .
get data for this station within the specified date range .
read data from this ray .
returns the number of variables contained in this object . for simple and vector type variables it always returns 1 . to count the number of simple - type variable in the variable tree rooted at this variable set <code > leaves< / code > to <code > true< / code > .
gets the indexed variable . for a dstructure this returns the <code > basetype< / code > from the <code > index< / code > th column from the internal storage <code > vector< / code > .
prints the value of the variable with its declaration . this function is primarily intended for debugging opendap applications and text - based clients such as geturl .
reads data from a <code > datainputstream< / code > . this method is only used on the client side of the opendap client / server connection .
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
returns a clone of this <code > structure< / code > . see dapnode . clonedag ()
writes data to a <code > dataoutputstream< / code > . this method is used primarily by gui clients which need to download opendap data manipulate it and then re - save it as a binary file .
islatlon2d is true check parameter to see if its a 2d lat / lon coordinate
this looks for snippets in the variable name / desc as to whether it wants u v or p 2d coordinates
compare 2 tables print report .
cos between two vectors = dot ( v ) / norm () * norm ( v )
dot product of 2 vectors
get the l2 norm of this vector .
normalize this vector so it has norm = 1 . 0 .
//////////////////////////////////////////////////////////////
pull services out of the datasets and into the catalog
/ * private void readxml ( string filename ) throws ioexception { try { staxstreambuilder staxbuilder = new staxstreambuilder () ; xmlinputfactory xmlinputfactory = xmlinputfactory . newinstance () ; xmlstreamreader xmlstreamreader = xmlinputfactory . createxmlstreamreader ( new fileinputstream ( filename )) ; document jdomdoc = staxbuilder . build ( xmlstreamreader ) ; readcatalog ( jdomdoc . getrootelement () ) ;
/ * <xsd : element name = catalog > <xsd : complextype > <xsd : sequence > <xsd : element ref = service minoccurs = 0 maxoccurs = unbounded / > <xsd : element ref = property minoccurs = 0 maxoccurs = unbounded / > <xsd : element ref = dataset minoccurs = 1 maxoccurs = unbounded / > < / xsd : sequence >
/ * <xsd : element name = access > <xsd : complextype > <xsd : sequence > <xsd : element ref = datasize minoccurs = 0 / > // whyd we do that ? < / xsd : sequence > <xsd : attribute name = urlpath type = xsd : token use = required / > <xsd : attribute name = servicename type = xsd : string / > <xsd : attribute name = dataformat type = dataformattypes / > < / xsd : complextype > < / xsd : element >
/ * <xsd : element name = service > <xsd : complextype > <xsd : sequence > <xsd : element ref = property minoccurs = 0 maxoccurs = unbounded / > <xsd : element ref = service minoccurs = 0 maxoccurs = unbounded / > < / xsd : sequence >
/ * <xsd : element name = catalogref substitutiongroup = dataset > <xsd : complextype > <xsd : complexcontent > <xsd : extension base = datasettype > <xsd : attributegroup ref = xlink / > <xsd : attribute name = useremotecatalogservice type = xsd : boolean / > < / xsd : extension > < / xsd : complexcontent > < / xsd : complextype > < / xsd : element >
/ * <xsd : complextype name = datasettype > <xsd : sequence > <xsd : group ref = threddsmetadatagroup minoccurs = 0 maxoccurs = unbounded / >
/ * <! -- group of elements can be used in a dataset or in metadata elements -- > <xsd : group name = threddsmetadatagroup > <xsd : choice > <xsd : element name = documentation type = documentationtype / > <xsd : element ref = metadata / > <xsd : element ref = property / >
//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
/ * <xsd : element name = metadata > <xsd : complextype > <xsd : choice > <xsd : group ref = threddsmetadatagroup minoccurs = 0 maxoccurs = unbounded / > <xsd : any namespace = ##other minoccurs = 0 maxoccurs = unbounded processcontents = lax / > < / xsd : choice >
/ * <xsd : complextype name = sourcetype > <xsd : sequence > <xsd : element name = name type = controlledvocabulary / >
/ * <xsd : complextype name = timecoveragetype > <xsd : sequence > <xsd : attribute name = calendar type = xsd : string / > <xsd : choice minoccurs = 2 maxoccurs = 3 > <xsd : element name = start type = datetypeformatted / > <xsd : element name = end type = datetypeformatted / > <xsd : element name = duration type = duration / > < / xsd : choice > <xsd : element name = resolution type = duration minoccurs = 0 / > < / xsd : sequence > < / xsd : complextype >
/ * <xsd : element name = variables > <xsd : complextype > <xsd : choice > <xsd : element ref = variable minoccurs = 0 maxoccurs = unbounded / > <xsd : element ref = variablemap minoccurs = 0 / > < / xsd : choice > <xsd : attribute name = vocabulary type = variablenamevocabulary use = optional / > <xsd : attributegroup ref = xlink / > < / xsd : complextype > < / xsd : element >
a time span as defined in the w3c xml schema 1 . 0 specification : pnynmndtnhnmns where ny represents the number of years nm the number of months nd the number of days t is the date / time separator nh the number of hours nm the number of minutes and ns the number of seconds . the number of seconds can include decimal digits to arbitrary precision .
test
/ * public long senddata ( writablebytechannel wbc structuredata sdata ) throws ioexception { long size = 0 ; bytebuffer bb = iosphelper . copytobytebuffer ( sdata ) ; byte [] datab = bb . array () ; size + = writebytes ( wbc ncstream . magic_data ) ; // magic size + = ncstream . writevint ( wbc datab . length ) ; // data len size + = writebytes ( wbc datab ) ; // data return size ; }
get the parameter with id . if not found look in default table .
get the parameter with id but dont look in default table .
reading
/ * wmo standard table 2 : version number 3 . codes and data units for fm 92 - x ext . grib . ...................... 001 p pressure pa pa ...................... 002 msl mean sea level pressure pa pa ...................... 003 none pressure tendency pa s ** - 1 pa s ** - 1 ...................... 004 pv potential vorticity k m ** 2 kg ** - 1 s ** - 1 k m ** 2 kg ** - 1 s ** - 1 ...................... 005 none icao standard atmosphere reference height m m
this method will read in ecmwf grib1 tables . note that these tables are generated locally by unidata and come directly from the ecmwf grib - api package localconcepts files . they are generated by : <p > ucar . nc2 . grib . grib1 . tables . ecmwflocalconcepts <p > the original localconcepts files are located in : <p / > grib / src / main / sources / ecmwfeccodes / <p / > since we write the table file that are ultimately read by cdm the format is controled and is the following : <p > paramnum shortname [ description ] ( units ) <p > for example <p > 251 atte [ adiabatic tendency of temperature ] ( k )
order : num name desc unit
adds a prefix to the database by name .
adds a prefix symbol to the database .
returns the prefix from the given set with the given identifier .
check its an acceptable form of email
test
peek ahead
_more_
_more_
_more_
_more_
_more_
_more_
_more_
_more_
_more_
get the value of the projection parameter . an illegalargument exception is thrown if the parameter is not found .
convert ogc spatial reference wkt to a projectionimpl . an illegalargumentexception may be thrown if a parameter is missing .
calculate the crc of the entire byte array
is a thin grid
gets the number of points in each line for quasi / thin grids list of numbers of points in each row ( length = nrows x 2 octets where nrows is the total number of rows defined within the grid description )
///////////////////////////////////////////////
selected datacursor api overrides
utilities
returns { @code true } if we should add 2d latitude & longitude variables to the output file . this method could return { @code false } for several reasons :
code table 5 - 2010 edition of wmo manual on codes
a string representation of the time coordinate whether its an interval or not .
append an error message to the message log . call check () to get the log when everything is done .
utilities
set the offsets based on m . getsizebytes () . also sets members . setstructuresize () .
sets the next polygon which make up the multipolygon which this polygon is a part of . if next is a cfpolygon automatically connects the other polygon to this polygon as well .
sets the previous polygon which makes up the multipolygon which this polygon is a part of . if prev is a cfpolygon automatically connect the other polygon to this polygon as well .
given a dataset variable and index automatically sets up a previously constructed polygon . if the specified polygon is not found in the dataset returns null
get named property .
see if the service base is reletive
set current projection if found else deselect
normal case already handled this is the case where a time has been specified and only one runtime
register an ioserviceprovider using its class string name .
register an ioserviceprovider . a new instance will be created when one of its files is opened .
register an ioserviceprovider . a new instance will be created when one of its files is opened . this differs from the above in that it specifically locates the target iosp and inserts the new one in front of it in order to override the target . if the iospclass is already registered remove it and reinsert . if the target class is not present then insert at front of the registry
see if a specific ioserviceprovider is registered
see if a specific ioserviceprovider is registered and if so remove it .
debugging
open an existing file ( read only ) with option of cancelling .
open an existing file ( read only ) with option of cancelling setting the randomaccessfile buffer size for efficiency with an optional special object for the iosp .
find out if the file can be opened but dont actually open it . experimental .
open an existing file ( read only ) specifying which iosp is to be used .
removes the { @code file : } or { @code file : // } prefix from the location if necessary . also replaces back slashes with forward slashes .
open an in - memory netcdf file with a specific iosp .
open an in - memory netcdf file .
read a local cdm file into memory . all reads are then done from memory .
read a remote cdm file into memory . all reads are then done from memory .
close all resources ( files sockets etc ) associated with this file . if the underlying file was acquired it will be released otherwise closed . if isclosed () already nothing will happen
find a group with the specified ( full ) name . an embedded / is interpreted as separating group names .
find a variable with the specified ( escaped full ) name . it may possibly be nested in multiple groups and / or structures . an embedded . is interpreted as structure . member . an embedded / is interpreted as group / variable . if the name actually has a . you must escape it ( call netcdffile . escapename ( varname )) any other chars may also be escaped as they are removed before testing .
finds a dimension with the specified full name . it may be nested in multiple groups . an embedded / is interpreted as a group separator . a leading slash indicates the root group . that slash may be omitted but the { @code fullname } will be treated as if it were there . in other words the first name token in { @code fullname } is treated as the short name of a group or dimension relative to the root group .
look up global attribute by ( full ) name .
look up global attribute by name ignore case .
find an attribute with the specified ( escaped full ) name . it may possibly be nested in multiple groups and / or structures . an embedded . is interpreted as structure . member . an embedded / is interpreted as group / group or group / variable . an embedded @ is interpreted as variable@attribute if the name actually has a . you must escape it ( call netcdffile . escapename ( varname )) any other chars may also be escaped as they are removed before testing .
find a string - valued global or variable attribute by attribute name ( ignore case ) return the value of the attribute . if not found return defaultvalue
cdl representation of netcdf header info non strict
write cdl representation to outputstream .
write cdl representation to printwriter .
the actual work is here
write the ncml representation : dont show coodinate values
write the ncml representation : dont show coodinate values
/ * check if file has changed and reread metadata if needed . all previous object references ( variables dimensions etc ) may become invalid - you must re - obtain . do not use this routine yet - not fully tested
add an attribute to a group .
add optional string attribute to a group .
add a group to the parent group .
add a shared dimension to a group .
remove a shared dimension from a group by name .
add a variable to the given group .
create a new variable and add to the given group .
create a new variable of type datatype . char and add to the given group .
remove a variable from the given group by name .
generic way to send a message to the underlying iosp . this message is sent after the file is open . to affect the creation of the file you must send into the factory method .
if there is an unlimited dimension make all variables that use it into a structure . a variable called record is added . you can then access these through the record structure .
make this immutable .
completely empty the objects in the netcdf file . used for rereading the file on a sync () .
finish constructing the object model . this construsts the global variables attributes and dimensions . it also looks for coordinate variables .
/ * do not call this directly use variable . read () !! ranges must be filled ( no nulls )
read a variable using the given section specification . the result is always an array of the type of the innermost variable . its shape is the accumulation of all the shapes of its parent structures .
read data from a top level variable and send data to a writablebytechannel . experimental .
do a bulk read on a list of variables and return a corresponding list of array that contains the results of a full read on each variable . this is mostly here so dodsnetcdf can override it with one call to the server .
read a variable using the given section specification .
debugging - do not use
create a valid cdm object name . control chars ( < 0x20 ) are not allowed . trailing and leading blanks are not allowed and are stripped off . a space is converted into an underscore _ . a forward slash / is converted into an underscore _ .
given a cdmnode create its full name with appropriate backslash escaping of the specified characters .
create a synthetic full name from a group plus a string
inclusion is an or
exclusion is an and
all and filters must be satisfied
accessors
given a cdm_t < - > dap_t pair insert into the maps
given a dap_t < - > cdm_t pair remove from the maps
returns the attribute type as a <code > string< / code > .
returns the attribute type as a <code > string< / code > .
returns the attribute value at <code > index< / code > .
returns the attribute value at <code > index< / code > .
append a value to this attribute .
check if the value is legal for a given type .
check if the value is legal for a given type and try to convert to specified type .
check if string is a valid byte .
check if string is a valid int16 .
check if string is a valid int32 .
check if string is a valid uint32 .
check if string is a valid float32 .
check if string is a valid float64 .
returns a clone of this <code > attribute< / code > . see dapnode . clonedag ()
get the data type of an attribute . make it unsigned if the variable is unsigned .
returns a distinct integer for each of the { @link datatype#isnumeric () numeric } data types that can be used to ( roughly ) order them by the range of the datatype . { @code byte < ubyte < short < ushort < int < uint < long < ulong < float < double } . { @code - 1 } will be returned for all non - numeric data types .
returns the data type that is the largest among the arguments . relative sizes of data types are determined via { @link #rank ( datatype ) } .
returns the smallest numeric data type that : <ol > <li > can hold a larger integer than { @code datatype } can< / li > <li > if integral has the same signedness as { @code datatype } < / li > < / ol > the relative sizes of data types are determined in a manner consistent with { @link #rank ( datatype ) } . <p / > <table border = 1 > <tr > <th > argument< / th > <th > result< / th > < / tr > <tr > <td > byte< / td > <td > short< / td > < / tr > <tr > <td > ubyte< / td > <td > ushort< / td > < / tr > <tr > <td > short< / td > <td > int< / td > < / tr > <tr > <td > ushort< / td > <td > uint< / td > < / tr > <tr > <td > int< / td > <td > long< / td > < / tr > <tr > <td > uint< / td > <td > ulong< / td > < / tr > <tr > <td > long< / td > <td > double< / td > < / tr > <tr > <td > ulong< / td > <td > double< / td > < / tr > <tr > <td > any other data type< / td > <td > just return argument< / td > < / tr > < / table > <p / > the returned type is intended to be just big enough to hold the result of performing an unsigned conversion of a value of the smaller type . for example the { @code byte } value { @code - 106 } equals { @code 150 } when interpreted as unsigned . that won t fit in a ( signed ) { @code byte } but it will fit in a { @code short } .
returns true if this is a gridded dataset that is accessible via wms .
return true if the given string is a valid single - line string . <p > <p > a string will be considered a valid single - line string if it does not contain any characters from these unicode general categories : <p > <ul > <li > cc - other control< / li > <li > cf - other format< / li > <li > cs - other surrogate< / li > <li > co - other private use< / li > <li > cn - other not assigned< / li > <li > zl - separator line< / li > <li > zp - separator paragraph< / li > < / ul > <p > <p > or in other words allow : letters numbers marks punctuation symbols and space separators .
return true if the given string is a valid path . <p > <p > a string is considered a valid path if : <ul > <li > when passed to validsinglelinestring ( string ) true is returned and <li > it does not contain any parent path segments ( .. / ) . < / li > < / li > < / ul >
return true if the given string is a valid file path . <p > <p > a string is considered a valid file path if : <ul > <li > when passed to validpath ( string ) true is returned ; and< / li > <li > it does not contain the java file path separator ( java . io . file . pathseparatorchar ) which is system dependant . < / li > < / ul >
return true if the given string is a valid id string . <p > <p > a string is considered a valid id string if : <ul > <li > it contains no space separator characters ( unicode general category zs - separator space ) ; and< / li > <li > true is returned when the string is passed to validsinglelinestring ( string ) . < / li > < / ul >
return true if the given string contains any less than ( < ) or greater than ( > ) characters ; otherwise return false .
return true if the given string contains any ampersand ( & ) characters ; otherwise return false .
return true if the given string contains any backslash ( \ ) characters ; otherwise return false .
return true if the given string is true or false ignoring case .
return true if the given string is an alphanumeric string .
return true if the given string is an alphanumeric string and one of the valid strings in the constrained set .
return true if the given path does not ascend into parent directory .
check that the given string is a valid percenthexoctets string . the string is considered valid if it only contains a sequence of % prefixed two character strings where each two character string is composed only of us - ascii digits and upper - or lower - case a - f . <p > for example : %31%32 or %7b%7d%7e
return the percenthexoctets string that represents the given unicode code point in the given character set or null if the given character set cannot encode the given code point .
adds a param and value .
adds a param and value .
adds a param and value .
gets a param and value .
compare griddefrecords the numerics will use nearlyequals so values that differ in 3 or 4th decimal places will return equal . this is being coded because the ndfd model dx differ in the 3 decimal place otherwise equal .
step 1 - read and extract a bufr message
return where in the buffer we got to .
/ * message datarow { string fullname = 1 ; datatype datatype = 2 ; section section = 3 ; bool bigend = 4 ; uint32 version = 5 ; bool isvlen = 7 ; uint32 nelems = 9 ;
/ * message member { string shortname = 1 ; datatype datatype = 2 ; repeated uint32 shape = 3 ; // or section? bool isvlen = 4 ; }
invoked once on first request so that everything is available especially spring stuff .
controller entry point ( s )
/ * parser core
/ * selection procedures
remove double quotes from around a string . if there s not both start and ending quotes does nothing .
given a stack of basetype variables mark these as part of the current projection . this function assumes that if the tos contains a ctor type variable all of its members are to be projected . also assume all variables under the tos are ctor variables and only the ctor itself is to be projected ; the member within the ctor that is part of the projection will be on the stack too .
this parses then fills in the evaluator from the ast
write ncml from given dataset
read text from textarea through ncmlreader then write it back out via resulting dataset
read text from textarea through ncmlreader then write it back out via resulting dataset
static so can be called from static enum classes
read in the index index raf already open ; return null on failure
/ * extend gribcollection { repeated partition partitions = 100 ; required bool ispartitionofpartitions = 101 ; repeated uint32 run2part = 102 ; // masterruntime index to partition index }
/ * private boolean ignoreinrange ( int i ) { warning we do not have signed / unsigned info available if ( this . basetype == datatype . enum1 && ( i > = byte . min_value || i < = ubyte_max )) return true ; else if ( this . basetype == datatype . enum2 && ( i > = short . min_value || i < = ushort_max )) return true ; else if ( this . basetype == datatype . enum4 ) // always ok return true ; else return false ; }
string representation .
initialize the stationhelper .
stationtimeseriesfeaturecollection
nestedpointfeaturecollection
validate this resultservice object . return true if valid false if invalid .
convert a latlonpoint to projection coordinates
convert lat / lon coordinates to projection coordinates .
convert lat / lon coordinates to projection coordinates .
get the azimuth in degrees
get the elevation angle in degrees
unidata added
get the array of per - ray latitudes . if we do not have per - ray position information null is returned .
get the array of per - ray longitudes . if we do not have per - ray position information null is returned .
get the array of per - ray altitudes . if we do not have per - ray position information null is returned .
get the array of azimuths for this sweep .
get the array of elevations for this sweep .
create a subset of the structure consisting only of the given member variables
create a subset of the structure consisting only of the one member variable
add a member variable
set the list of member variables .
remove a variable : uses the variable name to find it .
replace a variable with another that has the same name : uses the variable name to find it . if old var is not found just add the new one
set the parent group of this structure and all member variables .
find the variable member with the specified ( short ) name .
create a structuremembers object that describes this structure . caution : do not use for iterating over a structuredata or arraystructure - get the structuremembers object directly from the structuredata or arraystructure .
force recalculation of size of one element of this structure - equals the sum of sizes of its members . this is used only by low level classes like iosps .
use this when this is a scalar structure . its the same as read () but it extracts the single structuredata out of the array .
use this when this is a one dimensional array of structures or you are doing the index calculation yourself for a multidimension array . this will read only the ith structure and return the data as a structuredata object .
for rank 1 array of structures read count structures and return the data as an arraystructure . use only when this is a one dimensional array of structures .
get an efficient iterator over all the data in the structure .
get string with name and attributes . used in short descriptions like tooltips .
/ * <bufr_19_1_1_tablea_en > <no > 27< / no > <codefigure > 28< / codefigure > <meaning_en > precision orbit ( satellite ) < / meaning_en > <status > operational< / status > < / bufr_19_1_1_tablea_en >
data category name from table a
get the name of the type of the projection .
add an attribute to this projection
get a header for display .
convert projection coordinates to lat / lon coordinate .
convert projection coordinates to lat / lon coordinate .
convert lat / lon coordinates to projection coordinates .
convert lat / lon coordinates to projection coordinates .
alternate way to calculate latlontoprojbb originally in gridcoordsys . difficult to do this in a general way .
convert a lat / lon bounding box to a world coordinate bounding box by finding the minimum enclosing box . handles lat / lon points that do not intersect the projection panel .
convert a world coordinate bounding box to a lat / lon bounding box by finding the minimum enclosing box .
compute lat / lon bounding box from projection bounding box by finding the minimum enclosing box .
for negative angles d should be negative m & s positive .
for negative angles d should be negative m & s positive .
/ * public static void latlongtoxyz ( projectionpoint ll point3d xyz ) { double c = math . cos ( ll . y ) ; xyz . x = c * math . cos ( ll . x ) ; xyz . y = c * math . sin ( ll . x ) ; xyz . z = math . sin ( ll . y ) ; }
/ * java translation of nice numbers for graph labels by paul heckbert from graphics gems academic press 1990
shared by all instances
get which cf version this is ie cf - 1 . x
guess the value of zispositive based on z axis name and units
this is here because it doesnt fit into the 3d array thing .
augment coards axis type identification with standard names ( including dimensionless vertical coordinates ) and cf . axis attributes
remove last file
/ * set the grid
/ * get the data value at this projection ( x y ) point .
/ * get an x y z data volume for the given time private void makedatavolume ( griddatatype g int time ) { try { datavolume = g . readvolumedata ( time ) ; } catch ( java . io . ioexception e ) { system . out . println ( error reading netcdf file + e ) ; datavolume = null ; } lastgrid = g ; lasttime = time ; lastlevel = - 1 ; // invalidate lastslice = - 1 ; // invalidate datavolumechanged = true ; }
set colorscale limits missing data
do the rendering to the given graphics2d object .
/ * draw using generalpath shape private generalpath gp = new generalpath ( generalpath . wind_even_odd 5 ) ; private shape makeshape ( double lon1 double lat1 double lon2 double lat2 ) { gp . reset () ; projectionpoint pt = drawprojection . latlontoproj ( lat1 lon1 ) ; gp . moveto ( ( float ) pt . getx () ( float ) pt . gety () ) ;
is this a child of that ?
find the messagetype that matches this name .
read a message
debugging
installs alignment decorators in all of the table s columns .
installs alignment decorators in the table column at { @code colviewindex } .
returns the key adding a trailing { @link #s3_delimiter delimiter } . returns { @code null } if the key is { @code null } .
returns the parent uri of this uri . the determination is completely text - based using the { @link #s3_delimiter delimiter } . if the key is { @code null } { @code null } is returned . if it is non - { @code null } but doesn t have a logical parent the returned uri will have a { @code null } key ( but the same bucket ) . for example the parent of { @code s3 : // my - bucket / my - key } ( bucket = my - bucket key = my - key ) will be { @code s3 : // my - bucket } ( bucket == my - bucket key = null ) .
creates a new uri by resolving the specified path relative to { @code this } . if { @code key == null } the key of the returned uri will simply be { @code relativepath } .
gets a temporary file to which the content of the s3object that this uri points to can be downloaded . the path of the file is { @code $ { java . io . tmpdir } / s3objects / $ { hashcode () } / $ { getbasename () }} . this method does not cause the file to be created ; we re just returning a suitable path .
specify the hmac api key and secret to be used for authenticated requests
cross - platform way of finding an executable in the $path .
create a simple label . create newlines with \ n .
create a simple multiline label .
create a html label .
create a html label from markdown . the following patterns are allowed : <br > \ n newline ** bold ** * italics * ~~strike through~~ _underlined_ ^overlined^ __subscript__ ^^superscript^^ .
create either a simple html or markdown label . if the value is not surrounded by < and > a simple label is created . otherwise if value contains some html tags a html label is created . otherwise a markdown label is created .
returns the {
creates a socket representing a connection to a cloud sql instance .
returns {
todo ( berezv ) : separate creating socket and performing connection to make it easier to test
converts the string property of ip types to a list by splitting by commas and upper - casing .
todo ( berezv ) : synchronize per instance instead of globally
implements the interface for com . mysql . cj . protocol . socketfactory for mysql - connector - java prior to version 8 . 0 . 13 . this change is required for backwards compatibility .
purges an invalid logger from the cache .
compile all sources
compile single source
add source code to the compiler
reads graphics control extension values .
reads next variable length block from input .
get the next frame in the animation sequence .
creates new frame image from current data ( and previous frames as specified by their disposition codes ) .
reads next variable length block from input .
use this method to initialize the show / hide listeners for the dialog .
persons in string representation .
this method is called by the javafx runtime when the application is initialized . see { @link application#init () } for more details . <p > in this method the initialization of the guice container is done . for this reason this method is marked as final and cannot be overwritten by users . <p > please use { @link #initmvvmfx () } for your own initialization logic .
try to inject the given { @link resourcebundle } into the given target instance .
this method is used to set the clock to a fixed time . this is useful for tests . this way it s possible to create date / time instances with a predictable value for your tests .
returns the message with the highest priority using the following algorithm : - if there are messages with { @link severity#error } take the first one . - otherwise if there are messages with { @link severity#warning } take the first one . - otherwise an empty optional is returned .
merges the provided resourcebundle with the global one ( if any ) .
merges the list of resourcebundles with the global one ( if any ) . <p / > the global resourcebundle has a lower priority then the provided ones . if there is the same key defined in the global and in one of the provided resourcebundles the value from the provided resourcebundle will be used . <p / > the order of resourcebundles in the list defines the priority for resourcebundles . resourcebundles at the start of the list have a <strong > lower< / strong > priority compared to bundles at the end of the list . this means that the last resourcebundle will overwrite values from previous resourcebundles ( including the global resourcebundle ( if any )) . *
returns an instance of the given type . when there is a custom injector defined ( see : { @link #setcustominjector ( javafx . util . callback ) } ) then this injector is used . otherwise a new instance of the desired type is created . this is done by a call to { @link class#newinstance () } which means that all constraints of the newinstance method are also need to be satisfied .
if the list changed we want the recreate the targettype representation
maps an add event of the model list to new elements of the { @link #viewmodellist } .
maps an remove event of the model list to new elements of the { @link #viewmodellist } .
maps an update event of the model list to new elements of the { @link #viewmodellist } .
maps an replace event of the model list to new elements of the { @link #viewmodellist } .
gets a person . s
create a new builderfactory instance that contains all custom factories of this instance combined with the list of factories passed as argument to this method . <br / > this instance of the builderfactory is not changed by this method .
puts a new ( key value ) into the map . <p >
removes all garbage collected values with their keys from the map . since we don t know how much the referencequeue . poll () operation costs we should not call it every map operation .
returns a <code > set< / code > view of the mappings in this map . <p >
returns a <code > collection< / code > view of the values contained in this map . <p >
add a list of validation messages for the specified validator .
/ * remove all given messages for the given validator .
/ * remove all messages for this particular validator .
set person id for the screen
loads the java written view of the given type and injects the viewmodel for this view . <br > if the given view type implements the { @link javafx . fxml . initializable } interface the initialize method of this interface will be invoked . when this is not the case an implicit initialization will be done that is working similar to the way the { @link javafx . fxml . fxmlloader } is working . <br > when there is a <strong > public< / strong > no - args method named initialize is available this method will be called . when there is a <strong > public< / strong > field of type { @link java . util . resourcebundle } named resources is available this field will get the provided resourcebundle injected . <br > the initialize method ( whether from the { @link javafx . fxml . initializable } interface or implicit ) will be invoked <strong > after< / strong > the viewmodel was injected . this way the user can create bindings to the viewmodel in the initialize method .
this method is trying to invoke the initialize method of the given view by reflection . this is done to meet the conventions of the { @link javafx . fxml . fxmlloader } . the conventions say that when there is a <strong > public< / strong > no - args method with the simple name initialize and the class does not implement the { @link javafx . fxml . initializable } interface the initialize method will be invoked . <br > this method is package scoped for better testability .
injects the given resourcebundle into the given view using reflection . this is done to meet the conventions of the { @link javafx . fxml . fxmlloader } . the resourcebundle is only injected when there is a <strong > public< / strong > field of the type { @link java . util . resourcebundle } named resources . <br > this method is package scoped for better testability .
when the given source binding has a value of <code > null< / code > an empty string is used for the returned binding . otherwise the value of the source binding is used .
returns the { @link java . lang . reflect . field } of the viewmodel for a given view type and viewmodel type . if there is no annotated field for the viewmodel in the view the returned optional will be empty .
this method is used to get the viewmodel instance of a given view / codebehind .
injects the given viewmodel instance into the given view . the injection will only happen when the class of the given view has a viewmodel field that fulfills all requirements for the viewmodel injection ( matching types no viewmodel already existing ... ) .
this method is used to create and inject the viewmodel for a given view instance .
creates a viewmodel instance for a view type . the type of the view is determined by the given view instance .
if a viewmodel has a method annotated with { @link initialize } or method with the signature <code > public void initialize () < / code > it will be invoked . if no such method is available nothing happens .
returns a collection of {
this method adds listeners for the {
this method is used to check if the given view instance has one or more fields that try to inject a scope with the {
set the currently selected country . this will lead to an update of the { @link #subdivisions () } observable list and the { @link #subdivisionlabel () } .
load all countries from the xml file source with datafx .
load all subdivisions from the xml file source with datafx .
this notification will be send to the ui - thread ( if the ui - toolkit was bootstrapped ) . if no ui - toolkit is available the notification will be directly published . this is typically the case in unit tests .
/ * helper
this method is invoked when the javafx application is initialized . see { @link javafx . application . application#init () } for more details . <p > unlike the original init method in { @link javafx . application . application } this method contains logic to initialize the spring - boot container . for this reason this method is now final to prevent unintended overriding . please use { @link #initmvvmfx () } for you own initialization logic .
resets all defined fields to their default values . <p > default values can be defined as last argument of the overloaded field methods ( see { @link #field ( stringgetter stringsetter string ) } ) or by using the { @link #usecurrentvaluesasdefaults () } method .
use all values that are currently present in the wrapped model object as new default values for respective fields . this overrides / updates the values that were set during the initialization of the field mappings . <p > subsequent calls to { @link #reset () } will reset the values to this new default values . <p > usage example : <pre > modelwrapper { @code<person > } wrapper = new modelwrapper { @code< > } () ;
take the current value of each property field and write it into the wrapped model element . <p > if no model element is defined then nothing will happen . <p > <b > note : < / b > this method has no effects on the values of the defined property fields but will only change the state of the wrapped model element .
take the current values from the wrapped model element and put them in the corresponding property fields . <p > if no model element is defined then nothing will happen . <p > <b > note : < / b > this method has no effects on the wrapped model element but will only change the values of the defined property fields .
this method can be used to copy all values of this { @link modelwrapper } instance to the model instance provided as argument . existing values in the provided model instance will be overwritten . <p > this method doesn t change the state of this modelwrapper or the wrapped model instance .
add a new field of type string to this instance of the wrapper . this method is used for model elements that are following the normal java - beans - standard i . e . the model fields are only available via getter and setter methods and not as javafx properties .
add a new immutable field of type string to this instance of the wrapper . this method is used for immutable model elements that have getters to get values for it s fields but not setters . instead immutables have methods that take a new value for a field and return a new cloned instance of the model element with only this field updated to the new value . the old model instance isn t changed .
add a new field of type { @link string } to this instance of the wrapper . this method is used for model elements that are following the enhanced javafx - beans - standard i . e . the model fields are available as javafx properties . <p >
add a new field of type string to this instance of the wrapper . see { @link #field ( stringgetter stringsetter ) } . this method additionally takes a string identifier as first parameter . <p / > this identifier is used to return the same property instance even when the method is invoked multiple times .
add a new immutable field of type string to this instance of the wrapper . see { @link #immutablefield ( stringgetter stringimmutablesetter } ) . this method additionally takes a string identifier as first parameter . <p / > this identifier is used to return the same property instance even when the method is invoked multiple times .
add a new field of type string to this instance of the wrapper . see { @link #field ( stringpropertyaccessor ) } . this method additionally takes a string identifier as first parameter .
/ * field type boolean
/ * field type double
/ * field type float
/ * field type integer
/ * field type long
/ * field type generic
/ * field type list
this helper method is needed because there is no equivalent of {
/ * field type map
add a rule for this validator . <p > the rule defines a condition that has to be fulfilled . <p > a rule is defined by an observable boolean value . if the rule has a value of <code > true< / code > the rule is fulfilled . if the rule has a value of <code > false< / code > the rule is violated . in this case the given message object will be added to the status of this validator . <p > there are some predefined rules for common use cases in the { @link observablerules } class that can be used .
add a complex rule for this validator . <p > the rule is defined by an { @link observablevalue } . if this observable contains a { @link validationmessage } object the rule is considered to be violated and the { @link validationstatus } of this validator will contain the validation message object contained in the observable value . if the observable doesn t contain a value ( in other words it contains <code > null< / code > ) the rule is considered to be fulfilled and the validation status of this validator will be valid ( given that no other rule is violated ) . <p >
creates an observable list that always has {
this method is the entry point of the fluent api to load a java based view .
this method is the entry point of the fluent api to load a fxml based view .
register the given { @link changelistener } to the { @link observablevalue } . the listener is added to the observable and will be added for management so it can be cleaned up with the { @link #clean () } method .
register the given { @link listchangelistener } to the { @link observablelist } . the listener is added to the observable and will be added for management so it can be cleaned up with the { @link #clean () } method .
register the given { @link invalidationlistener } to the { @link observable } . the listener is added to the observable and will be added for management so it can be cleaned up with the { @link #clean () } method .
this method is used to clear the given map . to do this you need to implement a biconsumer that calls the specific method to remove a listener from an observable .
this method is overridden to initialize the mvvmfx framework . override the {
this method is called when the javafx application is initialized . see { @link javafx . application . application#init () } for more details .
this method is called when the application should stop . see { @link javafx . application . application#stop () } for more details .
when the selected item changed we want to set the index property too
returns all fields with the given annotation . only fields that are declared in the actual class of the instance are considered ( i . e . no fields from super classes ) . this includes private fields .
returns all fields of the given type and all parent types ( except object ) . <br > the difference to { @link class#getfields () } is that getfields only returns public fields while this method will return all fields whatever the access modifier is . <br >
helper method to execute a callback on a given member . this method encapsulates the error handling logic and the handling of accessibility of the member .
this method can be used to set ( private / public ) fields to a given value by reflection . handling of accessibility and errors is encapsulated .
helper method to execute a callback on a given member . this method encapsulates the error handling logic and the handling of accessibility of the member . the difference to { @link reflectionutils#accessmember ( accessibleobject callable string ) } is that this method takes a callback that doesn t return anything but only creates a sideeffect .
load the viewtuple by it s viewtype .
this method is used to create a string with the path to the fxml file for a given view class .
load the viewtuple by the path of the fxml file .
load the viewtuple by the path of the fxml file .
query for the style row from a style mapping row
{
{
{
get the pixel value as a 16 bit unsigned integer value
get the pixel values of the image as 16 bit unsigned integer values
validate that the image type is single channel 16 bit
draw a coverage data tile from the double array of unsigned short pixel values formatted as short [ row ] [ width ]
draw a coverage data tile and format as png bytes from the double array of unsigned short pixel values formatted as short [ row ] [ width ]
draw a coverage data image tile and format as png bytes from the double array of unsigned 16 bit integer pixel values formatted as int [ row ] [ width ]
draw a coverage data image tile from the double array of unsigned coverage data values formatted as double [ row ] [ width ]
create a new 16 bit single channel image
set the pixel value
set the pixel value
create the coverage data tile table with metadata and extension
set the tile data from a bitmap
{
{
{
{
{
{
perform a raw database query
perform the query and wrap as a result
{
{
query using the query from a previous query result
query using the user query arguments
convert the cursor to the result type cursor
index the feature row . this method assumes that indexing has been completed and maintained as the last indexed time is updated .
index the feature rows in the cursor
get the feature row for the geometry index
{
{
register a cursor wrapper for the provided table name . database queries will wrap the returned cursor
{
{
{
retrieve the tile row
get a tiled gridded coverage data
get a tiled gridded coverage data use the coverage data pixel tile size as the request size width and height
get a tiled gridded coverage data use the coverage data pixel tile size as the request size width and height request as the specified projection
create the coverage data tile table with metadata and extension
{
{
get the coverage data tile results by finding the tile matrix with values
get the coverage data tile results by zooming in or out as needed from the provided tile matrix to find values
get the coverage data tile results by zooming in from the provided tile matrix
get the coverage data tile results by zooming out from the provided tile matrix
get the tile matrix for the zoom level as defined by the area of the request
get the coverage data value of the pixel in the tile row image
set the icon for the geometry type
get the icon for the geometry type
{
{
open or get a connection using the sqlite android bindings connection
decode the bytes to a bitmap with options
compress the bitmap to a byte array
create a new table metadata
delete the database table name
update the last indexed time
update the last indexed time
update the last indexed time
get a table metadata
get a table metadata
get a table metadata or create if it does not exist
get a geopackage id from the name
create a table metadata from the current cursor location
create the rtree extension for the feature table
get the feature row from the rtree index table row
perform a raw query
{
{
{
query for rows within the bounding box in the provided projection
query for rows within the geometry envelope
count the rows within the geometry envelope
query for rows within the bounds
build a where clause from the bounds for overlapping ranges
build where arguments from the bounds to match the order in { @link #buildwhereargs ( double double double double ) }
manually query for rows within the bounding box in the provided projection
manually count the rows within the bounding box in the provided projection
manually query for rows within the geometry envelope
manually query for rows within the bounds
manually count the rows within the bounds
{
read the data bounds without allocating pixel memory . access values using : { @link bitmapfactory . options#outwidth } { @link bitmapfactory . options#outheight } { @link bitmapfactory . options#outmimetype } { @link bitmapfactory . options#outcolorspace } and { @link bitmapfactory . options#outconfig }
set the data from a full quality bitmap
set the data from a bitmap
set the bitmap compress config
get the tile count of tiles to be generated
adjust the tile matrix set and bounds
adjust the tile matrix set and web mercator bounds for google tile format
adjust the tile matrix set and wgs84 bounds for geopackage format . determine the tile grid width and height
adjust the tile matrix set and web mercator bounds for geopackage format . determine the tile grid width and height
get the bounding box of tiles
get the tile grid of the zoom level
query for a tile
query for tiles at a zoom level in descending row and column order
get the zoom level for the provided width and height in the default units
get the zoom level for the provided width and height in the default units
get the closest zoom level for the provided width and height in the default units
get the approximate zoom level for the provided length in the default units . tiles may or may not exist for the returned zoom level . the approximate zoom level is determined using a factor of 2 from the zoom levels with tiles .
query for the bounding
delete a tile
count of tiles at a zoom level
determine if the tiles are in the google tile coordinate format
{
get the pixel value as a float from the image and the coordinate
get the pixel values of the image as floats
validate that the image type
{
{
draw a coverage data image tile from the flat array of float pixel values of length tilewidth * tileheight where each pixel is at : ( y * tilewidth ) + x
draw a coverage data image tile and format as tiff bytes from the double array of float pixel values formatted as float [ row ] [ width ]
draw a coverage data image tile from the flat array of coverage data values of length tilewidth * tileheight where each coverage data value is at : ( y * tilewidth ) + x
{
create a new image
set the pixel value into the image
create the coverage data tile table with metadata and extension
build a json compatible object
get the cached geopackage or open and cache the geopackage
{
{
get the current row
{
enable requery attempt of invalid rows after iterating through original query rows . only supported for { @link #movetonext () } and { @link #getrow () } usage .
move to the next position of invalid rows to requery . perform the requery the first time .
{
build a json compatible object
query for style mappings by base id
delete by base is and geometry type
get a rectangle using the tile width height bounding box and the bounding box section within the outer box to build the rectangle from
get a rectangle with rounded floating point boundaries using the tile width height bounding box and the bounding box section within the outer box to build the rectangle from
check if the rectangle is valid
check if the rectangle is valid allowing empty ranges
check if the rectangle is valid
check if the rectangle is valid allowing empty ranges
{
{
{
delete all databases that do not exist or the database file does not exist
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
create the required geopackage application id and tables in the newly created and open database connection . then close the connection .
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
{
validate the geopackage database
{
{
{
{
{
validate the database and close when validation fails . throw an error when not valid .
validate the database and close it . throw an error when not valid .
validate the database header and integrity . throw an error when not valid .
validate the header of the database file to verify it is a sqlite database
determine if the header of the database file is valid
add all internal databases to the collection
add all external databases to the collection
import the geopackage stream
get all external geopackage metadata
get the geopackage metadata
get the geopackage metadata of the database at the external path
check if the database is temporary ( rollback journal )
create a new geometry metadata
create a new geometry metadata from an envelope
create a new geometry metadata from an envelope
populate a new geometry metadata from an envelope
delete the geometry metadata
delete geometry metadata by database
delete the geometry metadata
create the geometry metadata or update if it already exists
update the geometry metadata
get a table metadata
get a table metadata
get a table metadata
query for all table geometry metadata
query for the bounds of the feature table index
query for the bounds of the feature table index
query for all table geometry metadata
query for all table geometry metadata matching the bounding box in the same projection
query for all table geometry metadata count matching the bounding box in the same projection
query for all table geometry metadata matching the bounding box in the same projection
query for all table geometry metadata matching the envelope
query for all table geometry metadata count matching the envelope
query for all table geometry metadata matching the envelope
query for all table geometry metadata count matching the envelope
create a geometry metadata from the current cursor location
{
update all rows matching the where clause with the provided values
{
{
{
draw a tile with the provided text label in the middle
get the simple attributes rows that exist with the provided ids
{
{
{
{
{
{
{
{
{
{
check the cursor returned from the integrity check to see if things are ok
{
get a user mapping dao from a table name
get a related simple attributes table dao
get the related id mappings for the base id
get the base id mappings for the related id
determine if the base id and related id mapping exists
{
{
get the count of the cursor and close it
register the cursor wrapper into the geopackage
read the database table and create a dao
get the tile from the request bounding box in the request projection
draw the tile from the tile results
reproject the tile to the requested projection
get the tile matrices that may contain the tiles for the bounding box matches against the bounding box and zoom level options
get the tile row results of tiles needed to draw the requested bounding box tile
call after making changes to the point icon point radius or paint stroke widths . determines the pixel overlap between tiles
set the density
set the line paint
set the polygon paint
draw the tile and get the bytes from the x y and zoom level
draw a tile bitmap from the x y and zoom level
draw a tile bitmap from the x y and zoom level by querying features in the tile location
query for feature result count in the x y and zoom
query for feature result count in the bounding box
query for feature results in the x y and zoom level by querying features in the tile location
query for feature results in the bounding box
create an expanded bounding box to handle features outside the tile that overlap
create an expanded bounding box to handle features outside the tile that overlap
draw a tile bitmap from the x y and zoom level by querying all features . this could be very slow if there are a lot of features
when the simplify tolerance is set simplify the points to a similar curve with fewer points .
get the feature style for the feature row and geometry type
get the feature style for the feature row and geometry type
get the point paint for the feature style or return the default paint
get the line paint for the feature style or return the default paint
get the polygon paint for the feature style or return the default paint
get the polygon fill paint for the feature style or return the default paint
get the feature style paint from cache or create and cache it
get the style paint from cache or create and cache it
check if the bitmap was drawn upon ( non null and not transparent ) . return the same bitmap if drawn else recycle non null bitmaps and return null
get the paint for the style row and draw type
get the paint for the style row id and draw type
set the paint for the style id and draw type
set the paint for the style id and draw type
cache the icon bitmap for the icon row
create or retrieve from cache an icon bitmap for the icon row
{
{
{
{
wrap the content values names in quotes
create the final bitmap from the layers resets the layers
recycle the layered bitmaps
get the bitmap for the layer index
get the canvas for the layer index
create a new empty bitmap and canvas
get a style mapping dao from a table name
get a style dao
get a icon dao
get the feature table default feature styles
get the feature table default styles
get the style of the feature table and geometry type
get the feature table default icons
get the icon of the feature table and geometry type
get the feature styles for the feature row
get the feature styles for the feature table and feature id
get the feature style ( style and icon ) of the feature row with the provided geometry type searching in order : feature geometry type style or icon feature default style or icon table geometry type style or icon table default style or icon
get the feature style default ( style and icon ) of the feature row searching in order : feature default style or icon table default style or icon
get the styles for the feature row
get the style of the feature row with the provided geometry type searching in order : feature geometry type style feature default style table geometry type style table default style
get the default style of the feature row searching in order : feature default style table default style
get the style of the feature searching in order : feature geometry type style feature default style table geometry type style table default style
get the default style of the feature searching in order : feature default style table default style
get the style of the feature searching in order : feature geometry type style feature default style when tablestyle enabled continue searching : table geometry type style table default style
get the default style of the feature searching in order : feature default style when tablestyle enabled continue searching : table default style
get the icons for the feature row
get the icon of the feature row with the provided geometry type searching in order : feature geometry type icon feature default icon table geometry type icon table default icon
get the default icon of the feature row searching in order : feature default icon table default icon
get the icon of the feature searching in order : feature geometry type icon feature default icon table geometry type icon table default icon
get the default icon of the feature searching in order : feature default icon table default icon
get the icon of the feature searching in order : feature geometry type icon feature default icon when tableicon enabled continue searching : table geometry type icon table default icon
get the default icon of the feature searching in order : feature default icon when tableicon enabled continue searching : table default icon
get the styles for feature id from the style mapping dao
get the icons for feature id from the icon mapping dao
set the feature table default feature styles
set the feature table default styles
set the feature table style for the geometry type
set the feature table style for the geometry type
set the feature table default icons
set the feature table icon for the geometry type
set the feature table icon for the geometry type
set the feature styles for the feature row
set the feature styles for the feature table and feature id
set the feature style ( style and icon ) of the feature row
set the feature style ( style and icon ) of the feature row for the specified geometry type
set the feature style default ( style and icon ) of the feature row
set the feature style ( style and icon ) of the feature
set the feature style ( style and icon ) of the feature
set the styles for the feature row
set the styles for the feature table and feature id
set the style of the feature row
set the style of the feature row for the specified geometry type
set the default style of the feature row
set the style of the feature
set the default style of the feature
set the icons for the feature row
set the icons for the feature table and feature id
set the icon of the feature row
set the icon of the feature row for the specified geometry type
set the default icon of the feature row
get the icon of the feature searching in order : feature geometry type icon feature default icon table geometry type icon table default icon
set the default icon of the feature
get the style id either from the existing style or by inserting a new one
get the icon id either from the existing icon or by inserting a new one
insert a style mapping row
delete the feature table style for the geometry type
delete the feature table icon for the geometry type
delete the table style mappings
delete the table style mapping with the geometry type value
delete the feature row style for the geometry type
delete the feature row style for the geometry type
delete the feature row icon for the geometry type
delete the feature row icon for the geometry type
delete the style mapping with the geometry type value
get all the unique style row ids the table maps to
get all the unique icon row ids the table maps to
get all the unique style row ids the features map to
get all the unique icon row ids the features map to
get the image bytes
flush the output stream and set the image bytes close the stream
get the pixel at the coordinate
read all the pixels from the image
{
{
{
draw the feature on the canvas
draw the geometry on the canvas
draw the line path on the canvas
draw the path on the canvas
add the linestring to the path
add the polygon on the canvas
draw the point on the canvas
get or create a feature row cache for the table name
remove the cached feature row
clear and resize all caches and update the max cache size
get the cached table styles querying and caching if needed
get the cached table icons querying and caching if needed
get the feature style ( style and icon ) of the feature row with the provided geometry type searching in order : feature geometry type style or icon feature default style or icon table geometry type style or icon table default style or icon
get the feature style ( style and icon ) of the feature searching in order : feature geometry type style or icon feature default style or icon table geometry type style or icon table default style or icon
get the style of the feature row with the provided geometry type searching in order : feature geometry type style feature default style table geometry type style table default style
get the style of the feature searching in order : feature geometry type style feature default style table geometry type style table default style
get the icon of the feature row with the provided geometry type searching in order : feature geometry type icon feature default icon table geometry type icon table default icon
get the icon of the feature searching in order : feature geometry type icon feature default icon table geometry type icon table default icon
set the feature table style for the geometry type
set the feature table icon for the geometry type
set the feature style ( style and icon ) of the feature row for the specified geometry type
set the feature style ( style and icon ) of the feature
set the style of the feature row for the specified geometry type
set the style of the feature
set the icon of the feature row for the specified geometry type
get the icon of the feature searching in order : feature geometry type icon feature default icon table geometry type icon table default icon
{
{
get a rtree index table dao for the feature dao
{
set the width
set the height
get the derived width and height from the values and icon data scaled as needed
get the tile side ( width and height ) dimension based upon the display density scale
get the tile density based upon the display density scale and tile dimensions
{
{
read the blob column value in chunks
{
{
{
{
read the table
set the color
get the color or default value
set the color
validate and adjust the color value
create a color from the hex color and opacity
get a geopackage manager
prioritize the query location order . all types are placed at the front of the query order in the order they are given . omitting a location leaves it at it s current priority location .
prioritize the query location order . all types are placed at the front of the query order in the order they are given . omitting a location leaves it at it s current priority location .
set the index location order overriding all previously set types
set the index location order overriding all previously set types
set the geopackage progress
index the feature tables for the index types
index the feature table
index the feature row for the index types . this method assumes that indexing has been completed and maintained as the last indexed time is updated .
index the feature row . this method assumes that indexing has been completed and maintained as the last indexed time is updated .
delete the feature index from the index types
delete the feature index for the feature row from the index types
delete the feature index for the geometry id from the index types
delete the feature index for the geometry id
retain the feature index from the index types and delete the others
retain the feature index from the index types and delete the others
determine if the feature table is indexed
get the indexed types that are currently indexed
get the date last indexed
query for all feature index results
query for all feature index count
query for the feature index bounds
query for feature index results within the bounding box in the provided projection
get the indexed type or throw an error if not indexed
{
{
get the internal storage file for the file path
get the internal storage patch for the file path
get the geometry type
set the geometry type
determine if the url has bounding box variables
replace x y and z in the url
determine if the url has x y or z variables
replace the bounding box coordinates in the url
replace the url parts with the bounding box
{
{
{
get the geometry
{
index the feature row . this method assumes that indexing has been completed and maintained as the last indexed time is updated .
index the feature table
index the feature rows in the cursor
index the feature row
update the least indexed time
delete the feature table index
delete the index for the geometry id
determine if the database table is indexed after database modifications
get the date last indexed
query for all geometry metadata
query for geometry metadata within the bounding box projected correctly
query for geometry metadata count within the bounding box projected correctly
query for geometry metadata within the geometry envelope
query for geometry metadata count within the geometry envelope
query for geometry metadata within the bounding box in the provided projection
query for geometry metadata count within the bounding box in the provided projection
get the bounding box in the feature projection from the bounding box in the provided projection
get the geometry metadata for the current place in the cursor
get the feature row for the current place in the cursor
get the feature row for the geometry metadata
query for the tile tables linked to a feature table and return tile daos to those tables
query for the feature tables linked to a tile table and return feature daos to those tables
get the bounding box for the feature tile generator from the provided and from the feature table
{
{
{
query by both base id and related id
get the unique base ids
get the unique related ids
delete user mappings by base id
delete user mappings by related id
delete user mappings by both base id and related id
build the where ids clause
create a new geopackage metadata
delete the database
rename the geopackage metadata to the new name
rename the geopackage name to the new name
get all geopackage metadata
get all external geopackage metadata
get geopackage metadata by name
get geopackage metadata by id
get geopackage metadata or create it if it does not exist
determine if the geopackage is external
get external geopackage metadata by external path
get metadata where the name is like
get metadata where the name is not like
get metadata where the name is like or not like
create a geopackage metadata from the current cursor location
{
{
{
{
handle the created view
sets the { @link viewpager . onpagechangelistener } to the embedded { @link viewpager } created by the container .
attach attributes in tag
the layoutinflater oncreateview is the fourth port of call for layoutinflation . but only for none customviews . basically if this method doesn t inflate the view nothing probably will .
nasty method to inflate custom layouts that haven t been handled else where . if this fails it will fall back through to the phonelayoutinflater method of inflating custom views where calligraphy will not have a hook into .
}
/ * convert a level to equivalent syslog severity . only levels for printing methods i . e trace debug warn info and error are converted .
creates a new { @link ch . qos . logback . core . net . autoflushingobjectwriter } instance .
perform smtpappender specific appending actions mainly adding the event to a cyclic buffer .
finds a configuration file by system property
uses the given classloader to search for a resource
configures logback with the first configuration found in the following search path . if no configuration found nothing is done and logging is disabled .
adds a status message for the result of the resource search
{
converts a socket address to a reasonable display string .
creates an executor service suitable for use by logback components .
start converters in the chain of converters .
this method differentiates rollingfileappender from its super class .
sets the rolling policy . in case the policy argument also implements { @link triggeringpolicy } then the triggering policy for this appender is automatically set to be the policy argument .
add a property to the properties of this execution context . if the property exists already it is overwritten .
if a key is found in propertiesmap then return it . otherwise delegate to the context .
{
this method takes a string which may contain html tags ( ie &lt ; b&gt ; &lt ; table&gt ; etc ) and replaces any &lt ; &gt ; ... characters with respective predefined entity references .
this method takes a stringbuilder which may contain html tags ( ie &lt ; b&gt ; &lt ; table&gt ; etc ) and replaces any &lt ; and &gt ; characters with respective predefined entity references .
ensures that embedded cdend strings ( ]] &gt ; ) are handled properly within message ndc and throwable tag text .
retains all values in the subject collection that are matched by at least one of a collection of regular expressions . <p > this method is a convenience overload for { @link #retainmatching ( collection collection ) } .
retains all values in the subject collection that are matched by at least one of a collection of regular expressions . <p > the semantics of this method are conceptually similar to { @link collection#retainall ( collection ) } but uses pattern matching instead of exact matching .
removes all values in the subject collection that are matched by at least one of a collection of regular expressions . <p > this method is a convenience overload for { @link #removematching ( collection collection ) } .
removes all values in the subject collection that are matched by at least one of a collection of regular expressions . <p > the semantics of this method are conceptually similar to { @link collection#removeall ( collection ) } but uses pattern matching instead of exact matching .
big - endian
big - endian
when the parsing step is done the node list can be transformed into a converter chain .
e = teopt
eopt = e|~
t = literal | % c | % format_modifier c
formats a {
do not perform any character escaping except for % and ) .
given date convert this instance to a regular expression .
{
instantiates an evaluator of the given class and sets its name .
once the children elements are also parsed now is the time to activate the evaluator options .
for internal use . this method is intended for use by staticloggerbinder .
instantiate the context selector class designated by the user . the selector must have a constructor taking a loggercontext instance as an argument .
sets properties for use in configs
gets the path to the external storage directory only if mounted .
returns the absolute path to the directory on the android filesystem similar to { @link #getfilesdirectorypath () } . the difference is these files are excluded from automatic backup to remote storage by { @code android . app . backup . backupagent } . this api is only available on sdk 21 + . on older versions this function returns an empty string .
returns the absolute path to the directory on the android filesystem where databases are stored for the current application .
the <b > file< / b > property takes a string value which should be the name of the file to append to .
if the value of <b > file< / b > is not <code > null< / code > then {
<p > sets and <i > opens< / i > the file where the log output will go . the specified file must be writable .
gets the absolute path to the filename starting from the app s files directory if it is not already an absolute path
return true if event passed as parameter has level error or higher returns false otherwise .
return the value associated with an mdc entry designated by the key property . if that value is null then return the value assigned to the defaultvalue property .
update the mask so as to execute change detection code about once every 100 to 8000 milliseconds .
loop through the filters in the list . as soon as a filter decides on accept or deny then that value is returned . if all of the filters return neutral then neutral is returned .
{
creates a new {
instantiates an layout of the given class and sets its name .
creates a new {
creates key managers using the receiver s key store configuration .
creates trust managers using the receiver s trust store configuration .
constructs a key store factory bean using jsse system properties .
constructs a resource location from a jsse system property .
converts a string describing the location of a resource into a url object .
instantiates an layout of the given class and sets its name .
this implementation checks if any of the converters in the chain handles exceptions . if not then this method adds a { @link throwableproxyconverter } instance to the end of the chain . <p > this allows appenders using this layout to output exception information event if the user forgets to add %ex to the pattern . note that the appenders defined in the core package are not aware of exceptions nor loggingevents . <p > if for some reason the user wishes to not print exceptions then she can add %nopex to the pattern .
this method computes whether a chain of converters handles exceptions or not .
default method for stopping the logback context
print the contents of the context status but only if they contain warnings or errors occurring later then the threshold .
print the contents of the context statuses but only if they contain errors .
print context s status data with a timestamp higher than the threshold .
}
{
{
{
{
convert a level to equivalent syslog severity . only levels for printing methods i . e debug warn info and error are converted .
logback - 411 and logback - 750
get an entry from the livemap if not found search the lingerersmap .
{ @inheritdoc }
{ @inheritdoc }
mark component identified by key as having reached its end - of - life .
this method is used to parse a string such as 5 . 7 5 . 7 or - 5 . 7 into a formatinfo .
a relatively robust file renaming method which in case of failure due to src and target being on different volumes falls back onto renaming by copying .
attempts tp determine whether both files are on different volumes . returns true if we could determine that the files are on different volumes . returns false otherwise or if an error occurred while doing the check .
see http : // logback . qos . ch / manual / configuration . html#variablesubstitution
very similar to <code > system . getproperty< / code > except that the { @link securityexception } is absorbed .
lookup a key from the environment .
gets an android system property
very similar to <code > system . getproperty< / code > except that the { @link securityexception } is absorbed . also checks android system properties as a fallback .
return a string [] of size two . the first item containing the key part and the second item containing a default value specified by the user . the second item will be null if no default value is specified .
if <code > value< / code > is true then <code > true< / code > is returned . if <code > value< / code > is false then <code > true< / code > is returned . otherwise <code > default< / code > is returned . <p > case of value is unimportant .
this method clears all internal properties except internal status messages closes all appenders removes any turbofilters fires an onreset event removes all status listeners removes all context listeners ( except those which are reset resistant ) . <p > as mentioned above internal status messages survive resets .
get the caller information for this logging event . if caller information is null at the time of its invocation this method extracts location information . the collected information is cached for future use . <p > note that after serialization it is impossible to correctly extract caller information . < / p >
set the mdc map for this event .
if no key is specified return all the values present in the mdc in the format k1 = v1 k2 = v2 ...
returns true if the file specified by { @link #setpath ( string ) path } property exists . returns false otherwise .
{
extract caller data information as an array based on a throwable passed as parameter
is currentclass present in the list of packages considered part of the logging framework?
add a new status object .
this implementation does not allow duplicate installations of onconsolestatuslistener
check if any implicit actions are applicable . as soon as an applicable action is found it is returned . thus the returned list will have at most one element .
return the list of applicable patterns for this
sets the classloader to lookup the class for android . os . systemproperties
get the value for the given key in the android system properties
get the value for the given key in the android system properties returned as a boolean .
converts a name string s first letter to lowercase
gets a class s method descriptors
gets a class s property descriptors . all properties have methods whose name begins with set or get . the setters must have a single parameter and getters must have none .
{
{
{
sets the value of the <b > target< / b > option . recognized values are system . out and system . err . any other value will be ignored .
checks that requires parameters are set and if everything is in order activates this appender .
close the underlying {
<p > sets the @link outputstream } where the log output will go . the specified <code > outputstream< / code > must be opened by the user and be writable . the <code > outputstream< / code > will be closed when the appender instance is closed .
actual writing occurs here . <p > most subclasses of <code > writerappender< / code > will need to override this method .
resets this manager . <p > all registered components are stopped and removed from the manager .
this utility method adds a new onconsolestatuslistener to the context passed as parameter .
now property definer is initialized by all properties and we can put property value to context
return the name of the current context name as found in the logging event .
do not perform any character escaping . <p > note that this method assumes that it is called after the escape character has been consumed .
events of level trace debug and info are deemed to be discardable .
instantiates a shutdown hook of the given class and sets its name .
once the children elements are also parsed now is the time to activate the shutdown hook options .
creates a {
closes a closeable while suppressing any {
closes a socket while suppressing any {
closes a server socket while suppressing any {
configures ssl parameters on an {
gets the set of enabled protocols based on the configuration .
gets the set of enabled cipher suites based on the configuration .
applies include and exclude patterns to an array of default string values to produce an array of strings included by the patterns .
creates a new { @link linkedblockingdeque } with the given { @code capacity } . in case the given capacity is smaller than one it will automatically be converted to one .
convert a string into a scope . scope . local is returned by default .
add all the properties found in the argument named props to an interpretationcontext .
attach an appender . if the appender is already in the list in won t be added again .
call the <code > doappend< / code > method on all attached appenders .
returns <code > true< / code > if the specified appender is in the list of attached appenders <code > false< / code > otherwise .
remove the appender passed as parameter form the list of attached appenders .
remove the appender with the name passed as parameter form the list of appenders .
this method is invoked by parent logger to let this logger know that the prent s levelint changed .
details .
invoke all the appenders of this logger .
remove the appender passed as parameter form the list of appenders .
create a child of this logger by suffix that is the part of the name extending this logger . for example if this logger is named x . y and the lastpart is z then the created child logger will be named x . y . z .
the next methods are not merged into one because of the time we gain by not creating a new object [] with the params . this reduces the cost of not logging by about 20 nanoseconds .
method that calls the attached turbofilter objects based on the logger and the level .
support slf4j interception during initialization as introduced in slf4j version 1 . 7 . 15
loops until the desired connection is established and returns the resulting connector .
creates the parent directories of a file . if parent directories not specified in file s path then nothing is done and this returns gracefully .
prepends a string to a path if the path is relative . if the path is already absolute the same path is returned ( nothing changed ) . this is useful for converting relative paths to absolute ones given the absolute directory path as a prefix .
convert a level to an integer object .
convert an integer passed as argument to a level . if the conversion fails then this method returns the specified default .
convert the string passed as argument to a level . if the conversion fails then this method returns the value of <code > defaultlevel< / code > .
convert one of the integer values defined in { @link locationawarelogger } interface to an instance of this class i . e . a level .
convert this level instance to an integer value defined in the { @link locationawarelogger } interface .
returns true if the class of the object o passed as parameter is * not * marked with the noautostart annotation . return true otherwise .
creates a new {
invokes the appropriate jce factory method to obtain a new {
compute the number of occurrences a resource can be found by a class loader .
search for a resource using the classloader passed as parameter .
get the class loader of the object passed as argument . return the system class loader if appropriate .
returns the class loader of clazz in an access privileged section .
return the class loader which loaded the class passed as argument . return the system class loader if appropriate .
if running under jdk 1 . 2 load the specified class using the <code > thread< / code > <code > contextclassloader< / code > if that fails try class . forname . under jdk 1 . 1 only class . forname is used .
checks that required parameters are set and if everything is in order activates this appender .
writes an event to android s logging mechanism ( logcat )
gets the logcat tag string of a logging event
{
{
set a new property for the execution context by name value pair or adds all the properties found in the given file .
get the position of the separator character if any starting at position fromindex .
return true if event passed as parameter contains one of the specified user - markers .
creates a {
returns a name to identify each client thread .
this method assumes that both files a and b exists .
start the appender
perform smtpappender specific appending actions delegating some of them to a subclass and checking if the event triggers an e - mail to be sent .
this method determines if there is a sense in attempting to append . <p > it checks whether there is a set output target and also if there is a set layout . if these checks fail then the boolean value <code > false< / code > is returned .
send the contents of the cyclic buffer as an e - mail message .
}
add a new mdcvaluepair
this method first finds the mdc value for key . it then finds the level threshold associated with this mdc value from the list of mdcvaluelevelpair passed to this filter . this value is stored in a variable called levelassociatedwithmdcvalue . if it null then it is set to the { @link #defaultthreshold } value .
attempt to create a converter using the information found in convertermap .
attempt to create a converter using the information found in compositeconvertermap .
given the filenamepattern string this method determines the compression mode depending on last letters of the filenamepatternstr . patterns ending with . gz imply gzip compression endings with . zip imply zip compression . otherwise and by default there is no compression .
configures logback with the configuration xml read from a file located at the given url
configures logback with the configuration xml read from a given file
configures logback with the configuraiton xml read from an input stream and then closes the stream
builds a generic configuration - xml interpreter
configures logback with the configuration xml read from an input source .
configures logback with sax events of configuration xml
given a key return the corresponding property value . if invoked with the special key context_name the name of the context is returned .
the context name can be set only if it is not already set or if the current name is the default context name namely default or if the current name and the old name are the same .
returns true if the statusmanager associated with the context passed as parameter has one or more statuslistener instances registered . returns false otherwise .
return the time of last reset . - 1 if last reset time could not be found
add an <code > event< / code > as the last event in the buffer .
get the <i > i< / i > th oldest event currently in the buffer . if <em > i< / em > is outside the range 0 to the number of elements currently in the buffer then <code > null< / code > is returned .
get the oldest ( first ) element in the buffer . the oldest element is removed from the buffer .
resize the cyclic buffer to <code > newsize< / code > .
{
{
{
}
parses the pattern and creates the converter linked list .
returns a map where the default converter map is merged with the map contained in the context .
returns appropriate html headers .
returns the appropriate html footers .
instantiates an appender of the given class and sets its name .
once the children elements are also parsed now is the time to activate the appender options .
/ * ( non - javadoc )
{
{
creates a copy of the collection of all clients that are presently being tracked by the server .
{
adds a client to the collection of those being tracked by the server .
removes a client from the collection of those being tracked by the server .
put a context value ( the <code > val< / code > parameter ) as identified with the <code > key< / code > parameter into the current thread s context map . note that contrary to log4j the <code > val< / code > parameter can be null . <p > if the current thread does not have a context map it is created as a side effect of this call .
remove the the context identified by the <code > key< / code > parameter .
get the context identified by the <code > key< / code > parameter .
returns the keys in the mdc as a {
return a copy of the current thread s context map . returned value may be null .
convert <code > val< / code > a string parameter to an object of a given type .
returned value may be null and in most cases it is null .
loop through the filters in the chain . as soon as a filter decides on accept or deny then that value is returned . if all of the filters return neutral then neutral is returned .
{
add a new rule i . e . a pattern action pair to the rule store . <p > note that the added action s loggerrepository will be set in the process .
match for x / y / * has higher priority than matches for x / *
suffix matches are matches of type * / x / y
heuristically determines whether the current os is android
package access for testing purposes .
return the set of files matching the stemregex as found in directory . a stemregex does not contain any slash characters or any folder separators .
{
{
{
print status messages retrospectively
returns the integer value corresponding to the named syslog facility .
the <b > facility< / b > option must be set one of the strings kern user mail daemon auth syslog lpr news uucp cron authpriv ftp ntp audit alert clock local0 local1 local2 local3 local4 local5 local6 local7 . case is not important .
determine if a node has already been visited already by checking the cycledetectionstack for it s existence . this method is used -- rather than stack . contains () -- because we want to ignore the node s next attribute when comparing for equality .
gets a file object from a file path to a sqlite database
/ * ( non - javadoc )
removes expired logs from the database
determines whether it s time to clear expired logs
gets the {
/ * ( non - javadoc )
inserts the main details of a log event into the database
updates an existing row of an event with the secondary details of the event . this includes mdc properties and any exception information .
binds the main details of a log event to a sqlite statement s parameters
binds a logging event s arguments ( e . g . <code > logger . debug ( x = {} y = {} arg1 arg2 ) < / code > ) to a sqlite statement s parameters
gets the first 254 characters of an object s string representation . this is used to truncate a logging event s argument binding if necessary .
computes the reference mask for a logging event including flags to indicate whether mdc properties or exception info is available for the event .
merges a log event s properties with the properties of the logger context . the context properties are first in the map and then the event s properties are appended .
updates an existing row with property details ( context properties and event s properties ) .
binds the calling function s details ( filename line etc . ) to a sqlite statement s arguments
inserts an exception into the logging_exceptions table
returns the number of prefix components that this pattern has in common with the pattern p passed as parameter . by prefix components we mean the components at the beginning of the pattern .
different status objects lying on the same cycle
uses javabeans {
set a property on this propertysetter s object . if successful this method will invoke a setter method on the underlying object . the setter is the one for the specified property name and the value is determined partly from the setter argument type and partly from the value specified in the call to this method .
set the named property given a { @link propertydescriptor } .
can the given clazz instantiable with certainty?
returns the string true if the { @link #setresource ( string ) resource } specified by the user is available on the class path false otherwise .
child threads should get a copy of the parent s hashmap .
eopt = e|~
t = literal | $ { v }
v = e ( : = e|~ )
c = e ( : = e|~ )
processes an include
opens the given url logging any exceptions
removes the head tag and tail tag if they are named either included or configuration
gets the event name of a {
starts the server .
{
test whether this error is transient .
set the default hosts for algolia places .
search for places .
search for places .
get a place by its objectid .
add a data selection query to this index . note : all queries are implicitly browse queries ( and not search queries ) .
replace all data selection queries associated to this index .
set the delay after which data is considered to be obsolete .
lazy instantiate the local index .
----------------------------------------------------------------------
launch a sync . if a sync is already running this call is ignored . otherwise the sync is enqueued and runs in the background .
launch a sync only if the data is obsolete . the data is obsolete if the last successful sync is older than the delay between syncs or if the data selection queries have been changed in the meantime .
refresh the local mirror . warning : should be called from a background thread .
search the online api falling back to the local mirror if enabled in case of error .
search the online api .
search the online api .
----------------------------------------------------------------------
run multiple queries on this index explicitly targeting the online api .
run multiple queries on this index explicitly targeting the online api .
run multiple queries on this index explicitly targeting the offline mirror .
run multiple queries on this index explicitly targeting the online api .
run multiple queries on this index explicitly targeting the offline mirror .
browse the local mirror ( initial call ) . same semantics as { @link index#browseasync } .
browse the local mirror ( subsequent calls ) . same semantics as { @link index#browsefromasync } .
get an individual object from the online api falling back to the local mirror in case of error ( when enabled ) .
get an individual object explicitly targeting the online api not the offline mirror .
get an individual object explicitly targeting the online api not the offline mirror .
get an individual object explicitly targeting the online api not the offline mirror .
get an individual object explicitly targeting the offline mirror not the online api .
get an individual object explicitly targeting the offline mirror not the online api .
get individual objects from the online api falling back to the local mirror in case of error ( when enabled ) .
get individual objects explicitly targeting the online api not the offline mirror .
get individual objects explicitly targeting the online api not the offline mirror .
get individual objects explicitly targeting the online api not the offline mirror .
get individual objects explicitly targeting the offline mirror not the online api .
get individual objects explicitly targeting the offline mirror not the online api .
----------------------------------------------------------------------
search for facet values explicitly targeting the online api not the offline mirror . same parameters as {
search for facet values explicitly targeting the online api not the offline mirror . same parameters as {
search for facet values explicitly targeting the offline mirror not the online api .
searches inside this index ( asynchronously ) .
searches inside this index ( synchronously ) .
run multiple queries on this index with one api call . a variant of { @link client#multiplequeriesasync ( list client . multiplequeriesstrategy completionhandler ) } where the targeted index is always the receiver .
searches inside this index synchronously .
perform a search with disjunctive facets generating as many queries as number of disjunctive facets ( helper ) .
perform a search with disjunctive facets generating as many queries as number of disjunctive facets ( helper ) .
searches ( asynchronously ) for some text in a facet values .
searches for some text in a facet values optionally restricting the returned values to those contained in objects matching other ( regular ) search criteria .
searches for some text in a facet values optionally restricting the returned values to those contained in objects matching other ( regular ) search criteria .
adds an object to this index ( asynchronously ) . <p > warning : for performance reasons the arguments are not cloned . since the method is executed in the background you should not modify the object after it has been passed . < / p >
adds an object to this index assigning it the specified object id ( asynchronously ) . if an object already exists with the same object id the existing object will be overwritten . <p > warning : for performance reasons the arguments are not cloned . since the method is executed in the background you should not modify the object after it has been passed . < / p >
adds an object to this index assigning it the specified object id ( asynchronously ) . if an object already exists with the same object id the existing object will be overwritten . <p > warning : for performance reasons the arguments are not cloned . since the method is executed in the background you should not modify the object after it has been passed . < / p >
adds several objects to this index ( asynchronously ) .
update several objects ( asynchronously ) .
partially update an object ( asynchronously ) . <p > ** note : ** this method will create the object if it does not exist already . if you don t wish to you can use { @link #partialupdateobjectasync ( jsonobject string boolean completionhandler ) } and specify false for the createifnotexists argument .
partially update an object ( asynchronously ) .
partially update several objects ( asynchronously ) . <p > ** note : ** this method will create the objects if they do not exist already . if you don t wish to you can use { @link #partialupdateobjectsasync ( jsonarray boolean completionhandler ) } and specify false for the createifnotexists argument .
partially update several objects ( asynchronously ) .
gets an object from this index optionally restricting the retrieved content ( asynchronously ) .
gets an object from this index optionally restricting the retrieved content ( asynchronously ) .
gets several objects from this index ( asynchronously ) .
gets several objects from this index ( asynchronously ) optionally restricting the retrieved content ( asynchronously ) .
wait until the publication of a task on the server ( helper ) . all server tasks are asynchronous . this method helps you check that a task is published .
deletes an object from this index ( asynchronously ) .
deletes an object from this index ( asynchronously ) .
deletes several objects from this index ( asynchronously ) .
deletes several objects from this index ( asynchronously ) .
deletes all objects matching a query ( helper ) using browse and deleteobjects .
gets this index s settings ( asynchronously ) .
set this index s settings ( asynchronously ) . <p > please refer to our <a href = https : // www . algolia . com / doc / android#index - settings > api documentation< / a > for the list of supported settings .
set this index s settings ( asynchronously ) . <p > please refer to our <a href = https : // www . algolia . com / doc / android#index - settings > api documentation< / a > for the list of supported settings .
browse the index from a cursor . this method should be called after an initial call to browseasync () . it returns a cursor unless the end of the index has been reached .
browse the index from a cursor . this method should be called after an initial call to browseasync () . it returns a cursor unless the end of the index has been reached .
clear this index .
adds an object in this index .
custom batch .
gets an object from this index .
gets an object from this index .
gets several objects from this index .
gets several objects from this index .
update partially an object ( only update attributes passed in argument ) .
partially override the content of several objects .
override the content of object .
override the content of several objects .
deletes all objects matching a query using browse and deleteobjects .
deletes all records matching the query .
searches inside the index .
searches inside the index .
wait the publication of a task on the server . all server task are asynchronous and you can check with this method that the task is published .
gets the settings of this index .
set settings for this index .
deletes the index content without removing settings and index specific api keys .
run multiple queries on this index with one api call . a variant of { @link client#multiplequeries ( list string requestoptions ) } where all queries target this index .
build a query string from a map of url parameters .
parse a url query parameter string and store the resulting parameters into this query .
set a parameter in an untyped fashion . this low - level accessor is intended to access parameters that this client does not yet support .
search for entries around a given latitude / longitude .
change the radius for around latitude / longitude queries .
deprecated use {
deprecated use {
get the value of <b > deprecated< / b > { @code facetfilters } parameter .
a list of language codes for which plural won t be considered as a typo ( for example car / cars will be considered as equals ) . if empty or null this disables the feature .
search for entries inside one area or the union of several areas defined by the two extreme points of a rectangle .
search for entries inside a given area defined by the points of a polygon .
search for entries inside a given area defined by several polygons .
get the value of <b > deprecated< / b > { @code facetfilters } parameter .
select how the query words are interpreted :
enable the removal of stop words disabled by default . in most use - cases we dont recommend enabling this option .
select the strategy to adopt when a query does not return any result .
parse a query object from a url query parameter string .
perform a search with disjunctive facets generating as many queries as number of disjunctive facets .
filter disjunctive refinements from generic refinements and a list of disjunctive facets .
compute the queries to run to implement disjunctive faceting .
aggregate results from multiple queries into disjunctive faceting results .
search inside this index ( asynchronously ) .
search inside this index ( synchronously ) .
run multiple queries on this index with one api call . a variant of { @link client#multiplequeriesasync ( list client . multiplequeriesstrategy completionhandler ) } where the targeted index is always the receiver .
get an object from this index optionally restricting the retrieved content ( asynchronously ) .
get several objects from this index ( asynchronously ) .
get this index s settings ( asynchronously ) .
browse all index content ( initial call ) . this method should be called once to initiate a browse . it will return the first page of results and a cursor unless the end of the index has been reached . to retrieve subsequent pages call browsefromasync with that cursor .
browse the index from a cursor . this method should be called after an initial call to browseasync () . it returns a cursor unless the end of the index has been reached .
search for facet values ( asynchronously ) . same parameters as {
search for facet values ( synchronously ) .
build the index from local data stored on the filesystem .
build the index from local data stored in raw resources .
perform a search with disjunctive facets generating as many queries as number of disjunctive facets ( helper ) .
delete all objects matching a query ( helper ) .
create a copy of a json object with a specific <code > objectid< / code > attribute .
write a temporary file containing a json object .
write a temporary file containing json objects . the files are written as an array .
write a temporary file containing textual data in utf - 8 encoding .
obtain a mirrored index . although this will always be an instance of { @link mirroredindex } mirroring is deactivated by default .
obtain a purely offline index .
test if an index has offline data on disk .
list existing offline indices . only indices that * actually exist * on disk are listed . if an instance was created but never synced or written to it will not appear in the list .
list existing offline indices .
delete an offline index . this deletes the data on disk . if the index does not exist this method does nothing .
delete an offline index . this deletes the data on disk . if the index does not exist this method does nothing .
move an existing offline index .
move an existing offline index .
----------------------------------------------------------------------
delete a file or directory recursively deleting any descendant files / directories if it s a directory .
write a stream of bytes to a file .
set a url parameter ( untyped version ) . whenever possible you should use a typed accessor .
set an http header that will be sent with every request .
add a software library to the list of user agents .
reads the inputstream as utf - 8
reads the inputstream into a byte array
send the query according to parameters and returns its result as a jsonobject
send the query according to parameters and returns its result as a jsonobject
ensures that the entity content is fully consumed and the content stream if exists is closed .
get the hosts that are not considered down in a given list .
force to * first * search around a specific latitude / longitude . the default is to search around the location of the user determined via his ip address ( geoip ) .
change the radius for around latitude / longitude queries .
get the current radius for around latitude / longitude queries .
set the type of place to search for .
parse a query object from a url query parameter string .
set a parameter in an untyped fashion . this low - level accessor is intended to access parameters that this client does not yet support .
start the iteration .
search inside this index ( asynchronously ) .
perform a search with disjunctive facets generating as many queries as number of disjunctive facets ( helper ) .
search for some text in a facet values optionally restricting the returned values to those contained in objects matching other ( regular ) search criteria .
list existing indexes .
delete an index .
delete an index .
move an existing index . if the destination index already exists its specific api keys will be preserved and the source index specific api keys will be added .
move an existing index . if the destination index already exists its specific api keys will be preserved and the source index specific api keys will be added .
run multiple queries potentially targeting multiple indexes with one api call .
run multiple queries potentially targeting multiple indexes with one api call .
batch operations .
batch operations .
list all existing indexes
delete an index
move an existing index .
puts a value in the cache computing an expiration time
get a value from the cache
run the log processor with the currently provided arguments .
combines { @link performancestats } instances e . g . from different simulator workers . <p > for the real - time performance monitor during the { @link testphase#run } the maximum value should be set so we get the maximum operation count and throughput values of all { @link performancestats } instances of the last interval . <p > for the total performance number and the performance per simulator agent the added values should be set so we get the summed up operation count and throughput values . <p > the method always sets the maximum values for latency .
spawns a new thread for the given { @link runnable } .
waits for all threads to finish .
compares two version strings .
writes the cause to file .
copies a directory recursively .
initializes the simulatorproperties with additional properties .
binds a single property contained in the { @link testcase } instance onto the object instance .
returns a single property contained in the { @link testcase } instance .
gets the value for a static field .
searches a method by name .
launching is done asynchronous so we don t block the calling thread ( messaging thread )
http : // stackoverflow . com / questions / 35842 / how - can - a - java - program - get - its - own - process - id
sleeps a random amount of time . <p > the call is ignored if maxdelaynanos equals or smaller than zero .
formats a percentage of two numbers and adds padding to the left .
formats a double number and adds padding to the left .
formats a long number and adds padding to the left .
prepares the key store and our keys for encrypting / decrypting . keys will be generated if we haven t done so yet and keys will be re - generated if the old ones have been invalidated . in both cases our k / v store will be cleared before continuing .
and jsonpaircontext . read
corresponding hex value
write the bytes in array buf as a json characters escaping as needed
wrapped in quotes to output as a json string .
context dictates escaping write out as json string .
context if skipcontext is true .
not do a complete regex check to validate that this is actually a number .
read in a json number . if the context dictates read in enclosing quotes .
when expected or if wrapped in quotes when not expected .
read in a json string containing base - 64 encoded data and decode it .
when invoked by a derived instance sends the given call to the server .
send the given call to the server .
////////////////////
when invoked by a derived instance places the given call in a queue to be sent to the server .
resolves a file system location to an eclipse workspace resource .
causes the platform to update guvnor decoration notions .
causes the repository view to refresh if it is open .
tries to find the resource history view attempting to open it if necessary .
opens a read - only in - memory editor .
convenience method for reporting log in failure
prompts for user name and password for a given guvnor repository .
returns a buffer ( byte array ) of size <code > buffer_size< / code > from the pool . when the buffer is no longer needed it should be put back in the pool for future use by calling <code > putbuffer< / code > .
puts the given buffer into the pool for future use . the size of the buffer must be <code > buffer_size< / code > .
creates a page displayed when there are no servers defined .
switch between the servers and default / empty page .
start the animation thread
adds the given property href to this propertybehavior s list of live properties . the property href must not be <code > null< / code > and the form of this property behavior must not already be omit or keepallalive .
returns an <code > enumeration< / code > over this propertybehavior s property hrefs . the methods <code > ismerge () < / code > and <code > iskeepallalive< / code > return false if this propertybehavior is in the keep some alive form .
returns <code > true< / code > if this propertybehavior is in the keep all alive form otherwise returns <code > false< / code > .
sets whether this propertybehavior is in the keep all alive form or not .
sets whether this propertybehavior is in the omit form or not .
adds the given href to this activelock s locktoken . the href must not be <code > null< / code > .
returns the depth of this activelock ; for example <code > context . depth_zero< / code > .
returns an <code > enumeration< / code > of <code > string< / code > s containing this activelock s lock token hrefs .
returns this activelock s owner or <code > null< / code > if this active lock has no owner .
sets the depth of this activelock to the given depth . the depth must not be null and must be one of : <ul > <li > <code > context . depth_zero< / code > <li > <code > context . depth_one< / code > <li > <code > context . depth_infinity< / code > < / ul >
sets whether this activelock is shared or exclusive . if isshared is <code > true< / code > the activelock is set as shared otherwise the activelock is set as exclusive .
creates and sets an owner element on this activelock and returns an editor on it .
sets the timeout on this activelock to the given timeout . if the timeout is <code > null< / code > the current timeout is removed .
/ * ( non - javadoc )
creates a new webdav lockinfo element and sets it as the root of the given document . returns an editor on the new lockinfo element . the document must not be <code > null< / code > and must not already have a root element .
returns <code > true< / code > if this lockinfo is shared and <code > false< / code > if it is exclusive .
add a conditionfactor to a conditionterm .
create a conditionterm by parsing the given if header as defined by section 9 . 4 in the webdav spec .
see if this conditionterm matches the given conditionterm . this is an and operation . all the factors in the conditionterm must match .
get the appropriate content assistance for each partition .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
$non - nls - 1$
/ * create and returns a java project based on the current editor input or returns null
/ * do we already have a completion for that string that would be either a local variable or a field?
get a reader to the dsl contents
this does the hunting around the projec to find the . dsl file .
this will load in the dsl config file using the dslmapping from drools - compiler
sniffs out the expander / dsl config name as best it can .
returns the given <code > url< / code > with a trailing slash appended to it . if the <code > url< / code > already has a trailing slash the <code > url< / code > is returned unchanged . <table > <caption > example< / caption > <tr > <th > given url< / th > <th > returned url< / th > <tr > <td > http : // hostname / folder < / td > <td > http : // hostname / folder / < / td > <tr > <td > http : // hostname / folder / < / td > <td > http : // hostname / folder / < / td > < / table >
returns the child url formed by joining the given member with the given parent url .
returns the child url formed by joining the given member with the given parent url .
returns all elements in the given urls path . <table > <caption > example< / caption > <tr > <th > given url< / th > <th > element< / th > <tr > <td > http : // hostname / < / td > <td > [] < / td > <tr > <td > http : // hostname / folder / < / td > <td > [ folder ] < / td > <tr > <td > http : // hostname / folder / file< / td > <td > [ folder file ] < / td > < / table >
returns the last element in the given urls path or <code > null< / code > if the url is the root . <table > <caption > example< / caption > <tr > <th > given url< / th > <th > last element< / th > <tr > <td > http : // hostname / < / td > <td > null< / td > <tr > <td > http : // hostname / folder / < / td > <td > folder< / td > <tr > <td > http : // hostname / folder / file< / td > <td > file< / td > < / table >
returns the parent url of the given url or <code > null< / code > if the given url is the root . <table > <caption > example< / caption > <tr > <th > given url< / th > <th > parent url< / th > <tr > <td > http : // hostname / < / td > <td > null< / td > <tr > <td > http : // hostname / folder / file< / td > <td > http : // hostname / folder / < / td > < / table >
returns the root url of the given url . <table > <caption > example< / caption > <tr > <th > given url< / th > <th > root url< / th > <tr > <td > http : // hostname / < / td > <td > http : // hostname / < / td > <tr > <td > http : // hostname / folder / file< / td > <td > http : // hostname / < / td > < / table >
returns the given url with its trailing slash removed . if the url has no trailing slash the url is returned unchanged . <table > <caption > example< / caption > <tr > <th > given url< / th > <th > returned url< / th > <tr > <td > http : // hostname / folder < / td > <td > http : // hostname / folder < / td > <tr > <td > http : // hostname / folder / < / td > <td > http : // hostname / folder < / td > < / table >
returns a boolean indicating whether the given urls overlap . <table > <caption > example< / caption > <tr > <th > first url< / th > <th > second url< / th > <th > do they overlap< / th > <tr > <td > http : // hostname / folder / < / td > <td > http : // hostname / folder / < / td > <td > true< / td > <tr > <td > http : // hostname / folder / < / td > <td > http : // hostname / folder / file < / td > <td > true< / td > <tr > <td > http : // hostname / folder / file < / td > <td > http : // hostname / folder / < / td > <td > true< / td > <tr > <td > http : // hostname / folder1 / < / td > <td > http : // hostname / folder2 / < / td > <td > false< / td > < / table >
returns a boolean indicating whether the given urls overlap . <table > <caption > example< / caption > <tr > <th > first url< / th > <th > second url< / th > <th > do they overlap< / th > <tr > <td > http : // hostname / folder / < / td > <td > http : // hostname / folder / < / td > <td > true< / td > <tr > <td > http : // hostname / folder / < / td > <td > http : // hostname / folder / file < / td > <td > true< / td > <tr > <td > http : // hostname / folder / file < / td > <td > http : // hostname / folder / < / td > <td > true< / td > <tr > <td > http : // hostname / folder1 / < / td > <td > http : // hostname / folder2 / < / td > <td > false< / td > <tr > <td > http : // hostname1 / folder / < / td > <td > http : // hostname2 / folder / < / td > <td > false< / td > < / table >
return a menu which launches the various wizards
returns the content length of this message s body or - 1 if the content length is unknown .
returns the content type of this response s body or <code > null< / code > if the content type is unknown .
returns this response s body as a dom <code > document< / code > . this response must have a document body .
/ * ( non - javadoc )
creates and adds a response element to this multistatus and returns an editor on it .
creates a new webdav multistatus element and sets it as the root of the given document . returns an editor on the new multistatus element . <p > the document must not be <code > null< / code > and must not already have a root element . < / p >
returns an <code > enumeration< / code > over this multistatus responses .
$non - nls - 1$
adds the given href to the end of the set of hrefs . if the href already exists it is not added .
creates a new href set element with the given name and sets it as the root of the given document . returns an editor on the new href set element . the document must not be <code > null< / code > and must not already have a root element .
returns an <code > enumeration< / code > over the set of hrefs .
inserts the given newhref before the given refhref in the set of hrefs . if newhref already exists it is not inserted .
remove the given href from the set of hrefs .
gets this response s first propstat with the given status and adds an element created from the given property name as a property of the propstat s prop . if such a propstat does not exists it is created . the propstat s response description is set to the given response description or removed if the response description is <code > null< / code > . returns the propstat . the property name must not be <code > null< / code > and its qualifier and local part must not be <code > null< / code > and must not be the empty string . the status must not be <code > null< / code > . this response must not already be in the status form .
gets this response s first propstat with the given status and adds a clone of the given element as a property of its prop . if such a propstat does not exists it is created . the propstat s response description is set to the given response description or removed if the response description is <code > null< / code > . returns the propstat . the element and status must not be <code > null< / code > . this response must not already be in the status form .
adds the given href to this response . if <code > sethref ( string ) < / code > hasn t been called and no hrefs have been added this method sets the first href and is thus equivalent to <code > sethref ( string ) < / code > . the href must not be <code > null< / code > . this response must not already be in propstat form .
creates and adds a propstat element on this response and returns an editor on it .
changes all of this response s propstats with the given old status to have the given new status . in addition their response descriptions are changed to be the given response description or removed if the given response description is <code > null< / code > . the old status and new status must not be <code > null< / null > . this response must not be in the status form .
returns this response s first href .
returns an <code > enumeration< / code > of this response s hrefs ( not including the first href ) .
returns an <code > enumeration< / code > of this response s <code > propstat< / code > s .
returns this response s status .
returns <code > true< / code > if this response is in propstat form and <code > false< / code > if it is in status form .
sets this response s response description to the given value . if the value is <code > null< / code > and a response description has already been set it is removed .
sets the status on this response to the given status . the status must not be <code > null< / code > . this response must not already be in the propstat form .
appends a new member to the end of this object with the specified name and the json representation of the specified string . <p > this method <strong > does not prevent duplicate names< / strong > . calling this method with a name that already exists in the object will append another member with the same name . in order to replace existing members use the method <code > set ( name value ) < / code > instead . however <strong > <em > add< / em > is much faster than <em > set< / em > < / strong > ( because it does not need to search for existing members ) . therefore <em > add< / em > should be preferred when constructing new objects . < / p >
sets the value of the member with the specified name to the json representation of the specified string . if this object does not contain a member with this name a new member is added at the end of the object . if this object contains multiple members with this name only the last one is changed . <p > this method should <strong > only be used to modify existing objects< / strong > . to fill a new object with members the method <code > add ( name value ) < / code > should be preferred which is much faster ( as it does not need to search for existing members ) . < / p >
returns the basic authorization credentials for the given username and password . the credentials have the following form : <code > credentials = basic basic - credentials basic - credentials = base64 - user - pass base64 - user - pass = &lt ; base64 encoding of user - pass except not limited to 76 char / line&gt ; user - pass = userid : password userid = * &lt ; text excluding : &gt ; password = * text < / code > <p > userids might be case sensitive . <p > for example if the user s name is aladdin and the user s password is open sesame the following credentials are supplied : <code > basic qwxhzgrpbjpvcgvuihn1c2ftzq == < / code >
report a property change to registered listeners ( for example edit parts ) .
return the current stack frame context or a valid stack frame for the given value .
returns true if the first class is the same or a subtype of the second class .
/ * completions for object instance members
/ * completions for static class members
attempt to compare proposals of different types based on the tokenized display string
/ * filters accessor method proposals to replace them with their mvel expression equivalent for instance a completion for getstatus () would be replaced by a completion for status when asking for stters only then only setters or writable fields will be returned
creates a webdav element with the given name and appends it as a child of the given parent . returns the child element . the parent must not be <code > null< / code > and must be a webdav element . the name of the child must not be <code > null< / code > .
creates a webdav element with the given name and appends it as a child of the given parent . in addition a text node created from the given data is created and appended to the child . returns the child element . the parent must not be <code > null< / code > and must be a webdav element . the name of the child must not be <code > null< / code > . the data must not be <code > null< / code > .
returns a clone of the given node . the given document becomes the owner document of the clone .
creates a webdav element with the given name and adds it as the root of the given document . in addition the webdav namespace is declared on the new element . returns the new element . the document must not be <code > null< / code > and must not already have a root element . the name of the element to be created must not be <code > null< / code > .
adds a namespace declaration to the given element . if only the prefix is <code > null< / code > a default namespace is declared . if the prefix and the namespaceurl are <code > null< / code > the default namespace is removed . the element must not be <code > null< / code > . if the namespaceurl is <code > null< / code > the <code > prefix< / code > must also be <code > null< / code > .
ensures that the given node is a webdav element with the given name returning it as an <code > element< / code > if it is .
ensures that the given object is not <code > null< / code > .
ensures that the given object is <code > null< / code > .
ensures that the given node is a text node returning it as a <code > text< / code > node if it is .
clones the given element and its subtrees and sets it as the root of the given document . returns the cloned element . the document must not have a root and must not be <code > null< / code > . the element must not be <code > null< / code > .
clones the given node and its subtrees and sets it as the root of the given parent node . returns the cloned node . the parent node and the node to be cloned must not be <code > null< / code > .
returns the first child of the given parent that is a webdav element with one of the given names or <code > null< / code > if no such child exists . <p > if firsttolast is true the search for the child starts at the parent s first child otherwise the search starts at the parent s last child . the parent must not be <code > null< / code > and must be a webdav element . the names of children to search for must not be <code > null< / code > . < / p >
<p > returns the child webdav element of the given parent that is nearest in position to a webdav element with the given name or <code > null< / code > if no such child exists . <p > children are expected to be in the order specified by the given names . if firsttolast is true the search for the child starts at the parent s first child otherwise the search starts at the parent s last child . <p > the parent must not be <code > null< / code > and must be a webdav element . the name of the child to search for must not be <code > null< / code > . the parent s valid child names must not be <code > null< / code > and must contain the name of the child being searched for . <p > the returned child is as follows : <ul > <li > searching first to last< / li > <ul > <li > returns <code > null< / code > if an element with the given name should appear as the last child< / li > <li > returns the first occurring child if an element with the given name is a child< / li > <li > returns a child if an element with the given name would appear before it< / li > < / ul > <li > searching last to first< / li > <ul > <li > returns <code > null< / code > if an element with the given name would appear as the first child< / li > <li > returns the last occurring child if an element with the given name is a child< / li > <li > returns a child if an element with the given name would appear after it< / li > < / ul > < / ul >
returns the first child element of the given parent element or <code > null< / code > if no such child exists . if firsttolast is true the search for the child starts at the parent s first child otherwise the search starts at the parent s last child . the parent must not be <code > null< / code > .
returns the data of the first child text node of the first webdav child with the given name of the given parent or the empty <code > string< / code > if no such child text node exists or <code > null< / code > if no such child exists . if firsttolast is true the search for the child starts at the parent s first child otherwise the search starts at the parent s last child . the parent must not be <code > null< / code > and must be a webdav element . the name of the child must not be <code > null< / code > .
returns the first webdav child of the given parent or <code > null< / code > if no such child exists . the parent must not be <code > null< / code > and must be a webdav element .
returns the first child of the given parent that is a webdav element with one of the given names or <code > null< / code > if no such child exists . <p > the search for the child starts at the parent s first child . the parent must not be <code > null< / code > and must be a webdav element . the names of children to search for must not be <code > null< / code > . < / p >
returns the first child of the given parent that is a webdav element with the given name or <code > null< / code > if no such child exists . <p > the search for the child starts at the parent s first child . the parent must not be <code > null< / code > and must be a dav : namespace element . the name of the child to search for must not be <code > null< / code > .
returns the data of the given parent s first text node or the empty <code > string< / code > if no such text node exists . the search for the text node starts at the parent s first child . the parent must not be <code > null< / code > .
returns the last child of the given parent that is a webdav element with the given name or <code > null< / code > if no such child exists . <p > the search starts at the parent s last child . the parent must not be <code > null< / code > and must be a dav : namespace element . the name of the child to search for must not be <code > null< / code > .
returns the given element s namespace declarations . the element must not be <code > null< / code > .
returns the given element s namespace declarations . the given namespace declarations should be the element s parent s or <code > null< / code > if the element has no parent . if removeduplicatensdeclarations is <code > true< / code > duplicate namespace declarations are removed from the element s attributes . the element must not be <code > null< / code > .
returns the next sibling element of the given element or <code > null< / code > if no such sibling exists . only the sibling s next children are searched . the element must not be <code > null< / code > .
returns the first webdav sibling of the given element that has one of the given names or <code > null< / code > if no such sibling exists . only the sibling s next children ( not the previous children ) are searched . the element must not be <code > null< / code > and must be a webdav element . the possible names of the sibling to search for must not be <code > null< / code > .
returns the next webdav sibling of the given element that has the given name or <code > null< / code > if no such sibling exists . only the sibling s next children are searched . the element must not be <code > null< / code > and must be a webdav element . the name of the sibling to search for must not be <code > null< / code > .
returns the local part of the given name or <code > null< / code > if its name has no local part . the name must not be <code > null< / code > . <table > <caption > example< / caption > <tr > <th > name< / th > <th > local name< / th > <tr > <td > d : foo< / td > <td > foo< / td > <tr > <td > foo< / td > <td > foo< / td > <tr > <td > d : < / td > <td > null< / td > <tr > <td > : foo< / td > <td > foo< / td > <tr > <td > : < / td > <td > null< / td > < / table >
returns the local part of the name of the given element or <code > null< / code > if its name has no local part . the element must not be <code > null< / code > . <table > <caption > example< / caption > <tr > <th > tag name< / th > <th > local name< / th > <tr > <td > d : foo< / td > <td > foo< / td > <tr > <td > foo< / td > <td > foo< / td > <tr > <td > d : < / td > <td > null< / td > <tr > <td > : foo< / td > <td > foo< / td > <tr > <td > : < / td > <td > null< / td > < / table >
returns the url of the given element s namespace or <code > null< / code > if it has no namespace . the element must not be <code > null< / code > .
returns the namespace prefix part of the given name or <code > null< / code > if its name has no prefix . the name must not be <code > null< / code > . <table > <caption > example< / caption > <tr > <th > name< / th > <th > namespace prefix< / th > <tr > <td > d : foo< / td > <td > d< / td > <tr > <td > foo< / td > <td > null< / td > <tr > <td > d : < / td > <td > d< / td > <tr > <td > : foo< / td > <td > null< / td > <tr > <td > : < / td > <td > null< / td > < / table >
returns the namespace prefix part of the name of the given element or <code > null< / code > if its name has no prefix . the element must not be <code > null< / code > . <table > <caption > example< / caption > <tr > <th > tag name< / th > <th > namespace prefix< / th > <tr > <td > d : foo< / td > <td > d< / td > <tr > <td > foo< / td > <td > null< / td > <tr > <td > d : < / td > <td > d< / td > <tr > <td > : foo< / td > <td > null< / td > <tr > <td > : < / td > <td > null< / td > < / table >
returns a qualified name that is formed from the given element s namespace name and namespace local name . the qualified name s qualifier is the element s namespace name and the qualified name s local name is the element s local name . the element must not be <code > null< / code > .
returns the first webdav sibling of the given element that has the given name or <code > null< / code > if no such sibling exists . if firsttolast is true only the sibling s next children are searched otherwise only the siblings previous children are searched . the element must not be <code > null< / code > and must be a webdav element . the name of the sibling to search for must not be <code > null< / code > .
returns the data of the given parent s first text node or the empty <code > string< / code > if no such text node exists . if firsttolast is true the search for the text node starts at the parent s first child otherwise the search starts at the parent s last child . the parent must not be <code > null< / code > .
returns the first webdav sibling of the given element that has the same name as the element or <code > null< / code > if no such sibling exists . if firsttolast is true only the sibling s next children are searched otherwise only the siblings previous children are searched . the element must not be <code > null< / code > and must be a webdav element .
creates a webdav element with the given name and inserts it before the given sibling . returns the new sibling . the sibling must not be <code > null< / code > and must be a webdav element . the name of the new sibling must not be <code > null< / code > .
returns a boolean indicating whether or not the given node is a webdav element . the node may be <code > null< / code > in which case <code > false< / code > is returned .
returns a boolean indicating whether or not the given node is a webdav element with the given name . the node may be <code > null< / code > in which case <code > false< / code > is returned . the name must not be <code > null< / code > .
removes redundant namespace declarations from the given node and all its children to maximum depth . the node must not be <code > null< / code > .
resolves the given namespace prefix in the namespace of the given element . if the given prefix is <code > null< / code > the default namespace is resolved . returns the url of the namespace or <code > null< / code > if the prefix could not be resolved .
<p > creates a webdav element with the given name and sets it as a child of the given parent . returns the child element . <p > children are positioned in the order specified by the given names . if a child with the same name as the child already exist the child is replaced . if firsttolast is true the search for the child s position starts at the parent s first child otherwise the search starts at the parent s last child . <p > the parent must not be <code > null< / code > and must be a webdav element . the child s name must not be <code > null< / code > . the parent s valid child names must not be <code > null< / code > and must contain the name of the child .
<p > sets the given child element as a child of the given parent . <p > children are positioned in the order specified by the given names . if a child with the same name already exists it is replaced . if firsttolast is true the search for the child s position starts at the parent s first child otherwise the search starts at the parent s last child . <p > the parent must not be <code > null< / code > and must be a webdav element . the child must not be null and its namespace prefix must resolve to the webdav namespace url in the parent . the parent s valid child names must not be <code > null< / code > and must contain the name of the child .
resets the stream to its beginning so it can be read again .
for user triggered content assistance
add an incoming or outgoing connection to this vertex .
return the property value for the given propertyid or null .
remove an incoming or outgoing connection from this vertex .
set the location of this vertex .
set the property value for the given property id .
set the size of this vertex . will not update the size if newsize is null .
constructs constraints string
replaces existing zoommanager with the new one .
$non - nls - 1$
/ * ( non - javadoc ) method declared on viewersorter .
creates a new lockentry and adds it to this supported lock . returns an editor on the new lockentry .
returns an <code > enumeration< / code > over this supportedlock s <code > lockentry< / code > s .
/ * ( non - javadoc )
add new basevertex to the graph
remove a vertex from this graph
this method is called upon plug - in activation
this method is called when the plug - in is stopped
returns the string from the plugin s resource bundle or key if not found .
returns the plugin s resource bundle
form colors default colors for now .
do nothing if date format is not supported
do nothing if date format is not supported .
$non - nls - 1$
/ * ( non - javadoc )
utility to create an error status for this plug - in .
utility method to log errors in the egit plugin .
adds the given field editor to this page .
adjust the layout of the field editors so that they are properly aligned .
applys the font to the field editors managed by this page .
calculates the number of columns needed to host all field editors .
recomputes the page s error state by calling <code > isvalid< / code > for every field editor .
/ * ( non - javadoc ) method declared on preferencepage .
the field editor preference page implementation of an <code > idialogpage< / code > method disposes of this page s controls and images . subclasses may override to release their own allocated swt resources but must call <code > super . dispose< / code > .
returns a parent composite for a field editor . <p > this value must not be cached since a new parent may be created each time this method called . thus this method must be called each time a field editor is constructed . < / p >
initializes all field editors .
the field editor preference page implementation of a <code > preferencepage< / code > method loads all the field editors with their default values .
the field editor preference page implementation of this <code > preferencepage< / code > method saves all field editors by calling <code > fieldeditor . store< / code > . note that this method does not save the preference store itself ; it just stores the values back into the preference store .
the field editor preference page implementation of this <code > ipreferencepage< / code > ( and <code > ipropertychangelistener< / code > ) method intercepts <code > is_valid< / code > events but passes other events on to its superclass .
/ * ( non - javadoc ) method declared on idialog .
{
{
fires a property change event with the given source property name old and new value . used when the event source should be different from this mockup preference store .
{
{
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
in addition to
adds zoom - related contributions .
especially when parsing incomplete rules
returns the variables defined in the given rule ( fragment ) . the key is the name of the variable . the value is a list of 2 string : - the first one is the class name of the variable - the second one is the property of the given class that defines the type of this variable note that this property could be nested if this property is null then the given class is the type of the variable
decodes the given <code > url< / code > from an <code > ascii< / code > readable <code > url< / code > that is safe for transport . returns the result .
decodes the file and reference parts of a <code > url< / code > from an <code > ascii< / code > readable <code > url< / code > that is safe for transport . returns the result .
returns the base64 encoded <code > string< / code > of the given data .
returns a new context that is based on the given context .
for the sort field
setup table listeners for gui events .
create the table
returns the value to which the given url is mapped to in the table . if the given url not mapped to any value or is malformed returns <code > null< / code > .
returns the value to which the given <code > url< / code > is mapped to in the table . if the given <code > url< / code > not mapped to any value returns <code > null< / code > .
returns the value to which the specified url is mapped to in the table . if the specified url is not mapped to any value returns <code > null< / code > .
returns an <code > enumeration< / code > over the keys in this <code > urltable< / code > .
maps the given url to the given value in this table .
maps the given <code > url< / code > to the given value in this table .
maps the specified url to the given value in this table .
the method will create a new node instance and try to add it as a child node . if an node with the same string token exists the method will return the existing node instead .
the method will check to see if a node with the same string token already exists . if it doesn t it will add the token as a child and return the same node .
be used directly . use droolsmodelbuilder instead .
/ * ( non - javadoc )
add a condition to this precondition . conditions are or d together to check for a matching resource .
add a condition created from the given uri and state token . this is a convenience method used primarily to create preconditions for lock tokens that must be provided in the resource context for methods that update the resource .
see if this precondition contains a matching condition .
asserts that the given object is not <code > null< / code > . if this is not the case some kind of unchecked exception is thrown . the given message is included in that exception to aid debugging .
asserts that the given boolean is <code > true< / code > . if this is not the case some kind of unchecked exception is thrown . the given message is included in that exception to aid debugging .
returns this propstat s prop .
returns this propstat s status .
creates and sets a new prop on this propstat and returns an editor on it .
sets the status on this propstat to the given status . the status must not be <code > null< / code > .
because of how the backtext works we need to get the last line so that we can pass it to the dslutility
returns the last line that doesn t start with a dash
the dsltree is configurable . it can either return just the child of the last token found or it can traverse the tree and generate all the combinations beneath the last matching node . todo i don t know how to add configuration to the editor so it needs to be hooked up to the configuration for the editor later .
lookup the message with the given id in this catalog and bind its substitution locations with the given string .
lookup the message with the given id in this catalog and bind its substitution locations with the given strings .
lookup the message with the given id in this catalog and bind its substitution locations with the given string values .
encodes the given file and reference parts of a <code > url< / code > into an <code > ascii< / code > readable <code > string< / code > that is safe for transport . returns the result .
encodes the given <code > url< / code > into an <code > ascii< / code > readable <code > url< / code > that is safe for transport . returns the result .
/ * ( non - javadoc )
create the sample process file .
create the sample process junit test file .
/ * ( non - javadoc )
return the version number of the kie workbench that is installed on the given server . if the server is not running or not responsive use a value from the preference store .
/ * ( non - javadoc )
/ * ( non - javadoc )
<p > finds the index of the given object in the array starting at the given index . < / p >
/ * ( non - javadoc )
/ * ( non - javadoc )
rete visits each of its objecttypenodes .
helper method to ensure nodes are not visited more than once .
the identity hashcode for the given object is used as its unique dot identifier .
adds a remove to the given propertyupdate and returns an editor on its prop .
adds a set to the given propertyupdate and returns an editor on its prop .
returns an <code > enumeration< / code > over this propertyupdate s set and remove property elements .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
answer a new resource locator that identifies a particular server resource by it s url and label .
define reconciler - this has to be done for each partition . currently there are 3 partitions inside rule outside rule and inside comment .
get the appropriate content assistance for each partition .
answers whether the receiver and the argument are considered identical . to be identical the receiver and the argument must have the same status code message and extended status information .
does this condition contain the given conditionterm?
create a condition by parsing the given if header as defined by section 9 . 4 in the webdav spec .
create a condition by parsing the given if header as defined by section 9 . 4 in the webdav spec .
creates a clone of the given element and adds it to this prop . the element must not be <code > null< / code > .
creates a new element with the given name and adds it to this prop . the name must not be <code > null< / code > and its qualifier and local name must not be <code > null< / code > and must not be the empty string .
returns an <code > enumeration< / code > over this prop s property <code > element< / code > s .
returns an <code > enumeration< / code > over this prop s property <code > qualifiedname< / code > s .
create a statetoken by parsing the given if header as defined by section 9 . 4 in the webdav spec .
adds text editor for rules and rete graph viewer
/ * ( non - javadoc )
send an http delete request to the kie console .
send an http post request to the kie console .
sends a job status request to the kie server .
}
/ * ( non - javadoc )
replaces existing zoommanager with the new one .
creates a new webdav update element and sets it as the root of the given document . returns an editor on the new element . <p > the document must not be <code > null< / code > and must not already have a root element . < / p >
creates a new webdav update element and sets it as the root of the given document . returns an editor on the new element . <p > the document must not be <code > null< / code > and must not already have a root element . < / p >
returns this response s first dav : version child element .
sets the dav : label child element .
sets the dav : version child element .
starts this operation synchronously .
post - process the pull results allowing the user to deal with uncommitted changes and re - pull if the initial pull failed because of these changes
replaces the element at the specified position in this array with the json representation of the specified string .
creates and adds a new activelock on this lockdiscovery and returns an editor on it .
returns an <code > enumeration< / code > over this lockdiscovery s <code > activelock< / code > s .
filter out the proposals whose content does not start with the given prefix .
read some text from behind the cursor position . this provides context to both filter what is shown based on what the user has typed in and also to provide more information for the list of suggestions based on context .
calculates layouting for provided graph .
painting antialiased vertex
/ * ( non - javadoc )
maps object to editpart .
returns an image descriptor for the image file at the given plug - in relative path . uses the plug ins image registry to cache it .
declare an image in the registry table .
returns the digest authorization credentials for the given directives . the credentials have the following form : <code > credentials = digest digest - response digest - response = 1# ( username | realm | nonce | digest - uri | response | [ algorithm ] | [ cnonce ] | [ opaque ] | [ message - qop ] | [ nonce - count ] | [ auth - param ] ) username = username = username - value username - value = quoted - string realm = realm = realm - value realm - value = quoted - string nonce = nonce = nonce - value nonce - value = quoted - string digest - uri = uri = digest - uri - value digest - uri - value = request - uri ; as specified by http / 1 . 1 response = response = request - digest request - digest = &lt ; &gt ; 32lhex &lt ; &gt ; lhex = 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | a | b | c | d | e | f algorithm = algorithm = ( md5 | md5 - sess | token ) cnonce = cnonce = cnonce - value cnonce - value = nonce - value opaque = opaque = quoted - string message - qop = qop = qop - value nonce - count = nc = nc - value nc - value = 8lhex < / code > <p > if the qop value is auth or auth - int : <code > request - digest = &lt ; &gt ; &lt ; kd ( h ( a1 ) unq ( nonce - value ) : nc - value : unq ( cnonce - value ) : unq ( qop - value ) : h ( a2 ) ) &lt ; &gt ; kd ( secret data ) = h ( concat ( secret : data )) h ( data ) = md5 ( data ) unq ( data ) = unqouted ( data ) < / code > <p > if the qop directive is not present : <code > request - digest = &lt ; &gt ; &lt ; kd ( h ( a1 ) unq ( nonce - value ) : h ( a2 ) ) &lt ; &gt ; < / code > <p > if the algorithm directive s value is md5 or is unspecified then a1 is : <code > a1 = unq ( username - value ) : unq ( realm - value ) : passwd passwd = &lt ; user s password &gt ; < / code > <p > if the algorithm directive s value is md5 - sess then a1 is : <code > a1 = h ( unq ( username - value ) : unq ( realm - value ) : passwd ) : unq ( nonce - value ) : unq ( cnonce - value ) < / code > <p > if the qop directive s value is auth or is unspecified then a2 is : <code > a2 = method : digest - uri - value < / code > <p > if the qop value is auth - int then a2 is : <code > a2 = method : digest - uri - value : h ( entity - body ) < / code >
adds new vertex to specified depth
finds specified vertex from the rows .
finds the longest row width .
dumps all row vertices to system . err
optimizes all rows for optimal presentation
todo : search the native way to find the sourcefield ifile
/ * ( non - javadoc )
/ * ( non - javadoc )
loads model from rule base calculates rete view and initializes diagram model .
loads rete model and initializes zoom manager .
moves all <code > diagram< / code > nodes to upper left corner and shifting to right if neccessary to get rid of negative xy coordinates .
draws graph .
tries to find a match for the provided breakpoint information from the list of registered breakpoints . for stepping and possibly other purposes it returns also a breakpoint for cases where exactly the same line was not found .
/ * ( non - javadoc )
/ * ( non - javadoc )
pass in a nlmapping item for display / edits . changes will be applied to this object only if the user clicks ok .
sets this baseline control elment description to the given href .
return a boolean value indicating whether or not the server for this resource is dav compliant .
helper method to close a response from the server . <p > note that the argument may be <code > null< / code > in which case the call has no effect . < / p >
make a copy of this resource and place it at the location defined by the given locator . <p > uses default values of depth : infinity and overwrite : false for the copy . < / p >
make a copy of this resource and place it at the location specified by the given destination locator .
if the given response contains a multistatus body the bodies status are checked for errors . if an error is found an exception is thrown .
helper method to extract the property status response from a multi status reponse and populate a urltable with the results .
return the content of this resource as an input stream . the input stream should be closed by the user .
return an enumeration over activelocks which lists the locks currently held on this resource . return an empty enumeration if the lock discovery property is not found on the resource .
returns a collection handle for the parent of this resource . <p > note that this method does not perform a method call to the server to ensure that the collection exists . < / p > <p > returns <code > null< / code > if this resource is the root .
fetches and returns the specified properties for this resource and its children to the given depth . the returned table is a urltable of hashtables . the keys in the first table are the <code > url< / code > s of the resources . the nested table is a table where the keys are the names ( <code > qualifiedname< / code > ) of the properties and the values are the properties values ( <code > propertystatus< / code > ) .
return the property status for the property with the given name .
fetch and return the property names for the resource and the children resources to the specified depth . returns <code > urltable< / code > mapping resource urls to enumerations over the property names for that resource .
retrieve the version tree infomration for the receiver assuming that the receiver is a version or a version - controlled resource . <p > the version tree info comprises a <code > urltable< / code > whose keys are the <code > url< / code > s of each version in the version history and whose values are <code > vector< / code > s of the resource s immediate predecessor <code > url< / code > s . note that the root version is ( uniquely ) identified by an empty set of predecessors . < / p >
return the header from a message send to the server .
lock this resource using the specified parameters .
move this resource to the location specified by the given locator . if a resource already exists at the destination and the overwrite boolean is true then write over top of the existing resource . otherwise do not . the enumeration is over qualified names which are the names of the properties to move .
check in the receiver and answer a new locator on the resulting version resource .
check out the receiver and answer a new locator on the resulting checked out resource . the result may be the same as the receiver s locator if the server did not create a new resource as a consequence of the check out ( i . e . if it was checking out a vesion - controlled resource rather than a version ) .
refresh the lock on this resource with the given lock token . use the specified timeout value .
remove the properties with the given names from this resource .
remove the property with the given name from this resource .
set the content of this resource to be the data stored in the given input stream . the type encoding is given in the content type argument and should be in the media format described by rfc2616 sec 3 . 7 . the stream will automatically be closed after the data is consumed . if the resource does not exist it is created with the given content .
set the given properties on this resource .
set the given property on this resource .
unlock this resource with the given lock token .
perform an update on the receiver to set the version it is based upon .
bring the receiver under version control . this means that the receiver is replaced by a version - controlled resource . note that the client may send version control to a resource that is already under version control with no adverse effects .
delete this resource from the repository optionally succeeding in the delete if the resource was not found on the server .
check the given status code and throw a webdav exception if the code indicates failure . if the code is success this method does nothing .
return a boolean value indicating whether or not this resource exists on the server . <p > this implementation uses the http head method so the url may or may not exist in the dav namespace . the dav resource_type property is not checked . < / p >
check to see if the resource is a working resource . <p > the resource is a working resource if it has &lt ; dav : checked - out&gt ; and does not have &lt ; dav : auto - checkout&gt ; in the &lt ; dav : supported - live - properties - set&gt ; . < / p >
this is a helper method to check to see if the resource has a property with the given name that in turn has a child with a given name .
adds the specified binding to this editor s bindings element . the given href and segment must not be <code > null< / code > .
returns an <code > enumeration< / code > over this bindings <code > binding< / code > s .
answer a dom <code > element< / code > that represents a set of <code > string< / code > . <p > the set is represented by a single <code > element< / code > whose name is given as the <code > setname< / code > argument . each member of the set is a child <code > element< / code > named <code > membername< / code > that has text taken from the <code > memberenum< / code > an <code > enumeration< / code > of <code > string< / code > .
/ * ( non - javadoc )
/ * ( non - javadoc )
returns the content length of this message s body or - 1 if the content length is unknown .
writes this request s body to the given output stream . this method may be called more than once during the lifetime of this request .
converts the given byte array to its equivalent hexadecimal string and returns the result .
converts the given int array to its equivalent hexadecimal string and returns the result .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
creates a new webdav propfind element and sets it as the root of the given document . returns an editor on the new propfind element . the document must not be <code > null< / code > and must not already have a root element .
returns <code > true< / code > iff this propfind is in the all prop form .
sets whether this propfind is in the all prop form .
sets whether this propfind is in the prop name form .
creates and sets a new prop on this propfind and returns an editor on it . this propfind must not already be in the all prop or prop name form .
looks behind gets stuff after the white space . basically ripping out the last word .
attempt to enhance a consequence backtext such that it should compile in mvel @param backtext @return a substring of the back text that should be compilable without syntax errors by the mvel compiler
/ * propertyname extraction and bean convention methods names checks
given a data depicting a method ( name # or params / args returned type key ) tries to return a bean property name derived from that method . if a bean property name is not found the initial method name is returned
given a data depicting a method ( name # or params / args returned type key ) tries to return a writable bean property name derived from that method . if a writable ( ie setter ) bean property name is not found the initial method name is returned
determine if the given method is a bean accessor ( ie getter / setter )
compensates for lack of getsimplename in java . lang . class borrowed and adpated from mvel s org . mvel . util . parsetools . getsimpleclassname ( class )
updates the outline page .
returns the content length of this message s body or - 1 if the content length is unknown .
writes this messages body to the given output stream . this method may only be called once during the lifetime of this message .
i don t see the need for any of this custom stepover stuff why is it here?
this will create markers for parse errors . parse errors mean that antlr has picked up some major typos in the input source .
this will create markers for build errors that happen after parsing .
skips the next character in s if it matches c otherwise a <code > parserexception< / code > is thrown .
returns the next quoted string is s ( quotes included ) . throws a <code > parserexception< / code > if the next substring in s is not a quoted string .
returns the next token in s . throws a <code > parserexception< / code > if the next substring in s is not a token .
skips the next sequence of white space in s . an exception is not thrown if there is no matching white space .
finds the local guvnor metadata file associated with a given resource .
adds a resource to guvnor .
commits changes to guvnor .
finds the local guvnor metadata file associated with a given resource .
copy all the default values into the receiver .
return the value for the given key .
get the sender s estimate of the time since the response was generated . return the int value for the age key . return - 1 if the value is not set .
get the content length in bytes of the entity body . return the value for the content_length key . returns - 1 if the content - length has not been set .
return the integer value for the max_forwards key .
get the flag that indicates if copy or move should overwrite an existing destination . return the boolean value for the overwrite key .
return the boolean value for the passthrough key .
get the lock timeout value . the value - 1 means that the value was not set the value - 2 means that the value was infinity . return the integer value for the timeout key .
return an enumeration over the context s keys . ( recursively computes the keys based on keys defaults as well )
put the given key - value pair into the context .
set the lock timeout value in seconds . pass - 1 to clear the value pass - 2 to set infinity . set the integer value for the timeout key .
method will create a bufferedreader to read the file .
method will use the bufferedreader to read the contents of the file . it calls other methods to parse the line and build the tree .
method will strip out the when then * at the beginning of each line and the mapped drl expression
method will return just the object metadata
method will strip the metadata from the text string
the method is different than addtokens ( stringtokenizer ) . this method expects additional metadata . it expects to get an object name or * meaning all . if the metadata is a wildcard all it will add the tokens to all the top level nodes that are immediate child of root .
method adds the token to root
the method will tokenize the text and try to find the node that matches and return the children . the method will traverse down the network as far as it can and return the children at that level .
the method expects the caller to pass the object
for convienance the method will return a list of strings that are children of the last node found . if the editor wants to generate the children strings call the method with true
for convienance the method will return a list of strings that are children of the last node found . if the editor wants to generate the children strings call the method with true
method will prepend the parent text to the child and generate the possible combinations in text format .
the method will print the dsltree to system . out in text format .
method will print the node and then iterate over the children
method will print n number of tabs
reads a json value from the given string .
returns a jsonvalue instance that represents the given <code > float< / code > value .
/ * ( non - javadoc )
creates a directory listing .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
returns an image descriptor for the image file at the given plug - in relative path
adds the given proxy server exception pattern to this client . origin servers whose hostname match the pattern do not communicate through the defualt proxy server . the pattern must contain zero or one stars ( * ) . a star must appear at either the beginning or the end of the pattern . a star matches zero or more characters . the following are valid patterns : <ul > <li > www . company . com : 80< / li > <li > * . company . com< / li > <li > www . company . * < / li > < / ul >
returns the context for the origin server at the given <code > url< / code > .
returns an <code > enumeration< / code > over the origin server <code > url< / code > s known to this client . the known origin server <code > url< / code > s are gleaned from this client s mapped contexts and mapped proxy server <code > url< / code > s .
returns the <code > url< / code > of the proxy server that the origin server at the given <code > url< / code > uses or <code > null< / code > if no proxy server is used .
sends the given request to the server and returns the server s response .
set the context for the origin server at the given <code > url< / code > . if the given context is <code > null< / code > the context for the specified origin server is removed .
sets the <code > url< / code > of the proxy server that this client uses to communicate with the origin server at the given <code > url< / code > . if the proxy server <code > url< / code > is <code > null< / code > the default proxy server is used if the specified origin server does not match a proxy server exception pattern .
returns this connection s <code > inputstream< / code > .
returns this connection s <code > outputstream< / code > .
returns the request header value associated with the given field name or <code > null< / code > if there is no such field name .
returns the response header field name at the given position or <code > null< / code > if there is no field name at that position .
returns the response header field value at the given position or <code > null< / code > if there is no value at that position .
returns the response header field value that is associated with the given field name or <code > null< / code > if there is no value associated with that field name .
sets the <code > url< / code > of the proxy server this connection uses to communicate with the origin server . if <code > null< / code > is given no proxy server is used .
sets the request header value associated with the given field .
sets the <code > url< / code > of this connection s resource .
sets the factory this connection uses to create sockets . if the given socket factory is <code > null< / code > the default socket is used .
create the sample rule launcher file .
create the sample rule file .
create the sample ruleflow file .
create the sample ruleflow launcher file .
/ * ( non - javadoc )
returns only the installable units that are features ignoring feature groups .
/ * ( non - javadoc )
writes the content of this editor to the given stream . possible formats are for example swt . image_bmp image_gif image_jpeg image_png .
copy all the default values into the receiver .
return the value for the given key .
return an enumeration over the context s keys . ( recursively computes the keys based on keys defaults as well )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
constraint has field extractor and this method is returning fieldname it .
constraint s evaluator string
constraint field string
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
adds guvnor - specific resource properties to the collection .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
create a new version - controlled configuration on the given baseline .
binds the given member in this collection to the resource identified by the given source locator . if the member already exists or is already bound to a resource it is not replaced .
binds the given member in this collection to the resource identified by the given source locator . if overwrite is <code > false< / code > and such a member already exists or such a member is already bound to a resource it is not replaced . otherwise if overwrite is <code > true< / code > and such a member already exists or such a member is already bound to a resource it is replaced .
return the locator of the member of this collection with the given name . does not perform a call to the server to check the existence of the member .
return a set of handles representing the members of this collection . <p > each member of the set will be typed to be a <code > resourcehandle< / code > or a <code > collectionhandle< / code > depending upon whether it implements collection semantics . note that workspaces will be returned as regular collection handles and should be converted to workspace handles if required ( test using isworkspace () ) . < / p >
optimizing vertices for optimal presentation
authorizes the given request by setting its authorization credentials in the given context . if the given response is not <code > null< / code > it is assumed to contain an authenticate challenge that is used to derive the authorization credentials . returns true if the authorization succeeds and false otherwise .
confirms whether the given response is valid by proving the server knows the client s authentication secret ( password ) . moreover the server may wish to communicate some authentication information in the response for the purposes of authorizing future request .
confirms whether the given response is valid by proving the server knows the client s authentication secret ( password ) . moreover the server may wish to communicate some authentication information in the response for the purposes of authorizing future request . <p > this method should be overridden by schema specific authenticators .
returns the new authentication information gleaned from the given authenticate challenge and the given old authentication information . the old authentication information may be <code > null< / code > . the authentication information usually contains directives such as usernames and passwords . <p > this method should be overridden by schema specific authenticators .
returns the authorization credentials for the given request . the authorization credentials are derived from the given authentication info . the authentication info may contain directives such as usernames and passwords . <p > this method should be overridden by schema specific authenticators .
returns an authorization authority for the given authentication scheme or <code > null< / code > if there is no such authority .
computes the md5 hash value of the given <code > string< / code > and returns the result as a hex <code > string< / code > .
computes the md5 hash value of the body of the given request and returns the result as a hex <code > string< / code > .
returns the given <code > string< / code > with its quotes removed .
create a conditionfactor ( either a statetoken or entitytag ) by parsing the tokenizer contining an if header value .
repository
initializes the controls of this dialog .
/ * ( non - javadoc ) method declared on dialog .
returns whether this page s visual components all contain valid values .
/ * ( non - javadoc ) @see org . eclipse . jface . window . dialog#getdialogboundssettings ()
create an entitytag by parsing the given if header as defined by section 3 . 11 of the http / 1 . 1 spec .
construct a unique entitytag . the tag is constructed by concatening the current time with the current thread s hash code .
create a new workspace in the location described by this handle . <p > a new workspace is created using a mkworkspace method call . < / p >
gets opposite of specified vertex .
ecc
eccpkcs8
pkcs8
eccsec1 openssl d2i_ecprivatekeydersec1 opensslecc . rsapkcs1eccsec1
sec1pkcs8
sec1bcecprivatekey
sec1ecprivatekeyparameters openssl i2d_ecprivatekeydereccsec1ec_group javaopensslecc
eccx509
x509
copy from bc
copy from bc

xy64
ecc
ecc
sums two {
releases any internal resources . it is responsibility of the caller to close {
initializes {
executes a bulk import in the azure cosmos db database service . <blockquote > <pre > { @code connectionpolicy connectionpolicy = new connectionpolicy () ; retryoptions retryoptions = new retryoptions () ; // set to 0 to let bulk importer handles throttling retryoptions . setmaxretryattemptsonthrottledrequests ( 0 ) ; connectionpolicy . setretryoptions ( retryoptions ) ; connectionpolicy . setmaxpoolsize ( 200 ) ;
extracts effective {
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
try to validate all the otps provided .
after validation of an otp check that it came from a yubikey that actually belongs to the user trying to authenticate .
get username and token ( s ) from the application using the javax . security . auth . callback . callbackhandler passed to our initialize () function .
{
{
given publicid vvcccccfhc scans filename for a line like yk . vvcccccfhc . user = alice and returns alice if found . null is returned in case there is no matching line in file .
stores an association between username and yubikey publicid in filename .
{
{
{
/ * ( non - javadoc )
/ * ( non - javadoc )
access protectedurl using username and otp for basic auth . check if what we get back contains expectedoutput .
tries to clear all the passwords from memory .
fires off a validation request to each url in the list returning the first one that is not { @link responsestatus#replayed_request }
configure what urls to use for validating otps . these urls will have all the necessary parameters appended to them . example : { https : // api . yubico . com / wsapi / 2 . 0 / verify }
extract the public id of a yubikey from an otp it generated .
determines whether a given otp is of the correct length and only contains printable characters as per the recommendation .
returns an evaluation that contains the node source and whether it is a set operation . if there are no evaluation objects in the pool one is created and returned .
returns an evaluation that contains the node source and whether it is a set operation .
returns true if this property is described by an indexedpropertydescriptor and that if followed by an index specifier it will call the index get / set methods rather than go through property accessors .
/ * methodaccessor interface
clears all of the cached reflection information normally used to improve the speed of expressions that operate on the same classes or are executed multiple times .
checks if the current jvm is java language > = 1 . 5 compatible .
gets the target class of an object for looking up accessors that are registered on the target . if the object is a class object this will return the class itself else it will return object s getclass () result .
returns the base name ( the class name without the package name prepended ) of the object given .
returns the base name ( the class name without the package name prepended ) of the class given .
returns the package name of the object s class .
returns the package name of the class given .
returns a pointer string in the usual format for these things - 0x<hex digits > .
returns a pointer string in the usual format for these things - 0x<hex digits > for the object given . this will always return a unique value for each object .
returns a unique descriptor string that includes the object s class and a unique integer identifier . if fullyqualified is true then the class name will be fully qualified to include the package name else it will be just the class base name .
utility to convert a list into an object [] array . if the list is zero elements this will return a constant array ; toarray () on list always returns a new object and this is wasteful for our purposes .
returns the parameter types of the given method .
finds the appropriate parameter types for the given { @link method } and { @link class } instance of the type the method is associated with . correctly finds generic types if running in > = 1 . 5 jre as well .
returns the parameter types of the given method .
permission will be named invoke . <declaring - class > . <method - name > .
gets the class for a method argument that is appropriate for looking up methods by reflection by looking for the standard primitive wrapper classes and exchanging for them their underlying primitive class objects . other classes are passed through unchanged .
tells whether the given object is compatible with the given class --- that is whether the given object can be passed as an argument to a method or constructor whose parameter type is the given class . if object is null this will return true because null is compatible with any type .
tells whether the first array of classes is more specific than the second . assumes that the two arrays are of the same length .
gets the appropriate method to be called for the given target method name and arguments . if successful this method will return the method within the target that can be called and the converted arguments in actualargs . if unsuccessful this method will return null and the actualargs will be empty .
invokes the specified method against the target object .
invokes the specified method against the target object .
if the checkaccessandexistence flag is true this method will check to see if the method exists and if it is accessible according to the context s memberaccess . if neither test passes this will return notfound .
don t use this method as it doesn t check member access rights via {
this method returns the property descriptors for the given class as a map .
this method returns a propertydescriptor for the given class and property name using a map lookup ( using getpropertydescriptorsmap () ) .
gets the property descriptor with the given name for the target class given .
determines the index property type if any . returns <code > indexed_property_none< / code > if the property is not index - accessible as determined by ognl or javabeans . if it is indexable then this will return whether it is a javabeans indexed property conforming to the indexed property patterns ( returns <code > indexed_property_int< / code > ) or if it conforms to the ognl arbitrary object indexable ( returns <code > indexed_property_object< / code > ) .
registers the specified { @link classcacheinspector } with all class reflection based internal caches . this may have a significant performance impact so be careful using this in production scenarios .
finds the best possible match for a method on the specified target class with a matching name .
compares the { @link ognlcontext#getcurrenttype () } and { @link ognlcontext#getprevioustype () } class types on the stack to determine if a numeric expression should force object conversion . <p / > <p / > normally used in conjunction with the <code > forceconversion< / code > parameter of { @link ognlruntime#getchildsource ( ognlcontext object node boolean ) } . < / p >
attempts to get the java source string represented by the specific child expression via the { @link javasource#togetsourcestring ( ognlcontext object ) } interface method .
attempts to get the java source string represented by the specific child expression via the { @link javasource#togetsourcestring ( ognlcontext object ) } interface method .
prints the stack trace for this ( and possibly the encapsulated ) exception on the given print stream .
prints the stack trace for this ( and possibly the encapsulated ) exception on the given print writer .
/ * nullhandler interface
read a character .
sequence ( level 14 )
assignment expression ( level 13 )
logical or ( || ) ( level 11 )
logical and ( && ) ( level 10 )
bitwise or non - short - circuiting or ( | ) ( level 9 )
exclusive or ( ^ ) ( level 8 )
bitwise or non - short - circuiting and ( & ) ( level 7 )
equality / inequality ( == / ! = ) ( level 6 )
boolean relational expressions ( level 5 )
bit shift expressions ( level 4 )
binary addition / subtraction ( level 3 )
multiplication / division / remainder ( level 2 )
unary ( level 1 )
navigation chain : property references method calls projections selections etc .
apply an expression to all elements of a collection creating a new collection as the result .
apply a boolean expression to all elements of a collection creating a new collection containing those elements for which the expression returned true .
apply a boolean expression to all elements of a collection creating a new collection containing those elements for the first element for which the expression returned true .
apply a boolean expression to all elements of a collection creating a new collection containing those elements for the first element for which the expression returned true .
compares two objects for equality even if it has to convert one of them to the other type . if both objects are numeric they are converted to the widest type and compared . if one is non - numeric and one is numeric the non - numeric is converted to double and compared to the double numeric value . if both are non - numeric and comparable and the types are compatible ( i . e . v1 is of the same or superclass of v2 s type ) they are compared with comparable . compareto () . if both values are non - numeric and not comparable or of incompatible classes this will throw and illegalargumentexception .
returns true if object1 is equal to object2 in either the sense that they are the same object or if both are non - null if they are equal in the <code > equals () < / code > sense .
evaluates the given object as a boolean : if it is a boolean object it s easy ; if it s a number or a character returns true for non - zero objects ; and otherwise returns true for non - null objects .
evaluates the given object as a long integer .
evaluates the given object as a double - precision floating - point number .
evaluates the given object as a biginteger .
evaluates the given object as a bigdecimal .
evaluates the given object as a string and trims it if the trim flag is true .
returns a constant from the numerictypes interface that represents the numeric type of the given object .
//////////////////////////////////////////////////////////////
///////////////////////////////////////////////////////////////
returns the value converted numerically to the given class type this method also detects when arrays are being converted and converts the components of one array to the type of the other .
converts the specified value to a primitive integer value .
returns the constant from the numerictypes interface that best expresses the type of an operation which can be either numeric or not on the two given types .
returns the constant from the numerictypes interface that best expresses the type of an operation which can be either numeric or not on the two given objects .
returns a new number object of an appropriate type to hold the given integer value . the type of the returned object is consistent with the given type argument which is a constant from the numerictypes interface .
returns a new number object of an appropriate type to hold the given real value . the type of the returned object is always either float or double and is only float if the given type tag ( a constant from the numerictypes interface ) is float .
utility method that converts incoming exceptions to { @link runtimeexception } instances - or casts them if they already are .
/ * =================================================================== overridden methods ===================================================================
gets the current class type being evaluated on the stack as set by { @link #setcurrenttype ( class ) } .
represents the last known object type on the evaluation stack will be the value of the last known { @link #getcurrenttype () } .
returns the evaluation at the relative index given . this should be zero or a negative number as a relative reference back up the evaluation stack . therefore getevaluation ( 0 ) returns the current evaluation .
pushes a new evaluation onto the stack . this is done before a node evaluates . when evaluation is complete it should be popped from the stack via <code > popevaluation () < / code > .
pops the current evaluation off of the top of the stack . this is done after a node has completed its evaluation .
used by { @link #castexpression ( ognl . ognlcontext ognl . node string ) } to store the cast java source string in to the current { @link ognlcontext } . this will either add to the existing string present if it already exists or create a new instance and store it using the static key of { @link #pre_cast } .
returns the appropriate casting expression ( minus parens ) for the specified class type .
convenience method called by many different property / method resolving ast types to get a root expression resolving string for the given node . the callers are mostly ignorant and rely on this method to properly determine if the expression should be cast at all and take the appropriate actions if it should .
used by { @link #getrootexpression ( ognl . node object ognl . ognlcontext ) } to determine if the expression needs to be cast at all .
helper utility method used by compiler to help resolve class - > method mappings during method calls to { @link ognlexpressioncompiler#getsuperorinterfaceclass ( java . lang . reflect . method class ) } .
/ * ( non - javadoc )
fail safe getter creation when normal compilation fails .
fail safe setter creation when normal compilation fails .
creates a { @link classloader } instance compatible with the javassist classloader and normal ognl class resolving semantics .
gets either a new or existing { @link classpool } for use in compiling javassist classes . a new class path object is inserted in to the returned { @link classpool } using the passed in <code > loader< / code > instance if a new pool needs to be created .
/ * returns the node on the top of the stack and remove it from the stack .
/ * override this method if you want to customize how the node dumps out its children .
this method may be called from subclasses jjtclose methods . it flattens the tree under this node by eliminating any children that are of the same class as this node and copying their children to this node .
returns ognlruntime . notfound if the property does not exist .
returns ognlruntime . notfound if the property does not exist .
adds a child to the list of children of this evaluation . the parent of the child is set to the receiver and the children references are modified in the receiver to reflect the new child . the lastchild of the receiver is set to the child and the firstchild is set also if child is the first ( or only ) child .
reinitializes this evaluation to the parameters specified .
/ * =================================================================== overridden methods ===================================================================
/ * =================================================================== protected methods ===================================================================
converts an escape sequence into a character value .
parses the given ognl expression and returns a tree representation of the expression that can be used by <code > ognl< / code > static methods .
parses and compiles the given expression using the { @link ognl . enhance . ognlexpressioncompiler } returned from { @link ognl . ognlruntime#getcompiler () } .
creates and returns a new standard naming context for evaluating an ognl expression .
creates and returns a new standard naming context for evaluating an ognl expression .
creates and returns a new standard naming context for evaluating an ognl expression .
creates and returns a new standard naming context for evaluating an ognl expression .
appends the standard naming context for evaluating an ognl expression into the context given so that cached maps can be used as a context .
appends the standard naming context for evaluating an ognl expression into the context given so that cached maps can be used as a context .
appends the standard naming context for evaluating an ognl expression into the context given so that cached maps can be used as a context .
gets the currently configured { @link typeconverter } for the given context - if any .
sets the root object to use for all expressions in the given context - doesn t necessarily replace root object instances explicitly passed in to other expression resolving methods on this class .
evaluates the given ognl expression tree to extract a value from the given root object . the default context is set for the given context and root via <code > adddefaultcontext () < / code > .
evaluates the given ognl expression tree to extract a value from the given root object . the default context is set for the given context and root via <code > adddefaultcontext () < / code > .
gets the value represented by the given pre - compiled expression on the specified root object .
gets the value represented by the given pre - compiled expression on the specified root object .
evaluates the given ognl expression to extract a value from the given root object in a given context
evaluates the given ognl expression tree to extract a value from the given root object .
evaluates the given ognl expression tree to extract a value from the given root object .
convenience method that combines calls to <code > parseexpression < / code > and <code > getvalue< / code > .
convenience method that combines calls to <code > parseexpression < / code > and <code > getvalue< / code > .
evaluates the given ognl expression tree to insert a value into the object graph rooted at the given root object . the default context is set for the given context and root via <code > adddefaultcontext () < / code > .
sets the value given using the pre - compiled expression on the specified root object .
evaluates the given ognl expression tree to insert a value into the object graph rooted at the given root object .
convenience method that combines calls to <code > parseexpression < / code > and <code > setvalue< / code > .
checks if the specified { @link node } instance represents a constant expression .
checks if the specified expression represents a constant expression .
returns default watch service identifier based on operating system .
starttimeout in milliseconds
{
performs mapping from the position in generated source file to the position in { @code routes } file it was generated from . <br > <br > returns : <ul > <li > position in { @code routes } file< / li > <li > { @code null } value if file of the input position is not recognized as generated from { @code routes } file< / li > < / ul >
copied from abstractplay2sourcepositionmapper . java
contrary to its name this doesn t necessarily reload the app . it is invoked on every request and will only trigger a reload of the app if something has changed .
called from less script must be public
called from less script must be public
process all the comma delimited list of packages . <p > package names are effectively converted into a directory on the file system and the class files are found and processed . < / p >
returns preconfigured archiver
check for potential duplicate file exception before archive processing starts
private utility methods
reads the content of the file to a string .
=== test ===================================================================================
{
{
creates and configures ant project for java task .
adds string type system property to ant java task .
adds file type system property to ant java task .
{
{
performs mapping from the position in generated source file to the position in twirl template file it was generated from . <br > <br > returns : <ul > <li > position in twirl template file< / li > <li > { @code null } value if file of the input position is not recognized as generated from twirl template file< / li > < / ul >
}
increment the counter in the current bucket by one for the given { @link numerusrollingnumberevent } type . <p > the { @link numerusrollingnumberevent } must be a counter type <code > hystrixrollingnumberevent . iscounter () == true< / code > .
get the sum of all buckets in the rolling counter for the given { @link numerusrollingnumberevent } type . <p > the { @link numerusrollingnumberevent } must be a counter type <code > hystrixrollingnumberevent . iscounter () == true< / code > .
get an array of values for all buckets in the rolling counter for the given { @link numerusrollingnumberevent } type . <p > index 0 is the oldest bucket . <p > the { @link numerusrollingnumberevent } must be a counter type <code > hystrixrollingnumberevent . iscounter () == true< / code > .
get the max value of values in all buckets for the given { @link numerusrollingnumberevent } type . <p > the { @link numerusrollingnumberevent } must be a max updater type <code > hystrixrollingnumberevent . ismaxupdater () == true< / code > .
/ * package for testing
add value ( or values ) to current bucket .
returns the current maximum . the returned value is <em > not< / em > an atomic snapshot : invocation in the absence of concurrent updates returns an accurate result but concurrent updates that occur while the value is being calculated might not be incorporated .
/ * package
to create the config make use of the provided { @link directorychooserconfig#builder () } .
shows a confirmation dialog that asks the user if he wants to create a new folder . user can modify provided name if it was not disallowed .
change the directory that is currently being displayed .
changes the state of the buttons depending on the currently selected file or folder .
sets up a fileobserver to watch the current directory .
returns the selected folder as a result to the activity the fragment s attached to . the selected folder can also be null .
creates a new folder in the current directory with the name create_directory_name .
returns true if the selected file or directory would be valid selection .
called when the activity is first created .
returns true if the specified <code > string< / code > parses as a valid domain name with a recognized top - level domain . the parsing is case - insensitive .
returns true if the specified <code > string< / code > matches any iana - defined infrastructure top - level domain . leading dots are ignored if present . the search is case - insensitive .
returns true if the specified <code > string< / code > matches any iana - defined generic top - level domain . leading dots are ignored if present . the search is case - insensitive .
returns true if the specified <code > string< / code > matches any iana - defined country code top - level domain . leading dots are ignored if present . the search is case - insensitive .
returns true if the specified <code > string< / code > matches any widely used local domains ( localhost or localdomain ) . leading dots are ignored if present . the search is case - insensitive .
/ * helper method to invoke java . net . idn . toascii ( string ) . allows code to be compiled with java 1 . 4 and 1 . 5
****************************************** lifecycle methods *******************************************
start a foreground job showing a progress bar as long as the job runs . a foreground job shows a modal dialog that can t be cancelled while the app does some processing . this should be used for short jobs only that block the ui . of course this contradicts many of the android guidelines but with short jobs we mean < 1 second and only in rare cases should it me more ( e . g . when the garbage collector kicks in which would normally lead to stuttering ) . using foreground jobs gives a better user experience in these rare cases . the user has to wait but he / she knows it because there s a progess bar .
start a background job showing a progress bar as long as the job runs . this seems contradictory but with background job we mean one that runs off the ui thread to prevent an anr . we still have to wait for the processing to be done because we need the result .
****************************************** handle tags *******************************************
handles ol and ul start tags
handles ol and ul end tags
handles li tags
handles li tags
converts an html color ( named or numeric ) to an integer rgb value .
determines which edges are hit by touching at ( x y ) .
the edge parameter specifies which edges the user is dragging .
grows the cropping rectange by ( dx dy ) in image space .
grows the cropping rectange by ( dx dy ) in image space .
returns the cropping rectangle in image space .
maps the cropping rectangle from image space to screen space .
this needs to be called before anything else because we need the media factory .
find the start and end of the paragraph ( s ) encompassing the current selection . a paragraph spans from one \ n ( exclusive ) to the next one ( inclusive )
sets the edit mode to plain or rich text . the text will be converted automatically to rich / plain text if autoconvert is true .
sets the edit mode to plain or rich text and updates the content at the same time . the caller needs to make sure the content matches the correct format ( if you pass in html code as plain text the editor will show the html code ) .
set the text for this editor . <p > it will convert the text from rich text to plain text if the editor s mode is set to use plain text . or to a spanned text ( only supported formatting ) if the editor s mode is set to use rich text <p > we need to prevent onselectionchanged () to do anything as long as settext () hasn t finished because the layout doesn t seem to update before settext has finished but onselectionchanged will still be called during settext and will receive the out - dated layout which doesn t allow us to apply styles and such .
same as string gettext ( rtformat format ) but this method returns the rttext instead of just the actual text .
add a spanwatcher for the changeable implementation
call this to have an effect applied to the current selection . you get the effect object via the static data members ( e . g . rtedittext . bold ) . the value for most effects is a boolean indicating whether to add or remove the effect .
space
converts this rich text to another rich text . the default implementation doesn t support any conversion except the one to itself ( which is technically no conversion ) . <p > the method has to make sure that the original rich text isn t modified . it does however not make sure that the returned rttext isn t referencing the original rttext meaning modifying the resulting object might also modify the original object .
****************************************** spannablestring methods *******************************************
this method returns the spinner view
returns the spinner entry view
converts a spanned text to html
****************************************** process paragraphs *******************************************
convert a spanned text within a paragraph
escape plain text parts : < > & space -- > ^lt ; &gt ; etc .
creates a file with a non - conflicting file name in a specified folder based on an existing file name .
creates a file uri for a file defined by its absolute path . the method can handle the case of an absolute path ( e . g . / data / data .... ) and a uri path containing the file : // scheme ( e . g . file : /// data / data ... )
retrieve local file path for an arbitrary uri
return a namespace name from a qname . the attribute flag tells us whether to return an empty namespace name if there is no prefix or use the schema default instead .
return a local name from a qname .
sets an attribute and its value into an attributesimpl object . attempts to set a namespace declaration are ignored .
normalize an attribute value ( id - style ) . cdata - style attribute normalization is already done .
sets an attribute and its value into this element type .
append a portion of a character sequence to the { @link stringbuilder } .
write a portion of a character array to the { @link stringbuilder } .
retrieve the file name for a system font .
retrieve the file name for a font in the asset folder .
makes a new buffer available either by allocating a new one or re - cycling an existing one .
write the bytes to byte array .
write a byte to byte array .
writes the entire contents of the specified input stream to this byte stream . bytes from the input stream are read directly into the internal buffers of this streams .
writes the entire contents of this byte stream to the specified output stream .
fetches entire contents of an <code > inputstream< / code > and represent same data as result inputstream . <p > this method is useful where <ul > <li > source inputstream is slow . < / li > <li > it has network resources associated so we cannot keep it open for long time . < / li > <li > it has network timeout associated . < / li > < / ul > it can be used in favor of { @link #tobytearray () } since it avoids unnecessary allocation and copy of byte [] . <br > this method buffers the input internally so there is no need to use a <code > bufferedinputstream< / code > .
gets the current contents of this byte stream as a input stream . the returned stream is backed by buffers of <code > this< / code > stream avoiding memory allocation and copy thus saving space and time . <br >
gets the curent contents of this byte stream as a byte array . the result is independent of this stream .
set the text size .
normalizes a path removing double and single dot path steps and removing any final directory separator . <p > this method normalizes a path to a standard format . the input may contain separators in either unix or windows format . the output will contain separators in the format specified . <p > a trailing slash will be removed . a double slash will be merged to a single slash ( but unc names are handled ) . a single dot path segment will be removed . a double dot will cause that path segment and the one before to be removed . if the double dot has no parent path segment to work with { @code null } is returned . <p > the output will be the same on both unix and windows including the separator character . <pre > / foo // -- > / foo / foo / . / -- > / foo / foo / .. / bar -- > / bar / foo / .. / bar / -- > / bar / foo / .. / bar / .. / baz -- > / baz // foo // . / bar -- > / foo / bar / .. / -- > null .. / foo -- > null foo / bar / .. -- > foo foo / .. / .. / bar -- > null foo / .. / bar -- > bar // server / foo / .. / bar -- > // server / bar // server / .. / bar -- > null c : \ foo \ .. \ bar -- > c : \ bar c : \ .. \ bar -- > null ~ / foo / .. / bar / -- > ~ / bar ~ / .. / bar -- > null < / pre >
internal method to perform the normalization .
converts all separators to the unix separator of forward slash .
returns the index of the last extension separator character which is a dot . <p > this method also checks that there is no directory separator after the last dot . to do this it uses { @link #indexoflastseparator ( string ) } which will handle a file in either unix or windows format . <p > the output will be the same irrespective of the machine that the code is running on .
return an array of the markup objects attached to the specified slice of a spannable and whose type is the specified type or a subclass of it ( see spanned . getspans ( int int class<t > )) .
hitting cropping rectangle .
pan the displayed image to make sure the cropping rectangle is visible .
view s center and scale according to the cropping rectangle .
reset document locator supplying systemid and publicid .
scan html source reporting lexical events .
validate a value against the set of regular expressions returning a string value of the aggregated groups .
the paragraph is selected by the selection if : <p > - they have at least one character in common - the selection is a point within the paragraph ( 01 \ n - > 0 till 2 intersects while the span is [ 0 3 ] ) - the selection is a point within or at the end of the last paragraph ( 01 - > 0 till 2 intersects while the span is [ 0 2 ] ) e . g . [ 10 10 ] will intersect the paragraph [ 0 10 ] only if it s the last paragraph
indicates whether the <code > reader< / code > has more lines . if there is an <code > ioexception< / code > then { @link #close () } will be called on this instance .
returns the next line in the wrapped <code > reader< / code > .
add or replace an element type for this schema .
add or replace a default attribute for an element type in this schema .
specify natural parent of an element in this schema .
get an elementtype by name .
get an entity value by name .
todo : on android m we need to ask the write_external_storage permission explicitly
returns true if the authority is properly formatted . an authority is the combination of hostname and port . a <code > null< / code > authority value is considered invalid . note : this implementation validates the domain unless a regexvalidator was provided . if a regexvalidator was supplied and it matches then the authority is regarded as valid with no further checks otherwise the method checks against the authority_pattern and the domainvalidator ( allow_local_urls )
returns true if the path is valid . a <code > null< / code > value is considered invalid .
this important method makes sure that all paragraph effects are applied to whole paragraphs . while it s optimized for performance it s still an expensive operation so it shouldn t be called too often .
returns the absolute file path for a certain rtmediatype . <p > the media type specific path as provided by rtmediatype is appended to the storage path ( e . g . <storage area > / images for image files ) .
/ * use case 1 : inserting media objects into the rich text editor .
apply this effect to the selection . if value is null then the effect will be removed from the current selection .
<p > checks if a field has a valid e - mail address . < / p >
returns true if the domain component of an email address is valid .
todo finding links doesn t work with right alignment and potentially other formatting options
call this when an operation is performed to add it to the undo stack .
re - do the last undone operation for a specific rich text editor
flush all operations for a specific rich text editor ( method unused at the moment )
****************************************** private methods *******************************************
a memory optimized algorithm for string . replaceall
get thread status and create one if specified .
the following three methods are used to keep track of bitmapfaction . options used for decoding and cancelling .
the following three methods are used to keep track of which thread is being disabled for bitmap decoding .
the real place to delegate bitmap decoding to bitmapfactory .
use this method to preload fonts asynchronously e . g . when the app starts up .
retrieve the fonts from the asset and the system folder .
retrieve the fonts from the asset folder .
retrieve the fonts from the system folders .
get contents of an <code > inputstream< / code > as a <code > byte [] < / code > . use this method instead of <code > tobytearray ( inputstream ) < / code > when <code > inputstream< / code > size is known . <b > note : < / b > the method checks that the length can safely be cast to an int without truncation before using { @link ioutils#tobytearray ( java . io . inputstream int ) } to read into the byte array . ( arrays can have no more than integer . max_value entries anyway )
get the contents of an <code > inputstream< / code > as a <code > byte [] < / code > . use this method instead of <code > tobytearray ( inputstream ) < / code > when <code > inputstream< / code > size is known
get the contents of a <code > reader< / code > as a <code > byte [] < / code > using the specified character encoding . <p / > this method buffers the input internally so there is no need to use a <code > bufferedreader< / code > .
get the contents of a <code > reader< / code > as a <code > byte [] < / code > using the specified character encoding . <p / > character encoding names can be found at <a href = http : // www . iana . org / assignments / character - sets > iana< / a > . <p / > this method buffers the input internally so there is no need to use a <code > bufferedreader< / code > .
get the contents of a <code > url< / code > as a <code > byte [] < / code > .
get the contents of a <code > urlconnection< / code > as a <code > byte [] < / code > .
get the contents of an <code > inputstream< / code > as a character array using the specified character encoding . <p / > this method buffers the input internally so there is no need to use a <code > bufferedinputstream< / code > .
get the contents of an <code > inputstream< / code > as a character array using the specified character encoding . <p / > character encoding names can be found at <a href = http : // www . iana . org / assignments / character - sets > iana< / a > . <p / > this method buffers the input internally so there is no need to use a <code > bufferedinputstream< / code > .
get the contents of a <code > reader< / code > as a character array . <p / > this method buffers the input internally so there is no need to use a <code > bufferedreader< / code > .
get the contents of an <code > inputstream< / code > as a list of strings one entry per line using the specified character encoding . <p / > this method buffers the input internally so there is no need to use a <code > bufferedinputstream< / code > .
get the contents of an <code > inputstream< / code > as a list of strings one entry per line using the specified character encoding . <p / > character encoding names can be found at <a href = http : // www . iana . org / assignments / character - sets > iana< / a > . <p / > this method buffers the input internally so there is no need to use a <code > bufferedinputstream< / code > .
return an iterator for the lines in an <code > inputstream< / code > using the character encoding specified ( or default encoding if null ) . <p / > <code > lineiterator< / code > holds a reference to the open <code > inputstream< / code > specified here . when you have finished with the iterator you should close the stream to free internal resources . this can be done by closing the stream directly or by calling <p / > the recommended usage pattern is : <pre > try { lineiterator it = ioutils . lineiterator ( stream charset ) ; while ( it . hasnext () ) { string line = it . nextline () ; /// do something with line } } finally { ioutils . closequietly ( stream ) ; } < / pre >
return an iterator for the lines in an <code > inputstream< / code > using the character encoding specified ( or default encoding if null ) . <p / > <code > lineiterator< / code > holds a reference to the open <code > inputstream< / code > specified here . when you have finished with the iterator you should close the stream to free internal resources . this can be done by closing the stream directly or by calling { @link lineiterator#close () } or { @link lineiterator#closequietly ( lineiterator ) } . <p / > the recommended usage pattern is : <pre > try { lineiterator it = ioutils . lineiterator ( stream utf - 8 ) ; while ( it . hasnext () ) { string line = it . nextline () ; /// do something with line } } finally { ioutils . closequietly ( stream ) ; } < / pre >
writes bytes from a <code > byte [] < / code > to chars on a <code > writer< / code > using the default character encoding of the platform . <p / > this method uses { @link string#string ( byte [] ) } .
writes bytes from a <code > byte [] < / code > to chars on a <code > writer< / code > using the specified character encoding . <p / > this method uses { @link string#string ( byte [] string ) } .
writes chars from a <code > char [] < / code > to bytes on an <code > outputstream< / code > using the specified character encoding . <p / > this method uses { @link string#string ( char [] ) } and { @link string#getbytes ( string ) } .
writes chars from a <code > charsequence< / code > to bytes on an <code > outputstream< / code > using the default character encoding of the platform . <p / > this method uses { @link string#getbytes () } .
writes chars from a <code > charsequence< / code > to bytes on an <code > outputstream< / code > using the specified character encoding . <p / > this method uses { @link string#getbytes ( string ) } .
writes chars from a <code > stringbuffer< / code > to a <code > writer< / code > .
writes chars from a <code > stringbuffer< / code > to bytes on an <code > outputstream< / code > using the default character encoding of the platform . <p / > this method uses { @link string#getbytes () } .
writes chars from a <code > stringbuffer< / code > to bytes on an <code > outputstream< / code > using the specified character encoding . <p / > character encoding names can be found at <a href = http : // www . iana . org / assignments / character - sets > iana< / a > . <p / > this method uses { @link string#getbytes ( string ) } .
writes the <code > tostring () < / code > value of each item in a collection to an <code > outputstream< / code > line by line using the default character encoding of the platform and the specified line ending .
writes the <code > tostring () < / code > value of each item in a collection to an <code > outputstream< / code > line by line using the specified character encoding and the specified line ending .
writes the <code > tostring () < / code > value of each item in a collection to an <code > outputstream< / code > line by line using the specified character encoding and the specified line ending . <p / > character encoding names can be found at <a href = http : // www . iana . org / assignments / character - sets > iana< / a > .
writes the <code > tostring () < / code > value of each item in a collection to a <code > writer< / code > line by line using the specified line ending .
copy some or all chars from a large ( over 2gb ) <code > inputstream< / code > to an <code > outputstream< / code > optionally skipping input chars . <p / > this method uses the provided buffer so there is no need to use a <code > bufferedreader< / code > . <p / >
compare the contents of two readers to determine if they are equal or not . <p / > this method buffers the input internally using <code > bufferedreader< / code > if they are not already buffered .
compare the contents of two readers to determine if they are equal or not ignoring eol characters . <p / > this method buffers the input internally using <code > bufferedreader< / code > if they are not already buffered .
{
sets up instance variables that haven t been set by setfeature
buffer both the inputstream and the reader
get an inputstream based on a publicid and a systemid
needs to support chars past u + ffff
with a semicolon .
deferring to the schema for named ones .
e is the next element to be started if we know what it is
pop the stack irrevocably
pop the stack restartably
get the prefix from a qname
return true if we have a foreign name
parsing the complete xml document type definition is way too complex but for many simple cases we can extract something useful from it . <p > doctypedecl :: = <!doctype s name ( s externalid ) ? s? ( [ intsubset ] s? ) ? > declsep :: = pereference | s intsubset :: = ( markupdecl | declsep ) * markupdecl :: = elementdecl | attlistdecl | entitydecl | notationdecl | pi | comment externalid :: = system s systemliteral | public s pubidliteral s systemliteral
if the string is quoted trim the quotes .
recognises quotes around a phrase and doesn t split it .
so that the argument can be safely pushed
canonicalize case .
called to retrieve per - instance state before being killed so that the state can be restored in the constructor .
perform any final cleanup before the component is destroyed .
register a rich text editor . <p > before using the editor it needs to be registered to an rtmanager . using means any calls to the editor ( settext will fail if the editor isn t registered ) ! must be called from the ui thread .
unregister a rich text editor . <p > this method may be called before the component is destroyed to stop any interaction with the editor . not doing so may result in ( asynchronous ) calls coming through when the activity / fragment is already stopping its operation . <p > must be called from the ui thread . <p > important : calling this method is obsolete once the ondestroy ( boolean ) is called
register a toolbar . <p > only after doing that can it be used in conjunction with a rich text editor . must be called from the ui thread .
unregister a toolbar . <p > this method may be called before the component is destroyed to stop any interaction with the toolbar . not doing so may result in ( asynchronous ) calls coming through when the activity / fragment is already stopping its operation . <p > must be called from the ui thread . <p > important : calling this method is obsolete once the ondestroy ( boolean ) is called
****************************************** rttoolbarlistener *******************************************
/ * called from oneventmainthread ( mediaevent )
****************************************** rtedittextlistener *******************************************
media file was picked - > process the result .
linkfragment has closed - > process the result .
then translate it back into view ( i . e . eliminate black bars ) .
setup the base matrix so that the image is centered and scaled properly .
rather than the current 1024x768 this should be changed down to 200% .
check whether the effect exists in the currently selected text of the active rtedittext .
returns the value ( s ) of this effect in the currently selected text of the active rtedittext .
remove all effects of this type from the currently selected text of the active rtedittext . if the selection is empty ( cursor ) formatting for the whole text is removed .
equivalent to the spanned . getspans ( int int class<t > ) method . return the markup objects ( spans ) attached to the specified slice of a spannable . the type of the spans is defined in the spancollector .
make sure applytoselection works on whole paragraphs and call effects . cleanupparagraphs ( rtedittext ) afterwards .
find spans within that paragraph and add them to the paragraphspanprocessor to be removed once the paragraphspanprocessor processes its spans .
this method encodes the query part of an url
this method decodes an url with encoded query string
this method determines if the direction of a substring is right - to - left . if the string is empty that determination is based on the default system language locale . getdefault () . the method can handle invalid substring definitions ( start > end etc . ) in which case the method returns false .
tries to open a known file browsers to pick a directory .
****************************************** lifecycle methods *******************************************
****************************************** private methods *******************************************
/ * compute the sample size as a function of minsidelength and maxnumofpixels . minsidelength is used to specify that minimal width or height of a bitmap . maxnumofpixels is used to specify the maximal size in pixels that are tolerable in terms of memory usage .
thong added for rotate
****************************************** lifecycle methods *******************************************
****************************************** listener methods *******************************************
set a new output destination for the document .
force a namespace declaration with a preferred prefix . <p > <p > this is a convenience method that invokes { @link #setprefix setprefix } then { @link #forcensdecl ( java . lang . string ) forcensdecl } . < / p >
write the xml declaration at the beginning of the document . <p > pass the event on down the filter chain for further processing .
write a newline at the end of the document . <p > pass the event on down the filter chain for further processing .
write a start tag . <p > pass the event on down the filter chain for further processing .
write an end tag . <p > pass the event on down the filter chain for further processing .
write character data . <p > pass the event on down the filter chain for further processing .
write ignorable whitespace . <p > pass the event on down the filter chain for further processing .
write a processing instruction . <p > pass the event on down the filter chain for further processing .
force all namespaces to be declared . <p > this method is used on the root element to ensure that the predeclared namespaces all appear .
determine the prefix for an element or attribute name . <p >
write a raw character .
write a raw string .
write out an attribute list escaping values . <p > the names will have prefixes added to them .
return true if the attribute is an html boolean from the above list .
write an array of data characters with escaping .
write out the list of namespace declarations .
write an element or attribute name .
//////////////////////////////////////////////////////////////////
make this element anonymous . remove any <tt > id< / tt > or <tt > name< / tt > attribute present in the element s attributes .
clean the attributes of this element . attributes with null name ( the name was ill - formed ) or null value ( the attribute was present in the element type but not in this actual element ) are removed .
create a amazonkinesis client configured with some optional properties ( can also be configured using environment variables ) :
ensure that the kinesis stream exists ( creates it if does not exist ) .
create a stream if it does not already exist .
waits that the stream has been created .
todo very ugly fix
this method has to be called in the default implementation of an entity interface to declare that a relation is the reciprocal of another relation : <ul > <li > the straight relation is defined from the { @code tail } entity to the { @code head } entity . it must not have a default implementation< / li > <li > the reverse relation is defined from the { @code head } entity to the { @code tail } entity . it must have a default implementation that call this method< / li > < / ul > <p > at runtime this call is only issued during the model analysis . the entity instances proxies overrides this default implementation to return the needed information . <br >
complete snapshot n with lacking instance snapshots from snapshot n - 1
returns the single created shard ( stream has a single shard ) .
wait that the minimum duration between two getsharditeratorrequests has elapsed .
retrieves records corresponding to the request .
handle retry for amazon quotas
try to perform an amazon action and increase the duration between requests if some exception is exceeding resource usage exception is thrown .
create a awss3snapshotstore with some properties set to configure s3 client : ( + ) to configure the access both access key and secret key must be provided . ( * ) to configure the endpoint url the endpoint the port and the region must be provided .
throws an exception if the bucket does not exist or is not readable .
this method don t use cache . use with care . <br > if caching is required then use { @link #getmethodname ( class accessor ) }
load the stores .
{
creates a { @link iofilefilter } which collects found files into a collection and also populates a map with found resources and corresponding files .
validates arguments used by { @link defaultwildcardstreamlocator#findmatchedfiles ( string file ) } method .
uses the wildcardexpanderhandler to process all found files and directories .
replace all occurrences of a substring within a string with another string .
convenience method to return a collection as a delimited ( e . g . csv ) string . e . g . useful for <code > tostring () < / code > implementations .
delete any character in a given string .
{
{
{
add a single lint report to underlying collection .
initialize script builder for evaluation .
validates a js using jshint and throws { @link linterexception } if the js is invalid . if no exception is thrown the js is valid .
todo this method is duplicated in { @link csslint } . extract and reuse it .
reuse {
add to properties a new key with value extracted either from filterconfig or from configurable properties file . this method helps to ensure backward compatibility of the filterconfig vs configproperties configuration .
use this method rather than accessing the field directly because it will create a default one if none is provided .
override this method to provide a different config properties file location . it is very likely that you would like it to be the same as the one used by the { @link filterconfigwroconfigurationfactory } . the default properties file location is / web - inf / wro . properties .
to be used for internal usage . ensure that returned object is not null .
to be used for internal usage . ensure that returned object is not null .
{
use this factory method when you want to use the {
handles the resource model auto detection .
{
removes all
{
creates a map of postprocessors form a map of preprocessors . this method will be removed in 1 . 5 . 0 release when there will be no differences between pre & post processor interface .
the implementation uses jsr166 forkjoinpool implementation in case it is available and can be used otherwise the default { @link executorservice } is used .
todo rename to submitall . <p / > submits a chunk of jobs for parallel execution . this is a blocking operation - it will end execution when all submitted tasks are finished .
{
compiles the javascript template into plain javascript .
{
replace provided url with the new url if needed .
similar to { @link cssdatauripreprocessor#isreplaceaccepted ( string ) } but decides whether the computed datauri should replace the image url . it is useful when you want to limit the datauri size . by default the size of datauri is limited to 32kb ( because ie8 has a 32kb limitation ) .
{
{
{
{
{
notify all listeners about cacheperiod property changed . if passed newvalue is null the oldvalue is taken as new value . this is the case when the reloadcache is invoked .
notify all listeners about cacheperiod property changed . if passed newvalue is null the oldvalue is taken as new value . this is the case when the reloadmodel is invoked .
{
factory method . creates a { @link schedulerhelper } which consumes a factory providing a runnable . this approach allows lazy runnable initialization .
run the scheduler with the provided period of time . if the scheduler is already started it will be stopped ( not before the running job is complete ) .
the following method shuts down an executorservice in two phases first by calling shutdown to reject incoming tasks and then calling shutdownnow if necessary to cancel any lingering tasks :
/ ** when using jboss portal and it has some funny quirks ... actually a portal application have several small web application behind it . so when it intercepts a requests for portal then it start bombing the the application behind the portal with multiple threads ( web requests ) that are combined with threads for wro4j .
build a wrapped servlet request which will be used for dispatching .
{
{
add a {
initialize script builder for evaluation .
creates a { @link providerfinder } which will find providers of type provided as argument ..
collects also providers of type { @link configurableprovider } if the t type is a supertype of { @link configurableprovider } . if the type is already { @link configurableprovider } it will be ignored to avoid adding of duplicate providers .
this method is useful for mocking the lookup operation . the implementation will try to use java . util . serviceloader by default ( available in jdk6 ) and will fallback to serviceregistry for earlier jdk versions . the reason for this is to support gae environment which doesn t contain the serviceregistry in its whitelist .
{
the idea is to compute the aggregatedfolderpath based on a root folder . the root folder is determined by comparing the csstargetfolder ( the folder where aggregated css files are located ) with build directory or contextfolder . if rootfolder is null then the result is also null ( equivalent to using the csstargetfolder the same as the root folder .
use {
creates a {
appends a suffix to the source basename .
action -- do something! what you do is determined by the argument : <ul > <li > 1 output a . copy b to a . get the next b . < / li > <li > 2 copy b to a . get the next b . ( delete a ) . < / li > <li > 3 get the next b . ( delete b ) . < / li > < / ul > action treats a string as a single character . wow!<br / > action recognizes a regular expression if it is preceded by ( or or = .
returns a valid http contenttype s for a given filename . it first relies on the custom defaultcontenttypemap and if not found it will fall back to defaultfiletypemap from javax . activation . filetypemap . examples : - somefile . css resolves to text / css . - somefile . js . png resolves to image / png - / blah / index . html resolves to text / html . <p / > the implementation uses reflection to load <code > javax . activation . filetypemap< / code > class ( available in jdk6 ) in order to be compatible with jdk5 . if this class is not available the default content type is returned .
returns a valid http contenttype s for a given filename with charset . it first relies on the custom defaultcontenttypemap and if not found it will fall back to defaultfiletypemap from javax . activation . filetypemap . examples : - ( somefile . css utf - 8 ) resolves to text / css ; charset = utf - 8 . - ( somefile . js . png utf - 8 ) resolves to image / png - ( / blah / index . html utf - 8 ) resolves to text / html ; charset = 8
{
builds a {
{
use an empty stream to avoid container writing unwanted message when a resource is missing .
by default redirect does not allow writing to output stream its content . in order to support this use - case we need to open a new connection and read the content manually .
{
process each resource and replace it with a collection of resources if it contains wildcard .
computes the file name of the folder where the resource is located . the implementation uses a trick by invoking the {
create the handler which expand the resources containing wildcard .
replace provided url with the new url if needed .
locates an inputstream for the given uri .
initialize script builder for evaluation .
validates a js using jshint and throws { @link linterexception } if the js is invalid . if no exception is thrown the js is valid .
creates configuration by looking up in servletcontext attributes . if none is found a new one will be created using the configuration factory .
creates {
expose mbean to tell jmx infrastructure about our mbean ( only if jmxenabled is true ) .
register property change listeners .
perform actual processing .
invoked when a { @link exception } is thrown . allows custom exception handling . the default implementation proceeds with filter chaining when exception is thrown .
once set this configuration will be used instead of the one built by the factory .
{
identify duplicate group names .
merge this model with another model . this is useful for supporting model imports .
{
this implementation shows the problem with current design of locator implementation . needs to be changed .
{
apply resourcepostprocessors .
this method is synchronized to ensure that processor is injected before it is being used by other thread .
{
{
applies configured processor on the intercepted stream .
invoked when a { @link runtimeexception } is thrown . allows custom exception handling . the default implementation redirects to 404 for a specific { @link wroruntimeexception } exception when in deployment mode .
split multiple options into an array of options .
initialize script builder for evaluation .
initialize script builder for evaluation .
load the properties from the stream . the implementation will handle comments properly by removing them before properties are loaded .
parse the properties from the provided string containing a raw properties
creates a {
this method will ensure that you have a right and initialized instance of { @link standalonecontextaware } .
creates a custom instance of manager factory . the wromanagerfactory parameter value is used to identify the manager class .
allows explicitly to override the default implementation of the factory assuming {
initialize the created {
store digest for all resources contained inside the list of provided groups .
check if the provided group is a target group .
update the classpath .
{
override this method in order to provide different xml definition file name .
creates a resource and set the correct { @link resourcetype } based on uri extension . if resourcetype cannot be identified an exception is thrown .
perform a cleaning of the uri by trimming it and removing last / character if exists .
{
{
a factory method which uses { @link wroconfiguration } to get the configured wromanager classname .
initialized inner factory based on provided configuration .
initialize script builder for evaluation .
set a list of transformers to apply on decorated model factory .
{
visible for testing the init of a handlebarsjs template
{
check if url must be replaced or not . the replacement is not needed if the url of the image is absolute ( can be resolved by urlresourcelocator ) or if the url is a data uri ( base64 encoded value ) .
apply preprocessors on resources and merge them after all preprocessors are applied .
apply preprocessors on resources and merge them .
runs the pre processors in parallel .
apply a list of preprocessors on a resource .
decorates preprocessor with mandatory decorators . this method is synchronized to ensure that processor is injected before it is being used by other thread .
{
persist the fallbackstorage to the fallbackstoragefile . this method should be invoked only once during build since it is relatively expensive . not invoking it would break the incremental build feature .
scans the object and inject the supported values into the fields having @inject annotation present .
check for each field from the passed object if @inject annotation is present & inject the required field if supported otherwise warns about invalid usage .
return all fields for given object also those from the super classes .
analyze the field containing { @link inject } annotation and set its value to appropriate value . override this method if you want to inject something else but urilocatorfactory .
computes the url of the image to be replaced in a css resource .
css files hosted on external server should use its host as the root context when rewriting image url s starting with / character .
concatenates cssuri and imageurl after few changes are applied to both input parameters .
add a custom key - value pair attribute . each pair is added to an internal map . the custom attributes can be used to make the key more fine grained ( ex : based on browser version or a request parameter ) . both elements of the attribute ( key & value ) should be not null . if any of these are null the attribute won t be added .
{
{
{
add a single model transformer .
write to stream the content of the processed resource bundle .
set the aggregatedfolderpath if required .
extract variables map from variables body .
{
parse css find all defined variables & replace them .
replace variables from css with provided variables map .
{
{
{
{
transforms a post processor into pre processor .
indicates if the processor is eligible for usage based on provided criteria .
called when { @link linterexception } is thrown . allows subclasses to re - throw this exception as a { @link runtimeexception } or handle it differently . the default implementation simply logs the errors .
{
{
{
{
{
{
destroy the initialized object . this will trigger the re - initialization when {
{
{
performs actual gzip of the filtered content .
decorates a processor which will be applied on provided patterns .
decorates a processor which will not be applied on provided patterns .
{
factory method which requires all mandatory fields .
will persist the information regarding the provided resource in some internal store . this information will be used later to check if the resource is changed .
invokes the provided function for each detected css import .
after invoking this method on a resource the next invocation of { @link #isresourcechanged ( resource ) } will return true .
{
factory method for creating a { @link resourcelintreport } instance .
this filtering is required in order to ensure that no nulls are passed ( which happens when using gson for deserializing json collection .
{
extracts the resource type by parsing the uri & finds the extension . if extension is valid ( css or js ) returns corresponding resourcetype otherwise throws exception . <p > valid examples of uri are : <code > / context / somepath / test . js< / code > or <code > / context / somepath / test . css< / code > {
{
the minimization is can be switched off only in debug mode .
{
{
{
find a set of imported resources inside a given resource .
build a {
computes absolute url of the imported resource .
used to identify whether the { @link httpservletresponse#sc_not_modified } or { @link httpservletresponse#sc_ok } should be returned . currently a single timestamp is used to detect the change for all resources . this might be no accurate but at least it allows sending not_modified header much often resulting in less load on the server . <p / > override this method if a different way detecting change is required .
builds the request path for this request handler using the assumption that { @link wrofilter } has a mapping ending with a <code > * < / code > character .
creates a comma separated list of items .
creates a list of aliases based on provided string containing comma separated values of aliases .
initialize the context .
add a client side environment to the script context ( client - side aware ) .
this method will load json utility and aslo a douglas crockford s <a href = https : // github . com / douglascrockford / json - js / blob / master / cycle . js > utility< / a > required for decycling objects which would fail otherwise when using json . stringify .
evaluates a script and return { @link rhinoscriptbuilder } for a chained script evaluation .
evaluates a script and return { @link rhinoscriptbuilder } for a chained script evaluation .
evaluates a script from a reader .
evaluates a script .
perform processing of the uri .
encodes a fingerprint of the resource into the path . the result may look like this : $ { fingerprint } / mygroup . js
format the version of the resource in the path . default implementation use hash as a folder : <hash > / groupname . js . the implementation can be changed to follow a different versioning style like version parameter : / groupname . js?version = <hash >
called when {
invokes destroy method on all {
{
checks if the provided url is a resource proxy request .
computes the servlet context relative url to call this handler using a server - side invocation . hides the details about creating a valid url and providing the authorization key required to invoke this handler .
encodes a version using some logic .
computes the destination folder based on resource type .
process a single group .
wraps original exception into { @link wroruntimeexception } and throw it .
{
computes {
check if an uri from a particular group has changed .
a getter used for lazy loading overrides rubysassengine#getengine () and ensure the bourbon gem is imported ( required ) .
{
initialize script builder for evaluation .
this implementation will try to locate the provided resource inside contextfolder configured by standalonecontext . if a resource cannot be located the next contextfolder from the list will be tried . the first successful result will be returned .
todo this is duplicated code ( from super ) - > find a way to reuse it .
initialize script builder for evaluation .
validates a css resource using csslint and throws { @link csslintexception } if the resource is invalid . if no exception is thrown the resource is valid .
ensure that a not null pool will be created .
creates a {
{
{
{
{
finds the specified uri pattern inside a jar file . if the specified file isn t a valid jar default strategy will be used instead .
opens the specified jar file and returns a valid handle .
finds the specified wildcard - uri resource ( s ) inside a jar file and returns an { @link inputstream } to read a bundle of matching resources .
replaces the protocol specific prefix and removes the query path if it exist since it should not be accepted .
{
uses isminimizeenabled configuration to compute minimize value .
write the content to the {
{
allow adding more than one urilocators .
factory method which takes care of redundant decoration .
{
adds a ruby require to the ruby script to be run by this rubysassengine . it s safe to add the same require twice .
transforms a sass content into css using sass ruby engine . this method is synchronized because the engine itself is not thread - safe .
{
logs the summary as it was collected at this point .
a method which should be invoked on each new resource processing having as a side effect an increment of the counter holding the number of total processed resources .
{
ensure that the returned lock will never be null .
called when { @link csslintexception } is thrown . allows subclasses to re - throw this exception as a { @link runtimeexception } or handle it differently .
creates process responsible for running lessc shell command by reading the file content from the sourcefilepath
{
{
{
{
parses out the properties of a selector s body .
return an array of the data for tasks performed .
return a string with a table describing all tasks performed . for custom reporting call gettaskinfo () and use the task info directly .
creates compilation command for provided typescript input .
factory method which creates a {
factory method which creates a {
parse header value & puts the found values in headersmap field .
populates the map with headers used to disable cache .
method called for each request and responsible for setting response headers used mostly for cache control . override this method if you want to change the way headers are set . <br >
{
{
creates a more detailed message based on { @link rhinoexception } thrown by rhino execution . the message will contain a detailed description of the problem by inspecting the json value provided by exception .
recursively convert from native rhino to json . <p > recognizes javascript objects arrays and primitives . <p > special support for javascript dates : converts to { $date : timestamp } in json . <p > special support for mongodb objectid : converts to { $oid : objectid } in json . <p > also recognizes jvm types : java . util . map java . util . collection java . util . date .
retrieve pathinfo from a given location .
creates a folder like implementation for a class . ex : com . mycompany . myclass - > com / mycompany /
<p > check if a string starts with a specified prefix ( optionally case insensitive ) . < / p >
retrieve servletpath from a given location .
analyze headers of the request and searches for mangled ( by proxy ) for accept - encoding header and its mangled variations and gzip header value and its mangled variations .
transforms a java multi - line string into javascript multi - line string . this technique was found at { @link http : // stackoverflow . com / questions / 805107 / multiline - strings - in - javascript / }
utility used to verify that requesturi matches provided path
a factory method for creating a { @link resourceprocessor } based on provided { @link resourcepreprocessor } .
load the regular expression stored in in regexp . properties resource file .
copy and close the reader and writer streams .
creates a temp file which has a certain extension .
join two paths ( using unix separator ) and make sure to use exactly one separator ( by adding or removing one if required ) .
cleans the image url by trimming result and removing \ or \ characters if such exists .
similar to { @link filenameutils#getfullpath ( string ) } but fixes the problem with windows platform for situations when the path starts with / ( servlet context relative resources ) which are resolved to \ on windows .
similar to { @link filenameutils#normalize ( string ) } but fixes the problem with windows platform for situations when the path starts with / ( servlet context relative resources ) which are resolved to \ on windows .
factory method which uses default name for storing / retrieving attributes in {
creates a unique name used as a key to store the attribute in { @link servletcontext } .
sets the attribute into the servlet context . the name of the attribute will be computed for you .
remove all attributes from {
generate the datauri as string associated to the passed inputstream with encoding & type based on provided filename .
generates a data uri from a byte array and outputs to the given writer .
factory method for creating { @link reportxmlformatter } .
creates a report which handles the adaptation of type <f > to { @link lintitem } .
{
creates a {
creates a {
a context useful for running in web context ( inside a servlet container ) .
associate a context with the current request cycle .
remove context from the local thread .
decorates a callable with { @link contextpropagatingcallable } making it possible to access the { @link context } from within the decorated callable .
decorates the provided {
creates a {
will try an asynchronous check if the async configuration is enabled . if async check is not configured a synchronous check will be performed . the async check assumes that the { @link resourcewatcherrequesthandler } is enabled . <p / > if the async check is not allowed ( the request was not passed through { @link wrofilter } ) - no check will be performed . this is important for use - cases when wro resource is included using a taglib which performs a wro api call directly without being invoked through { @link wrofilter } .
check if resources from a group were changed . if a change is detected the changelistener will be invoked .
invoked when exception occurs .
will check if a given resource was changed and will invoke the appropriate callback .
check if the resource was changed from previous run . the implementation uses resource content digest ( hash ) to check for change .
updates the hash associated with the resource for a give groupname .
check if the group has at least one resource of some type .
replace one resource with a list of other resources . the use case is related to wildcard expander functionality when resources containing wildcard are replaced with a list of wildcard - free resources . the order of resources is preserved . <p / > the implementation is synchronized because it mutates the collection .
add a { @link resource } to the collection of resources associated with this group . <p / > the implementation is synchronized because it mutates the collection .
this method will replace all earlier defined resources with the provided list of resources . <p / > the implementation is synchronized because it mutates the collection .
utility method which copies all entries from source into target . entries with the same keys from target will be overridden with entries from source . this operation is similar to { @link map#putall ( map ) } but it doesn t require changing generics to construction like
creates process responsible for running tsc shell command by reading the file content from the sourcefilepath
creates the platform specific arguments to run the <code > tsc< / code > shell utility . default implementation handles windows and unix platforms .
initialize script builder for evaluation .
performs base64 encoding on the <code > raw< / code > bytebuffer writing it to the <code > encoded< / code > charbuffer . this is an experimental feature . currently it does not pass along any options ( such as { @link #do_break_lines } or { @link #gzip } .
serializes an object and returns the base64 - encoded version of that serialized object .
initialize the map
recursive method . add the parsed element group to the group collection . if the group contains group - ref element parse recursively this group .
creates a group and all its associated resources .
creates a resource from a given resourceelement . it can be css js . if resource tag name is group - ref the method will start a recursive computation .
creates a resource from a given resourceelement . the element is guaranteed to be of a simple non - recursive type ( i . e . css or js ) .
search for all resources for a group with a given name .
{
{
replace provided url with the new url if needed .
use {
mainly use for {
@see #trywait ( iterable long timeunit )
a typical usage : { @code <pre > // a fail - safe example list<future<user >> list = dosomeasynctasks () ; map<future<user > user > success ; try { success = trywait ( list 1 seconds ) ; } catch ( trywaituncheckedexception e ) { success = e . getsuccess () ; // there are still some success }
@see #trywait ( iterable long timeunit throwablefunction )
a typical usage : { @code <pre > // a fail - safe example list<integer > list = getsomeids () ; map<integer user > success ; try { success = trywait ( list 1 seconds id - > executor . submit (( ) - > retrieve ( id ))) ; } catch ( trywaituncheckedexception e ) { success = e . getsuccess () ; // there are still some success }
creates a { @link concurrentexecutor } with the given name ( used as a prefix for creating thread ) and given timeout for running threads . if a thread did not process a job within the given timeout the thread is terminated .
print logging information for the timer . the log only shows the recorded time of the completed start - stop cycles . if the timer is still running then it will not be stopped to add the currently measured time to the output but a warning will be logged .
stop a timer of the given string name for the given thread . if no such timer exists - 1 will be returned . otherwise the return value is the cpu time that was measured .
get a timer of the given string name that takes all possible times ( todos ) for the current thread . if no such timer exists yet then it will be newly created .
get a timer of the given string name and todos for the current thread . if no such timer exists yet then it will be newly created .
get a timer of the given string name for the given thread . if no such timer exists yet then it will be newly created .
print statistics about the saturation
waking up all workers waiting for new saturated contexts
updates the counter for processed contexts and jobs
check if the counter for saturated contexts and processed jobs can be increased and post - process the finished jobs
update the counter to the value provided it is greater . regardless of the returned value it is guaranteed that the value of the counter after execution will be at least the input value .
adds a { @link backwardlinkchainfrombackwardlinkrule } inferences for the given { @link forwardlink } in the given { @link context }
removes a { @link backwardlinkchainfrombackwardlinkrule } inferences for the given { @link forwardlink } from the given { @link context }
tests if a { @link backwardlinkchainfrombackwardlinkrule } inferences for the given { @link forwardlink } is present in the given { @link context }
the default implementation of all methods
computes all sub - { @link indexedpropertychain } s of the given { @link indexedpropertychain } if not computing before recording all { @link objectpropertyinference } s using the provided { @link producer } . it is ensured that all { @link objectpropertyinference } s are applied only once even if the method is called multiple times .
computes all sub - { @link indexedobjectproperty } s of the given { @link indexedpropertychain } if not computing before recording all { @link objectpropertyinference } s using the provided { @link producer } . it is ensured that all { @link objectpropertyinference } s are applied only once even if the method is called multiple times .
given an { @link indexedobjectproperty } computes a { @link multimap } from { @link indexedobjectproperty } s to { @link indexedobjectproperty } consisting of the the assignments t - > s such that both s and objectpropertychain ( s t ) are sub - properties of the given { @link indexedobjectproperty } . the provided { @link producer } is used to record all { @link objectpropertyinference } s that are applied in this computation of sub - { @link indexedpropertychain } s involved . it is ensured that the computation is performed only once .
adds the specified object property into the taxonomy if it is not in it yet and sets its direct sub - properties if not set yet .
collects sub - properties of <code > property< / code > that are equivalent to it . returns <code > null< / code > if <code > property< / code > is equivalent to the top property .
flushes index if needed and completes loading if there is new input . incremental mode should be changed only during completing loading .
ensures that saturation is restored and taxonomies are cleaned . also invalidates stages that depend on the saturation if it changed .
check consistency of the current ontology if this has not been done yet .
complete the taxonomy computation stage and the stages it depends on if it has not been done yet .
compute the inferred taxonomy of the named classes for the given ontology if it has not been done yet .
compute the inferred taxonomy of the named classes for the given ontology if it has not been done yet .
completes instance taxonomy computation stage and the stages that it depends on if this has not been done yet .
compute the inferred taxonomy of the named classes with instances if this has not been done yet .
compute the inferred taxonomy of the named classes with instances if this has not been done yet .
compute the inferred taxonomy of the object properties for the given ontology if it has not been done yet .
compute the inferred taxonomy of the object properties for the given ontology if it has not been done yet .
if the query results are not cached yet indexes the supplied class expression and if successful computes the query so that the results for this expressions are ready in { @link #classexpressionquerystate_ } .
decides whether the supplied ( possibly complex ) class expression is satisfiable . the query state is updated accordingly .
computes all atomic classes that are equivalent to the supplied ( possibly complex ) class expression . the query state is updated accordingly .
computes all atomic direct super - classes of the supplied ( possibly complex ) class expression . the query state is updated accordingly .
computes all atomic direct sub - classes of the supplied ( possibly complex ) class expression . the query state is updated accordingly .
computes all direct instances of the supplied ( possibly complex ) class expression . the query state is updated accordingly .
decides whether the supplied { @code axioms } are entailed by the currently loaded ontology .
decides whether the supplied { @code axiom } is entailed by the currently loaded ontology .
/ *
removes from { @link #todoentities_ } the entities which no longer occur in the ontology or for the context is already saturated ( thus consistency is already checked )
explains why an ontology inconsistency is entailed . if it is not entailed the returned proof is empty .
registers the supplied axioms for querying . if all necessary stages are run after calling this method for some axioms neither { @link #isentailed ( iterable ) } nor a { @link org . semanticweb . elk . reasoner . query . properentailmentqueryresult properentailmentqueryresult } for any of these axioms will throw { @link elkqueryexception } .
decides whether the supplied { @code axioms } are entailed . if some of the supplied axioms was not registered by { @link #registerqueries ( iterable ) } .
initialize the parameters of the computation for this stage ; this is the first thing to be done before stage is executed
clear the parameters of the computation for this stage ; this is the last thing to be done when the stage is executed *
marks this { @link abstractreasonerstage } as not completed ; this will require its execution next time unless { @link #setcompleted () } is called
invalidates this stage and all subsequent stages if not already done so
compute the hash for an entity node . this method implements a simple cache for nodes with unusually large numbers of members . this mainly covers the case where a huge number of classes is equal to owl : nothing due to modelling errors .
prunes { @link #toadd_ } . <p > <strong > { @code taxonomy_ } must not be { @code null } !< / strong >
returns collection that contains at least all individuals that are in ontology but either are removed from taxonomy or their type nodes in taxonomy were removed .
prunes { @link #toremove_ } . <p > <strong > { @code taxonomy_ } must not be { @code null } !< / strong >
returns collection that contains at least all individuals that are in taxonomy but either are removed from ontology or their context became not saturated .
obtain a { @link typenode } object for a given { @link elkclass } or { @code null } if none assigned .
@param factory the factory for creating conclusions
logs a warning message for unsupported owl api method
/ * methods required by the owlreasoner interface
computes the initial capacity of the table for storing elements . the capacity is the largest power of two that does not exceed the given value or { @link #maximum_capacity } .
removes the element at the given position of the table shifting if necessary other elements so that all elements can be found by linear probing .
removes the element at the given position of the table and the corresponding value at the same position shifting if necessary other elements and values so that all elements can be found by linear probing .
finds the position of the next element starting from the given position that would not be found by linear probing if the element at the given position are deleted . this should be the element whose index is smaller than this position .
tests if the set represented by given data array contains a given object .
adds the element to the set represented by given data array if it did not contain there already .
verifies that occurrence numbers are not negative
todo : perhaps convert using some visitor
adds all timers of the argument to the corresponding counters of this object . the timers should not be directly modified other than using this method during this operation . the timers in the argument will be reseted after this operation .
todo : simplify the implementation to use just one weak wrapper
add the values the corresponding values of the given timer
logging is switched off
creates stage that computes object property taxonomy .
@param factory the factory for creating conclusions
add an { @link owlthingcontextinitrule } to the given { @link modifiableontologyindex }
removes an { @link owlthingcontextinitrule } from the given { @link modifiableontologyindex }
associates the given key with the given value in the map defined by the keys and value arrays . if an entry with the key equal to the given one already exists in the map the value for this key will be overwritten with the given value .
remove the entry in the keys and values such that the key of the entry is equal to the given object according to the equality function .
increasing the capacity of the map
decreasing the capacity of the map
not a thread - safe method . shouldn t be invoked concurrently .
searches for the next non - { @code null } element after the given position before the start position
prints subclassof ( a owl : thing ) for all direct subclasses of owl : thing
prints class declarations
returns all super - nodes of a node whose direct super - nodes are <code > direct< / code > .
returns all sub - nodes of a node whose direct sub - nodes are <code > direct< / code > .
returns all instance nodes of the specified type node and all its sub - nodes .
creates a { @link chain } view of the value associated with the given key in the given { @link map } . the values of the map must be instances of the type that can be used in the { @link chain } interface . all operations with the returned { @link chain } such as addition or removal will be reflected accordingly in the corresponding value in the { @link map } .
finds and returns the entry in set that is structurally equal to the input entry if there is one . equality of entries is decided using { @link entry#structuralhashcode () } and { @link entry#structuralequals ( object ) } methods .
adds the given entry to this collection ; the entry is added even if a structurally equal entry ( modulo { @link entry#structuralhashcode () } and { @link entry#structuralequals ( object ) } ) is already present in the collection
removes and returns the entry in the set that is structurally equal to the specified entry . returns { @code null } if the set contains no such entry . equality of entries is decided using { @link entry#structuralhashcode () } and { @link entry#structuralequals ( object ) } methods .
rehashes the contents of this map into a new array with a new capacity . this method is called automatically when the number of entries in this set becomes below the { @link #undersize } or above the { @link #oversize } .
removes all entries from this set . the set will be empty after this call returns .
logging is switched off
@param factory the factory for creating conclusions
compute the combined hash code of several objects using their { @link #hashcode () } functions . the combined hash code depends on the order in which the objects are listed .
combine many hash codes with an associative commutative hash function . associativity ensures that the result of this functions can be further combined with other hash codes for getting the same result as if all hash codes had been combined in one step .
combine the hash codes of a collection of objects with an associative commutative hash function . associativity ensures that the result of this functions can be further combined with other hash codes for getting the same result as if all hash codes had been combined in one step .
combine the hash codes of a collection of objects with an associative commutative hash function . associativity ensures that the result of this functions can be further combined with other hash codes for getting the same result as if all hash codes had been combined in one step .
combine many hash codes into one in a way that depends on their order .
combine the hash codes of a collection of objects into one in a way that depends on their order .
combine the hash codes of a collection of objects into one in a way that depends on their order .
copies bytes from the input stream to the output stream
retrieves a set of resource names from a jar file ( the code source for the given java class )
@param factory the factory for creating conclusions
process the given input concurrently using the provided input processor . if the process has been interrupted this method can be called again to continue the computation .
combines the provided partial incompleteness monitors into the top - level monitor for reasoning tasks .
todo : parentheses and precedence of symbols
/ * read - write methods
removes the deleted rules from this {
commits the added rules to the main index and removes them from this {
sets the incremental mode for this { @code differentialindex } .
add { @link objectintersectionfromfirstconjunctrule } s for the given { @link modifiableindexedobjectintersectionof } in the given { @link modifiableontologyindex }
removes { @link objectintersectionfromfirstconjunctrule } s for the given { @link modifiableindexedobjectintersectionof } in the given { @link modifiableontologyindex }
todo : create a generic method for this operation ( used in other places )
@param factory the factory for creating conclusions
one - parameter public non - static methods called visit and declared in this class enumerate subclasses of { @link elkaxiom } ( parameter ) for which entailment queries are supported . this method returns { @code true } iff the subclass of { @link elkaxiom } specified as the parameter is a parameter type of some of these methods e . g . whether entailment query of such an { @link elkaxiom } is supported .
convenience method for printing a { @link taxonomy } to a file at the given location .
print the contents of the given { @link taxonomy } to the specified writer . expressions are ordered for generating the output ensuring that the output is deterministic .
convenience method for printing an { @link instancetaxonomy } to a file at the given location .
print the contents of the given { @link instancetaxonomy } to the specified writer . expressions are ordered for generating the output ensuring that the output is deterministic .
get a has string for the given { @link taxonomy } . besides possible hash collisions ( which have very low probability ) the hash string is the same for two inputs if and only if the inputs describe the same taxonomy . so it can be used to compare classification results .
process a taxonomy and write a normalized serialization .
process axioms related to one member of {
records that the given { @link classinference } has the given premise { @code classconclusion } that is not a conclusion of any inference in { @link #output_ } that do not use the conclusion of this { @link classinference } as one of the premises
compute the hash code of a taxonomy .
produces propagations of { @link indexedobjectsomevaluesfrom } over the given { @link indexedobjectproperty } in the given { @link context }
submitting a new input for processing . submitted input jobs are first buffered and then concurrently processed by workers . if the buffer is full the method blocks until new space is available .
printing an elk object through an appender .
clear all derived information for this {
prints differences with other { @link saturatedpropertychain }
increasing the capacity of the table
decreasing the capacity of the table
/ * checks that all system properties are set . we use system properties ( other than cmd args ) because they re easier to pass parameters into maven tests ( via surefire or failsafe plugins )
/ * a macro method reads system properties instantiates the task and runs it
/ * a macro method reads system properties instantiates the task collection and runs it
todo need a better name
@param factory the factory for creating conclusions
}
one - parameter public non - static methods called convert and declared in this class specify mapping between { @link owlobject } subclasses ( parameter ) and { @link elkobject } subclasses ( return type ) . this method returns a subclass of { @link elkobject } to which the subclass of { @link owlobject } specified as the parameter is mapped or { @code null } if it is not mapped .
@param visitor @return a { @link rulevisitor } that delegates the calls to the provided { @link rulevisitor } when for the { @link rule } which accepts this visitor { @link rule#istracingrule () } returns { @code true } . otherwise the { @link rulevisitor } returns { @code null } .
@param visitor the { @link subsumerdecompositionvisitor } used to execute the methods @param timer the { @link ruleapplicationtimer } used to mesure the time spent within the methods
process all pending { @link classinference } s of the given { @link context }
if the specified query was added to the index this method marks it as computed . does <strong > not< / strong > modify the cached query results .
if the specified query was added to the index this method marks it as not - computed and deletes the query results .
registers the supplied class expression for querying . if the expression has already been registered returns { @code false } . otherwise if this state did not keep track of the expression yet returns { @code true } . if all necessary stages are run after doing this the result retrieval methods e . g . { @link #issatisfiable ( elkclassexpression ) } will not throw { @link elkqueryexception } .
checks whether the supplied class expression is satisfiable if the result was already computed . if the class expression was not registered by { @link #registerquery ( elkclassexpression ) } or the appropriate stage was not completed yet throws { @link elkqueryexception } .
returns { @link node } containing all { @link elkclass } es equivalent to the supplied class expression if it is satisfiable . returns <code > null< / code > otherwise . if the class expression was not registered by { @link #registerquery ( elkclassexpression ) } or the appropriate stage was not completed yet throws { @link elkqueryexception } .
returns set of { @link node } s containing all { @link elkclass } es that are direct strict super - classes of the supplied class expression if it is satisfiable . returns <code > null< / code > otherwise . if the class expression was not registered by { @link #registerquery ( elkclassexpression ) } or the appropriate stage was not completed yet throws { @link elkqueryexception } .
returns set of { @link node } s containing all { @link elkclass } es that are direct strict sub - classes of the supplied class expression if it is satisfiable . returns <code > null< / code > otherwise . if the class expression was not registered by { @link #registerquery ( elkclassexpression ) } or the appropriate stage was not completed yet throws { @link elkqueryexception } .
returns set of { @link node } s containing all { @link elknamedindividual } s that are direct instances of the supplied class expression if it is satisfiable . returns <code > null< / code > otherwise . if the class expression was not registered by { @link #registerquery ( elkclassexpression ) } or the appropriate stage was not completed yet throws { @link elkqueryexception } .
logging is switched off
/ * can return a smaller subset than requested because one axiom can be randomly picked more than once
compute the hash code of a taxonomy .
add a direct super - class node . this method is not thread safe .
creates a new primary { @link saturationstatewriter } for the { @link saturationstate } to be used by an engine of this { @link ruleapplicationfactory } . this { @link saturationstatewriter } can be further extended and optimized .
some methods for checking correctness of arguments
concatenates several { @link iterable } s into one
splits the input { @link iterable } on batches with at most given number of elements .
splits the input { @link collection } on batches with at most given number of elements .
returns read - only view of the given set consisting of the elements satisfying a given condition if the number of such elements is known
prints key - value entries present in the first { @link multimap } but not in the second { @link multimap } using the given { @link writer } and prefixing all messages with a given prefix .
prints the elements present in the first { @link collection } but not in the second { @link collection } using the given { @link writer } and prefixing all messages with a given prefix .
a simple second - order map function for sets
returns the bit fragment that encodes the membership of an element for the given position in slices . the returned fragment is an integer whose lower bits correspond to whether an element occurs in the slice or not ( the lowest bit corresponds to the membership in slice = 0 next bit in slice = 1 etc )
changes the fragment that corresponds to the encoding of membership of an element at the given position . the change is specified by the bits of the last parameter : bit 1 means the corresponding value of the fragment should flip bit 0 means it should stay the same .
increasing the capacity of the table
decreasing the capacity of the table
inserts a given element into the given slice
removes the given object from the given slice
clears all slices of this {
generates inferences for subclassinclusion ( extendedrootmatchexpression rootmatchexpression ) where the arguments correspond to the values of respectively extendedrootmatch and rootmatch under { @link #toelkexpression ( indexedcontextrootmatch ) }
adds all counters of the argument to the corresponding counters of this object . the counters should not be directly modified other than using this method during this operation . the counter in the argument will be reseted after this operation .
log the start of a particular operation with info priority . this method should be used for long - running tasks and is mainly intended . multiple threads can independently log operations of the same name but ( obviously ) no single thread should use the same operation name to record the start and end of overlapping code .
log the start of a particular operation with the given priority . this method should be used for long - running tasks and is mainly intended . multiple threads can independently log operations of the same name but ( obviously ) no single thread should use the same operation name to record the start and end of overlapping code .
log the end of a particular operation the beginning of which has been logged using logoperationstart () using info priority .
log the end of a particular operation the beginning of which has been logged using logoperationstart () using the given logging priority .
log the current total memory usage with the specified priority .
this supposed to be the central place where the reasoner gets its configuration options
tries to shut down the reasoner within the specified time
helper method to get a { @link taxonomynode } from the taxonomy .
helper method to get an { @link instancenode } from the taxonomy .
helper method to get a { @link typenode } from the taxonomy .
helper method to get a { @link taxonomynode } from the property taxonomy .
return the { @code node } containing equivalent classes of the given { @link elkclassexpression } . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the { @code node } containing equivalent classes of the given { @link elkclassexpression } . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) subclasses of the given { @link elkclassexpression } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalent class of subclasses . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) subclasses of the given { @link elkclassexpression } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalent class of subclasses . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) superclasses of the given { @link elkclassexpression } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalent class of superclasses . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) superclasses of the given { @link elkclassexpression } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalent class of superclasses . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) sub - properties of the given { @link elkobjectproperty } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalence class of sub - properties . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) super - properties of the given { @link elkobjectproperty } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalence class of super - properties . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
return the ( direct or indirect ) instances of the given { @link elkclassexpression } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalent class of instances . calling of this method may trigger the computation of the realization if it has not been done yet .
return the ( direct or indirect ) instances of the given { @link elkclassexpression } as specified by the parameter . the method returns a set of { @link node } s each of which representing an equivalent class of instances . calling of this method may trigger the computation of the realization if it has not been done yet .
return the ( direct or indirect ) types of the given { @link elknamedindividual } . the method returns a set of { @link node } s each of which representing an equivalent class of types . calling of this method may trigger the computation of the realization if it has not been done yet .
check if the given { @link elkclassexpression } is satisfiable that is if it can possibly have instances . { @link elkclassexpression } s are not satisfiable if they are equivalent to { @code owl : nothing } . a satisfiable { @link elkclassexpression } is also called consistent or coherent . calling of this method may trigger the computation of the taxonomy if it has not been done yet .
prints the heading together with the separators
appends a string consisting of the given character to the first value so that when the values when formatted have in total { @value #format_width_ } characters
formats and the given values adding padding symbols if necessary . the given array may be modified but the values themselves are not modified .
creates a string of the given length consisting of the given character
defines an ordering on iris starting with { @link #owl_nothing } { @link #owl_thing } followed by the remaining iris in alphabetical order .
arguments are as follows : 0 - name of the reasoning task ( sat query classification consistency ) 1 - ontology path 2 - output path 3 - concept uri in case of sat
checks if { @link proofstep } is derived by { @link elkclassinclusionexistentialcomposition } inference where the last premise is derived from { @link elkpropertyinclusionoftransitiveobjectproperty }
prunes { @link #toadd_ } . <p > <strong > { @code taxonomy_ } must not be { @code null } !< / strong >
prunes { @link #toremove_ } . <p > <strong > { @code taxonomy_ } must not be { @code null } !< / strong >
add the values the corresponding values of the given counter
process the given input concurrently using the provided input processor . if the process has been interrupted this method can be called again to continue the computation .
from {
recursively converts object to xhtml data .
gets input parameter info which is part of the url mapping be it request parameters path variables or request body attributes .
recursively navigate to return a beanwrapper for the nested property path .
determines action input parameters for required url variables .
determines if the given class holds only one data item . can be useful to determine if a value should be rendered as scalar .
determines if the given string contains only 0 - 9 [ iso - latin - 1 ] or an optional leading + / - sign .
the relation type of the link .
the type parameter when present is a hint indicating what the media type of the result of dereferencing the link should be . note that this is only a hint ; for example it does not override the content - type header of a http response obtained by actually following the link . there must not be more than one type parameter in a link - value .
the hreflang parameter when present is a hint indicating what the language of the result of dereferencing the link should be . note that this is only a hint ; for example it does not override the content - language header of a http response obtained by actually following the link . multiple hreflang parameters on a single link - value indicate that multiple languages are available from the indicated resource .
the title parameter when present is used to label the destination of a link such that it can be used as a human - readable identifier ( e . g . a menu entry ) in the language indicated by the content - language header ( if present ) . the title parameter must not appear more than once in a given link - value ; occurrences after the first must be ignored by parsers .
the title * parameter can be used to encode the title label in a different character set and / or contain language information as per <a href = https : // tools . ietf . org / html / rfc5987 > rfc - 5987< / a > . the title * parameter must not appear more than once in a given link - value ; occurrences after the first must be ignored by parsers . if the parameter does not contain language information its language is indicated by the content - language header ( when present ) . <p > if both the title and title * parameters appear in a link - value processors should use the title * parameter s value . <p > the example below shows an instance of the link header encoding a link title using <a href = https : // tools . ietf . org / html / rfc2231 > rfc - 2231< / a > encoding to encode both non - ascii characters and language information . < / p > <pre > link : &lt ; / thebook / chapter2&gt ; rel = next ; title * = utf - 8 de n%c3%a4chstes%20kapitel < / pre >
the media parameter when present is used to indicate intended destination medium or media for style information ( see [ w3c . rec - html401 - 19991224 ] section 6 . 13 ) . note that this may be updated by [ w3c . cr - css3 - mediaqueries - 20090915 ] ) . its value must be quoted if it contains a semicolon ( ; ) or comma ( ) and there must not be more than one media parameter in a link - value .
the rev parameter has been used in the past to indicate that the semantics of the relationship are in the reverse direction . that is a link from a to b with rel = x expresses the same relationship as a link from b to a with rev = x . rev is deprecated by this specification because it often confuses authors and readers ; in most cases using a separate relation type is preferable .
by default the context of a link conveyed in the link header field is the iri of the requested resource . <p > when present the anchor parameter overrides this with another uri such as a fragment of this resource or a third resource ( i . e . when the anchor value is an absolute uri ) . if the anchor parameter s value is a relative uri parsers must resolve it as per [ rfc3986 ] section 5 . note that any base uri from the body s content is not applied .
adds link - extension params i . e . custom params which are not described in the web linking rfc .
affordance represented as http link header value . note that the href may be templated for convenience you can use { @link #getheadername () } to ensure a link or link - header is produced appropriately .
expands template variables arguments must satisfy all required template variables unsatisfied optional arguments will be removed .
expands template variables as far as possible unsatisfied variables will remain variables . this is primarily for manually created affordances . if the affordance has been created with linkto - methodon it should not be necessary to expand the affordance again .
expands template variables as far as possible unsatisfied variables will remain variables . this is primarily for manually created affordances . if the affordance has been created with linkto - methodon it should not be necessary to expand the affordance again .
allows to retrieve all rels defined for this affordance .
retrieves all revs for this affordance .
determines if the affordance has unsatisfied required variables . this allows to decide if the affordance can also be treated as a plain link without template variables if the caller omits all optional variables . serializers can use this to render it as a resource with optional search features .
creates a new { @link forwardedheader } from the given source .
the value of the parameter at sample invocation time formatted according to conversion configuration .
gets html5 parameter type for input field according to { @link type } annotation .
determines if request body input parameter has a hidden input property .
find out if property is included by searching through all annotations .
has any explicit include value or might have implicit includes because there is a hidden or readonly flag .
determines if request body input parameter should be excluded considering { @link input#exclude } .
is this action input parameter required based on the presence of a default value the parameter annotations and the kind of input parameter .
determines default value of request param or request header if available .
allows convenient access to multiple call values in case that this input parameter is an array or collection . make sure to check { @link #isarrayorcollection () } before calling this method .
gets request parameter name of this action input parameter .
writes bean description recursively .
gets property or class name in the current context either without prefix if the current vocab is the given vocabulary or prefixed otherwise .
}
gets exposed property or parameter name .
gets exposed property or parameter name for properties with an appropriate setter ( = write ) method .
recursively converts object to nodes of uber data .
converts single link to uber node .
converts single link to uber node .
renders input fields for bean properties of bean to add or update or patch .
returns { @link actioninputparameter } s contained in the method link .
todo move to propertyutil and remove current method for propertydescriptors cache search results
gets vocab for given bean .
gets explicitly defined terms e . g . on package class or mixin .
}
query consisting of expanded parameters and unexpanded parameters .
appends form and squashes non - get or post to post . if required adds _method field for handling by an appropriate filter such as spring s hiddenhttpmethodfilter .
classic submit or reset button .
renders input fields for bean properties of bean to add or update or patch .
appends simple input or select depending on availability of possible values .
creates a new { @link affordancebuilder } with a base of the mapping annotated to the given controller class . the additional parameters are used to fill up potentially available path variables in the class scope request mapping .
creates a new { @link affordancebuilder } with a base of the mapping annotated to the given controller class . the additional parameters are used to fill up potentially available path variables in the class scop request mapping .
builds affordance with one or multiple rels which must have been defined previously using { @link #rel ( string ) } or { @link #reverserel ( string string ) } . <p > the motivation for multiple rels is this statement in the web linking rfc - 5988 : &quot ; note that link - values can convey multiple links between the same target and context iris ; for example : < / p > <pre > link : &lt ; http : // example . org / &gt ; rel = start http : // example . net / relation / other < / pre > here the link to http : // example . org / has the registered relation type start and the extension relation type http : // example . net / relation / other . &quot ;
allows to define one or more reverse link relations ( a rev in terms of rfc - 5988 ) where the resource that has the affordance will be considered the object in a subject - predicate - object statement . <p > e . g . if you had a rel <code > ex : parent< / code > which connects a child to its father you could also use ex : parent on the father to point to the child by reverting the direction of ex : parent . this is mainly useful when you have no other way to express in your context that the direction of a relationship is inverted . < / p >
allows to define one or more reverse link relations ( a rev in terms of rfc - 5988 ) to collections in cases where the resource that has the affordance is not the object in a subject - predicate - object statement about each collection item . see { @link #rel ( typedresource string ) } for explanation .
allows to define one or more link relations for affordances that point to collections in cases where the resource that has the affordance is not the subject in a subject - predicate - object statement about each collection item . e . g . a product might have a loose relationship to ordered items where it can be posted but the ordered items do not belong to the product but to an order . you can express that by saying : <pre > typedresource order = new typedresource ( http : // schema . org / order ) ; // holds the ordered items resource&lt ; product&gt ; product = new resource&lt ; &gt ; () ; // has a loose relationship to ordered items product . add ( linkto ( methodon ( ordercontroller . class ) . postordereditem () . rel ( order ordereditem )) ; // order has ordered items not product has ordered items < / pre > if the order doesn t exist yet it cannot be identified . in that case you may pass null to express that
allows to define link header params ( not uritemplate variables ) .
returns a { @link uricomponentsbuilder } obtained from the current servlet mapping with scheme tweaked in case the request contains an { @code x - forwarded - ssl } header which is not ( yet ) supported by the underlying { @link uricomponentsbuilder } . if no { @link requestcontextholder } exists ( you re outside a spring web call ) fall back to relative uris .
copy of { @link servleturicomponentsbuilder#getcurrentrequest () } until spr - 10110 gets fixed .
adds actiondescriptors of the given affordancebuilder to this affordancebuilder .
returns the template as uri components without variable expansion .
expands the template using given parameters
expands the template using given parameters
applies parameters to template variables .
strips all variables which are not required by any of the given action descriptors . if no action descriptors are given nothing will be stripped .
gets first child of this uber node having the given name attribute .
gets first child of this uber node having the given rel attribute .
allows iterating over children of this uber node which have a data attribute .
works around some type inference limitations of java 8 .
returns a new persistenthashset of the values . the vararg version of this method is { @link org . organicdesign . fp . staticimports#set ( object ... ) } if the input contains duplicate elements later values overwrite earlier ones .
works around some type inference limitations of java 8 .
works around some type inference limitations of java 8 .
returns a new persistenthashmap of the given keys and their paired values skipping any null entries .
returns a new persistenthashmap of the given keys and their paired values . there is also a varargs version of this method : { @link org . organicdesign . fp . staticimports#map ( map . entry ... ) } . use the { @link org . organicdesign . fp . staticimports#tup ( object object ) } method to define key / value pairs briefly and easily .
/ * public static void main ( string [] args ) { try { arraylist words = new arraylist () ; scanner s = new scanner ( new file ( args [ 0 ] )) ; s . usedelimiter ( pattern . compile ( \\ w )) ; while ( s . hasnext () ) { string word = s . next () ; words . add ( word ) ; } system . out . println ( words : + words . size () ) ; immap map = persistenthashmap . empty ; immap map = new persistenthashmap () ; map ht = new hashtable () ; map ht = new hashmap () ; random rand ;
}
returns a new persistenttreemap of the given comparable keys and their paired values skipping any null entries .
returns a new persistenttreemap of the specified comparator and the given key / value pairs .
be extremely careful with this because it uses the default comparator which only works for items that implement comparable ( have a natural ordering ) . an attempt to use it with other items will blow up at runtime . either a withcomparator () method will be added or this will be removed .
returns a new empty persistenttreemap that will use the specified comparator .
returns a view of the mappings contained in this map . the set should actually contain unmodmap . unentry items but that return signature is illegal in java so you ll just have to remember .
{
{
returns the comparator used to order the keys in this map or null if it uses fn2 . default_comparator ( for compatibility with java . util . sortedmap ) .
{
{
returns the last key in this map or throws a nosuchelementexception if the map is empty .
returns the last key / value pair in this map or null if the map is empty .
returns an option of the key / value pair matching the given key or option . none () if the key is not found .
}
node<k v > concat ( node<k1 v1 > left node<k2 v2 > right ) {
static factory methods
than lazily evaluated and cached linked - list sequence model .
}
}
the number of items to drop from the beginning of the output .
provides a way to collect the results of the transformation .
thit implementation should be correct but could be slow in the case where previous operations are slow and the terminatewhen operation is fast and terminates early . it actually renders items to a mutable list then runs through the list performing the requested reduction checking for early termination on the result . if you can to a takewhile () or take () earlier in the transform chain instead of doing it here always do that . if you really need early termination based on the * result * of a fold and the operations are expensive or the input is huge try using a view instead . if you don t care about those things then this method is perfect for you .
returns a new persistenttreeset of the given comparator . always use this instead of starting with empty () because there is no way to assign a comparator to an existing set .
returns a new persistenttreeset of the given comparator and items .
returns a new persistenttreeset of the given comparable items .
{
{
{
{
{
{
{
public static factory method
map . entry factory method
returns a new rrbtree minus the given item ( all items to the right are shifted left one ) this is o ( log n ) .
helper function to avoid type warnings .
=============================== debugging and pretty - printing ===============================
if sel is managed correctly it ensures that the cast is accurate .
}
though this overrides list . contains ( object o ) it is effectively a convenience method for calling contains ( int i ) . therefore it only accepts integers longs bigintegers and strings that parse as signed decimal integers . it does not accept numbers since they can t easily be checked for truncation and floating - point might not round properly with respect to bounds or might not make sense if you are using your range to define a set of integers . handles truncation ( returns false ) for the types it accepts . throws exceptions for types it does not accept .
unlike most implementations of list this method has excellent o ( 1 ) performance! {
{
{
use this to prevent duplicate runtime types .
public static factory method
returns a new mutable vector . for some reason calling empty () . mutable () sometimes requires an explicit type parameter in java so this convenience method works around that .
public static factory method to create a vector from an iterable . a varargs version of this method is : {
returns the array ( of type e ) from the leaf node indicated by the given index .
returns the item specified by the given index .
{
inserts a new item at the end of the vecsicle .
efficiently adds items to the end of this persistentvector .
{
}
public static factory method
returns a new persistenthashmap of the given keys and their paired values . use the { @link staticimports#tup ( object object ) } method to define those key / value pairs briefly and easily . this data definition method is one of the few methods in this project that support varargs .
returns a new mutablemap of the given keys and their paired values . use the { @link staticimports#tup ( object object ) } method to define those key / value pairs briefly and easily . this data definition method is one of the few methods in this project that support varargs .
returns a mutable rrb tree {
returns a new mutableset of the values . this data definition method is one of the few methods in this project that support varargs . if the input contains duplicate elements later values overwrite earlier ones .
returns a mutablevector of the given items . this data definition method is one of the few methods in this project that support varargs .
returns a new immutable rrb tree { @link imrrbt } of the given items . an rrb tree is an immutable list that supports random inserts split and join ( the persistentvector does not ) . if you build it entirely with random inserts then the rrb tree get () method may be about 5x slower . otherwise performance is about the same .
returns a new persistenthashset of the values . this data definition method is one of the few methods in this project that support varargs . if the input contains duplicate elements later values overwrite earlier ones .
returns a new persistenttreemap of the specified comparator and the given key / value pairs . use the tup () method to define those key / value pairs briefly and easily . the keys are sorted according to the comparator you provide .
returns a new persistenttreeset of the given comparator and items .
returns a new persistenttreeset of the given comparable items .
returns a new persistentvector of the given items . this data definition method is one of the few methods in this project that support varargs .
if you need to wrap a regular java array outside this project to perform a transformation on it this method is the most convenient efficient way to do so .
wrap a string ( or charsequence ) to perform a character - by - character transformation on it .
creates a new stringbuilder with the given number of spaces and returns it .
there is arrays . tostring but this is intended to produce cymling code some day .
todo : we need one of these for each type of primitive for pretty - printing without commas .
construct a lazyref from the given initialization function .
this whole method is synchronized on the advice of goetz2006 p . 347
helper function to avoid type warnings .
returns a new array one longer than the given one with the specified item inserted at the specified index .
returns a new array containing the first n items of the given array .
called splice but handles precat ( idx = 0 ) and concat ( idx = origitems . length ) .
}
only call this if the array actually needs to be split ( 0 &lt ; splitpoint &lt ; orig . length ) .
only call this if the array actually needs to be split ( 0 &lt ; splitpoint &lt ; orig . length ) .
/ * ( non - javadoc )
some operations require that the transaction be suspended
verifies if the wrapped transaction is active and if dissociates it from the thread if needed
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
get a <code > resourceadaptorentitystate< / code > object from an integer value .
builds a service component contained in the specified du jar file with the specified and adds it to the specified deployable unit .
recursively walk a directory tree and return a list of all jars files found ; the list is sorted using file . compareto .
directory is valid if it exists does not represent a file and can be read .
create the links with possible interfaces
create the inheritance link with the sbb absract class provided by the sbb developer
add a concrete method invoking the interceptor <b > interceptorname < / b > with the same parameters name return type as the method <b > method < / b >
transform an array class to its string representation <br > example : string [] - > [ ljava . lang . string ;
get the jvm representation of the primitives types <br > exemple : int - > i boolean - > z and so on ...
copy declared methods from one class to another
copy methods to a class
/ * ( non - javadoc )
parser for the deployment descriptor . minimal version obtained from container .
get an <code > addressplan< / code > object from an integer value .
get an <code > addressplan< / code > object from a string value .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
determine whether the specified notification should be delivered to notification listeners using this notification filter .
builds a list of {
tmp dev methods
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
removes the specified sbb entity but without changing to sbb s class loader first .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
indicates if notifications are enabled for the specified parameter name
/ * ( non - javadoc )
/ * ( non - javadoc )
retrieves the set of ra entity link names referenced by the service componen which do not exist
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
install a service into slee
uninstall a service .
verifies if the specified ra entity link name is referenced by a non inactive service .
/ * ( non - javadoc )
adds the time for an event routing with a specific { @link eventtypeid } .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
get an <code > alarmlevel< / code > object from an integer value .
get an <code > alarmlevel< / code > object from a string value .
determine if this alarmlevel object represents a level that is higher than some other alarmlevel object . for the purposes of the comparison the following order from highest to lowest severity is assumed for alarm levels : <ul > <li > clear <li > critical <li > major <li > warning <li > indeterminate <li > minor < / ul >
}
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * creates the default usage parameter set
/ * ( non - javadoc )
/ * ( non - javadoc )
this method returns a list containing the names of the named sbb usage parameter sets that belong to the sbb specified by the sbbid argument and the service represented by the serviceusagembean object .
/ * ( non - javadoc )
/ * ( non - javadoc )
resets the usage parameters of only the sbb specified by the sbbid argument argument ( within the service represented by the serviceusagembean object ) .
resets the usage parameters of all sbbs within the service represented by the serviceusagembean object . the slee sets counter - type usage parameters to zero and removes all samples from sample - type usage parameters .
convenience method to retrieve the { @link abstractusageparameterset } for the specified sbb and name
lifecycle methods
sbb abstract class ( general rule  methods cannot start neither with ejb nor sbb ) <ul > <li > ( 1 . 1 ? ) must have package declaration <li > must implement in some way javax . slee . sbb ( only methods from interface can have sbb prefix ) <ul > <li > each method defined must be implemented as public  not abstract final or static < / ul > <li > must be public and abstract <li > must have public no arg constructor <li > must implement sbbexceptionthrown method <ul > <li > public not abstract final or static no return type 3 arguments : java . lang . exception java . lang . object javax . slee . activitycontextinterface < / ul > <li > must implement sbbrolledback <ul > <li > method must be public not abstract final or static <li > no return type <li > with single argument - javax . slee . roledbackcontext < / ul > <li > there is no finalize method < / ul >
this method checks for presence of
this method validates all methods in aci interface : <ul > <li > set / get methods and parameter names as in cmp fields decalration <li > methods must <ul > <li > be public abstract <li > setters must have one param <li > getters return type must match setter type <li > allowe types are : primitives and serilizable types < / ul > < / ul > <br > sbb descriptor provides method to obtain aci field names if this test passes it means that all fields there should be correct and can be used to verify aliases
see section 1 . 3 of jslee 1 . 1 specs
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
get a <code > servicestate< / code > object from an integer value .
get a <code > servicestate< / code > object from an integer value .
get an instance of a <code > sleeprovider< / code > peer class . this method is equivalent to {
get an instance of a <code > sleeprovider< / code > peer class using the specified class loader .
special handling of serialization
special handling of deserialization
get a collection of profileid objects that identify all the profiles contained in the specified profile table . the collection returned is immutable . any attempt to modify it either directly or indirectly will result in a java . lang . unsupportedoperationexception being thrown .
get a profiletableactivity object for a profile table .
get a profileid object that identifies the profile contained in the specified profile table where the specified profile attribute is set to the specified value . in the case of a profile attribute of an array type the type of the specified value must be the base component type of the array not the array type itself and the slee will return the profile identifier of any profile that contains the value within the array .
/ * ( non - javadoc )
method to display result of operation .
default implementation .
/ * ( non - javadoc )
determine whether the specified notification should be delivered to notification listeners using this notification filter .
private
determine whether the specified notification should be delivered to notification listeners using this notification filter .
executes a non transacted fire event operation .
/ * generates the profile entity factory class
binds the specified aci name with the specified activity context handle
unbinds the specified aci name with the specified activity context id
lookup of the activity context id bound to the specified aci name
retrieves a map of the bindings . key is the aci name and value is the activity context handle
/ * ( non - javadoc )
retrieves the next sbb entity to handle the event .
get a <code > tracelevel< / code > object from an integer value .
get a <code > tracelevel< / code > object from a string value .
determine if this tracelevel object represents a level that is higher than some other tracelevel object . for the purposes of the comparison off is considered a higher level than severe and finest is the lowest level .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
check which combination ( see jslee 1 . 0 spec section 10 . 5 . 2 ) matches the sbb developer s profile specification
validates an invocation of the { @link sbblocalobject } .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
builds the du component from a jar with the specified file name contained in the specified du jar file . the component is built in the specified deployment dir .
extracts the file with name <code > filename< / code > out of the <code > containingjar< / code > archive and stores it in <code > dstdir< / code > .
this method will extract all the files in the jar file
pipes data from the input stream into the output stream .
puts an object in cache data
tries to attaches an sbb entity
detaches an sbb entity
verifies if there at least one sbb entity attached
return a set with all sbb entities attached .
attaches a timer
detaches a timer
verifies if there at least one timer attached
returns the set of timers attached to the ac
adds the specified name to the set of names bound to the ac
removes the specified name from the set of names bound to the ac
verifies if there at least one name bound to the ac
returns the set of names bound to the ac
sets the aci cmp attribute
retrieves the aci cmp attribute
retrieves a map copy of the aci attributes set
fixme : add check for access?
/ * ( non - javadoc )
/ * ( non - javadoc )
initiates the notification info for usage mbeans
send the notification .
creates an instance of an { @link usagenotification } for the specified args . this operation is exposed to allow it be overriden by { @link sbbusagembean } impl .
retrieves the jain slee specs descriptor
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
downloads a remote du to a local folder
updates the list of components already deployed to slee .
method for installing a deployable unit into slee .
method for uninstalling a deployable unit into slee .
sets the du as not installed and remove it from waiting list if present there . also tries to undeploy du s waiting for dependencies to be removed .
method for performing the actions needed for ( un ) deployment .
method for showing current status of the deployment manager .
callback for {
if the message should be logged convert the jdk 1 . 4 logrecord to a log4j message .
get the log4j logger corresponding to the java . util . logger . logrecord
retrieves the component ids for components that refers the specified component
/ * ( non - javadoc )
/ * ( non - javadoc )
get a <code > timerpreservemissed< / code > object from an integer value .
get a <code > timerpreservemissed< / code > object from a string value .
retrieves a set containing sbb entity ids in the factory cache data
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
special handling of serialization
special handling of deserialization
/ * ( non - javadoc )
generic for all calls
newglobalpolicyholder ) {
private inputstream getstream ( url url ) throws ioexception {
this function must convert code source passed . meaning it must normalize url . for instance security framework may pass url that conceptualy matches pat specified policy files but comparison wont match . see url belowe . <ul > <li > <b > 1 - < / b > jar : file : / d : / java / servers / jboss - 5 . 0 . 0 . ga / server / default / deploy / restcomm . sar / lib / jar . jar! / < / li > <li > <b > 2 - < / b > file : / d : / java / servers / jboss - 5 . 0 . 0 . ga / server / default / deploy / - < / li > < / ul > url 1 is passed from security framework as source of loaded classes . however it is not matched by second one ( and is should )
some methods to expose info about what is goign on .
/ * ( non - javadoc )
create a new instance of this object and set the sbbcontext this places it into the object pool .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ *
retrieves the {
retrieves the {
determines if profile is in back end storage == visible to other compoenents than mbean if null is passed as argumetn it must check for any other than defualt?
this method renames profile table in backend storage . note : it should not be called directly use sleeprofiletablemanager instead!
triggers remove operation on this profile table .
retrieves the jain slee specs descriptor
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
updates the ra entity config properties
signals that the container is in running state
signals that the container is in stopping state
activates the ra entity
deactivates the ra entity
schedules the ending of all the entity activities this is needed on ra entity deactivation or slee container stop once the process ends it will invoke allactivitiesended to complete those processes
checks if the entity has activities besides the one passed as parameter ( if not null ) .
removes the entity it will unconfigure and unset the ra context the entity object can not be reused
retrieves the ra interface for this entity and the specified ra type
indicates a service was activated the entity will forward this notification to the ra object .
if it is a handle reference it gets the referred handle
callback to notify the entity and possibly the ra object informing activity handled ended .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
updates the ra configuration .
merges the current properties values with the new ones and uses the ra to verify the configuration
/ * ( non - javadoc )
requests the stopping of the ra object . if the operation succeeds the ra will transition to stopping state .
requests the deactivation of the ra object . if the operation succeeds the ra will transition to inactive state .
unconfigures the ra object
unsets the context of the ra object .
unsets the ft context of the ra object .
builds the profile attribute map using the cmp interface class
retrieves the jain slee specs descriptor
the real logic to resume the event context
/ * ( non - javadoc )
retrieves a set containing all activity context handles in the factory s cache data
/ * ( non - javadoc )
compare this notification source with the specified object for order . returns a negative integer zero or a positive integer if this object is less than equal to or greater than the specified object . <p > if <code > obj< / code > is a <code > profiletablenotification< / code > order is determined by comparing the encapsulated profile table name . otherwise if <code > obj< / code > is a <code > notificationsource< / code > ordering is determined by comparing the class name of this class with the class name of <code > obj< / code > .
create a new instance of this object and set the sbbcontext this places it into the object pool .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
removes the mbean
creates the usage param ( and its mbean ) for the specified name
retrieves the object name for the usage param mbean with the specified name
removes the usage param ( and its mbean ) for the specified name
convenience method to retrieve the { @link abstractusageparameterset } for the specified param set name .
/ * ( non - javadoc )
decorate the abstract class
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
retrieves the {
the logic to fire an event from an slee 1 . 0 sbb
the logic to fire an event from an slee 1 . 1 sbb
retrieves a profile given the cmp method name and profile id
sbb usage params
/ * ( non - javadoc )
/ * ( non - javadoc )
compute a convergence name for the sbb for the given slee event . convergence names are used to instantiate the sbb . i really ought to move this to sleecontainer . java
returns the set of names representing valid full access ( read&write ) javabean properties declared in the given class . note : the implementation is not as strict as in introspector ( @see java . beans . introspector#gettargetpropertyinfo () ) . it probably should be .
return the string allowing one to create an object ( integer boolean byte ... ) from a primitive type given in parameter .
return the string allowing one to create an object ( integer boolean byte ... ) from a primitive type given in parameter .
return the string allowing one to create a primitive type ( integer boolean byte ... ) from a primitive type given in parameter .
retrieve all abstract methods from a class
retrieve all concrete ( non - abstract and non - native ) methods from a class stored under key name + signature
retrieve all concrete ( non - abstract and non - native ) methods names from a class
collects all methods of the interfaces implemented / extended by the specified {
retrieve all methods from an interface including super interfaces except the ones specified in the provided map
creates an object pool for the specified profile table . if a transaction manager is used then and if the tx rollbacks the pool will be removed .
removes the object pool for the specified profile table . if a transaction manager is used then the removal is only after the tx commit .
removes the pool for the specified ids
---- mbean methods
/ * private class dataremovaclusterlistener implements dataremovallistener {
/ * ( non - javadoc )
{
{
determine whether the specified notification should be delivered to notification listeners using this notification filter .
get an <code > addresspresentation< / code > object from an integer value .
get an <code > addresspresentation< / code > object from a string value .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
non mbean - used only internal those methods are not exposed via jmx
this methods raises alarm . it must not receive alarmlevel . clear it has to be filtered .
usage methods . here we can be static for sure . rest must be tested .
/ * ( non - javadoc )
/ * ( non - javadoc )
retrieves the jain slee specs event type descriptor
signals that the specified {
signals that the specified {
method for deciding whether or not to accept the file .
initializer method for accepted files . will parse descriptors at this point .
this is where the fun begins . time to deploy!
fun has ended . time to undeploy .
mbean operation for getting deployer status .
------------------------------------------------------------
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
executes actions scheduled after commit succeeds
executes actions scheduled to run first after commit succeeds
executes actions scheduled for after a rollback
executes actions scheduled for before commit
executes actions scheduled for before commit at first
this method raturns tracer names of tracers that have been requested directly from notificationsource ( like through sbbcontext racontext etc )
this method returns tracer names that have been defined explicitly via settracelevel from tracembean
this method can be called multiple times .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
generates the profile mbean interface
this method generates concrete class of mbean impl
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
removes all replicated data
register the property editors for jboss jmx console so non string slee api types can be used in specs mbeans methods as args
generates classes for a slee component which defines usage parameters
compare this component identifier with the specified component identifier for order . returns a negative integer zero or a positive integer if this object is less than equal to or greater than the specified object . <p > component ordering is determined by comparing the component identifier attributes in the following order : <ol > <li > component type ( nb . any subclass of <code > componentid< / code > may be safely compared without causing a <code > classcastexception< / code > ) <li > component name <li > component vendor <li > component version < / ol >
private
retrieves the object pool for the specified sbb and service .
creates an object pool for the specified service and sbb . if a transaction manager is used then and if the tx rollbacks the pool will be removed .
removes the pool for the specified ids
/ * ( non - javadoc )
executes a non transacted end activity operation .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
checks the parameters of startactivity * methods
start activity logic independent of transaction management .
end activity logic independent of transaction management .
/ * ( non - javadoc )
checks that fire event methods can be invoked
event firing logic independent of transaction management .
/ * ( non - javadoc )
/ * ( non - javadoc )
generate the sbb local object class
generates the concrete methods of the class
user should overide it to provide different name for instance for boolean \ is \ prefix
this method is called to convert optarg from string form if no conversion is needed it should return passed object .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
determine whether the specified notification should be delivered to notification listeners using this notification filter .
set the profile table and profile referenced by this profile identifier to new values .
get an <code > address< / code > object containing the address form of the profile identified by this profile identifier .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
get a <code > sleestate< / code > object from an integer value .
get a <code > sleestate< / code > object from a string value .
protected deployableunitscard deployableunitscard ;
determine whether the specified notification should be delivered to notification listeners using this notification filter .
private
installs the specified {
installs the specified {
uninstalls the specified {
uninstalls the specified {
the contains method . this method returns true if the sbb entity represented by the sbb local object specified by the input argument is a member of this child relation . if the method argument is not an sbb local object is an invalid sbb local object or is an sbb local object whose underlying sbb entity is not a member of this child relation then this method returns false .
/ * ( non - javadoc )
spec page 62 the remove methods : clear remove removeall and retainall . o these methods may remove sbb entities from the child relation . the input argument specifies which sbb entities will be removed from the child relation or retained in the child relation by specifying the sbb local object or collection of sbb local objects that represent the sbb entities to be removed or retained . o removing an sbb entity from a child relation initiates a cascading removal of the sbb entity tree rooted by the sbb entity similar to invoking the remove method on an sbb local object that represents the sbb entity .
this method returns true if all sbb entities represented by the sbb local objects in the collection specified by the input argument are members of this child relation . if the collection contains an object that is not an sbb local object an sbb local object that is invalid or an sbb local object whose underlying sbb entity is not a member of this child relation then this method returns false .
removing an sbb entity from a child relation initiates a cascading removal of the sbb entity tree rooted by the sbb entity similar to invoking the remove method on an sbb local object that represents the sbb entity .
/ * ( non - javadoc )
/ * ( non - javadoc )
extension methods
/ * ( non - javadoc )
get a <code > failurereason< / code > object from an integer value . <p > this method returns the singleton objects for the failure reasons defined in this class . for all vendor - defined reason codes ( those greater than 0 in value ) a non - unique <code > failurereason< / code > object is return encapsulating that value .
get a jmx object name property string that uniquely identifies the specified slee internal component or subsystem suitable for inclusion in the object name of a usage mbean . this method makes use of the {
compare this notification source with the specified object for order . returns a negative integer zero or a positive integer if this object is less than equal to or greater than the specified object . <p > if <code > obj< / code > is a <code > subsystemnotification< / code > order is determined by comparing the encapsulated subsystem name . otherwise if <code > obj< / code > is a <code > notificationsource< / code > ordering is determined by comparing the class name of this class with the class name of <code > obj< / code > . <p >
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
stores the attr value converting and storing in the string field of the entity
/ * ( non - javadoc )
determine if this level object represents a level that is higher or more severe that some other level object . for the purposes of the comparison off is considered a higher level than severe .
resolve deserialisation references so that the singleton property of each enumerated object is preserved .
parser for the deployment config xml .
builds a list of {
cleans up the class pool cache
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
adds call to this profile .
retrieves a profile object for the table and specified profile name there is only one profile object per profile entity per transaction
adds transactional actions to the active transaction to passivate a profile object .
/ * ( non - javadoc )
should not be called when cmp interface validation fails cause it depends on result of it
shoudl not be run if other interfaces vaildation fails .
validated descriptor against some basic constraints : all references are correct some fields are declaredproperly no double definitions if proper elements are present - for instance some elements exclude others .
checks expression to check if collator refs and cmp fields are referenced correctly . type constraints are checked later . since in case of lack of parameter we have to relly totaly on cmp field type . additionaly this check if parameter and value are present together .
set the element as text value parse it and setvalue . the separator is cid_separator
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
------- management operations
generate the activity context interface class
generates the concrete methods of the class it generates a specific method implementation for the javax . slee . activitycontextinterface methods for the methods coming from the activitycontextinterface developer the call is routed to the base asbtract class
todo
/ * public string getloggingconfiguration ( string profile ) throws managementexception { try { return readfile ( getlog4jpath ( profile )) ; } catch ( ioexception ioe ) { throw new managementexception ( failed to read log4j configuration file for profile + profile + . does it exists? ioe ) ; } }
compare this alarm with the specified object for order . returns a negative integer zero or a positive integer if this object is less than equal to or greater than the specified object . <p > alarm ordering is determined by comparing unique the alarm identifier .
retrieves the jain slee specs descriptor
creates an instance of the { @link configproperties } for this component
retrieve the { @link activityflags } for this activity context
set a shared data item for the aci
add a naming binding to this activity context .
this is called to release all the name bindings after the activity end event is delivered to the sbb .
add the given name to the set of activity context names that we are bound to . the ac naming facility implicitly ends the activity after all names are unbound .
attach the given timer to the current activity context .
detach timer
end event has been delivered on the activity context .
attach an sbb entity to this ac .
detach the sbb entity
get an ordered copy of the set of sbbs attached to this ac . the ordering is by sbb priority .
--- private helpers
/ * ( non - javadoc )
ends the activity context .
adder method for a deployable component .
method for obtaining the external dependencies for this du if any .
method for checking if the du has all the dependencies needed to be deployed .
method for checking if this du contains any component that is already deployed .
getter for the install actions .
getter for the uninstall actions .
method for checking if this du components are referred by any others .
parser for the deployment config xml .
closes and unregisters the mbean for the specified profile if exists
retrieves the jmx objectname for a profile given its profile name and profile table name
moves to the write mode using specified object . the current java transaction will be suspended .
/ * ( non - javadoc )
/ * ( non - javadoc ) @see javax . slee . profile . profilembean#commitprofile ()
logic to execute before invoking a cmp setter method on the mbean
logic to execute after invoking a cmp setter method on the mbean
logic to execute before invoking a cmp getter method on the mbean
logic to execute after invoking a cmp getter method on the mbean
logic to execute before invoking a management method on the mbean
logic to execute after invoking a management method on the mbean
handles a { @link throwable } which was the result of a management method invocation
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
get a jmx object name property string that uniquely identifies the specified resource adaptor entity suitable for inclusion in the object name of a usage mbean . this method makes use of the {
compare this notification source with the specified object for order . returns a negative integer zero or a positive integer if this object is less than equal to or greater than the specified object . <p > if <code > obj< / code > is a <code > resourceadaptorentitynotification< / code > order is determined by comparing the encapsulated resource adaptor entity name . otherwise if <code > obj< / code > is a <code > notificationsource< / code > ordering is determined by comparing the class name of this class with the class name of <code > obj< / code > .
get a jmx object name property string that uniquely identifies the specified service and sbb suitable for inclusion in the object name of a usage mbean . this method makes use of the {
compare this notification source with the specified object for order . returns a negative integer zero or a positive integer if this object is less than equal to or greater than the specified object . <p > if <code > obj< / code > is an <code > sbbnotification< / code > order is determined by comparing first the encapsulated service component identifier and then if the service component identifiers are equal the encapsulated sbb component identifier . otherwise if <code > obj< / code > is a <code > notificationsource< / code > ordering is determined by comparing the class name of this class with the class name of <code > obj< / code > .
returns an unmodifiable set with all { @link abstractsleecomponent } s of the deployable unit .
deletes the whole path going through directories
returns the { @link deployableunitdescriptor } for this deployable unit .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
create a constructor . this method simply records the input parameters in appropriately named fields .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
generate the concrete sbb class
generates info that indicates if a method from {
creates a constructor with parameters <br > for every parameter a field of the same class is created in the concrete class and each field is gonna be initialized with the corresponding parameter
create a default constructor on the sbb concrete class
create a default usage parameter getter and setter .
create a method to retrive the entity from the sbbobject .
create the cmp field setters and getters
create the implementation of the fire event methods
create the get child relation method ( this method redirects the call to a child relation interceptor )
create the get profile cmp method ( this method redirects the call to a profile cmp interceptor )
create the narrow method to get the activity context interface
add a query expression to this composite expression .
check whether the specified expression contains a reference either direct or indirect to this expression .
place an object into the nonserializablefactory namespace for subsequent access by getobject . there cannot be an already existing binding for key .
remove a binding from the nonserializablefactory map .
remove a binding from the nonserializablefactory map .
a convience method that simplifies the process of rebinding a non - zerializable object into a jndi context . this version binds the target object into the default intitialcontext using name path .
--- end objectfactory interface methods
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
private -------------------------------------------------------
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
check whether the specified expression contains a reference either direct or indirect to this expression .
decorate the abstract sbb class
invokers for the simple types
create a constructor . this method simply records the input parameters in appropriately named fields .
/ * ( non - javadoc )
--- operations
this is main place where slee is accessed . this functions lists ac in various different ways . it can either return object [] of arrays representing ac of simple object [] that in fact contains string objects representing ids of activity contexts
/ * fixme uncomment code when everything is commited
not exist?
computes the real aci data field name
sets an sbb aci data field value
retrieves an sbb aci data field value
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
invoked from pool .
initialize state from default profile
invoked when pool removes object
retrieves the local representation for this profile object
fires a profile added or updated event if the profile object state is ready and the persistent state is dirty
retrieves the profile cmp slee 1 . 0 wrapper for this profile object
/ * ( non - javadoc )
/ * ( non - javadoc )
retrieves the jain slee specs descriptor
creates a class with the desired name and linked to the mentioned interfaces .
create the links with possible interfaces
create the inheritance link with the absract class provided by the developer
adds a field of the desired type to the declaring class .
adds a field of the desired type to the declaring class .
adds a field of the desired type to the declaring class .
generates a getter for the field ( get<fieldname > ) and adds it to the declaring class .
generates a setter for the field ( get<fieldname > ) and adds it to the declaring class .
generates getter and setter for the field ( get / set<fieldname > ) and adds them to the declaring class .
adds the selected annotation to the object along with the specified membervalues .
private method to add member values to annotation
this method returns the aci for the specified activity if exists it should be invoked by each impl of methods of an ra type aci factory .
retrieves the component javassist class pool
specifies the the deployable unit this component belongs . this method also sets the reverse relation adding the component to the deployable unit
indicates that the component was undeployed and thus should clean up any resources
/ * ( non - javadoc )
/ * ( non - javadoc )
creates a { @link receivableserviceimpl } instance from the specified service component
executes a non transacted start activity operation .
get the {
#####################
######################
this methods validate component which has usage parameter interface . its interface for methods . in case of 1 . 1 components parameters list must match evey method defined . in case of 1 . 0 components parameters list must be empty . it does not validate get usage method those
searches for provided interface in passed class object - it can be class or interface . if it finds it return instance of it .
returns methods of this interface and all super interfaces
}
creates an inputsource with a systemid corresponding to a local dtd file .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
this checks if tracer name is ok . it must not be null ;
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
method that does lookup and creates plos
installs a jain slee du .
loads all non slee generated classes from the component class loader to the component those will be needed for validation or runtime purposes
checks if all dependencies of a du component exists
creates the directory that will be used for unpacking the child jars for a given du .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
delivers to sbbs an event off the top of the queue for an activity context
/ * ( non - javadoc )
/ * ( non - javadoc )
generates the concrete profile entity class and a profile entity array attr value class for each attribute that is an array
generates a class that extends {
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
retrieves the entity manager for the current tx and the framework profile spec
start the slee container
shutdown the slee processes . the spec requires that system . exit () be called before this methods returns . we are not convinced this is necessary yet . a trivial implementation would be to make a call to the jboss server shutdown ()
/ * ( non - javadoc )
see section 1 . 3 of jslee 1 . 1 specs
/ * ( non - javadoc )
this method depending if securitymanger is present switches class loader using priviledged action this is requried as some action may be initiated by unsecure domains .
its used to embed calls in accesscontroller in case of insturmented code cause javassist does not support anonmous inner class .
/ * ( non - javadoc )
/ * ( non - javadoc )
verifies that the current transaction is still the one used to create the object
process a {
process a {
calculates the activity ttl
verifies if the specified class can be loaded by current thread class loader
retrieves a local object valid for thus current transaction .
similar to loggingmxbean return list of available loggers . filter is string that has to occur in loggers name .
resets all loggers level to default one
removes all loggers under certain branch .
tries to add logger if it doesnt exist
adds sockethandler to certain logger this logger must exist prior this function is called
tries to remove handler from logger .
adds notification handler to logger if it exists . its name is set to <b > notification< / b > . there can be only one notification handler . this handler holds reference to up to numberofentries log entries and fires notification . notification can be triggered prematurely in case when someone calls fetchlogcontent function this will cause notification to be fired along with log entries return as outcome of invocation .
/ * ( non - javadoc )
get an <code > addressscreening< / code > object from an integer value .
get an <code > addressscreening< / code > object from a string value .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
todo improve with sbb local object storage
/ * ( non - javadoc )
computes the index of the next executor to retrieve . adaptation of the { @link atomicinteger } incrementandget () code .
/ * ( non - javadoc )
generates the log4j logger name for the tracer with specified named and notification source .
syncs the slee tracer level with the one that related logger has in log4j
assigns the equiv log4j level to the tracer
manages the flags which cache if levels are enabled
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
this is internaly called by 1 . 1 tracers
this checks if the specified tracer name is ok .
write the current object and vendor - specific data to the output stream .
read the current object in the input stream from the stream optionally deserializing any vendor - specific data in the stream .
adds a direct dependency to this domain . direct dependencies are other domains which the domain depends on .
retrieves a flat list containing all dependencies for the domain i . e . all direct dependencies and their own dependencies .
finds a class locally i . e . in the urls managed by the extended urlclassloader .
finds a resource locally i . e . in the urls managed by the extended urlclassloader .
finds resources locally i . e . in the urls managed by the extended urlclassloader .
/ * ( non - javadoc )
creates and registers a profile mbean for the specified object .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
convenience method to create new instance of concrete impl class of { @link abstractusageparameterset } .
suspends the current tx ( if exists ) .
resumes the specified tx . if it is null nothing is done .
/ * ( non - javadoc )
retrieves the jain slee specs descriptor
retrieves the set of sbbs used by this service
retrieves the set of ra entity links referenced by the sbbs related with the service .
adds a url to the specified resource ( as returned by the system classloader ) . to the resource table of the resolver .
dumps the container state as a string useful for debug / profiling
initiates the slee container
shutdown of the slee container
ensures the standard slee lifecycle .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
create a named usage parameter getter .
generates info that indicates if a method from {
/ * ( non - javadoc )
find unique entry uses {
retrieve list uses {
retrieve set uses {
check if any result exists for query uses {
run insert query uses {
run update query uses {
set column to update . object is automatically translated onto matching jdbc type .
sets value for placeholder defined in query . placeholder name should not start with <b > : < / b > it is stripped off . based on passed object type appropriate jdbc type is chosen .
sets value for placeholder defined in query . placeholder name should not start with <b > : < / b > it is stripped off . based on passed object type appropriate jdbc type is chosen .
return new polyjdbc instance .
register custom mapping from clazz to sql type . sqltype should be one of { @link java . sql . types } . if you need to add some transformations register custom implementation of { @link org . polyjdbc . core . type . typewrapper } .
create <b > order by< / b > clause for given column can be used multiple times with multiple columns .
sets value for placeholder defined in query . placeholder name should not start with <b > : < / b > it is stripped off . based on passed object type appropriate jdbc type is chosen .
insert value into column of given name . object is automatically translated onto matching jdbc type .
run specified operations in safe transaction block .
set the list of containing resources . must all be instances of { @link searchlayer }
add a new containing resource . must be an instance of { @link searchlayer }
parse an iiif image api compliant region request string
returns the requested region
resolve the region request into an actual region that can be used for cropping the image
the spec says we have to urlencode values but only characters outside of the us ascii range and gen - delims from rfc3986 . however our url library can only encode the full set of gen - delims ( except the colon ) and sub - delims which iswhy we have to manually decode the encoded sub - delims ... great and pragmatic choice for readability more code for us : - )
create the canonical of the image api request . see http : // iiif . io / api / image / 2 . 1 / #canonical - uri - syntax
get type for on values that are plain uris by deducing the type from their parent .
obtain the completeness ( i . e . empty id and type it type and label id only or complex ) of a iiif resource . can be useful for determining how to serialize the resource e . g . often resources with only an id are serialized as a string .
set the viewing hints for this resource .
add one or more viewing hints for this resource .
sets the renderings . all renderings must have both a profile and a format .
add one or more renderings . all renderings must have both a profile and a format .
merge multiple profiles into one . useful for image servers that want to consolidate the limits given in a info . json .
merge two profiles .
parse a rotation request from an iiif image api compliant rotation string .
helper function to create converter from lambda *
adds one or more member resources . must be either instances of { @link manifest } or { @link collection } . all { @link collection } members must have at least one { @link de . digitalcollections . iiif . model . enums . viewinghint } .
adds one or more member resources . must be either instances of { @link range } or { @link canvas } . all members must have an identifier and a label .
/ * see http : // iiif . io / api / presentation / 2 . 1 / #language - of - property - values example : { description : { @value : here is a longer description of the object @language : en }}
parse an iiif image api compliant size request string
get the canonical form of this request . @see <a href = http : // iiif . io / api / image / 2 . 1 / #canonical - uri - syntax > iiif image api specification< / a >
resolve the request to dimensions that can be used for scaling based on the native size of the image region and the available profile .
like { @link #resolve ( dimension imageapiprofile ) } but can be used with a { @link rectangle } e . g . as returned from { @link regionrequest#resolve ( dimension ) } .
call once
initializes the androiddebugbridge and registers the defaulthardwaredevicemanager with the androiddebugbridge device change listener .
check whether this exception contains an exception of the given type : either it is of the given class itself or it contains a nested cause of the given type .
ugly implementation
get current android page s dump file
try to click gps popup window
push handlepopbox . jar to android tmp folder
clean file dump . xml qian . xml uidump . xml in tmp folder
pull dump file from android device to pc
use adb to send a keyevent to the device . <p > full list of keys available here : http : // developer . android . com / reference / android / view / keyevent . html
get crash log from aut
replace all occurrences of the regular expression with the replacement . the replacement string can contain $1 $2 etc . referring to matched groups in the regular expression .
same as replaceall ( string string ) but does not interpret $1 $2 etc . in the replacement string .
replace all occurrences of the pattern . the replacement object s replace () method is called on each match and it provides a replacement which is placed literally ( i . e . without interpreting $1 $2 etc . )
convert tabs to spaces .
introduce a number of spaces at the start of each line .
parse html tags returning a collection of htmltoken objects .
perform the conversion from markdown to html .
escape special characters
//////////// getproxyconnection ( ... ) //////////////
tries to take a { @code connholder } object from the underlying object pool . if successful never returns { @code null } .
//////////// restore ( ... ) //////////////
processes sql exceptions that have occurred on the given jdbc connection ( wrapped in a { @code connholder } ) .
<b > note : < / b > the pool name can be set only once ; pool renaming is not supported .
this method will be called when an operation invoked on a jdbc object throws an sqlexception . it will accumulate a list of all non - transient sql exceptions .
returns an array of all sql exceptions collected by {
creates and returns a new evictionlistener for the clhm . it is worth noting that this evictionlistener is called in the context of the thread that has executed an insert ( putifabsent ) operation which has increased the clhm size above its maxsize - in which case the clhm evicts its lru entry .
closes this clhmstatementcache and removes all entries from it .
see {
{ @inheritdoc }
returns <i > a possibly< / i > cached statementholder object for the given proxied connection object and the invoked on it prepare ... method with the given args .
////// the statementcreator implementation : ////////
////// the statementproceedingpoint implementation : ////////
handles all unrestricted method invocations that we can process before passing through the { @link #restrictedaccessentry } . this method will be overridden in the { @code abstractinvocationhandler } subclasses and will be the place to implement the specific to these subclasses logic for unrestricted method invocations handling . when the invoked { @code method } is not an unrestricted method the default implementation returns { @link #no_result } to indicate this .
handles all restricted method invocations that occur after ( and if ) we have passed through the { @link #restrictedaccessentry } . this method will be overridden in the { @code abstractinvocationhandler } subclasses and will be the place to implement the specific to these subclasses logic for restricted method invocations handling . the default implementation simply forwards the call to the original method of the proxied object .
/////////////////////////////////////////////////////////////////////////////////////////////
validates / initializes the given { @code rawconnection } via executing the given { @code sqlquery } .
/////////////////////////////////////////////////////////////////////////////////////////////
returns the extended pool name formatted as : <blockquote > { @code poolname@hashcode ( currentlytakenconns / remainingcreatedconns / poolmaxsize / poolstate / threadinterruptedstatus ) } < / blockquote > for example { @code p1@2db7a79b ( 1 / 1 / 10 / w / n ) } .
removes all garbage collected values with their keys from the map . since we don t know how much the referencequeue . poll () operation costs we should call it only in the add () method .
finds the parent barbershop type in the supplied set if any .
searches for $$barbershop class for the given instance cached for efficiency .
generates the class code and writes to a new source file .
this generates the actual style () method implementation for the $$barbershop class
remove the last param if there are multiple used for when we want to adapt a resource getter to one used with {
write bitvector01divider to outputstream . this method doesn t care about r0 and r1 . caller must write these bvs .
append bits from bit string . the bit string is the array of string that contains 8 characters which is 0 or 1 .
/
read data from inputstream . this method doesn t care about r0 and r1 . caller must load these bvs and set through setr0 and setr1 .
make an http get request to the given path and map the object under the given key in the json of the response to the java { @link class } of type { @link type } .
make an http get request to the given path and map the array under the given key in the json of the response to a { @link list } of type { @link type } .
deserialize the object to the type expected .
get the list of objects with a filter if there is anything that matches the filters .
get all the { @link card } that match a certain filter . @param filters list of filters supported by the web api @return list of all matching { @link card } s .
returns a {
the method that will generate a booster for the selected {
gets a list of {
gets a list of {
when running cucumber tests in parallel klov reporter should be attached only once in order to avoid duplicate builds on klov server .
adds the screenshot from the given path with the given title to the current step
sets the system information with the given key value pair
convert a level to equivalent syslog severity . only levels for printing methods i . e debug warn info and error are converted .
creates a primitive list based on an input list and a property path
add a new value to the list but don t employ a wrapper .
set a value in the list .
set a value in the list .
set a value in the list .
set in a new value no wrapper
this would be a good opportunity to reintroduce dynamic invoke
performs collections from the results .
performs collections from the results .
performs the actual selection from the results .
performs the actual selection from the results .
allows you to select a property or property path .
selects but allows having a different alias for the output .
selects but allows having a different alias for the output . \ *
will flush to secondary storage if needed . this is used mostly by remote_db at the moment .
will flush to secondary storage if needed . this is used mostly by remote_db at the moment .
create an annotation data list .
extract all annotation for a given property . searches current class and if none found searches super class for annotation . we do this because the class could be proxied with aop .
find annotation given a particular property name and clazz . this figures out the writemethod for the property and uses the write method to look up the annotation .
this needs to be refactored and put into reflection or something .
/ * everything that has a cache you need to hold on to should use this so they can all be stuffed into application context of web - app or ear if you use java ee .
lookup an object and supply a default value .
/ * this is the delegate for setting data . for instance set ( setrequest request ) and setsource ( setrequest request ) will both call this method instead of processing the set themself therefore providing a common and consistent way to handle the set - sff
convert an item from a list into a class using the classes constructor .
convert an item from a list into a class using the classes constructor .
convert an item from a list into a class using the classes constructor .
from map .
frommap converts a map into a java object .
frommap converts a map into a java object
creates an object from a value map .
basic tomap to create an object into a map .
this could be refactored to use core . typetype class and it would run faster . converts an object into a map
this converts a list of maps to objects . i always forget that this exists . i need to remember .
creates a list of maps from a list of class instances .
get the values from the annotation . we use reflection to turn the annotation into a simple hashmap of values .
create the validator by looking it up in the objectregistry and then populating it with values from the meta - data list .
lookup the list of validators for the current field and initialize them with validation meta - data properties .
this method looks up the validator in the registry .
this method applies the properties from the validationmetadata to the validator uses spring s beanwrapperimpl .
removes a property if it is null or an empty string . this allows the property to have a null or emtpy string in the meta - data but we don t copy it to the validator if the property is not set .
load the listfromclassloader
load the listfromclassloader
calculate utc time . this gets called every 20 mili - seconds or so .
get the size of the cache . this is not 100% accurate if cache is being concurrenly accessed .
calculate the hash .
configures default options .
opens the database
puts values into the key value store in batch mode
remove all of the keys passed .
search to a certain location .
load all of the key / values from the store .
keys are expected to be sorted
close the database connection .
/ * end universal methods .
reduce by functional support for int arrays .
fallback to reflection if the call - site will not work or did not work
min
calculate variance .
/ * end universal methods .
max
min
average
calculates variance
used internally to avoid loss and rounding errors a bit .
calculate median
main entry into system . <p / > <p / > <p / > if you are debugging something not coming into the system . <p / > start here!
/ * allows this base class to be initialized by the subclasses .
invokes method from list or map depending on what the object arg is .
a very fast reduce by . if performance is your thing this seems to be as fast a plain for loop when benchmarking with jmh .
big sum
max
calculate standard deviation .
useful for generated file names and generated work directories .
does the object match this expression . an expression is a collection of criteria .
this has to convert values to field type .
}
make criteria configurable
make criteria configurable
creates criteria from a list . this is used to configure criteria in json .
converts a json string into a criteria .
creates a primitive list based on an input list and a property path
add a new value to the list but don t employ a wrapper .
add a new value to the list but don t employ a wrapper .
add a new array to the list .
set a value in the list .
this would be a good opportunity to reintroduce dynamic invoke
does a binary search
does a binary search
gets the max item from the array . sorts the list descending first .
from the sorts this is the first few items .
grabs the last items after the sort .
grabs the last few items from the list .
returns the max value of the object with the property given .
returns the max value of the object with the property given .
returns the least few .
returns the min value using a natural sort .
returns the max value of the object with the property given .
returns the min value of the object with the property given .
this converts a list of maps to objects . i always forget that this exists . i need to remember .
processes an array of maps .
processes an collection of maps .
this converts / coerce a constructor argument to the given parameter type .
processes an collection of maps . this can inject into an array and appears to be using some of the typetype lib .
helper method to extract collection of values into some field collection . refactor : this could be refactored to use the org . boon . core . typetype system which should be faster . refactor
frommap converts a map into a java object . this version will see if there is a class parameter in the map and dies if there is not .
creates a list of maps from a list of class instances .
key
get the value at key
get the field label .
get the field label .
get the tool tip .
generate the field . transforms firstname into first name . this allows reasonable defaults for labels .
turn a single bytes into two hex character representation .
responses from server .
public setrequest ( datastoresource source action action long id string clientid long version long createtimestamp long updatetimestamp string key string payload ) {
search for a key in the key / value store .
put a value in the key / value store .
remove all of these values from the key value store .
called from worker thread .
called from worker thread . processes the incoming queue for read and writes .
start up the queue handlers .
puts character at index
gets slice of a string .
see if chars is in another string
add a char to a string
add many objects converted to strings together . null are ignored so be careful .
gets rid of null characters lurking in the string
split a string
split a string by space
split a string by pipe
convert arrays of chars to arrays of strings
convert to camel case and pass upper or lower
checks to see if a string is inside of another
convert to under bar case
see if they are equal or die
see if they are equal or die
do a nice pretty print of a number . add commas and such .
helper method to create a sort that is a composite of other sorts .
sort if you already know the reflection fields .
sort and you look up the reflection fields .
sort and you look up the reflection fields .
sort and you look up the reflection fields .
sort and you look up the reflection fields .
this is what really does the magic . this is the comparator creator .
this creates a list of children comparators based on the child list .
grabs the last value from a tree map ( navigable map ) .
grabs the value after this key from a tree map ( navigable map ) .
grabs the value before this key from a tree map ( navigable map ) .
end universal methods .
checks to see if two values are the same
checks to see if two arrays are equals
sum provides overflow protection .
max
min
calculate standard deviation .
calculate standard deviation .
round up to the nearest power of 2
the dogetmessagefrombundle does a bit of magic . if the message starts with { than it assumes it is an i18n message and looks it up in the resource bundle . if it starts with # { it assumes it is an expression and uses ognl jsf el or the universal el to look up the expression in the context .
this is the work horse . it does all of the sorting work for the simple cases . nulls are last by default .
this is the work horse . it does all of the sorting work for the simple cases .
main exit from system . <p / > <p / > if you are debugging something not coming out of the system . start here .
frommap converts a map into a java object
inject a map into an object s field .
convert an object to a list .
compiles a match .
/ *
create load all keys sql .
clones each list item into a new instance with copied fields . it is like doing a clone operation .
/ * end universal methods .
checks to see if we have a string field .
checks to see if this class has a string field .
checks to see if a class has a field .
this can be used for default sort .
getfirststringfieldnameendswith
getfirststringfieldnameendswithfromclass
gets the first sortable fields found .
comparison of entries this determines what we will order the cache by which determines which type of cache it is .
compare the time .
takes a list an an array or sorts
sort a list .
sort collection .
sort map entries .
sort map values .
sort map keys .
sort collection .
sort an array .
this creates the universal comparator object which is used by the sort work horse .
this creates the universal comparator object used for this .
this compares two values . if the objects are strings ( charsequence ) they are always compared lexicographically . if the objects are comparable they are always compared using a natural order .
get the value from the cache . it does not touch the lock so reads are fast . this does not touch the order list so it is fast .
used for testing as it gets the value without updating stats
remove the key . this touches the lock . so removes are ** not ** fast .
put the value . this touches the lock so puts are ** not ** fast .
avoid overflow .
evict if we are over the size limit .
perform the actual validation .
/ * initialize this instance .
if the type was not initialized we can still figure it out at runtime .
}
this flattens a list .
this flattens a list .
this gets called from the http post handler or event bus handler .
see if it is time to stop we have been interrupted . should we ignore it or break out of the loop .
queue and batch writer main logic . this is where the magic happens .
if we detect that the in - coming transfer outputdataqueue channel is empty then it could be an excellent time to sync to disk .
if we don t have any data and we have flushed then we can wait on the outputdataqueue . there is no sense spin - locking . the poll ( time timeunit ) call will block until there is something to do or until the timeout .
start up the health monitor .
starts up the batch writer .
gets the item by key from the mapping .
perform the actual validation .
this is the main criteria plan in case the name was not obvious .
run the filter on the group .
}
/ * creation
end universal
recieves a tick from our clock .
flush to disk .
attempts to close down log stream .
writes a buffer of data to the log system .
write the actual data to disk .
initialize the output stream .
get a value from the key value store .
put a value in the key / value store .
put all of these values in the key value store .
/ * never let the drift get greater than 200 ms .
get a value from the key value store .
convert a string key to bytes .
put a value in the key / value store .
remove all of these values from the key value store .
read the meta - data from a properties file .
this method loads the metadata properties file . the properties are cached in <b > metadatapropscache< / b > and will not be reloaded twice .
this method extracts meta - data from a string .
read the meta - data from annotation . this copies the meta - data from the annotation into a pojo . it first checks the meta - data cache if the meta data is not found in the cache it then reads it from the class .
extract basevalidator meta data .
extract meta - data from the annotationdata we collected thus far .
converts an annotationdata into a validatormetadata pojo .
compiles a match .
splits a string into many parts
split string by white space
split string by a list of delimiters
remove chars from a string
split string by a list of delimiters but none are empty within a range
parse float
parse a double
parse an int within a range
parse an long within a range
creates a primitive list based on an input list and a property path
add a new value to the list but don t employ a wrapper .
add a new value to the list but don t employ a wrapper .
set in a new value no wrapper
creates a primitive list based on an input list and a property path
add a new value to the list but don t employ a wrapper .
add a new value to the list but don t employ a wrapper .
set a value in the list .
set in a new value no wrapper
this would be a good opportunity to reintroduce dynamic invoke
responses from server .
gets the field value .
gets the field value .
gets the field value .
gets the field value .
this method handles walking lists of lists .
get fields from object or map . allows maps to act like they have fields .
get fields from map .
get property value loads nested properties
get property value
get property value
set property value to simulate dependency injection .
set a static value
this is an amazing little recursive method . it walks a fanout of nested collection to pull out the leaf nodes
this is one is forgiving of null paths . this works with getters first i . e . properties .
get an int property .
get property value
get property value
get property path typetype
get property path typetype
get property path typetype
/ * manages weak references .
gets a list of fields merges with properties if field is not found .
gets a list of fields merges with properties if field is not found .
the init method tries to generate the message keys . you should only call the init method if you don t inject values into the detailmessage and summarymessage .
creates a message .
actually creates the message .
convert the keys to values .
gets the current subject or the configured subject if the current subject is not found .
parse a text representation of a json data structure
this actually sends the request .
requests couchdb deletes a database .
requests couchdb creates a new database ; if one doesn t exist .
triggers a database <i > compact< / i > request .
request a database sends a list of uuids .
adds request / response interceptors for logging and validation .
json
list directory contents for a resource folder . not recursive . this is basically a brute - force implementation . works for regular files and also jars .
triggers a replication request .
helper
queries a view as an {
queries a view .
queries a view .
queries for scalar values . internal use .
queries a view for pagination returns a next or a previous page this method figures out which page to return based on the given param that is generated by an earlier call to this method quering the first page is done by passing a {
reverses the reading direction not the sort order .
supplies a key list when calling <tt > _all_docs< / tt > view .
synchronizes a design document to the database . <p > this method will first try to find a document in the database with the same id as the given document if it is not found then the given document will be saved to the database . <p > if the document was found in the database it will be compared with the given document using {
synchronize all design documents on desk to the database .
gets a design document from the database .
gets all design documents from desk .
gets a design document from desk .
adds a new document to the replicator database .
finds a document in the replicator database .
finds all documents in the replicator database .
removes a document from the replicator database .
finds an object of the specified type .
finds a document and return the result as {
finds a document given id and revision and returns the result as {
find documents using a declarative json querying syntax .
checks if a document exist in the database .
saves an object in the database using http <tt > post< / tt > request . <p > the database will be responsible for generating the document id .
saves a document with <tt > batch = ok< / tt > query param .
removes a document from the database given both a document <code > _id< / code > and <code > _rev< / code > values .
performs bulk documents create and update request .
saves an attachment to a new document with a generated <tt > uuid< / tt > as the document id . <p > to retrieve an attachment see {
saves an attachment to an existing document given both a document id and revision or save to a new document given only the id and rev as {
invokes an update handler . <pre > params params = new params () . addparam ( field foo ) . addparam ( value bar ) ; string output = dbclient . invokeupdatehandler ( designdoc / update1 docid params ) ; < / pre >
executes a http request . <p > <b > note< / b > : the response must be closed after use to release the connection .
performs a http get request .
performs a http get request .
performs a http get request .
performs a http put request saves or updates a document .
performs a http put request saves an attachment .
performs a http post request .
performs a http delete request .
validates a http response ; on error cases logs status and throws relevant exceptions .
sets a json string as a request entity .
builds {
adds an in - line document attachment .
requests change notifications of feed type continuous . <p > feed notifications are accessed in an <i > iterator< / i > style .
requests change notifications of feed type normal .
reads and sets the next feed in the stream .
<editor - fold defaultstate = collapsed desc = generated code > // gen - begin : initcomponents
gen - last : event_jbutton2actionperformed
gen - last : event_jcombobox3actionperformed
gen - last : event_jbutton4actionperformed
gen - last : event_jbutton5actionperformed
gen - last : event_jbutton6actionperformed
gen - last : event_jbutton8actionperformed
gen - last : event_jcombobox5actionperformed
gen - last : event_jtextfield7keytyped
converts percent to string .
converts percent to string .
converts double value to the text description .
converts amount to words . usage : moneytostr moneytostr = new moneytostr ( moneytostr . currency . uah moneytostr . language . ukr moneytostr . pennies . number ) ; string result = moneytostr . convert ( 123d ) ; expected : result =     00 
attempt to release any locks on shutdown so that other clients can obtain those locks without having to wait for them to expire .
observes { @link servletoutputstream } .
writes the given observable data to servletoutputstream .
functionality into a separate class .
intended to be used at the startup of the metricsserviceimpl to ensure we have enough tables for processing
returns the namespace id for a particular namespace name
returns if the request is a query request eg to perform a read
executed when a pooled connection is acquired .
determine the verb we should apply based on the http method being requested .
generates a subjectaccessreview object used to request if a user has a certain permission or not .
called when the kubernetes master server reponse has been inspected .
called if an exception occurs at any stage in the process .
eventually i would like service initialization async .
if a job is single execution then this is a no - op ; otherwise the scheduled jobs index and jobs tables are updated with the next execution time / details . if the job has missed its next execution it will get scheduled in the next available time slice . the job scheduler will actually execute the job immediately when the job falls behind but we still want to persist the scheduling update for durability .
this method is currently unused .
converts bucket points indexed by start time into a list ordered by start time . blanks will be filled with empty bucket points .
jmx management
allow special cases to pattern matching such as * - > . * and ! indicating the match shouldn t happen . the first ! indicates the rest of the pattern should not match .
asynchronously performs gc_grace_seconds updates if necessary . this method should <strong > not< / strong > be called until schema updates have finished .
changes the status code of the response sets the http reason phrase and ends the exchange .
parses the string into an interval . the string must match the regular expression ( \ d + ) ( min|hr|d ) ; otherwise an exception is thrown .
fetch all the data from a temporary table for the compression job . using tokenranges avoids fetching first all the metrics partition keys and then requesting them .
/ * applies micro - batching capabilities by taking advantage of token ranges in the cassandra
/ * apply our current retry policy to the insert behavior
force bucket count . this method does not guarantee that the last bucket includes the { @code end } value .
force bucket step .
send msg .
sene one way msg .
send delay msg .
in this simple proposal we re not testing complex iterations of scan cursor . scan is simply a wrapper for keys and the result is given in one single response no matter the count argument .
performs a wildcard matching for the text and pattern provided . source : http : // www . adarshr . com / papers / wildcard
https : // confluence . atlassian . com / bamboo / bamboo - variables - 289277087 . html
https : // docs . travis - ci . com / user / environment - variables / #default - environment - variables
use by loaders
add a file to the zip .
replace the contents of a file with a different text .
build a zip file containing the added entries .
generate a product by assembling components .
generate a product by assembling components .
generate a product by assembling components .
generate a product from a single piece .
fetch the content for the specified content id .
fetch the content for the specified order item .
upload the transformation zip with the stylesheet into archive .
generate a file by assembling components .
create a new directory in the given parent directory .
end this builder .
prepares a group by adding renderers adaptors and sub templates . override this if you want to add additional renderers . by default adds : <ul > <li > an {
registers a modeladaptor with the group . override this method if you want to suppress one ootb adaptor but not all .
registers a renderer with the group . override this method if you want to suppress one ootb renderer but not all .
prepares the template by adding the variables .
add a domain object to the batch of sips .
set the value of a property .
add an object that is to be owned by this object .
convert a date to <a href = https : // tools . ietf . org / html / rfc3339#section - 5 . 6 > iso 8601 datetime< / a > format .
convert an <a href = https : // tools . ietf . org / html / rfc3339#section - 5 . 6 > iso 8601 datetime< / a > string to a date .
returns a supplier that creates sequentially named files in the given directory .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that contains only structured data and is the only sip in its dss .
assemble a sip that is the only sip in its dss .
assemble a sip that is the only sip in its dss .
assemble a sip that is the only sip in its dss .
utility method to copy the bytes from an inputstream to an outputstream while also assembling a hash value in the process .
return a new factory for building xml documents that is configured to operate securely . the factory also supports <a href = http : // www . w3 . org / tr / rec - xml - names / > xml namespaces< / a > and validation .
parse the content of a given file into an xml document .
parse the content of a given reader into an xml document .
return the elements under a given parent element .
return the nodes under a given parent element .
return the first child element of a given parent element whose tag matches any of the given names . when no child names are given the first child element is returned .
return the elements under a given parent element whose tag matches any of the given names . when no child names are given all child elements are returned .
validate an xml document against an xml schema document .
returns an {
returns an {
parses the given yaml .
parses the given yaml .
build a sip archive from all files in a given directory tree .
sets the content .
sets the content from a named resource .
process a named entry in the zip file .
chinese characters transform
generate signature for request against qingstor .
generate signature for request against qingstor .
generate signature for request against qingstor .
generate signature for request against qingstor .
generate signature for request against qingstor .
<p > okhttp will use accept - encoding : gzip as default header which may not get content - length form server when download . < / p >
set signature and server time .
encodes hex octects into base64
decodes base64 data into octects
remove whitespace from mime containing encoded base64 data .
upload a file with a sync request .
upload a file with a sync request .
upload a file with a multi upload as a sync request .
when sending a request will call this method to sign with server .
set data in the upload with a recorder .
complete the multi upload .
upload a file with a simple put object upload as a sync request . <br > if a file s size is less than {
invoking a favoriteaction toggles it .
/ * package - private
/ * package - private
/ * implementation
caller must insure that the state being set has not already been added to the entry to avoid multiple events with the same state .
/ * implementation
creates a { @link notificationentry } from a { @link jpaentry } but will return null if that process cannot be performed in a valid way .
helper method to determine if an ssptoken has expired .
is the {
provides the known history of status changes for the specified user and notification <strong > in chronological order< / strong > .
/ * implementation
add all entries from the notification category to the <code > allentries< / code > list after adding an attribute category that contains the category . that allows uis that want the convenience of an uncategorized list such as datatables to obtain the data in a simple format that requires no additional processing but maintains the knowledge of the category of the entries .
get the list of notifications . supports optional ( and recommended! ) paging
create a notification .
get 1 notification by id .
get the set of addressees for a notification .
create a new addressee for a notification .
get a specific addressee
get the list of events for a notification .
get a specific event .
create a new event .
build the url for a specific notification .
provides a complete transaction log for a notification and a single recipient <strong > in chronological order< / strong > .
/ * implementation
search for a jpaentry with the specified id . if the entry exists in the persistence context it is returned ; otherwise null is returned .
obtains information about the user from the authorization header in the form of an oidc id token . in the future it would be better to provide a standard tool ( bean ) for this job in the <code > uportal - soffit - renderer< / code > component .
subclasses <em > must< / em > call <code > super . init () < / code > .
set the ssp api context . note : this method will ensure that that the api context starts with / and ensures that it does not end with a / .
{
{
get the authentication token to use .
returns the {
combine the contents of this response with the provided response and return a <b > new instance< / b > of { @link notificationresponse } . the original instances are unchanged .
return a <b > new instance< / b > of { @link notificationresponse } from which the specified errors have been removed . the original instances are unchanged .
return a <b > new instance< / b > of {
provides the total number of notifications contained in the response .
insert the given categories and their entries into the any existing categories of the same title . if a category doesn t match an existing one add it to the list .
best guess as to the reason this method exists : beans that produce fresh {
returns an empty collection and logs the event . all concrete implementations of {
fetch the set of ssp tasks for the uportal user .
error handler .
map and ssp response to a notificationresponse .
map a single notification entry .
attach any ssp specific actions to this entry if enabled .
some of the links i have seen from ssp are not well formed . try to convert any urls to a usable form .
get the category name to use for ssp notifications .
get the source value to use for a notification entry .
/ * implementation
invoking a readaction toggles it .
/ * package - private
when invoke is called a configured notification state is set for the entry if it has not already been set . { @link jpanotificationservice } and { @link cachenotificationservice } are used here to add the entry state and clear the cache for the user . this class is not managed by spring so these objects must be obtained using the spring context that { @code springcontext } provides .
/ * implementation
deserialize the given json formatted file back into a object .
/ * implementation
{
get the schoolid value from the request .
parse the person lookup response from ssp .
this { @link inotificationservice } is fundamentally about java portlets and there is nothing it can offer to this overload of <code > fetch< / code > .
invoking a hideaction toggles it .
/ * package - private
/ * package - private
/ * implementation
convenience method for obtaining the attributes in a more usable collection .
normalizes the point such that the frobenius norm is 1 .
returns true if the point is contained inside the box . the point is considered to be inside the box if the following test passes for each dimension . box . p0 . x &le ; point . x { @code < } box . p1 . x + box . lengthx
returns true if boxb is contained inside of or is identical to boxa .
find the closest point on the triangle to p .
returns the signed of the vector . if its in front it will be positive and negative if behind . in front is defined as being on the same side as the cross product of p2 - p0 and p1 - p0 .
set s this se3_f64 to be identical to the provided transform .
fully specify the transform using euler angles
fully specifies the transform using rodrigues ( axis angle ) or quaternions . if rodrigues then a = axisx b = axisy c = axisz d = theta . if quaternion then a = w b = x c = y d = z .
applies the transform to the src point and stores the result in dst . src and dst can be the same instance
applies the reverse transform to the src point and stores the result in dst . src and dst can be the same instance
applies the rotation to the src vector and stores the result in dst . src and dst can be the same instance
applies the reverse rotation to the src vector and stores the result in dst . src and dst can be the same instance
converts a rectangle into a quadrilateral
converts a rectangle into a polygon
converts a polygon into a quadrilateral
converts a rectangle into a quadrilateral
finds the minimum area bounding rectangle around the quadrilateral .
finds the minimum area bounding rectangle around the quadrilateral that is aligned with coordinate system axises .
computes the center or average point in the quadrilateral .
returns true if the polygon is ordered in a counter - clockwise order . this is done by summing up the interior angles .
computes the average of all the vertexes
checks to see if the vertexes of the two polygon s are the same up to the specified tolerance
checks to see if the vertexes of the two polygon s are the same up to the specified tolerance and allows for a shift in their order
flips the order of points inside the polygon . the first index will remain the same will otherwise be reversed
shifts all the vertexes in the polygon up one element . wraps around at the end
shifts all the vertexes in the polygon up one element . wraps around at the end
computes the convex hull of the set of points .
removes a node from a polygon if the two lines its attached two are almost parallel
remove a point if it s identical to a neighbor
remove a point if it s identical to a neighbor
compute the error as a function of the distance between the model and target . the target is sampled at regular intervals and for each of these points the closest point on the model is found . the returned metric is the average of difference between paired points .
converts the provided 3x3 matrix into a { @link homography2d_f64 } .
converts a { @link homography2d_f64 } into a 3x3 matrix .
computes the area of the intersection between the two polygons .
-------------------------------------------------------------------------
returns a point along the line . see parametric equation in class description .
http : // www . ecse . rpi . edu / homepages / wrf / research / short_notes / pnpoly . html
checks to see if the point is contained inside the concave polygon .
true if the point is contained inside the quadrilateral .
returns true of the the point is inside the triangle .
finds the point of intersection between two lines and returns the point .
finds the point of intersection between two lines . the point of intersection is specified as a point along the parametric line a . ( x y ) = ( x_0 y_0 ) + t * ( slope_x slope_y ) where t is the location returned .
finds the point of intersection between two lines segments .
<p > finds the intersection of two lines as a 2d point in homogeneous coordinates . because the solution is found in homogeneous coordinates it can even handle parallel lines which intersect at infinity . < / p >
finds the point of intersection between the two lines defined by the set sets of points passed in .
finds the point of intersection between a line and a line segment . the point of intersection is specified as the distance along the parametric line . if no intersection is found then double . nan is returned .
finds the area of the intersection of two polygons .
<p > checks to see if the specified point is inside the rectangle . a point is inside if it is &ge ; the lower extend and &lt ; the upper extent . < / p > <p > inside = x &ge ; x0 and x &le ; x1 and y &ge ; y0 and y &le ; y1 < / p >
<p > checks to see if the specified point is inside the rectangle . a point is inside if it is &ge ; the lower extend and &le ; the upper extent . < / p > <p > inside = x &ge ; x0 and x &le ; x1 and y &ge ; y0 and y &le ; y1 < / p >
tests to see if the provided point lies on or is contained inside the ellipse
checks to see if the two rectangles intersect each other
finds the intersection between two rectangles . if the rectangles don t intersect then false is returned .
returns the area of the intersection of two rectangles .
determines the location ( s ) that a line and ellipse intersect . returns the number of intersections found . note : due to floating point errors it s possible for a single solution to returned as two points .
converts { @link georegression . struct . so . rodrigues_f64 } into a rotation matrix .
converts axis angle ( { @link rodrigues_f64 } ) into a rotation matrix with out needing to declare a storage variable .
<p > converts { @link georegression . struct . so . rodrigues_f64 } into an euler rotation of different types< / p >
<p > converts { @link georegression . struct . so . rodrigues_f64 } into a unit { @link georegression . struct . so . quaternion_f64 } . < / p >
converts a unit {
<p > converts a quaternion into an euler rotation of different types< / p >
<p > converts a rotation matrix into an euler angle of different types< / p >
if the index is negative it returns the negative of the value at - index . starts at 0
extracts quaternions from the provided rotation matrix .
converts a rotation matrix into { @link georegression . struct . so . rodrigues_f64 } .
creates a rotation matrix about the x - axis .
sets the values in the specified matrix to a rotation matrix about the x - axis .
creates a rotation matrix about the y - axis .
creates a rotation matrix about the z - axis .
sets the values in the specified matrix to a rotation matrix about the z - axis .
converts an euler coordinate into a rotation matrix . different type of euler coordinates are accepted .
creates a rotation matrix about the specified axis .
<p > finds a rotation matrix which is the optimal approximation to an arbitrary 3 by 3 matrix . optimality is specified by the equation below : <br > <br > min ||r - q||<sup > 2< / sup > <sub > f< / sub > <br > r<br > where r is the rotation matrix and q is the matrix being approximated . < / p > <p / > <p > the technique used is based on svd and is described in appendix c of a flexible new technique for camera calibration technical report updated 2002 . < / p > <p / > <p > both origin and r can be the same instance . < / p >
<p > converts a unit quaternion into a rotation matrix . < / p >
sets the slope to the unit vector specified by the provided angle .
returns a point along the line . see parametric equation in class description .
converts the { @link se3_f64 } object into homogenous notation . <br >
converts the twist coordinate into homogenous format . <br > h = [ hat ( w ) v ; 0 0 ]
<p > computes the exponential map for a twist : <br > exp ( hat ( xi ) * theta ) = [ so ( i - so ) * ( w cross v ) + w * w<sup > t< / sup > v&theta ; 0 1 ] <br > so = exp ( hat ( w ) * theta ) < / p >
converts a rigid body motion into a twist coordinate . the value of theta used to generate the motion is assumed to be one .
specify the two transforms which values are to be interpolated between
interpolates a value between the first and second transform . a value close to 0 will be more similar to the initial and 1 more similar to the end .
makes sure x0 y0 is the lower extent and x1 y1 is the upper extent
converts a 2d polygon into a 3d polygon . the 2d points will lie on the x - y plane ( e . g . ( x y 0 )) and are converted to 3d using polytoworld .
<p > computes the weighted best fit line to the set of points using the polar line equation . the solution is optimal in the euclidean sense see [ 1 ] for more details . < / p >
svd based method for fitting a plane to a set of points . the plane s equation is returned as a point on the plane and the normal vector .
svd based method for fitting a plane to a set of points and a known point on the plane . the plane s equation is returned as a point on the plane and the normal vector .
resturns the length of the specified side that is composed of point index and index + 1
returns true if the point is inside the polygon . points along the border are ambiguously considered inside or outside .
returns the line / edge defined by vertex index and index + 1 .
converts the polygon into a list .
sets the polygon to be the same as the list . a true copy is created and no references to points in the list are saved .
converts symmetric 3x3 matrix back into a conic .
converts symmetric 3x3 matrix back into a conic . only the upper right portion of src is read .
converts the conic into a symmetric 3x3 matrix
converts symmetric 3x3 matrix back into a conic . only the upper right portion of src is read .
converts the conic into a parabola . if the conic isn t a parabola then it is converted into one by adjusting the value of b .
converts the parabola into a conic .
}
creates a skew symmetric cross product matrix from the provided tuple .
creates a skew symmetric cross product matrix from the provided tuple .
<p > computes the cross product : <br > <br > c = a x b < / p >
<p > computes the cross product : <br > <br > c = a x b<br > where a is in homogeneous coordinates . < / p >
<p > adds two points together . <br > <br > c = a + b < / p > <p / > <p > point c can be the same instance as a or b . < / p >
<p > adds two points together while scaling them . <br > <br > pt<sub > 2< / sub > = a<sub > 0< / sub > pt<sub > 0< / sub > + a<sub > 1< / sub > pt<sub > 1< / sub > < / p > <p / > <p > point c can be the same instance as a or b . < / p >
<p > ret = p0 + m * p1< / p >
<p > substracts two points from each other . <br > <br > c = a - b < / p > <p / > <p > point c can be the same instance as a or b . < / p >
rotates a 2d point by the specified angle .
rotates a 2d point by the specified angle .
mod = m * pt <p > pt and mod can be the same reference . < / p >
<p > computes mod = m * pt where both pt and mod are in homogeneous coordinates with z assumed to be equal to 1 and m is a 3x3 matrix . < / p > <p > pt and mod can be the same point . < / p >
x = p * x
<p > computes the following : <br > result = cross ( a ) <sup > t< / sup > * m<br > where m and result are 3x3 matrices cross ( a ) is the cross product matrix of a . < / p >
mod = m<sup > t< / sup > * pt . both pt and mod can be the same instance .
<p > computes the inner matrix product : <br > ret = x<sup > t< / sup > a<sup > t< / sup > y < / p >
computes the outer product of two vectors : <br > o = a * b<sup > t< / sup >
adds the outer product of two vectors onto a matrix : <br > ret = a + scalar * a * b<sup > t< / sup >
<p > computes the inner matrix product : ret = a * m * b<br > where ret is a scalar number . a and b are automatically converted into homogeneous coordinates . < / p >
<p > multiplies each element in the tuple by v . <br > p<sub > i< / sub > = p<sub > i< / sub > * v < / p >
divides each element by v
<p > changes the sign of the vector : <br > <br > t = - t < / p >
converts a geotuple3d_f64 into dmatrixrmaj
converts a dmatrixrmaj into geotuple3d_f64
assign the rodrigues coordinates using a 3 element vector . theta is the vector s magnitude and the axis of rotation is the unit vector .
converts an angle which is ( - pi to pi ) into a half circle angle ( - pi / 2 to pi / 2 ) .
returns an angle which is equivalent to the one provided but between ( inclusive ) - &pi ; and &pi ; .
returns an angle which is equivalent to the one provided but between ( inclusive ) - &pi ; and &pi ; .
bounds the angle between - &pi ; / 2 and &pi ; / 2
bounds the angle between - &pi ; / 2 and &pi ; / 2
angular distance in radians to go from anga to angb in counter clock - wise direction . the resulting angle will be from 0 to 2&pi ; .
angular distance in radians to go from anga to angb in counter clock - wise direction . the resulting angle will be from 0 to 2&pi ; .
angular distance in radians to go from anga to angb in clock - wise direction . the resulting angle will be from 0 to 2&pi ; .
angular distance in radians to go from anga to angb in clock - wise direction . the resulting angle will be from 0 to 2&pi ; .
<p > returns the difference between two angles and bounds the result between - pi and pi : <br > result = anga - angb<br > and takes in account boundary conditions . < / p >
<p > returns the difference between two angles and bounds the result between - pi and pi : <br > result = anga - angb<br > and takes in account boundary conditions . < / p >
angular distance between two half circle angles .
ensures a reflective bound so that the numbers from 0 to 1 where 0 is inclusive and 1 is inclusive . <pre > examples : 1 . 5 = 0 . 5 - 0 . 25 = 0 . 25 - 0 . 75 = 0 . 75 0 = 0 1 = 1 0 . 999 = 0 . 999 2 = 0 - 1 = 1 < / pre >
finds the intersection of a line and a plane . returns true if they intersect at a unique point or false if there is no intersection or an infinite number of intersections .
finds the intersection of a line and a plane . returns true if they intersect at a unique point or false if there is no intersection or an infinite number of intersections .
finds the line which is the intersection between the two planes . for a valid solution to be returned the planes must not be parallel to each other . if the planes are parallel then the slope of the returned line will have a value of zero for each element .
<p > finds the intersection between a 3d triangle and a line - segment . code ported from [ 1 ] . < / p >
<p > finds the intersection between a 3d triangle and a line - segment . code ported from [ 1 ] . internal working variables are provided in this interface to reduce memory creation / destruction . < / p >
<p > finds the intersection between a 3d triangle and a line . code ported from [ 1 ] . internal working variables are provided in this interface to reduce memory creation / destruction . < / p >
detects if a 2d convex polygon that has been moved into a 3d world is intersected by the 3d line . <pre > transformation : 1 ) each 2d point is converted into 3d : x = ( x y 0 ) 2 ) x = r * x + t where ( r t ) are a rigid body transform from poly to world frames < / pre >
determines if the point on the same plane as t is contained inside of t .
returns true if the point is contained inside the box . the point is considered to be inside the box if the following test passes for each dimension . box . x &le ; point . x { @code < } box . x + box . lengthx
<p > returns true if the point is contained inside the box with an exclusive upper extent . the point is considered to be inside the box if the following test passes : <br > box . p0 . x &le ; point . x { @code < } box . p1 . x<br > box . p0 . y &le ; point . y { @code < } box . p1 . y<br > box . p0 . z &le ; point . z { @code < } box . p1 . z<br > < / p >
finds the intersection of a line and sphere . there can be 0 1 or 2 intersections . if there is 1 intersection the same point is returned twice .
perform linear interpolation
the unit eigenvector corresponding to the maximum eigenvalue of q is the rotation parameterized as a quaternion .
computes the convex hull . the output will be in counter - clockwise order .
performs the following operation : output = z - component [ ( a - b ) cross ( a - c ) ]
specifies the covariance matrix . q = [ a11 a12 ; a12 a22 ]
sets the provided transform so that it does not transform any points .
converts {
converts it into a 4 by 4 homogeneous matrix .
converts a homogeneous representation into { @link se3_f64 } .
converts it into a 3 by 3 homogeneous matrix .
converts a homogeneous representation into { @link se2_f64 } .
sets the value of an { @link se3_f64 } using euler xyz coordinates for the rotation and a translation vector .
create se3 using axis - angle for rotation and xyz tanslation
can be used to see if two transforms are identical to within tolerance
finds the best fit projection of a onto se ( 3 ) . this is useful when a was estimated using a linear algorithm .
<p > returns the distance the closest point on a line segment is from the specified point . the closest point is bounded to be along the line segment . < / p >
<p > returns the distance of a point to the closest point on a line . < / p >
converts latitude and longitude coordinates into a unit vector
computes ( x - x_c ) ** 2 + ( y - y_c ) ** 2 - r . if ( x y ) lies on the circle then it should be 0 .
given three points find the circle that intersects all three . if false is returned that means the points all lie along a line and there is no circle .
radius squares of the circle that passes through these three points .
returns the point which minimizes the distance between the two lines in 3d . if the two lines are parallel the result is undefined .
<p > finds the closest point on line lo to l1 and on l1 to l0 . the solution is returned in param as a value of t for each line . < / p > <p > point on l0 = l0 . a + param [ 0 ] * l0 . slope<br > point on l1 = l1 . a + param [ 1 ] * l1 . slope < / p > @param l0 first line . not modified . @param l1 second line . not modified . @param param param [ 0 ] for line0 location and param [ 1 ] for line1 location .
finds the closest point on a line to the specified point .
finds the closest point on a line to the specified point as a function of distance along the line . the 3d coordinate of the point at d the returned value is p = ( x y z ) + ( slope . x slope . y slope . z ) * d .
finds the closest point on the plane to the specified point .
finds the closest point on the plane to the specified point .
finds the closest point on the plane to the origin .
finds the closest point on a line segment to the specified point .
find the point which minimizes its distance from the two line segments .
closest point from a 3d triangle to a point .
<p > computes the closest point along the line to the plane as a function of t : <br > [ x y z ] = [ x_0 y_0 z_0 ] + t [ slopex slopey slopz ] < / p >
applies a 2d homography transform to the point and stores the results in another variable . b = h * a where a is the input / orig point b is the output / result point and h is a homography from a to b .
applies a 2d special euclidean transform to the point and stores the results in another variable .
applies a 2d special euclidean transform to an array of points .
applies a 3d special euclidean transform to a list of points .
applies a 3d special euclidean transform to a list of points .
<p > . applies the transform specified by specialeuclidean to a point . <br > <br > p = r * p + t < / p > <p > both origpt and tranpt can be the same instance . < / p >
<p > . applies the transform specified by specialeuclidean to a homogenous point . <br > <br > p = [ r t ] * p < / p > <p > both origpt and tranpt can be the same instance . < / p >
<p > . applies the transform in the reverse direction<br > <br > p = r<sup > t< / sup > * ( p - t ) < / p > <p > both origpt and tranpt can be the same instance . < / p >
converts the polygon into a list .
sets the polygon to be the same as the list . a true copy is created and no references to points in the list are saved .
returns true if the two quadrilaterals are equal to each other to within tolerance . equality is defined by seeing if the distance between two equivalent vertexes is within tolerance .
returns the acute angle between the slope of two lines . lines do not need to ever intersect . found using the dot product .
returns the acute angle between the slope of two lines and assumes that the lines have been normalized such that a * a + b * b = 1 . this avoids the need to compute the square root twice . lines do not need to ever intersect . found using the dot product .
converts a line from polar form to parametric .
converts a line from polar form to general . after conversion the line will be normalized e . g . a * a + b * b == 1 .
converts a line from general to polar .
converts a line segment into a parametric line . the start point will be src . a and the direction will be in the direction of src . b - src . a
converts a line segment into a general line .
converts a line segment into a general line . line segment is defined by two points .
converts a line segment into a line in parametric format . it will point from a to b . point a and b must be unique .
converts a line from parametric to polar .
converts a line from parametric to general
converts a line from general to parametric
converts a plane in normal form into a general equation
<p > converts a plane in general form into normal form . the point on the plane in normal form will be the closest point to the origin . < / p >
converts a plane in tangent form into a plane in normal form
defines a plane using a 3d rigid body transform . + z is the 3rd column the rotation matrix . the plane s point is the translation . the plane reference frame is the x - y plane .
converts the plane into hessian normal form . this is done by dividing each coefficient by the euclidean norm of ( a b c ) .
applies the plane s definition to test to see if a point is one the plane
applies the plane s definition to test to see if a point is one the plane
there are an infinite number of possible 2d coordinate axises for a plane . this selects one which will be right handed using { @link utilvector3d_f64#perpendicularcanonical ( vector3d_f64 vector3d_f64 ) } and a cross product .
projects the point onto the 2d coordinate system specified by the provided x - axis . if the chose of x - axis is arbitrary { @link utilvector3d_f64#perpendicularcanonical ( vector3d_f64 vector3d_f64 ) } is recommended as a way to select
given a point on the plane s 2d coordinate system convert it back into a 3d point .
creates a transform from the plane s reference frame into world s reference frame . the z - axis is set to the plane s normal and the x - axis and y - axis are arbitrarily choosen . points which lie along the plane will lie along its x - y plane .
checks to see if the two geotuple have values which are nearly the same . false is always returned if the dimension is different .
generic copy routine . it is recommended that this be overridden with a faster implementation .
computes the square of the euclidean norm .
converts a { @link linesegment3d_f64 } into { @link lineparametric3d_f64 } .
computes the value of t for a point on the parametric line
returns true if any of its parameters have an uncountable number
determines if they are equivalent up to a scale factor
<p > computes the unweighted best fit line to the set of points using the polar line equation . the solution is optimal in the euclidean sense see [ 1 ] for more details . < / p >
the box s area . area = lengthx * lengthy * lengthz
computes and return the center of the cube .
computes the acute angle between the two lines . does not check for intersection
given two sets of corresponding points compute the { @link se2_f64 } transform which minimizes the difference between the two sets of points .
given two sets of corresponding points compute the { @link se3_f64 } transform which minimizes the difference between the two sets of points .
checks to see if the homogenous 3d point lies on the plane at infinity
normally distributed homogenous 3d point . w is fixed
converts a point from homogenous coordinates into euclidean
applies a 2d affine transform to the point and stores the results in another variable .
applies a 2d affine transform to the point and stores the results in another variable .
returns the acute angle between the two vectors . computed using the dot product .
sets the vector equal to a - b .
tests to see if the two vectors are identical up to a sign difference
sets this rectangle to be equal to the passed in rectangle .
in - place minus operation . this = a - b .
dot product between this and a = this . x * a . x + this . y * a . y + this . z * a . z
<p > convert from quadratic to rotated formats . equations taken from [ 1 ] . < / p >
convert from rotated to quadratic .
computes the value of the quadratic ellipse function at point ( x y ) . should equal 0 if the point is along the ellipse .
computes the value of the quadratic ellipse function at point ( x y ) . should equal 1 if the point is on the ellipse .
computes the point on the ellipse at location t where t is an angle in radians
computes the value of t used to specify a point s location
computes the tangent to the ellipse at the specified location
<p > finds two points on the ellipse that in combination with point pt each define a line that is tangent to the ellipse . < / p >
<p > finds four lines which are tangent to both ellipses . both ellipses must not intersect . line 0 and line 3 will not intersect the line joining the center of the two ellipses while line 1 and 2 will . < / p >
<p > selects 4 pairs of points . each point in the pair represents an end point in a line segment which is tangent to both ellipsea and ellipseb . both ellipses are assumed to not intersect each other . if a fatal error occurs the function will return false . however it can return true and did not converge . to check for convergence call { @link #isconverged () } . < / p >
select the initial tangent points on the ellipses . this is done by :
selects a tangent point on the ellipse which is closest to the original source point of a .
makes sure x0 y0 is the lower extent and x1 y1 is the upper extent
<p > returns the euclidean distance squared from this to a . no floating point operations are used . < / p >
finds the best fit matrix in so ( 3 ) for the input matrix .
used to retrieve the corners of the box .
distance of the closest point between two lines . parallel lines are correctly handled .
distance from the point to the closest point on the line .
distance from the point to the closest point on the line segment .
distance between a plane and a point . a signed distance is returned where a positive value is returned if the point is on the same side of the plane as the normal and the opposite if it s on the other .
returns the signed distance a point is from the sphere s surface . if the point is outside of the sphere it s distance will be positive . if it is inside it will be negative . <p > < / p > distance = ||sphere . center - point|| - r
returns the signed distance a point is from the cylinder s surface . if the point is outside of the cylinder it s distance will be positive . if it is inside it will be negative .
signed distance from a 3d point to 3d triangle . the sign indicates which side of the triangle the point is on . see { @link georegression . metric . alg . distancepointtriangle3d_f64 } for the details .
where = p + t * slope .
returns a point along the line . see parametric equation in class description .
<p > returns the euclidean distance of the closest point on the line from a point . < / p >
<p > returns the euclidean distance of the closest point on the line from a point . < / p >
<p > returns the euclidean distance squared of the closest point on the line from a point . < / p >
<p > returns the euclidean distance of the closest point on a line segment to the specified point . < / p >
<p > returns the euclidean distance of the closest point on a line segment to the specified point . < / p >
<p > returns the euclidean distance squared of the closest point on a line segment to the specified point . < / p >
finds the distance between the two line segments
finds the distance squared between the two line segments
returns the euclidean distance of the closest point on the quadrilateral to the provided point .
returns the euclidean distance squared of the closest point on the quadrilateral to the provided point .
returns the euclidean distance of the closest point on the polygon to the provided point .
returns the euclidean distance squared of the closest point on the polygon to the provided point .
<p > returns the euclidean distance of the closest point on the line to the specified point . < / p >
<p > returns the signed euclidean distance of the closest point on the line to the specified point . the line is assumed be normalized . see { @link linegeneral2d_f64 } for details on normalization . < / p >
returns the distance of the closest point on the line from the origin
euclidean distance of closest point on ellipse to point p .
euclidean distance squared of closest point on ellipse to point p .
adds the next transform in the sequence .
<p > finds the closest point on line to the specified point . < / p >
<p > finds the closest point on line to the specified point . < / p >
<p > computes the closest point along the line as a function of t : <br > [ x y ] = [ x_0 y_0 ] + t [ slopex slopey ] < / p >
<p > computes the closest point along the line as a function of t : <br > [ x y ] = [ x_0 y_0 ] + t [ slopex slopey ] < / p >
finds the closest point on the line segment to the provided point p .
computes the closest point on an ellipse to the provided point . if there are multiple solutions then one is arbitrarily chosen .
fits the polynomial curve to the data .
fits the conic to the points . strongly recommended that you transform the points such that they have zero mean and a standard deviation along x and y axis independently .
creates a random vector where each axis is selected from a uniform distribution .
selects a vector which will be perpendicular .
checks to see if the two vectors are identical to within tolerance . each axis is checked individually .
rescales the vector such that its normal is equal to one .
creates a matrix from the set of column vectors . each vector is a column in the new matrix .
converts matrices into vectors . all matrices must be vectors with 3 elements .
returns the acute angle between the two vectors . computed using the dot product .
<p > in - place addition< / p >
<p > addition< / p >
scalar multiplication
checks to see if the two rectangles intersect each other
finds the intersection between two rectangles . if the rectangles don t intersect then false is returned .
http : // www . ecse . rpi . edu / homepages / wrf / research / short_notes / pnpoly . html
checks to see if the point is contained inside the concave polygon .
true if the point is contained inside the rectangle
true if the point is contained inside the rectangle
<p > addition< / p >
euclidean distance from the point
specifies the ellipse which point distance is going to be found from
find the closest point on the ellipse to the specified point . to get the solution call { @link #getclosest () }
converts the quaternion into a unit quaternion .
fits the conic to the points . strongly recommended that you transform the points such that they have zero mean and a standard deviation along x and y axis independently .
computes the area of an arbitrary triangle from 3 - vertices .
area of a quadrilateral computed from two triangles .
area of a simple polygon . meaning it can be concave or convex but can t have self intersections
finds the point which has the mean location of all the points in the list . this is also known as the centroid .
finds the point which has the mean location of all the points in the array . this is also known as the centroid .
computes the mean / average of two points .
finds the minimal volume { @link georegression . struct . shapes . rectanglelength2d_f64 } which contains all the points .
finds the minimal volume { @link georegression . struct . shapes . rectanglelength2d_f64 } which contains all the points .
puts the points into counter - clockwise order around their center .
computes the mean and covariance matrix from the set of points . this describes a normal distribution
randomly generates points from the specified normal distribution
a * x + b * y + c = 0
ensures that a * a + b * b == 1
in - place minus operation . this = a - b .
finds the minimum area bounding rectangle which is aligned to the x and y axis around the list of points . note ( x0 y0 ) is inclusive and ( x1 y1 ) is exclusive .
finds the minimum area bounding rectangle which is aligned to the x and y axis around the polygon . note ( x0 y0 ) is inclusive and ( x1 y1 ) is exclusive .
returns true if the polygon is ordered in a counter - clockwise order . this is done by summing up the interior angles .
flips the order of points inside the polygon . the first index will remain the same will otherwise be reversed
determines if the polugon is convex or concave .
returns true if the cross product would result in a strictly positive z ( e . g . z &gt ; 0 ) . if true then the order is clockwise .
checks to see if the vertexes of the two polygon s are the same up to the specified tolerance
checks to see if the vertexes of the two polygon s are the same up to the specified tolerance and allows for a shift in their order
finds the point which has the mean location of all the points in the list . this is also known as the centroid .
<p > in - place addition< / p >
in - place scalar multiplication
returns the absolute value of the component with the largest absolute value
<p > fits points to the quadratic polynomial . it s recommended that you apply a linear transform to the points to ensure that they have zero mean and a standard deviation of 1 . then reverse the transform on the result . a solution is found using the pseudo inverse and inverse by minor matrices . < / p >
<p > fits points to the quadratic polynomial using a qrp linear solver . < / p >
<p > fits points to the cubic polynomial . it s recommended that you apply a linear transform to the points to ensure that they have zero mean and a standard deviation of 1 . then reverse the transform on the result . a solution is found using the pseudo inverse and inverse by minor matrices . < / p >
<p > fits points to a 2d quadratic polynomial . there are two inputs and one output for each data point . it s recommended that you apply a linear transform to the points . < / p >
euclidean distance between the two specified points
euclidean distance squared between the two specified points
randomly generates a set of points on the plane centered at the plane s origin using a uniform distribution .
creates a list of random points from a uniform distribution along each axis
creates a list of random points from a normal distribution along each axis
computes the mean of the list of points .
computes the mean of the list of points up to element num .
finds the minimal volume { @link box3d_f64 } which contains all the points .
discards any cached principal for the given collection of credentials .
discards any cached principal for the collection of credentials satisfying the given predicate .
combine the given string collections into a set using case - insensitive matching . if there are multiple instances of the same string but with different capitalization only the first one found will be included .
get the set of features defined in the server . xml
gets features from the configdropins s defaults or overrides directory
adds features from the given server file into the origresult or a new set if origresult is null .
parse features from an include node .
parse feature elements from a featuremanager node trimming whitespace and treating everything as lowercase .
get the json files corresponding to the product properties from the lib / versions / * . properties files
download the json file for the given product .
returns true if this scenario is not supported for installing from maven repository which is one of the following conditions : from parameter is specified ( don t need maven repositories ) or esa files are specified in the configuration ( not supported with maven for now )
gets the set of all open liberty features by scanning the product jsons .
returns true if all features in featurestoinstall are open liberty features .
returns whether the reference collection contains all of the strings in the target collection ignoring case .
resolve download and install features from a maven repository . this method calls the resolver with the given jsons and feature list downloads the esas corresponding to the resolved features then installs those features .
download the override bundle from the repository with the given groupid and artifactid corresponding to the latest version in the range between the current open liberty version ( inclusive ) and the next version ( exclusive ) . returns a string in the format filepath ; bundlename where bundlename is the bundle symbolic name from its manifest .
gets the next product version number .
extracts the bundle symbolic name from the jar manifest .
find latest install map jar from specified directory
returns whether file2 can replace file1 as the install map jar .
returns the extracted version from filename
performs pairwise comparison of version strings including nulls and non - integer components .
performs product validation by running bin / productinfo validate
runs the productinfo command and returns the output
check whether the given artifact is a spring boot uber jar
converts map<string string > to map<libertypropertyi string > . validates each key property name .
check that the given key exists in arquillianproperties
we assume any environment that is not headless will have a web browser to display the image in a web page .
prints a request for a text input to the window . <br > <b > example : < / b > { @code string name = fancymessagebox . askfortextinput ( what is your nickname? nicknames ) ; }
prints the message to the window . <br > <b > example : < / b > { @code fancymessagebox . showmessage ( girl programmers rule! just the facts ) ; }
parses a file <div > <b > example : < / b > { @code parser . parsertffile ( filename data ) } < / div >
paints a circle <div > <b > example : < / b > { @code circle . paint ( g caller ) } < / div >
makes a cool shape fast <div > <b > example : < / b > {
draws an entire tortoise -- fast! <div > <b > example : < / b > {
checks if a tortoise can eat a slice of a pizza <div > <b > example : < / b > { @code tortoise . eatpizza ( pizza ) } < / div >
create the makeasquare recipe -- #11 . 1
create the movetothesquarestart recipe -- #4 . 1
create the movebacktocenter recipe
a convenience function to check if two objects are equal .
uses a rtf viewer to display the results of a model ( or text ) <div > <b > example : < / b > { @code viewer . displayrtffile ( text ) } < / div >
loads an int from a string .
randomly chooses a number between the minimum and maximum <div > <b > example : < / b > { @code int grade = numberutils . getrandomint ( 1 100 ) ; } < / div >
ignore the following it s needed to run the deep dive
checks to see if a pizza has a particular kind of topping <div > <b > example : < / b > { @code pizza . hastopping ( topping ) } < / div >
*******************************************************************
------------- recipe for createcolorpalette -- #8 . 2
------------- recipe for drawoctogon -- #9 . 2
captures an image of the result of your program and displays it to you
calculate the <a href = http : // en . wikipedia . org / wiki / taxicab_geometry > manhattan distance< / a > between two positions .
create a copy of the puzzle where the blank swapped with the value in the target position
calculate the distance between the goal by summing the distance between each cell and its goal .
sets a sound that you can play through your speakers . use a tkpsound ( there is a list ) <br > <b > example : < / b > {
plays a tkpsound through your speakers . you must first set the tkpsound <br > <b > example : < / b > {
prints a formatted string to standard output using the specified format string and arguments and then flushes standard output .
prints a formatted string to standard output using the locale and the specified format string and arguments ; then flushes standard output .
unit tests some of the methods in <tt > stdout< / tt > .
recipe for makeafishydecision with the numberoffish
draws a line segment between ( <em > x< / em > <sub > 0< / sub > <em > y< / em > <sub > 0< / sub > ) and ( <em > x< / em > <sub > 1< / sub > <em > y< / em > <sub > 1< / sub > ) .
draws one pixel at ( <em > x< / em > <em > y< / em > ) . this method is private because pixels depend on the display . to achieve the same effect set the pen radius to 0 and call { @code point () } .
draws a point centered at ( <em > x< / em > <em > y< / em > ) . the point is a filled circle whose radius is equal to the pen radius . to draw a single - pixel point first set the pen radius to 0 .
draws a circle of the specified radius centered at ( <em > x< / em > <em > y< / em > ) .
draws an ellipse with the specified semimajor and semiminor axes centered at ( <em > x< / em > <em > y< / em > ) .
draws a circular arc of the specified radius centered at ( <em > x< / em > <em > y< / em > ) from angle1 to angle2 ( in degrees ) .
draws a square of side length 2r centered at ( <em > x< / em > <em > y< / em > ) .
draws a rectangle of the specified size centered at ( <em > x< / em > <em > y< / em > ) .
draws a polygon with the vertices ( <em > x< / em > <sub > 0< / sub > <em > y< / em > <sub > 0< / sub > ) ( <em > x< / em > <sub > 1< / sub > <em > y< / em > <sub > 1< / sub > ) ... ( <em > x< / em > <sub > <em > n< / em > &minus ; 1< / sub > <em > y< / em > <sub > <em > n< / em > &minus ; 1< / sub > ) .
draws the specified image centered at ( <em > x< / em > <em > y< / em > ) . the supported image formats are jpeg png and gif . as an optimization the picture is cached so there is no performance penalty for redrawing the same image multiple times ( e . g . in an animation ) . however if you change the picture file after drawing it subsequent calls will draw the original picture .
draws the specified image centered at ( <em > x< / em > <em > y< / em > ) rotated given number of degrees and rescaled to the specified bounding box . the supported image formats are jpeg png and gif .
write the given text string in the current font centered at ( <em > x< / em > <em > y< / em > ) .
write the given text string in the current font centered at ( <em > x< / em > <em > y< / em > ) and rotated by the specified number of degrees .
saves the drawing to using the specified filename . the supported image formats are jpeg and png ; the filename suffix must be <tt > . jpg< / tt > or <tt > . png< / tt > .
prints to screen any variable information to be viewed .
/ * setup code
sets up a particular set of colors on the color wheel <div > <b > example : < / b > {
draws an <i > amazing< / > tkp inner p <div > <b > example : < / b > {
draws an <i > awesome< / > tkp outer p <div > <b > example : < / b > {
draws an <i > outstanding< / > tkp right bracket <div > <b > example : < / b > {
draws an <i > incredible< / > tkp t <div > <b > example : < / b > {
draws an <i > impressive< / > tkp k <div > <b > example : < / b > {
adds a turtle instance to a window note : this method must be called before calling any other methods on turtle instances <p > <b > example : < / b > { @code multiturtlewindow . addturtle ( myturtle ) } < / p >
------------- recipe for createcolorpalette ( hint : use pencolors ) -- #8
------------- recipe for adjustpen -- #9
------------- recipe for drawpentagon -- #10
sets the speed that a turtle instance moves <p > <b > example : < / b > { @code myturtle . setspeed ( speed ) } < / p >
sets the distance that a turtle instance moves in pixels <p > <b > example : < / b > { @code myturtle . move ( 100 ) } < / p >
draws a lightning bolt of a specified length <p > <b > example : < / b > { @code myturtle . drawlightning ( length ) } < / p >
paints a diamond <div > <b > example : < / b > { @code diamond . paint ( g caller ) } < / div >
------------- recipe for weaveonelayer -- #9
------------- recipe for drawtriangle -- #4
returns a random integer uniformly in [ a b ) .
returns a random real number uniformly in [ a b ) .
returns a random integer from a geometric distribution with success probability <em > p< / em > .
returns a random integer from a poisson distribution with mean &lambda ; .
returns a random integer from the specified discrete distribution .
unit test .
sets http http according to path . it must exist as http .
loads http from the http
capitalizes the first character of the word given . it will convert i to i
un capitalizes the first character of the word given . it will convert i to i
create as a { @link user } resource .
updates a single { @link user } matches with the given id . <p > status code : not found 404 not matches 412
updates a single { @link user } matches with the given id . <p > status code : not found 404 not matches 412
returns modified list of the entities regarding to the search model . { @inheritdoc }
returns modified list of the entities regarding to the search model . { @inheritdoc }
returns modified list of the entities regarding to the search model . { @inheritdoc }
returns modified list of the entities regarding to the search model . { @inheritdoc }
returns modified list of the entities regarding to the search model . { @inheritdoc }
returns modified list of the entities regarding to the search model . { @inheritdoc }
{ @inheritdoc }
helps to fix path
initializes the environment .
create a { @link htriggerinfo } resource .
update a htriggerinfo resource with the matches given id . <p > status code : not found 404 not matches 412
returns all htriggerinfo as a collection with the matches given job id .
generates join query for the given joincriteria
combines the token and cookie sentence
checks the expiration date of token . renews and puts at header of response .
extracts the accesstoken from cookies
registers any guice - bound providers or root resources .
check username and password for authentication <p > status code : unauthorized no have authentication . internal_server_error blocked .
log out
user information returns <p > status code : unauthorized no have authentication .
user change password <p > status code : not_found not found user . precondition_failed change passsword error .
creates { @link optional } { @link io . robe . auth . credentials } instance from provided tokenstring
fill permission list with role and sub - role permissions recursively .
return all hjobinfo as a collection
return a hjobinfo resource with the matches given id . <p > status code : not found 404
returns all htriggerinfo as a collection with the matches given job id .
returns all htriggerinfo as a collection with the matches given job id .
returns all htriggerinfo as a collection with the matches given job id .
returns all htriggerinfo as a collection with the matches given job id .
executes the desired method call with a new instance of the { @link resourceservlet } implementation . transaction management is done here .
adds a projection to this list of projections after wrapping it with an alias
get menu for logged user
create a { @link menu } resource .
creates an identical jobdetail instance from the given parameters .
creates an identical trigger instance from the given annotation .
helps to set count and intervals
helps to set start and end times
takes the mail item into the queue and manages the mail sender thread . if thread is alive it will send the mail at the end of current thread queue . else a new thread will be created and started .
called to write the message body .
initializes the environment . forwards the configuration to quartz . collect { @link jobinfoprovider } classes initializes scheduler collects all subtypes of { @link org . quartz . job } annotated with { @link robejob } including { @link @robetrigger } s * collects additional triggers from providers * registers them all for future control .
initialize scheduler and start jobmanager
returns an ordered list of the fields which belongs to the given class .
returns a map of the fields which belongs to the given class with field name as key .
adds hibernate bundle for provider connection asset bundle for io . robe . admin screens and class scanners for <ul > <li > entities< / li > <li > healthchecks< / li > <li > providers< / li > <li > injectableproviders< / li > <li > resources< / li > <li > tasks< / li > <li > managed objects< / li > < / ul >
{ @inheritdoc } in addition adds exception mapper .
returns all services and menus collection with the matches given role id .
create a { @link role } resource .
create { @link service ) resource and matches with the given id .
refreshing service with description <p > todo exception handler
parses or wraps the exception and transforms it to a human readable json loaded response .
configure method for token generation configurations and encryptor configure
generates attribute has with useragent remoteaddr keys . combines them and hashes with sha256 and sets the variable .
generates a tokenstring with a new expiration date and assigns it .
sends a mail with the given item .
read more https : // github . com / dropwizard / dropwizard / issues / 932
verify that the supplied password matches the password for this user . password should be stored as a hash . it is recommended you use the hashpassword ( password accountname ) method in this class . this method is typically used for reauthentication for the most sensitive functions such as transactions changing email address and changing other account information .
generate strong password that takes into account the user s information and old password . implementations should verify that the new password does not include information such as the username fragments of the old password and other information that could be used to weaken the strength of the password .
changes the password for the specified user . this requires the current password as well as the password to replace it with . the new password should be checked against old hashes to be sure the new password does not closely resemble or equal any recent passwords for that userentry . password strength should also be verified . this new password must be repeated to ensure that the user has typed it in correctly .
returns the userentry matching the provided accountname . if the accoundid is not found an anonymous userentry or null may be returned .
returns a string representation of the hashed password using the accountname as the salt . the salt helps to prevent against rainbow table attacks where the attacker pre - calculates hashes for known strings . this method specifies the use of the user s account name as the salt value . the encryptor . hash method can be used if a different salt is required .
ensures that the account name passes site - specific complexity requirements like minimum length .
ensures that the password meets site - specific complexity requirements like length or number of character sets . this method takes the old password so that the algorithm can analyze the new password to see if it is too similar to the old password . note that this has to be invoked when the user has entered the old password as the list of old credentials stored by esapi is all hashed . additionally the user object is taken in order to verify the password and account name differ .
sets http http according to path . it must exist as http .
generates hash ( md5 ) from http path and last modification date
loads http from the http
writes http to a cache ( byte array )
todo this method should be refactoring .
implemented just to get method .
initializes the environment .
creates a { @link org . reflections . reflections } with the given packages ( configuration )
collects all classes extended { @link io . robe . guice . scanner . scanner } and adds them to environment
begins new transaction in a new session and performs operations provided in { @link transactionwrapper } <br / > in case of an exception is thrown the { @link transactionexceptionhandler } will be invoked .
begins new transaction in a new session and performs operations provided in { @link transactionwrapper } <br / > in case of an exception is thrown the { @link transactionexceptionhandler } will be invoked .
if present backup current the session in {
opens a new session sets flush mode and bind this session to {
if transaction is present and active then commit .
if transaction is present and active then rollback .
closes and unbinds the current session . <br / > if {
starts the progress .
get hierarchical menu service for permission
return all { @link permission } s as a collection .
creates a { @link permission } resource . <p > status code : not found 404 not matches 412
roleoid . permissionoid . code
merges all path patterns and and creates a single string value which will be equal with service methods path annotation value and http method type . generated string will be used for permission checks .
initializes the environment .
determines if cryptography restrictions apply . restrictions apply if the value of { @link cipher#getmaxallowedkeylength ( string ) } returns a value smaller than { @link integer#max_value } if there are any restrictions according to the javadoc of the method . this method is used with the transform <code > aes / cbc / pkcs5padding < / code > as this is an often used algorithm that is <a href = https : // docs . oracle . com / javase / 8 / docs / technotes / guides / security / standardnames . html#impl > an implementation requirement for java se< / a > .
create { @link systemparameter ) resource .
create or update { @link systemparameter ) resource .
first it checks is there any annotation class for parsing operations if it is parses with given format if there is a exception while parsing with given format catches and tries with default values if there is no given format tries with static values
gets current response created with exception parameters .
generates = equals
! = not equals operator
< less than operator
< = less or equals than operator
> greater than operator
> = greater or equals than operator
~ = contains than operator
| = in list operator
update the list of declared namespaces with a new namespace .
adds or replaces the content of the representation .
define rel semantics for this representation .
add a link to this resource .
add a link to this resource .
add a link to this resource .
add a link to this resource .
add a link to this resource .
replace the value of this resource with a new value optionally of a new type .
adds a new namespace .
creates a new { @code immutableset } from the given { @code iterable } .
returns the root cause of the given { @code throwable } . if the given { @code throwable } is not the result of a previous one it is considered as the root .
returns the chain of { @code throwable } s that caused the given one . the given { @code throwable } is the first element in the returned { @code list } the last one is the root cause .
returns the stack trace of the given { @code throwable } as a { @code string } .
returns the stack frames of the given { @code throwable } . the stack frames are simply obtained from calling { @code tostring } on each { @link stacktraceelement } of { @code t } .
re - throws the given { @code throwable } if it is already an instance of { @code runtimeexception } or { @link error } and if not wraps it in a { @code runtimeexception } before throwing it .
serializes the given { @code serializable } object into an array of { @code byte } s .
deserializes the given array of { @code byte } s into an object .
returns whether the specified range in the given { @code string } can be encoded into utf - 8 .
returns whether the specified range in the given byte array represents valid utf - 8 encoded characters .
returns the utf - 8 encoding of the given { @code string } .
returns the utf - 8 encoding of the specified character sequence .
encodes the given { @code int } value using little - endian byte ordering convention into the given array starting at the given offset .
encodes the given { @code long } value using little - endian byte ordering convention into the given array starting at the given offset .
decodes the first 4 bytes starting at { @code off } of the given array into an { @code int } value using little - endian byte ordering convention .
decodes the first 8 bytes starting at { @code off } of the given array into a { @code long } value using little - endian byte ordering convention .
copies the content of the given { @code inputstream } into the given { @code writer } using the system s default charset .
copies the content of the given { @code inputstream } into the given { @code writer } using the specified charset .
copies the content of the given { @code reader } into the given { @code outputstream } using the system s default charset .
copies the content of the given { @code reader } into the given { @code outputstream } using the specified charset .
returns whether the given streams have the same content .
reads the whole content of the given { @code reader } into a { @code string } .
reads the whole content of the given { @code inputstream } into a { @code string } using the system s default charset .
reads the whole content of the given { @code inputstream } into a { @code string } using the specified charset .
reads all the lines from the given source { @code reader } . note that the returned { @code list } is immutable .
reads all the lines from the given source { @code inputstream } using the system s default charset . note that the returned { @code list } is immutable .
reads all the lines from the given source { @code inputstream } using the specified charset . note that the returned { @code list } is immutable .
creates and returns a new immutable { @code kdf } instance implementing the pbkdf1 algorithm ( rfc 2898 ) .
creates and returns a new immutable { @code kdf } instance implementing the pbkdf2 algorithm ( rfc 2898 ) .
creates and returns a new immutable { @code kdf } instance implementing the hkdf algorithm ( rfc 5869 ) .
creates and returns a new immutable { @code kdf } instance implementing the scrypt algorithm ( rfc 7914 ) .
copies the contents of { @code src } to { @code dst } . if { @code dst } doesn t exist it will be created . if it already exists it can be either a directory or a regular file if { @code src } is also a regular file . named after the unix command of the same name .
copies the contents of the given input { @code file } to the given { @code outputstream } . named after the unix command of the same name .
copies the contents of the given { @code inputstream } to the given output { @code file } . named after the unix command of the same name .
moves a file from one path to another . named after the unix command of the same name .
deletes the given { @code file } s . directories will be recursively deleted . named after the unix command of the same name .
creates empty files at the specified paths or updates the last modification time of the files at the specified paths . named after the unix command of the same name .
reads the first ( up to { @code n } ) bytes of the given { @code file } . named after the unix command of the same name .
reads the last ( up to { @code n } ) bytes of the given { @code file } . named after the unix command of the same name .
returns whether the given { @code file } s have the same content . two regular files are considered equal if they contain the same bytes . two directories are considered equal if they both contain the same items where an item is either a directory or a regular file ( items must have the same name and content in both directories ) .
returns the file name without its path or extension . this method is named after the basename unix command .
returns an { @code outputstream } to write to the given { @code file } .
reads the content of the given { @code file } .
parses a { @code mediatype } from its { @code string } representation .
creates a new { @code mediatype } with the given type and subtype .
returns the value of the charset parameter if it is specified or { @code null } otherwise .
returns a new { @code mediatype } instance similar to this one but with the specified parameter set to the given value .
returns a new { @code mediatype } instance having the same type and subtype as this one but whose parameters is the union of this instances parameters with the given ones ( the given parameters have precedence over this instance s parameters ) .
returns a new { @code mediatype } instance similar to this one but without the specified parameter .
returns a new { @code mediatype } instance with the same type and subtype as this instance but without any parameters .
returns whether this media type is within the specified media range . namely it returns { @code true } if the type of { @code range } is the wildcard or is equal to the type of this instance and if the subtype of { @code range } is the wildcard or is equal to the subtype of this instance and if all the parameters present in { @code range } are also present in this instance .
concatenates the given { @code iterable } s into a single one . note that the returned { @code iterable } is only a view that is any subsequent update on any of the input { @code iterable } s will affect the returned view . the input { @code iterable } s will not be polled until necessary . the returned view s { @code iterator } supports { @link iterator#remove () } when the corresponding input { @code iterator } supports it .
returns a cyclic { @code iterable } that cycles indefinitely over the given { @code iterable } s elements . the returned { @code iterable } s { @code iterator } supports { @code iterator#remove () } .
returns an { @code iterable } that cycles indefinitely over the given elements . the returned { @code iterable } s { @code iterator } supports { @link iterator#remove () } .
returns whether the given { @code iterable } s contain equal elements in the same order .
returns an { @code iterable } view of the given { @code iterable } that will only return its first { @code limit } items . the returned view s { @code iterator } s support { @link iterator#remove () } if the original { @code iterator } does .
returns an { @code iterable } view of the given { @code iterable } that skips its first { @code n } elements . the returned { @code iterable } s { @code iterator } supports { @link iterator#remove () } if the original { @code iterator } does .
returns a { @code list } containing all the given { @code iterable } s elements .
returns a { @code set } containing all the given { @code iterable } s elements . the returned { @code set } has the same iteration order as the source { @code iterable } .
returns a { @code bag } containing all the given { @code iterable } s elements . the returned { @code bag } has the same iteration order as the source { @code iterable } .
adds the padding bits and the message length to the input data .
creates a new { @code immutablelist } from the given { @code collection } .
creates a new { @code immutablelist } from the given { @code iterable } .
creates a new { @code immutablelist } from the given { @code iterator } .
creates a new { @code immutablelist } containing the given elements .
creates a new { @code immutablelist } containing the given elements .
returns the first ( up to 10 ) lines of the given { @code file } using the specified charset . named after the unix command of the same name .
returns the first ( up to { @code n } ) lines of the given { @code file } using the system s default charset . named after the unix command of the same name .
returns the first ( up to { @code n } ) lines of the given { @code file } using the specified charset . named after the unix command of the same name .
returns the last ( up to 10 ) lines of the given { @code file } using the specified charset . named after the unix command of the same name .
returns the last ( up to n ) lines of the given { @code file } using the specified charset . named after the unix command of the same name .
returns a new { @code bufferedreader } to read the given { @code file } using the specified charset .
returns a new { @code bufferedwriter } to write to the given { @code file } using the system s default charset .
returns a new { @code bufferedwriter } to write to the given { @code file } using the specified charset .
reads the whole content of the given { @code file } as a { @code string } using the specified charset .
reads all the lines from the given { @code file } using the system s default charset . note that the returned { @code list } is immutable .
creates a new { @code urn } by parsing the given { @code string } . this function invokes the { @link urn#urn ( java . lang . string ) } constructor ; any { @code urnsyntaxexception } thrown by the constructor is caught and wrapped in a new { @code illegalargumentexception } which is then thrown . this method is provided for use in situations where it is known that the given { @code string } is a legal { @code urn } .
finds and returns the resource having the given name using the { @linkplain thread#getcontextclassloader () context class loader } . note that if the context class loader is { @code null } the class loader that loaded this class will be used instead .
finds and returns the resource having the given name ( relative to the specified class ) .
copies the content of this resource to the specified stream .
copies the content of this resource to the specified stream .
reads and returns this resource s content as a { @code byte [] } .
reads and returns this resource s content as a { @code string } .
reads and returns all this resource s lines . note that the returned { @code list } is immutable .
returns whether the given { @code calendar } s represent the same instant .
returns whether the given { @code date } s represent the same local time .
returns whether the given { @code calendar } s represent the same local time .
returns whether the given { @code date } s represent the same day .
returns whether the given { @code calendar } s represent the same day .
returns whether the given { @code date } s represent the same week .
returns whether the given { @code calendar } s represent the same week .
returns whether the given { @code date } s represent the same month .
returns whether the given { @code calendar } s represent the same month .
returns whether the given { @code date } s represent the same year .
returns whether the given { @code calendar } s represent the same year .
parses a { @code string } representing a date into a { @code date } instance . the given formats will be used sequentially until a successful parsing is obtained . a parsing is considered successful if it parses the whole input { @code string } .
parses a { @code string } representing a date into a { @code date } instance . the given formats will be used sequentially until a successful parsing is obtained . a parsing is considered successful if it parses the whole input { @code string } .
returns the { @code string } representation of the given { @code date } according to the specified format pattern .
converts a { @code date } into a { @code calendar } .
concatenates all the given { @code iterator } s into a single one . the source { @code iterator } s aren t polled until necessary . the returned { @code iterator } supports { @link iterator#remove () } when the corresponding input { @code iterator } supports it .
concatenates all the given { @code iterator } s into a single one . the source { @code iterator } s aren t polled until necessary . the returned { @code iterator } supports { @link iterator#remove () } when the corresponding input { @code iterator } supports it .
returns an { @code iterator } that cycles indefinitely over the content of the given source { @code iterator } . the source { @code iterator } is not polled until necessary . the returned { @code iterator } supports { @link iterator#remove () } .
returns an { @code iterator } that cycles indefinitely over the given elements . the returned { @code iterator } supports { @link iterator#remove () } .
returns whether the given { @code iterator } s contain equal elements in the same order . note that this method consumes entirely the input { @code iterator } s .
creates an { @code iterator } returning only the first { @code limit } elements of the given { @code iterator } . the source { @code iterator } is not polled until necessary . the returned { @code iterator } supports { @link iterator#remove () } if the source { @code iterator } supports it .
skips { @code n } elements from the given { @code iterator } .
returns a { @code set } containing all the given { @code iterator } s elements . the returned { @code set } has the same iteration order as the given { @code iterator } . this method consumes entirely the input { @code iterator } .
returns a { @code bag } containing all the given { @code iterator } s elements . the returned { @code bag } has the same iteration order as the given { @code iterator } . this method consumes entirely the input { @code iterator } .
returns whether the given { @code string } only contains space \ n \ r or \ t characters .
abbreviates the given { @code string } using the specified ellipsis so that the returned { @code string } s length is equal to { @code length } .
concatenates the given { @code string } s .
computes and returns the damerau - levenshtein distance between the given { @code string } s . this distance is obtained by counting the minimum number of operations needed to transform one { @code string } into the other where an operation is defined as an insertion deletion or substitution of a single character or a transposition of two adjacent characters .
returns a random { @code string } using the given characters and the specified source of randomness . all characters have equal likelihood to appear in the resulting { @code string } assuming that the source of randomness is fair .
returns the { @code string } obtained by repeating { @code count } times the given { @code string } .
randomly permutes the characters from the given { @code string } using the specified source of randomness . all permutations occur with equal likelihood assuming that the source of randomness is fair . this implementation uses the optimized version of the fisher - yates shuffle algorithm ( fisher yates durstenfeld knuth ) and thus runs in linear time .
returns the new { @code string } obtained by stripping the first and last { @code n } characters from the given one .
returns the new { @code string } obtained by stripping the first { @code n } characters from the given one .
returns the new { @code string } obtained by stripping the last { @code n } characters from the given one .
returns a copy of the given { @code string } with leading whitespaces omitted .
returns a copy of the given { @code string } with trailing whitespaces omitted .
returns a { @code string } of length at least { @code len } created by prepending as many copies of { @code padchar } as necessary to reach that length .
returns a { @code string } of length at least { @code len } created by appending as many copies of { @code padchar } as necessary to reach that length .
quotes the given { @code string } with double quotes . if the given { @code string } has multiple quotes only one of them is kept .
unquotes the given { @code string } that is this method removes any leading or trailing double quotes . if the given { @code string } is not quoted returns it unmodified .
counts the occurrences of the substring { @code sub } in { @code str } .
creates a new { @code url } by parsing the given { @code string } . this function invokes the { @link url#url ( java . lang . string ) } constructor ; any { @code malformedurlexception } thrown by the constructor is caught and wrapped in a new { @code illegalargumentexception } which is then thrown . this method is provided for use in situations where it is known that the given { @code string } is a legal { @code url } .
relativizes the specified full { @code url } against the given base . behaves as { @link java . net . uri#relativize ( java . net . uri ) } .
resolves the specified path against the given base { @code url } . behaves as { @link java . net . uri#resolve ( java . lang . string ) } .
returns the qualified name of the given class ( package name followed by a dot followed by the class name ) . for array classes this method returns the component type class name followed by as many [] as the array s dimension .
returns only the name of the given class that is without its package name and without its eventual outer class name .
returns the name of the package of the given class or the empty { @code string } if the class is defined in the default package .
returns all the super types of the given class that is all the classes in which any instance of the given class can be cast into .
returns the { @code set } of common super types of the given classes that is all the classes in which any instance of the given classes can be cast into .
verifies that the given password matches the hashed one .
reads the next line from the standard input using the given charset .
writes the given byte to this buffer .
writes the given data to this buffer .
returns { @code len } bytes from this buffer starting at { @code off } .
concatenates the given arrays into a single one .
concatenates the given arrays into a single one .
copies the specified range of elements from the given array into a new array . the returned array will be padded with { @code 0 } if necessary so that it has an exact length of { @code len } .
copies the specified range of elements from the given array into a new array . the returned array will be padded with { @code null } if necessary so that it has an exact length of { @code len } .
returns a copy of the given array . the original array and the returned copy will have identical length and content .
returns a new array containing the same elements as the given one but in reverse order .
returns a new array containing the same elements as the given one but in reverse order .
returns a new array containing the same elements as the given one but rotated by the given distance . the element at index { @code i } in the returned array corresponds to the element in the original array at index { @code ( i - distance ) } mod { @code a . length } for all values of { @code i } between { @code 0 } and { @code a . length - 1 } inclusive . note that rotation by { @code 0 } or by a multiple of { @code a . length } is a no - op .
returns a new array containing the same elements as the given one but rotated by the given distance . the element at index { @code i } in the returned array corresponds to the element in the original array at index { @code ( i - distance ) } mod { @code a . length } for all values of { @code i } between { @code 0 } and { @code a . length - 1 } inclusive . note that rotation by { @code 0 } or by a multiple of { @code a . length } is a no - op .
returns a copy of the given array where its element have been randomly permuted using the specified source of randomness . all permutations occur with equal likelihood assuming that the source of randomness is fair . this method uses the optimized version of the fisher - yates shuffle algorithm ( fisher yates durstenfeld knuth ) and thus runs in linear time .
returns a sorted copy of the given array of objects into ascending order according to the natural ordering of its elements ( all elements in the array must implement the { @link comparable } interface ) .
returns a sorted copy of the given array of objects into ascending order according to the order induced by the given { @code comparator } .
converts an array of { @code long } s to an array of { @code long } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code integer } s to an array of { @code int } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code short } s to an array of { @code short } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code character } s to an array of { @code char } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code byte } s to an array of { @code byte } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code boolean } s to an array of { @code boolean } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code float } s to an array of { @code float } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code double } s to an array of { @code double } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code long } s to an array of { @code long } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code int } s to an array of { @code integer } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code short } s to an array of { @code short } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code char } s to an array of { @code character } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code byte } s to an array of { @code byte } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code boolean } s to an array of { @code boolean } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code float } s to an array of { @code float } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
converts an array of { @code double } s to an array of { @code double } s . returns { @code null } if the given array is { @code null } . does not modify the input array .
decodes { @code len } ascii encoded bytes from the given input buffer starting at { @code off } .
returns whether the given { @code string } is an alphabetic sequence that is a sequence which only contains letters .
returns whether the given { @code string } is an alphanumeric sequence that is a sequence which only contains letters and digits .
returns a { @code string } in which all uppercase ascii characters have been replaced by their lowercase equivalent ( all other characters are unchanged ) .
returns a { @code baseencoding } that behaves as this one except that it adds the specified separator after every { @code n } characters when encoding data and ignores any occurence of the specified separator when decoding encoded data .
encodes the given data bytes according to this { @code baseencoding } s configuration .
decodes the given encoded { @code string } according to this { @code baseencoding } s configuration . decoding is not case - sensitive when possible ( namely for base16 base32 and base32hex schemes ) .
decodes the specified range from the given encoded { @code string } according to this { @code baseencoding } s configuration . decoding is not case - sensitive when possible ( namely for base16 base32 and base32hex schemes ) .
returns the { @code fraction } representation of the given value .
creates a { @code fraction } from its { @code string } representation .
adds the given value to this one and returns the result in reduced form .
subtracts the given value from this one and returns the result in reduced form .
multiplies this value by the given one and returns the result in reduced form .
divides this value by the given one and returns the result in reduced form .
returns the { @code fraction } obtained by raising this to the given power in reduced form .
returns the opposite of this { @code fraction } . the result is not reduced before being returned .
returns the reduced form of this { @code fraction } . also note that the sign information will be held by the numerator .
creates a new { @code immutableset } from the given { @code collection } .
creates a new { @code immutableset } from the given { @code iterable } .
creates a new { @code immutableset } from the given { @code iterator } .
creates a new { @code immutableset } containing the given elements .
creates a new { @code immutableset } containing the given elements .
parses the given duration s { @code string } representation into a { @code duration } instance . the given { @code string } must be a list of value / unit pairs separated by + - \ n \ t \ r { @code & } or characters or by the and { @code string } . values must be integer ( either positive or negative ) values . valid units are : milliseconds millisecond millis and ms for milliseconds seconds second sec secs and s for seconds minutes minute min mins and m for minutes hours hour and h for hours days day and d for days . values must be separated from their unit by a whitespace character . parsing is not case sensitive .
creates a new { @code duration } representing the given amount in the given unit .
creates a new { @code duration } instance by summing all the given { @code duration } s values .
creates a new { @code duration } instance representing the amount of time elapsed between the given dates .
returns the maximum of the given values .
returns the minimum of the given values .
returns the arithmetic mean of the given values . this method is not subject to overflow .
returns the arithmetic mean of the given values . this method is not subject to overflow .
returns the absolute value of the given value provided the result fits into a { @code long } .
returns the absolute value of the given value provided the result fits into an { @code int } .
returns the difference of { @code a } and { @code b } provided the result fits into a { @code long } .
returns the product of { @code a } and { @code b } provided the result fits into a { @code long } .
returns the product of { @code a } and { @code b } provided the result fits into an { @code int } .
returns the result of the integer division of the first number by the second provided the result fits into a { @code long } .
returns the result of the integer division of the first number by the second provided the result fits into an { @code int } .
returns the value of the first argument raised to the power of the second provided the result fits into a { @code long } . this method implements the exponentiation by squaring method . please refer to <a href = http : // en . wikipedia . org / wiki / exponentiation_by_squaring > wikipedia< / a > for further information .
returns the greatest common divisor of the absolute value of the given two numbers . this method first computes the absolute values of the given numbers thus it doesn t accept { @code long . min_value } . also note that if one of the given values is { @code 0 } this method will return the absolute value of the second argument . this method implements the binary gcd algorithm ( also known as stein s algorithm ) . for further information on this algorithm please refer to <a href = http : // en . wikipedia . org / wiki / binary_gcd_algorithm > wikipedia< / a > .
returns the greatest common divisor of the absolute value of the given two numbers . this method first computes the absolute values of the given numbers thus it doesn t accept { @code integer . min_value } . also note that if one of the given values is { @code 0 } this method will return the absolute value of the second argument . this method implements the binary gcd algorithm ( also known as stein s algorithm ) . for further information on this algorithm please refer to <a href = http : // en . wikipedia . org / wiki / binary_gcd_algorithm > wikipedia< / a > .
returns the least common multiple of the absolute value of the given two numbers . this method first computes the absolute values of the given numbers thus it doesn t accept { @code long . min_value } . also note that if one of the given values is { @code 0 } this method will return the absolute value of the second argument . this method uses the formula { @code lcm ( a b ) = ( a / gcd ( a b )) * b } . please refer to <a href = http : // en . wikipedia . org / wiki / least_common_multiple > wikipedia< / a > for further information .
casts the given { @code long } value to { @code int } if possible .
checks that the given reference is not { @code null } and returns it in case of success .
checks the truth of the given condition checking parameters validity .
checks the type of the given reference and in case of success casts and returns it .
checks the type of the given reference and in case of success casts and returns it .
performs a logical and on the given values that is this method returns { @code true } if and only if all the given { @code boolean } values are { @code true } and { @code false } in all other cases .
performs an exclusive or on the given values that is this method returns { @code true } if and only if only one of the given { @code boolean } values is { @code true } and { @code false } in all other cases .
parses the given { @code string } into a { @code boolean } . this method returns { @code true } if the given { @code string } contains true yes 1 or on .
returns a new { @code splitter } that will use the specified separator to split { @code string } s .
returns a new { @code splitter } that will use the specified pattern to split { @code string } s .
returns a new { @code splitter } that will behave as this one except that it will limit the number of times the splitting pattern is applied . if { @code limit } is strictly positive then the pattern will be applied at most { @code limit - 1 } times . if { @code limit } is non - positive then the splitting pattern will be applied as many times as possible .
returns a new { @code splitter } that will behave as this one except that it will ignore the given prefix .
returns a new { @code splitter } that will behave as this one except that it will ignore the given suffix .
returns a new { @code splitter } that will behave as this one except that it will ignore empty results .
returns a new { @code splitter } that will behave as this one except that it will replace empty results by the specified { @code string } .
splits the given { @code string } into parts according to its configuration .
returns a { @code comparator } that will call each { @code comparator } in the given array until one of them returns a non - zero result ( will return { @code 0 } if they all return { @code 0 } ) .
returns a { @code comparator } that will call each { @code comparator } in the given { @code iterable } until one of them returns a non - zero result ( will return { @code 0 } if they all return { @code 0 } ) .
returns a { @code comparator } that represents the reverse ordering of the given one . namely the returned { @code comparator } will return a negative value if the original returns a positive value and conversely will return a positive value if it returns a negative value .
returns a { @code comparator } that compares { @code comparable } objects in natural order . the returned comparator doesn t accept { @code null } values .
returns a new { @code comparator } that considers { @code null } values as less than all other values and compares non - { @code null } values with the given { @code comparator } .
returns a new { @code joiner } that will behave as this one except that it will trim inputs before joining them .
returns a new { @code joiner } that will behave as this one except that it will ignore { @code null } input values .
returns a new { @code joiner } that will behave as this one except that it will ignore empty input { @code string } s .
returns a new { @code joiner } that will behave as this one except that it will replace { @code null } input values with the specified { @code string } .
returns a new { @code joiner } that will behave as this one except that it will replace empty input { @code string } s with the specified value .
returns a new { @code joiner } that will behave as this one except that it will use the specified prefix when joining { @code string } s .
joins the given { @code string } s according to its configuration .
creates and returns a { @link digest } instance corresponding to the given algorithm .
creates and returns a { @link mac } instance corresponding to the given algorithm initialized with the provided secret key .
creates a new { @code immutablebag } from the given { @code collection } .
creates a new { @code immutablebag } from the given { @code iterable } .
creates a new { @code immutablebag } from the given { @code iterator } .
creates a new { @code immutablebag } containing the given elements .
creates a new { @code immutablebag } containing the given elements .
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
todo : test w / map of integer ...
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
-------------------------------------------------------------
fetch a locationforecastlts from the met api based on longitude latitude and altitude .
fetch a sunrise from the met api based on a given longitude latitude and date .
fetch a sunrise from the met api based on a given longitude latitude and date range .
get all point forecasts from now and to the given hours ahead .
get the most accurate forecast for the given date .
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link locationtype . symbol } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link windspeed } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link locationtype . stateofthesea } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link precipitation } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link tidalwater } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link precipitation } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link score } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link windspeed } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link locationtype . snowdepth } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link cloudiness } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link locationtype . weather } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link locationtype . winddirection } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link windspeed } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link uv } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link cloudiness } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link pressure } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link cloudiness } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link unitvalue } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link groundcover } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link windspeed } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link locationtype . forestfire } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link cloudiness } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link temperature } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link cloudiness } { @code > }}
fetch a textforecast for a named forecast
create a longterm forecast but only with a small subset of the weather data fields . typically for use in simple weather reports where you only show the predicted weather icon and temperature and not all the weather details .
create a longterm forecast .
create an untitled location from coordinate string .
fetch a list of all available textforecasts .
create an instance of { @link jaxbelement } { @code < } { @link probability } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create name for a wind symbol .
find matching beaufort level for a given point forecast .
wrap the construction of url s to avoid throwing of checked malformedurlexception . instead meteoexception is thrown .
check if the sun is shining for a given time .
get the pointforecast that matches the given time .
/ * find the period forecast that is the widest fit for a point forecast .
find the period forecast that has the best fitted forecast for a given period .
fetch textforecasts and warnings for a geographical point or area in norwegian .
fetch textforecasts and warnings for a geographical point or area .
retrieves the file extensions to use with the specified decoder . <p > if the specified decoder doesn t have any file extensions explicitly associated with it then a single empty string is returned .
convert a ( partial ) servicepath into a file name to access . the file names are in the format cfg_group_subgroup_appid_configurationclass [ . ext ] .
checks connection retrieves appropriate changelog and performs database update .
executes the specified script . the source of the script is supplied as a utf - 8 encoded { @code inputstream } . the default { @code scriptcontext } for the { @code scriptengine } is used .
calls a method on a script object compiled during a previous script execution which is retained in the state of the scriptengine .
return the referenced object potentially performing a remote datastore lookup and deserialisation . if the object is already present or has been previously acquired it is immediately returned .
create a referencedobject that uses a remote reference to data present in an objectsource .
create a referencedobject that directly wraps an object without a reference .
{ @inheritdoc }
perform exponential backoff / retry of acquiring a data file from an http source .
acquire a configuration class from the provider . the requested class will be a simple java object that when returned and can be interacted with using getters and other standard mechanisms . configuration classes may themselves contain other configuration objects which will be recursively acquired if marked @configuration . any fields marked @encrypted will be decrypted any fields marked and any validation annotations will be processed .
this is the recursive entry point for acquiring a complete configuration class to return . attempt to acquire a deserialised object representing the configuration class requested and analyse it for declared fields marked @configuration . if any are found the method recursively calls itself until all configuration is satisfied .
acquire decode and decrypt a configuration object from a data stream .
checks whether the string substitution functionality should be enabled .
excludes all com . sun . jersey classes .
returns the decoder that should be used to interpret the configuration files .
determine the first advertised service implementation for the specified interface . the implementations are advertised via the java serviceloader mechanism .
determine the first advertised service implementation for the specified interface . the implementations are advertised via the java serviceloader mechanism .
determine the first advertised service implementation for the specified interface . the implementations are advertised via the java serviceloader mechanism .
get all advertised service implementations of the specified interface .
retrieves a module by its simple name that implements a particular type t
return the referenced data as a stream potentially performing a remote lookup .
determine the size of the data .
create a referenceddata instance that wraps data but also has a reference .
get the components of the name at the specified numeric index
return a name that consists of a subsection of the current name .
is an arc colored and hence on a color chain?
exec - match regular expression
find - find a match for the main nfa ( no - complications case ) <p > first it runs the search machine in non - greedy mode ( shortest ) . the search machine is the nfa with . * added to the front and the back more or less . see makesearch . in many cases running the search machine shortest is considerably faster than running the actual regular expression in greedy ( longest ) . so even though this may seem like it would take extra time doing an extra scan the alternative is much slower . the search machine tells you if the expression can be found anywhere and if so where is the furthest possible end . < / p > <p > if the search machine succeeds the does an iteration to find the exact bounds ; the loop uses longest or shortest as appropriate to the flags . in c there was an option to _only_ run the search machine and return a simple boolean with no bounds . we have no api for that via an execflag . < / p > <p > if the top - level api call is lookingat we never want to scan down the data looking for matches . but shortest can still be much faster than longest . so the code runs the original machine first . if non - greedy expressions were very common i suppose that it would be faster to omit this step in that case . thereafter the loop has a check to bail if these is no match at the beginning of the data which is the constraint of lookingat . < / p >
cfind - find a match for the main nfa ( with complications )
cfindloop - the heart of cfind
subset - set any subexpression relevant to a successful subre
dissect - determine subexpression matches ( uncomplicated case )
condissect - determine concatenation subexpression matches ( uncomplicated )
altdissect - determine alternative subexpression matches ( uncomplicated )
cdissect - determine subexpression matches ( with complications ) the retry memory stores the offset of the trial midpoint from begin plus 1 so that 0 uniquely means clean slate .
crevdissect - determine backref shortest - first subexpression matches the retry memory stores the offset of the trial midpoint from begin plus 1 so that 0 uniquely means clean slate .
cbrdissect - determine backref subexpression matches
/ * - caltdissect - determine alternative subexpression matches ( w . complications ) ^ static int caltdissect ( struct vars * struct subre int int ) ;
makesearch - turn an nfa into a search nfa ( implicit prepend of . * ? ) nfa must have been optimize () d already .
cloneouts - copy out arcs of a state to another state pair modifying type
optst - optimize a subre subtree
numst - number tree nodes ( assigning retry indexes )
markst - mark tree nodes as inuse
/ * optimize results from top node
nfanode - do one nfa for nfatree
parse - parse an re this is actually just the top level which parses a bunch of branches tied together with | . they appear in the tree as the left children of a chain of | subres .
parsebranch - parse one branch of an re this mostly manages concatenation working closely with parseqatom () . concatenated things are bundled up as much as possible with separate nodes introduced only when necessary due to substructure .
checkstyle : off
checkstyle : on
deltraverse - the recursive heart of delsub this routine s basic job is to destroy all out - arcs of the state .
nonword - generate arcs for non - word - character ahead or behind
word - generate arcs for word character ahead or behind
scannum - scan a number
repeat - replicate subnfa for quantifiers the duplication sequences used here are chosen carefully so that any pointers starting out pointing into the subexpression end up pointing into the last occurrence . ( note that it may not be strung between the same left and right end states however! ) this used to be important for the subre tree although the important bits are now handled by the in - line code in parse () and when this is called it doesn t matter any more .
wordchrs - set up word - chr list for word - boundary stuff if needed the list is kept as a bunch of arcs between two dummy states ; it s disposed of by the unreachable - states sweep in nfa optimization . does next () . must not be called from any unusual lexical context . this should be reconciled with the \ w etc . handling in lex . c and should be cleaned up to reduce dependencies on input scanning .
bracket - handle non - complemented bracket expression also called from cbracket for complemented bracket expressions .
brackpart - handle one item ( or range ) within a bracket expression
scanplain - scan plain contents of [ . etc . certain bits of trickery in lex . c know that this code does not try to look past the final bracket of the [ . etc .
cbracket - handle complemented bracket expression we do it by calling bracket () with dummy endpoints and then complementing the result . the alternative would be to invoke rainbow () and then delete arcs as the b . e . is seen ... but that gets messy .
newlacon - allocate a lookahead - constraint subre
onechr - fill in arcs for a plain character and possible case complements this is mostly a shortcut for efficient handling of the common case .
dovec - fill in arcs for each element of a cvec all kinds of mcce complexity removed .
compile a pattern .
compile a pattern .
/ * back chain
retrieve the color for a character .
pseudocolor - allocate a false color to be managed by other means .
subcolor - allocate a new subcolor ( if necessary ) to this char internal api that can do a range of characters ; called from { @link #subrange } .
newsub - allocate a new subcolor ( if necessary ) for a color
subrange - allocate new subcolors to this range of chars fill in arcs . the range will overlap existing ranges ; even in the simplest case it will overlap the initial white range . for each existing range that it overlaps allocate a new color mark the range as mapping to that color and add an arc between the states for that color .
okcolors - promote subcolors to full colors
colorchain - add this arc to the color chain of its color
uncolorchain - delete this arc from the color chain of its color
rainbow - add arcs of all full colors ( but one ) between specified states
colorcomplement - add arcs of complementary colors the calling sequence ought to be reconciled with cloneouts () .
dumpcolors - debugging output
/ * not speedy . this is for debugging .
lexstart - set up lexical stuff scan leading options
prefixes - implement various special prefixes
lexnest - call a subroutine interpolating string at the lexical level note this is not a very general facility . there are a number of implicit assumptions about what sorts of strings can be subroutines .
next - get next token
brenext - get next bre token this is much like eres except for all the stupid backslashes and the
checkstyle : off
/ * chr value ; errors signalled via err
retrieve the color for a full codepoint .
called at the start of a match . arguably we could just construct a new dfa each time .
miss -- the state set was not found in the statesets .
longest - longest - preferred matching engine
lastcold - determine last point at which no progress had been made
eclass - because we have no mcce support this just processing single characters .
allcases - supply cvec for all case counterparts of a chr ( including itself ) this is a shortcut preferably an efficient one for simple characters ; messy cases are done via range () .
return a unicodeset for a character class name . it appears that the names that tcl accepts are also acceptable to icu .
carcsort - sort compacted - nfa arcs by color really dumb algorithm but if the list is long enough for that to matter you re in real trouble anyway .
dumpst - dump a subre tree
/ * called by all the resetting functions . allows find to work as specified .
factory method for new states .
moveouts - move all out arcs of a state to another state
moveins - move all in arcs of a state to another state you might think this could be done better by just updating the existing arcs and you would be right if it weren t for the desire for duplicate suppression which makes it easier to just make new ones to exploit the suppression built into newarc .
copyins - copy all in arcs of a state to another state
copyouts - copy all out arcs of a state to another state
get rid of a state releasing all its arcs . i m not sure that all this is needed as opposed to depending on the gc .
unwire a state from the nfa .
cparc - allocate a new arc within an nfa copying details from old one
dupnfa - duplicate sub - nfa another recursive traversal this time using tmp to point to duplicates as well as mark already - seen states . ( you knew there was a reason why it s a state pointer didn t you? : - ))
duptraverse - recursive heart of dupnfa
/ * - cleartraverse - recursive cleanup for algorithms that leave tmp ptrs set
specialcolors - fill in special colors for an nfa
dumpnfa - dump an nfa in human - readable form
dumpstate - dump an nfa state in human - readable form
dumparcs - dump out - arcs in human - readable form
dumprarcs - dump remaining outarcs recursively in reverse order
dumparc - dump one outarc in readable form including prefixing tab
optimize - optimize an nfa
analyze - ascertain potentially - useful facts about an optimized nfa
pullback - pull back constraints backward to ( with luck ) eliminate them
- pull - pull a back constraint backward past its source state a significant property of this function is that it deletes at most one state -- the constraint s from state -- and only if the constraint was that state s last outarc .
pushfwd - push forward constraints forward to ( with luck ) eliminate them
push - push a forward constraint forward past its destination state a significant property of this function is that it deletes at most one state -- the constraint s to state -- and only if the constraint was that state s last inarc .
combine - constraint lands on an arc what happens?
cleanup - clean up nfa after optimizations
markreachable - recursive marking of reachable states
markcanreach - recursive marking of states which can reach here
fixempties - get rid of empty arcs
unempty - optimize out an empty arc if possible actually as it stands this function always succeeds but the return value is kept with an eye on possible future changes .
reads the given rule parameters file .
get all configured rule interpreter plugins .
get all configured report plugins .
return the selection of rules .
the main method .
run tasks according to the given arguments .
extract an error message from the given exception and its causes .
gather all options which are supported by the task ( i . e . including standard and specific options ) .
gathers the standard options shared by all tasks .
gathers the task specific options for all tasks .
returns a string containing the names of all supported tasks .
parse the command line and execute the requested task .
parse the command line
executes a task .
read the plugin properties file if specified on the command line or if it exists on the class path .
print usage information .
determine the jqassistant_home directory .
create the class loader to be used for detecting and loading plugins .
parses the given list of option values into a map of resources and their associated ( optional ) scopes .
writes a geometry to geojson . note that any data stored in getuserdata () of the geometries that is not on the top level geometrycollection is lost in the process .
/ * the shell of a polygon in geojson is defined in counterclockwise order in jts it is the other way round
identify which countries are guaranteed to contain the given bounding box fully . the given bounding box may wrap around the 180th longitude i . e minlongitude = 170 and maxlongitude = - 170 .
identify which countries intersect with the given bounding box . the given bounding box may wrap around the 180th longitude i . e minlongitude = 170 and maxlongitude = - 170 .
http : // geomalgorithms . com / a03 - _inclusion . html
if there s no match returns the result with {
given a target and params this method tries to do the reverse routing and returns the uri .
--------------------------------------------------------------------------
--------------------------------------------------------------------------
this method does nothing if the path pattern has already been added . a path pattern can only point to one target .
removes the route specified by the path pattern .
removes all routes leading to the target .
returns the number of routes in this router .
adds route to the first section .
adds route to the other section .
adds route to the last section .
removes the route specified by the path pattern .
removes all routes leading to the target .
checks if there s any matching route .
----------------------------------------------------------------------------
there are two different criterion for if a property is null or checking equality . this is a convience method to return the one based on if value is null or not .
generates the file name string for an owner and book name .
generates the { @link file } object to use for storing retrieving and deleting the bookmark set .
gets a bookmarkset for the request using the injected { @link ownerresolver } and { @link nameresolver } . <br > <br > if <code > create< / code > is false and no bookmarkset exists for the name and owner null is returned . <br > <br > if <code > create< / code > is true and no bookmarkset exists for the name and owner a new bookmarkset is created .
returns an immutable sorted view of the values of the children map . the sorting is done using the current childcomparator . warning this is has a time cost of 2n log ( n ) on every call .
folders are always greater than non - folders if they are both folders or both not folders they are equal .
compairs the entries by name note created and modified properties in that order .
if both classes are not bookmarks they are equal . if they are both bookmarks they are compared by url then newwindow properties .
gets preferences for the request using the injected { @link ownerresolver } and { @link nameresolver } . <br > <br > if <code > create< / code > is false and no preferences exists for the name and owner null is returned . <br > <br > if <code > create< / code > is true and no preferences exists for the name and owner a new preferences is created .
returns an immutable sorted view of the values of the children map . the sorting is done using the current childcomparator . warning this is has a time cost of 2n log ( n ) on every call .
get the optional short description <p > the short description is the first line of { @link #getdescription () } < / p >
sets the last - modified time of the servlet class file associated with this jspservletwrapper .
compile ( if needed ) and load a tag file
compile and load a prototype for the tag file . this is needed when compiling tag files with circular dependencies . a prototpe ( skeleton ) with no dependencies on other other tag files is generated and compiled .
get a list of files that the current page has source dependency on .
/ * handles the case where a requested jsp file no longer exists .
/ * parses a jsp document by responding to sax events .
/ * processes the given list of included files .
/ * receives notification of the start of an element .
/ * receives notification of character data inside an element .
/ * receives notification of the end of an element .
/ * see org . xml . sax . ext . lexicalhandler .
/ * see org . xml . sax . ext . lexicalhandler .
/ * see org . xml . sax . ext . lexicalhandler .
/ * receives notification of the start of a namespace mapping .
/ * receives notification of the end of a namespace mapping .
private utility methods
/ * checks if the xml element with the given tag name is a custom action and returns the corresponding node object .
/ * adds the tag library associated with the given uri namespace to the translation unit that this parser is associated with .
/ * ensures that the given body only contains nodes that are instances of templatetext .
/ * parses the given file included via an include directive .
/ * checks an element s given uri qname and attributes to see if any of them hijack the jsp prefix that is bind it to a namespace other than http : // java . sun . com / jsp / page .
/ * checks the given uri and qname to see if they hijack the jsp prefix which would be the case if qname contained the jsp prefix and uri was different from http : // java . sun . com / jsp / page .
/ * gets saxparser .
load the class with the specified name searching using the following algorithm until it finds and returns the class . if the class cannot be found returns <code > classnotfoundexception< / code > . <ul > <li > call <code > findloadedclass ( string ) < / code > to check if the class has already been loaded . if it has the same <code > class< / code > object is returned . < / li > <li > if the <code > delegate< / code > property is set to <code > true< / code > call the <code > loadclass () < / code > method of the parent class loader if any . < / li > <li > call <code > findclass () < / code > to find this class in our locally defined repositories . < / li > <li > call the <code > loadclass () < / code > method of our parent class loader if any . < / li > < / ul > if the class was found using the above steps and the <code > resolve< / code > flag is <code > true< / code > this method will then call <code > resolveclass ( class ) < / code > on the resulting class object .
start of iasri 4709374
/ * load jsp class data from file .
call and wrap { @link exception } s into a { @link runtimeexception }
call and wrap { @link exception } s into an exception provided by the function . <p > if the function returns { @code null } a { @link runtimeexception } will be created instead . < / p >
parse the basic authentication header
generated servlet and tag handler implementations call this method to retrieve an instance of the protectedfunctionmapper . this is necessary since generated code does not have access to create instances of classes in this package .
stores a mapping from the given el function prefix and name to the given java method .
creates an instance for this class and stores the method for the given el function prefix and name . this method is used for the case when there is only one function in the el expression .
resolves the specified local name and prefix into a java . lang . method . returns null if the prefix and local name are not found .
initializes the contents of the xmlstring structure with the specified values .
initializes the contents of the xmlstring structure with copies of the given string structure . <p > <strong > note : < / strong > this does not copy the character array ; only the reference to the array is copied .
interface extensions
resolves the specified variable within the given context . returns null if the variable is not found .
parses a jsp page or tag file . this is invoked by the compiler .
processes an include directive with the given path .
extracts tag file directive information from the tag file with the given name .
parses the jsp page or tag file with the given path name .
/ * ensures that the page encoding specified in the jsp config element ( with matching url pattern ) if present matches the page encoding specified in the xml prolog of a jsp document ( xml syntax ) and the page encoding derived from the bom .
/ * checks to see if the given uri is matched by a url pattern specified in a jsp - property - group in web . xml and if so returns the value of the <page - encoding > element .
determines the syntax ( standard or xml ) and page encoding properties for the given file and stores them in the isxml and sourceenc instance variables respectively .
/ * determines page source encoding for page or tag file in jsp syntax by reading ( in this order ) the value of the pageencoding page directive attribute or the charset value of the contenttype page directive attribute .
/ * scans the given attributes for the attribute with the given name which is either pageencoding or contenttype and returns the specified page encoding .
/ * resolve the name of the file and update basedirstack () to keep track of the current base directory for each included file . the root file is always an absolute path so no need to put an initial value in the basedirstack .
/ * checks to see if the given page contains as its first element a <root > element whose prefix is bound to the jsp namespace as in :
create a compiler object .
gets a resource as a stream relative to the meanings of this context s implementation .
gets the location of the tld associated with the given taglib uri .
==================== removal ====================
==================== compile and reload ====================
==================== manipulating the class ====================
read a single character . this method will block until a character is available an i / o error occurs or the end of the stream is reached .
read characters into a portion of an array . this method will block until some input is available an i / o error occurs or the end of the stream is reached .
find the last modification timestamp of all channels
we assume that the bootclassloader never uses the context classloader to find classes in itself .
not be used as a delegate otherwise we endup in endless recursion .
false is returned when a cycle is being detected
reads the stream header into a buffer . this is a helper function for the constructors .
decompresses into an array of bytes . <p > if <code > len< / code > is zero no bytes are read and <code > 0< / code > is returned . otherwise this will try to decompress <code > len< / code > bytes of uncompressed data . less than <code > len< / code > bytes may be read only in the following situations : <ul > <li > the end of the compressed data was reached successfully . < / li > <li > an error is detected after at least one but less <code > len< / code > bytes have already been successfully decompressed . the next call with non - zero <code > len< / code > will immediately throw the pending exception . < / li > <li > an exception is thrown . < / li > < / ul >
returns the number of uncompressed bytes that can be read without blocking . the value is returned with an assumption that the compressed input data will be valid . if the compressed data is corrupt <code > corruptedinputexception< / code > may get thrown before the number of bytes claimed to be available have been read from this input stream .
closes the stream and optionally calls <code > in . close () < / code > . if the stream was already closed this does nothing . if <code > close ( false ) < / code > has been called a further call of <code > close ( true ) < / code > does nothing ( it doesn t call <code > in . close () < / code > ) . <p > if you don t want to close the underlying <code > inputstream< / code > there is usually no need to worry about closing this stream either ; it s fine to do nothing and let the garbage collector handle it . however if you are using { @link arraycache } <code > close ( false ) < / code > can be useful to put the allocated arrays back to the cache without closing the underlying <code > inputstream< / code > . <p > note that if you successfully reach the end of the stream ( <code > read< / code > returns <code > - 1< / code > ) the arrays are automatically put back to the cache by that <code > read< / code > call . in this situation <code > close ( false ) < / code > is redundant ( but harmless ) .
paginate from a full data set
calls {
convert a string to a metakey if possible
fill extra requirements the rpm file itself may have
actually build the rpm file <p > <strong > note : < / strong > this method may only be called once per instance < / p >
returns an array of taglibraryinfo objects representing the entire set of tag libraries ( including this taglibraryinfo ) imported by taglib directives in the translation unit that references this taglibraryinfo .
checks to see if the given tag name maps to a tag file path and if so parses the corresponding tag file .
parses the jsp version and tlib - version from the implicit . tld at the given path .
get the digest of a closed file
get the size of a closed file
validate the name of the channel
seeks <code > n< / code > bytes forward in this stream . <p > this will not seek past the end of the file . if the current position is already at or past the end of the file this doesn t seek at all and returns <code > 0< / code > . otherwise if skipping <code > n< / code > bytes would cause the position to exceed the stream size this will do equivalent of <code > seek ( length () ) < / code > and the return value will be adjusted accordingly . <p > if <code > n< / code > is negative the position isn t changed and the return value is <code > 0< / code > . it doesn t seek backward because it would conflict with the specification of { @link java . io . inputstream#skip ( long ) inputstream . skip } .
gets how much memory the encoder will need with the given filter chain . this function simply calls <code > getencodermemoryusage () < / code > for every filter in the array and returns the sum of the returned values .
gets how much memory the decoder will need with the given filter chain . this function simply calls <code > getdecodermemoryusage () < / code > for every filter in the array and returns the sum of the returned values .
decompresses into an array of bytes . <p > if <code > len< / code > is zero no bytes are read and <code > 0< / code > is returned . otherwise this will try to decompress <code > len< / code > bytes of uncompressed data . less than <code > len< / code > bytes may be read only in the following situations : <ul > <li > the end of the compressed data was reached successfully . < / li > <li > an error is detected after at least one but less than <code > len< / code > bytes have already been successfully decompressed . the next call with non - zero <code > len< / code > will immediately throw the pending exception . < / li > <li > an exception is thrown . < / li > < / ul >
returns the number of uncompressed bytes that can be read without blocking . the value is returned with an assumption that the compressed input data will be valid . if the compressed data is corrupt <code > corruptedinputexception< / code > may get thrown before the number of bytes claimed to be available have been read from this input stream .
seeks to the specified absolute uncompressed position in the stream . this only stores the new position so this function itself is always very fast . the actual seek is done when <code > read< / code > is called to read at least one byte . <p > seeking past the end of the stream is possible . in that case <code > read< / code > will return <code > - 1< / code > to indicate the end of the stream .
seeks to the beginning of the given xz block .
does the actual seeking . this is also called when <code > read< / code > needs a new block to decode .
locates the block that contains the given uncompressed position .
locates the given block and stores information about it to <code > info< / code > .
initializes a new blockinputstream . this is a helper function for <code > seek () < / code > .
generate codes for collections the pseudo code is :
generate iterators for data types supported in items
get a list of all relevant maven artifacts
check if an artifact is a zip file <p > an artifact is a zip file if at least one of th following tests is true : <ul > <li > its lower case name ends with <code > . zip< / code > < / li > <li > the meta data field <code > mvn : extension< / code > is set to <code > zip< / code > <li > the meta data field <code > mime : type< / code > is set to <code > application / zip< / code > < / ul > < / p >
converts the opts array from backward indexes to forward indexes . then it will be simple to get the next symbol from the array in later calls to <code > getnextsymbol () < / code > .
updates the state and reps for the current byte in the opts array .
calculates prices of a literal a short rep and literal + rep0 .
calculates prices of long rep and long rep + literal + rep0 .
calculates prices of a normal match and normal match + literal + rep0 .
decompresses into an array of bytes . <p > if <code > len< / code > is zero no bytes are read and <code > 0< / code > is returned . otherwise this will block until <code > len< / code > bytes have been decompressed the end of the lzma2 stream is reached or an exception is thrown .
returns the number of uncompressed bytes that can be read without blocking . the value is returned with an assumption that the compressed input data will be valid . if the compressed data is corrupt <code > corruptedinputexception< / code > may get thrown before the number of bytes claimed to be available have been read from this input stream . <p > in lzma2inputstream the return value will be non - zero when the decompressor is in the middle of an lzma2 chunk . the return value will then be the number of uncompressed bytes remaining from that chunk . the return value can also be non - zero in the middle of an uncompressed chunk but then the return value depends also on the <code > available () < / code > method of the underlying inputstream .
/ * ( non - javadoc )
/ * ( non - javadoc )
read a single character . this method will block until a character is available an i / o error occurs or the end of the stream is reached .
read characters into a portion of an array . this method will block until some input is available an i / o error occurs or the end of the stream is reached .
throws an exception for expected byte .
throws an exception for invalid byte .
gets the location of the tld associated with the given taglib uri .
scan the all the tlds accessible in the web app . for performance reasons this is done in two stages . at servlet initialization time we only scan the jar files for listeners . the container passes a list of system jar files that are known to contain tlds with listeners . the rest of the jar files will be scanned when a jsp page with a tld referenced is compiled .
/ * populates taglib map described in web . xml .
scans the given jarurlconnection for tld files located in meta - inf ( or a subdirectory of it ) . if the scanning in is done as part of the servletcontextinitializer the listeners in the tlds in this jar file are added to the servlet context and for any tld that has a <uri > element an implicit map entry is added to the taglib map .
/ * searches the filesystem under / web - inf for any tld files and scans them for <uri > and <listener > elements .
scan the given tld for uri and listeners elements .
/ * scans all jars accessible to the webapp s classloader and its parent classloaders for tlds .
/ * add the jars in the manifest class - path to the list jars
add a new jspservletwrapper .
get the parent class loader .
save the bytecode for the class in a map . the current time is noted .
retrieve the time the bytecode for a class was created
save the bytecode for a class to disk .
method used by background thread to check the jsp dependencies registered with this class for jsp s .
method used to initialize classpath for compiles .
method used to initialize securitymanager data .
start the background thread that will periodically check for changes to compile time included files in a jsp .
stop the background thread that is periodically checking for changes to compile time included files in a jsp .
the background thread that checks for changes to files included by a jsp and flags that a recompile is required .
find by the locator <p > this method does not acquire the read lock this has to be done by the caller < / p >
find a channel by name
find a channel
update the channel to deploy group cache map
methods of deployauthservice
statistics
copy the remaining content of one stream to the other
copy the remaining content of one reader to the { @link appendable } ( or { @link writer }
the main entry for parser
attributes :: = ( s attribute ) * s?
parse attributes for a reader provided for external use
attribute :: = name s? eq s? ( <% = rtattributevaluedouble | attributevaluedouble | <% = rtattributevaluesingle | attributevaluesingle } note : jsp and xml spec does not allow while spaces around eq . it is added to be backward compatible with tomcat and with other xml parsers .
name :: = ( letter | _ | : ) ( letter | digit | . | _ | - | : ) *
attributevaluedouble :: = ( quotedchar - ) * ( | <translation_error > ) rtattributevaluedouble :: = (( quotedchar - ) * - (( quotedchar - ) % > ) ( % > | translation_error )
may be send to el processor .
/ * invokes parsercontroller to parse the included page
/ * parses a page directive with the following syntax : pagedirective :: = ( s attribute ) *
/ * parses an include directive with the following syntax : includedirective :: = ( s attribute ) *
add a list of files . this is used for implementing include - prelude and include - coda of jsp - config element in web . xml
/ * parses a taglib directive with the following syntax : directive :: = ( s attribute ) *
/ * parses a directive with the following syntax : directive :: = s? ( page pagedirective | include includedirective | taglib taglibdirective ) s? % >
/ * parses a directive with the following syntax :
/ * parses a tag directive with the following syntax : pagedirective :: = ( s attribute ) *
/ * parses a attribute directive with the following syntax : attributedirective :: = ( s attribute ) *
/ * parses a variable directive with the following syntax : pagedirective :: = ( s attribute ) *
/ * jspcommentbody :: = ( char * - ( char * -- % > )) -- % >
/ * declarationbody :: = ( char * - ( char * % > )) % >
/ * xmldeclarationbody :: = ( s? / > ) | ( s? > ( char * - ( char * < )) cdsect? ) * etag | <translation_error > cdsect :: = cdstart cdata cdend cdstart :: = <! [ cdata [ cdata :: = ( char * - ( char * ]] > char * )) cdend :: = ]] >
/ * expressionbody :: = ( char * - ( char * % > )) % >
/ * elexpressionbody ( following $ { or # { to first unquoted } ) // xxx add formal production and confirm implementation against it // once it s decided
/ * scriptletbody :: = ( char * - ( char * % > )) % >
param :: = <jsp : param s attributes s? emptybody s?
/ * for include : stdactioncontent :: = attributes parambody
/ * for forward : stdactioncontent :: = attributes parambody
/ * for getproperty : stdactioncontent :: = attributes emptybody
/ * for setproperty : stdactioncontent :: = attributes emptybody
/ * emptybody :: = / > | ( > etag ) | ( > s? <jsp : attribute namedattributes etag )
/ * for usebean : stdactioncontent :: = attributes optionalbody
/ * parses optionalbody but also reused to parse bodies for plugin and param since the syntax is identical ( the only thing that differs substantially is how to process the body and thus we accept the body type as a parameter ) .
attempts to parse jspattributeandbody production . returns true if it matched or false if not . assumes emptybody is okay as well .
/ * params :: = > s? ( ( <jsp : body > ( ( s? param + s? < / jsp : body > ) | <translation_error > ) ) | param + ) < / jsp : params >
/ * fallback :: = / > | ( > s? <jsp : body > ( ( s? ( char * - ( char * < / jsp : body > ) ) < / jsp : body > s? ) | <translation_error > ) < / jsp : fallback > ) | ( > ( char * - ( char * < / jsp : fallback > ) ) < / jsp : fallback > )
/ * for plugin : stdactioncontent :: = attributes pluginbody
/ * plugintags :: = ( <jsp : params params s? ) ? ( <jsp : fallback fallback? s? ) ?
/ * standardaction :: = include stdactioncontent | forward stdactioncontent | invoke stdactioncontent | dobody stdactioncontent | getproperty stdactioncontent | setproperty stdactioncontent | usebean stdactioncontent | plugin stdactioncontent | element stdactioncontent
/ * # < customaction customactionbody
/ * parse for a template text string until < or $ { is encountered recognizing escape sequences \ % \ $ and \ # .
/ * xmltemplatetext :: = ( s? / > ) | ( s? > ( ( char * - ( char * ( < | $ { ) ) ) ( $ { elexpressionbody ) ? cdsect? ) * etag ) | <translation_error >
/ * allbody :: = ( <% -- jspcommentbody ) | ( <%
/ * scriptlessbody :: = ( <% -- jspcommentbody ) | ( <%
/ * templatetextbody :: = ( <% -- jspcommentbody ) | ( <%
/ * flag as error if an unbalanced end tag appears by itself .
tagdependentbody : =
/ * parses jsp : body action .
/ * parse the body as jsp content .
/ * parses named attributes .
determine the body type of <jsp : attribute > from the enclosing node
get the attribute that is non request time expression either from the attribute of the node or from a jsp : attrbute
searches all subnodes of this node for jsp : attribute standard actions with the given name and returns the namedattribute node of the matching named attribute nor null if no such node is found . <p > this should always be called and only be called for nodes that accept dynamic runtime attribute expressions .
searches all subnodes of this node for jsp : attribute standard actions and returns that set of nodes as a node . nodes object .
/ * adds this node to the body of the given parent .
get a list of matching factories <p > the returned list is a copy of the current state . the list may be modified by the caller but will not be updated by this tracker when the state changes . < / p >
add an attribute to this node replacing any existing attribute with the same name .
add a new child node to this node .
return the value of the specified node attribute if it exists or <code > null< / code > otherwise .
return an iterator of the attribute names of this node . if there are no attributes an empty iterator is returned .
return the first child node of this node with the specified name if there is one ; otherwise return <code > null< / code > .
return an iterator of all children of this node . if there are no children an empty iterator is returned .
return an iterator over all children of this node that have the specified name . if there are no such children an empty iterator is returned .
create a new instance without classifier and extension
checks to see if the given variable name is used as an alias and if so returns the variable name for which it is used as an alias .
start capturing thread s output .
stop capturing thread s output and return captured data as a string .
find printstream to which the output must be written to .
write field only when the value is set
write a field
create a new element and add it as the last child
create a new element and add it as the first child
get the text value of the first element with the matching name <p > assuming you have an xml file :
write a single character .
write a portion of an array of characters .
write a portion of a string .
close the stream flushing it first . once a stream has been closed further write () or flush () invocations will cause an ioexception to be thrown . closing a previously - closed stream however has no effect .
write the contents of this bodyjspwriter into a writer . subclasses are likely to do interesting things with the implementation so some things are extra efficient .
sets the writer to which all output is written .
reallocates buffer since the spec requires it to be unbounded .
creates the functions mappers for all el expressions in the jsp page .
traverse up from the provided parent and find the first which uses the same key
register a new model with the storage manager
stream directly from the storage
monitor the job only produces an html fragment of the current job state
clean up the path so that is looks like . / usr / local / file
authenticate the request is authenticated against the deploy keys <p > if the request could not be authenticated a basic authentication request is sent back and the { @link httpservletresponse } will be committed . < / p >
simply test if the request is authenticated against the channels deploy keys
read a single character . this method will block until a character is available an i / o error occurs or the end of the stream is reached .
complete the document but don t close the underlying writer
make an appropriate gson parser to processing channeldata instances
gets an integer [ 0 63 ] matching the highest two bits of an integer . this is like bit scan reverse ( bsr ) on x86 except that this also cares about the second highest bit .
compresses for lzma2 .
get a string from meta data <p > if the provided metadata set is <code > null< / code > then the result will also be <code > null< / code > . < / p >
get a string from meta data <p > if the provided metadata set is <code > null< / code > then the result will also be <code > null< / code > . < / p >
return an unmodifiable map of provided and extracted meta data
write out the announce file <br > writing a file like this seems a little bit strange from a java perspective . however there seems to be no other way to create a file with a provided set of initial file attributes other than { @link files#newbytechannel ( java . nio . file . path set fileattribute ... ) } . all other methods don t access file attributes .
returns the value of the javax . servlet . error . exception request attribute value if present otherwise the value of the javax . servlet . jsp . jspexception request attribute value .
__begin introspecthelpermethod
create a typed array . this is a special case where params are passed through the request and the property is indexed .
__begin lookupreadmethodmethod
use proprietaryevaluate public static void handlesetpropertyexpression ( object bean string prop string expression pagecontext pagecontext variableresolver variableresolver functionmapper functionmapper ) throws jasperexception { try { method method = getwritemethod ( bean . getclass () prop ) ; method . invoke ( bean new object [] { pagecontext . getexpressionevaluator () . evaluate ( expression method . getparametertypes () [ 0 ] variableresolver functionmapper null ) } ) ; } catch ( exception ex ) { throw new jasperexception ( ex ) ; } }
convert a possibly relative resource path into a context - relative resource path that starts with a / .
perform a requestdispatcher . include () operation with optional flushing of the response beforehand .
adds the given tag handler to this tag handler pool unless this tag handler pool has already reached its capacity in which case the tag handler s release () method is called .
calls the release () method of all tag handlers in this tag handler pool .
check if the uploaded artifact is actually a checksum file
private final static logger logger = loggerfactory . getlogger ( virtualizerimpl . class ) ;
finishes the stream without closing the underlying outputstream .
returns the exception associated with this page context if any .
evaluates an el expression
make the prefix by guessing the port from the osgi settings
test if this file is an xml file
parses the tag file and collects information on the directives included in it . the method is used to obtain the info on the tag file when the handler that it represents is referenced . the tag file is not compiled here .
compiles and loads a tagfile .
implements a phase of the translation that compiles ( if necessary ) the tag files used in a jsp files . the directives in the tag files are assumed to have been proccessed and encapsulated as tagfileinfo in the customtag nodes .
removed the java and class files for the tag prototype generated from the current compilation .
end glassfish 750
base dir for the webapp . used to generate class names and resolve includes
/ * parses comma - separated list of jsp files to be processed .
gets the list of jsp compilation errors caught during the most recent invocation of this instance s <code > execute< / code > method when failonerror has been set to false .
include the generated web . xml inside the webapp s web . xml .
locate all jsp files in the webapp . used if no explicit jsps are specified .
==================== private utility methods ====================
initializes the classloader as / if needed for the given compilation context .
find the web - inf dir by looking up in the directory tree . this is used if no explicit docbase is set but only files . xxx maybe we should require the docbase .
start sjsas 6327357
/ * purges all compilation errors related to jsp fragments .
moves to the next byte checks that there is enough available space and possibly normalizes the hash tables and the hash chain .
-------------------------------------
sets the delta distance in bytes . the new distance must be in the range [ distance_min distance_max ] .
search the stream for a match to a string
looks ahead to see if there are optional spaces followed by the given string . if so true is returned and those spaces and characters are skipped . if not false is returned and the position is restored to where we were before .
skip until the given string is matched in the stream . when returned the context is positioned past the end of the match .
skip until the given string is matched in the stream but ignoring chars initially escaped by a \ . when returned the context is positioned past the end of the match .
skip until the given end tag is matched in the stream . when returned the context is positioned past the end of the tag .
parse a space delimited token . if quoted the token will consume all characters up to a matching quote otherwise it consumes up to the first delimiter character .
parse utils - is current character a token delimiter ? delimiters are currently defined to be = &gt ; &lt ; and or any any space character as defined by <code > isspace< / code > .
register a new source file . this method is used to implement file inclusion . each included file gets a unique identifier ( which is the index in the array of source files ) .
unregister the source file . this method is used to implement file inclusion . each included file gets a uniq identifier ( which is the index in the array of source files ) .
push a file ( and its associated stream ) on the file stack . the current position in the current file is remembered .
pop a file from the file stack . the field current is retored to the value to point to the previous files if any and is set to null otherwise .
create an unclassified version of ourself
add custom binders assigned to the method <p > custom binders assigned to the method will be added to the binding manager instance . < / p >
returns the given stratum as a string : a stratumsection followed by at least one filesection and at least one linesection .
invoke compilationresult#getproblems safely so that it works with 3 . 1 . 1 and more recent versions of the eclipse java compiler . see https : // jsp . dev . java . net / issues / show_bug . cgi?id = 13
sets the compression options to the given preset . <p > the presets 0 - 3 are fast presets with medium compression . the presets 4 - 6 are fairly slow presets with high compression . the default preset ( <code > preset_default< / code > ) is 6 . <p > the presets 7 - 9 are like the preset 6 but use bigger dictionaries and have higher compressor and decompressor memory requirements . unless the uncompressed size of the file exceeds 8&nbsp ; mib 16&nbsp ; mib or 32&nbsp ; mib it is waste of memory to use the presets 7 8 or 9 respectively .
sets the dictionary size in bytes . <p > the dictionary ( or history buffer ) holds the most recently seen uncompressed data . bigger dictionary usually means better compression . however using a dictioanary bigger than the size of the uncompressed data is waste of memory . <p > any value in the range [ dict_size_min dict_size_max ] is valid but sizes of 2^n and 2^n&nbsp ; + &nbsp ; 2^ ( n - 1 ) bytes are somewhat recommended .
sets the number of literal context bits and literal position bits . <p > the sum of <code > lc< / code > and <code > lp< / code > is limited to 4 . trying to exceed it will throw an exception . this function lets you change both at the same time .
sets the number of position bits . <p > this affects what kind of alignment in the uncompressed data is assumed in general . the default ( 2 ) means four - byte alignment ( 2^<code > pb< / code > = 2^2 = 4 ) which is often a good choice when there s no better guess . <p > when the alignment is known setting the number of position bits accordingly may reduce the file size a little . for example with text files having one - byte alignment ( us - ascii iso - 8859 - * utf - 8 ) using <code > setpb ( 0 ) < / code > can improve compression slightly . for utf - 16 text <code > setpb ( 1 ) < / code > is a good choice . if the alignment is an odd number like 3 bytes <code > setpb ( 0 ) < / code > might be the best choice . <p > even though the assumed alignment can be adjusted with <code > setpb< / code > and <code > setlp< / code > lzma2 still slightly favors 16 - byte alignment . it might be worth taking into account when designing file formats that are likely to be often compressed with lzma2 .
sets the compression mode . <p > this specifies the method to analyze the data produced by a match finder . the default is <code > mode_fast< / code > for presets 0 - 3 and <code > mode_normal< / code > for presets 4 - 9 . <p > usually <code > mode_fast< / code > is used with hash chain match finders and <code > mode_normal< / code > with binary tree match finders . this is also what the presets do . <p > the special mode <code > mode_uncompressed< / code > doesn t try to compress the data at all ( and doesn t use a match finder ) and will simply wrap it in uncompressed lzma2 chunks .
sets the nice length of matches . once a match of at least <code > nicelen< / code > bytes is found the algorithm stops looking for better matches . higher values tend to give better compression at the expense of speed . the default depends on the preset .
sets the match finder type . <p > match finder has a major effect on compression speed memory usage and compression ratio . usually hash chain match finders are faster than binary tree match finders . the default depends on the preset : 0 - 3 use <code > mf_hc4< / code > and 4 - 9 use <code > mf_bt4< / code > .
gets how much memory the lzma2 decoder will need to decompress the data that was encoded with these options and stored in a . xz file . <p > the returned value may bigger than the value returned by a direct call to {
/ * dispatches the given jsp parse error to the configured error handler .
/ * dispatches the given jsp parse error to the configured error handler .
/ * dispatches the given jsp parse error to the configured error handler .
/ * dispatches the given jsp parse error to the configured error handler .
/ * dispatches the given jsp parse error to the configured error handler .
/ * dispatches the given jsp parse error to the configured error handler .
creates and throws a new exception from the given jasperexception by prepending the given location information ( containing file name line number and column number ) to the message of the given exception and copying the stacktrace of the given exception to the new exception .
/ * dispatches the given compilation error report and exception to the configured error handler .
/ * dispatches the given jsp parse error to the configured error handler .
/ * parses the given java compilation error message which may contain one or more compilation errors into an array of javacerrordetail instances .
filter the provided aspect lists by a predicate on the id
get all aspect ids which are currently missing but required by this aspect
sets the path prefix url for . xsd resources
sets the path prefix url for . dtd resources
end pwc 6386258
parse the specified xml document and return a <code > treenode< / code > that corresponds to the root node of the document tree .
parse the specified xml document and return a <code > treenode< / code > that corresponds to the root node of the document tree .
create and return a treenode that corresponds to the specified node including processing all of the attributes and children nodes .
/ * gets the compiled schema referenced by the given xml document .
/ * gets the compiled schema for the given schema public id .
create a new bindingmanager with default binders <p > this call creates a new bindingmanager instance and add the following binders : < / p > <ul > <li > { @link mapbinder } < / li > <li > { @link bindingmanagerbinder } < / li > < / ul >
merge all errors of this binding into this result
add a new binder <p > if the binder has to be initialized then all methods annotated with { @link initializer } will be called . < / p >
initialize the binder with our current state
this actively scans for available aspects and returns their information objects
generates an appropriate smap representing the current compilation context . ( jsr - 045 . )
returns an unqualified version of the given file path .
invoke tag plugin for the given custom tag if a plugin exists for the custom tag s tag handler .
gets {
puts the {
allocates a new byte array hopefully reusing an existing array from the cache .
this is like getbytearray but for int arrays .
prepare an import with dependencies <p > this method does resolve even transient dependencies and also adds the sources if requested < / p >
prepare a plain import process <p > prepare a simple import request with a specific list of coordinates < / p >
process the actual import request <p > this method takes the import configuration as is and simply tries to import it . not manipulating the list of coordinates any more < / p >
convert aether result list to aetherresult object
the following is a workaround until these problems are resolved .
returns an array of taglibraryinfo objects representing the entire set of tag libraries ( including this taglibraryinfo ) imported by taglib directives in the translation unit that references this taglibraryinfo .
/ *
/ * @param uri the uri of the tld @param ctxt the compilation context
/ * parses the tag file directives of the given tagfile and turns them into a taginfo .
translation - time validation of the xml document associated with the jsp page . this is a convenience method on the associated taglibraryvalidator class .
sets this mark s state to a new stream . it will store the current stream in it s includestack .
/ * restores this mark s state to a previously stored stream .
autodetects the encoding of the xml document supplied by the given input stream .
org . apache . xerces . impl . xmlentitymanager . startentity ()
returns the iana encoding name that is auto - detected from the bytes specified with the endian - ness of that encoding where appropriate .
org . apache . xerces . impl . xmldocumentscannerimpl . dispatch
scans an xml or text declaration . <p > <pre > [ 23 ] xmldecl :: = &lt ; ?xml versioninfo encodingdecl? sddecl? s? ? > [ 24 ] versioninfo :: = s version eq ( versionnum | versionnum ) [ 80 ] encodingdecl :: = s encoding eq ( encname | encname ) [ 81 ] encname :: = [ a - za - z ] ( [ a - za - z0 - 9 . _ ] | - ) * [ 32 ] sddecl :: = s standalone eq (( ( yes | no ) ) | ( ( yes | no ) ))
scans surrogates and append them to the specified buffer . <p > <strong > note : < / strong > this assumes the current char has already been identified as a high surrogate .
convenience function used in all xml scanners .
create a set of default repository links <p > this method calls { @link #fillrepolinks ( channelinformation list string int string int linktarget ) } by using the basename also as prefix and using a default { @code priorityoffset } of 10_000 < / p >
create a set of default repository links
create a set of default repository links
return the real path for the specified context - relative virtual path .
return a url object of a resource that is mapped to the specified context - relative path .
return an inputstream allowing access to the resource at the specified context - relative path .
return the set of resource paths for the directory at the specified context path .
log the specified message and exception .
/ * adds the servlet with the given name description class name init parameters and loadonstartup to this servlet context .
adds the filter with the given name description and class name to this servlet context .
updates the filter chain with a single filter . this is equivalent to passing a single - member filteroptions array to <code > updatefilters ( filteroptions [] ) < / code > .
updates the filter chain with 1 - 4 filters . <p > currently this cannot be used to update e . g . lzma2 options in the middle of a xz block . use <code > endblock () < / code > to finish the current xz block before calling this function . the new filter chain will then be used for the next xz block .
writes an array of bytes to be compressed . the compressors tend to do internal buffering and thus the written data won t be readable from the compressed output immediately . use <code > flush () < / code > to force everything written so far to be written to the underlaying output stream but be aware that flushing reduces compression ratio .
finishes the current xz block ( but not the whole xz stream ) . this doesn t flush the stream so it s possible that not all data will be decompressible from the output stream when this function returns . call also <code > flush () < / code > if flushing is wanted in addition to finishing the current xz block . <p > if there is no unfinished block open this function will do nothing . ( no empty xz block will be created . ) <p > this function can be useful for example to create random - accessible . xz files . <p > starting a new xz block means that the encoder state is reset . doing this very often will increase the size of the compressed file a lot ( more than plain <code > flush () < / code > would do ) .
flushes the encoder and calls <code > out . flush () < / code > . all buffered pending data will then be decompressible from the output stream . <p > calling this function very often may increase the compressed file size a lot . the filter chain options may affect the size increase too . for example with lzma2 the hc4 match finder has smaller penalty with flushing than bt4 . <p > some filters don t support flushing . if the filter chain has such a filter <code > flush () < / code > will call <code > endblock () < / code > before flushing .
finishes compression without closing the underlying stream . no more data can be written to this stream after finishing ( calling <code > write< / code > with an empty buffer is ok ) . <p > repeated calls to <code > finish () < / code > do nothing unless an exception was thrown by this stream earlier . in that case the same exception is thrown again . <p > after finishing the stream may be closed normally with <code > close () < / code > . if the stream will be closed anyway there usually is no need to call <code > finish () < / code > separately .
finishes compression and closes the underlying stream . the underlying stream <code > out< / code > is closed even if finishing fails . if both finishing and closing fail the exception thrown by <code > finish () < / code > is thrown and the exception from the failed <code > out . close () < / code > is lost .
gets the size of the lz window buffer that needs to be allocated .
gets approximate memory usage of the lzencoder base structure and the match finder as kibibytes .
creates a new lzencoder . <p > @param dictsize dictionary size
sets a preset dictionary . if a preset dictionary is wanted this function must be called immediately after creating the lzencoder before any data has been encoded .
moves data from the end of the buffer to the beginning discarding old data and making space for new input .
copies new data into the lzencoder s buffer .
process pending bytes remaining from preset dictionary initialization or encoder flush operation .
get the length of a match at the given distance .
get the length of a match at the given distance and forward offset .
verifies that the matches returned by the match finder are valid . this is meant to be used in an assert statement . this is totally useless for actual encoding since match finder s results should naturally always be valid if it isn t broken .
moves to the next byte checks if there is enough input available and returns the amount of input available .
package - level access
flush the output buffer to the underlying character stream without flushing the stream itself . this method is non - private only so that it may be invoked by printstream .
discard the output buffer .
flush the stream .
close the stream .
attempt to write a string pre - encoded with the page encoding .
write a single character .
write a portion of an array of characters .
write a portion of a string .
end pwc 6512276
lock and return { @link autocloseable } instance for unlocking use with a <tt > try - with - resources< / tt > construct :
/ * processes the given jsp parse error .
/ * processes the given javac compilation errors .
processes the given javac error report and exception .
puts all allocated arrays back to the underlying arraycache that haven t already been put there with a call to {
/ * returns the localized error message corresponding to the given error code .
/ * returns the localized error message corresponding to the given error code .
/ * returns the localized error message corresponding to the given error code .
/ * returns the localized error message corresponding to the given error code .
make a key from the aggregator fields
compile the jsp file into equivalent servlet in java source
compile the servlet from . java file to . class file
compile the jsp file from the current engine context . as an side - effect tag files that are referenced by this page are also compiled .
determine if a compilation is necessary by checking the time stamp of the jsp page with that of the corresponding . class or . java file . if the page has dependencies the check is also extended to its dependeants and so on . this method can by overidden by a subclasses of compiler .
remove generated files
get an instance of javacompiler . if running with jdk 6 use a jsr199javacompiler that supports jsr199 else if eclipse s jdt compiler is available use that . the default is to use javac from ant .
return true if the path refers to a jar file in web - inf and is a system jar .
decode into an array of bytes . <p > this calls <code > in . read ( buf off len ) < / code > and defilters the returned data .
calls <code > in . available () < / code > .
single quote and escape a character
generates declarations . this includes info of the page directive and scriptlet declarations .
compiles list of tag handler pool names .
generates the _jspinit () method for instantiating the tag handler pools . for tag file _jspinit has to be invoked manually and the servletconfig object explicitly passed .
generates the _jspdestroy () method which is responsible for calling the release () method on every tag handler in any of the tag handler pools .
generate preamble package name ( shared by servlet and tag handler preamble generation )
generate preamble imports ( shared by servlet and tag handler preamble generation )
generation of static initializers in preamble . for example dependant list el function map prefix map . ( shared by servlet and tag handler preamble generation )
declare tag handler pools ( tags of the same type and with the same attribute set share the same tag handler pool ) ( shared by servlet and tag handler preamble generation )
declare general - purpose methods ( shared by servlet and tag handler preamble generation )
generates the beginning of the static portion of the servlet .
generates an xml prolog which includes an xml declaration and an xml doctype declaration .
/ * generates the constructor . ( shared by servlet and tag handler preamble generation )
common part of postamble shared by both servlets and tag files .
generates the ending part of the static portion of the servlet .
the main entry for generator .
/ * generates tag handler preamble .
generates declarations for tag handler attributes and defines the getter and setter methods for each .
/ * generate setter for jspcontext so we can create a wrapper and store both the original and the wrapper . we need the wrapper to mask the page context from the tag file and simulate a fresh page context . we need the original to do things like sync at_begin and at_end scripting variables .
/ * generates implementation of javax . servlet . jsp . tagext . dynamicattributes . setdynamicattribute () method which saves each dynamic attribute that is passed in so that a scoped variable can later be created for it .
/ * creates a page - scoped variable for each declared tag attribute . also if the tag accepts dynamic attributes a page - scoped variable is made available for each dynamic attribute that was passed in .
/ * generates the getter method for the given attribute name .
/ * generates the setter method name for the given attribute name .
read in a map of properties
export the content of a channel
make an array of header entries with given charset <p > <strong > note : < / strong > further updates on this instance will not update the returned array . this is actually a copy of the current state . < / p >
validate xml view against the taglibraryvalidator classes of all imported tag libraries .
gets the next available tag handler from this tag handler pool instantiating one if this tag handler pool is empty .
adds the given tag handler to this tag handler pool unless this tag handler pool has already reached its capacity in which case the tag handler s release () method is called .
calls the release () method of all available tag handlers in this tag handler pool .
parse an el expression
parse an el expression string $ { ... } or # { ... }
skip until an el expression ( $ { or # { ) is reached allowing escape sequences \\ \ $ and \ # .
/ * parse a string in single or double quotes allowing for escape sequences \\ and ( \ or \ )
select the property group that has more restrictive url - pattern . in case of tie select the first .
find a property that best matches the supplied resource .
to find out if an uri matches an url pattern in jsp config . if so then the uri is a jsp page . this is used primarily for jspc .
print a standard comment for echo outputed chunk .
prints the current indention followed by the given string
prints the current indention and then the string and a \ n .
prints the given string .
checks if the token is a runtime expression . in standard jsp syntax a runtime expression starts with <% and ends with % > . when the jsp document is in xml syntax a runtime expression starts with % = and ends with % .
takes a potential expression and converts it into xml form
checks to see if the given scope is valid .
checks if all mandatory attributes are present and if all attributes present have valid names . checks attributes specified as xml - style attributes as well as attributes specified using the jsp : attribute standard action .
escape the 5 entities defined by xml .
convert a string value to boolean . besides the standard conversions done by boolean . valueof ( s ) . booleanvalue () the value yes ( ignore case ) is also converted to true . if s is null then false is returned .
returns the <tt > class< / tt > object associated with the class or interface with the given string name .
produces a string representing a call to the el interpreter .
validates the syntax of all el expressions within the given string .
gets the fully - qualified class name of the tag handler corresponding to the given tag file path .
converts the given path to a java package or fully - qualified class name
splits a string into it s components .
converts the given identifier to a legal java identifier
mangle the specified character to create a legal java class name .
test whether the argument is a java keyword
converts the given xml name to a legal java identifier . this is slightly more efficient than makejavaidentifier in that we only need to worry about . - and : in the string . we also assume that the resultant string is further concatenated with some prefix string so that we don t have to worry about it being a java key word .
compute the canonical name from a class instance . note that a simple replacment of $ with . of a binary name would not work as $ is a legal java identifier character .
given a list of jar files their manifest attribute class - path are scanned and jars specified there are added to the list . this is carried out recursively . note : this is needed to work around the jdk bug 6725230 .
create a random token <p > this method uses the internal instance of of a { @link securerandom } generator to create a new token . < / p >
add property entry only of value is not null
write a list of units inside a { @code units } element
write the unit as xml fragment
get a job instance for updating it . <p > the fetched job will automatically be cloned and persisted . < / p >
convert a modifier value to a bootstrap type modifier
get all meta data values which match namespace and key
/ * initializes this jspservlet .
<p > look for a <em > precompilation request< / em > as described in section 8 . 4 . 2 of the jsp 1 . 2 specification . <strong > warning< / strong > - we cannot use <code > request . getparameter () < / code > for this because that will trigger parsing all of the request parameters and not give a servlet the opportunity to call <code > request . setcharacterencoding () < / code > first . < / p >
-------------------------------------------------------- private methods
starts s1as
clean up timed out user registrations
check if the { @code p2 . repo : fragment - keys } field contains a matching key
get the last segment of a path the filename
decompresses into an array of bytes . <p > if <code > len< / code > is zero no bytes are read and <code > 0< / code > is returned . otherwise this will try to decompress <code > len< / code > bytes of uncompressed data . less than <code > len< / code > bytes may be read only in the following situations : <ul > <li > the end of the compressed data was reached successfully . < / li > <li > an error is detected after at least one but less <code > len< / code > bytes have already been successfully decompressed . the next call with non - zero <code > len< / code > will immediately throw the pending exception . < / li > <li > an exception is thrown . < / li > < / ul >
returns the number of uncompressed bytes that can be read without blocking . the value is returned with an assumption that the compressed input data will be valid . if the compressed data is corrupt <code > corruptedinputexception< / code > may get thrown before the number of bytes claimed to be available have been read from this input stream .
closes the stream and optionally calls <code > in . close () < / code > . if the stream was already closed this does nothing . if <code > close ( false ) < / code > has been called a further call of <code > close ( true ) < / code > does nothing ( it doesn t call <code > in . close () < / code > ) . <p > if you don t want to close the underlying <code > inputstream< / code > there is usually no need to worry about closing this stream either ; it s fine to do nothing and let the garbage collector handle it . however if you are using { @link arraycache } <code > close ( false ) < / code > can be useful to put the allocated arrays back to the cache without closing the underlying <code > inputstream< / code > . <p > note that if you successfully reach the end of the stream ( <code > read< / code > returns <code > - 1< / code > ) the arrays are automatically put back to the cache by that <code > read< / code > call . in this situation <code > close ( false ) < / code > is redundant ( but harmless ) .
provides a way for the sub class to get a { @link java . nio . bytebuffer } representation of a certain rollup object .
/ * consider 5 files getting merged in the buildstore . assuming the flush rate to be 1 file / min we need all the files together in order to construct 5 min rollup how are we going to decide that a particular range has been totally filled up and ready to be rolled? one behaviour which we will start seeing in the buildstore is higher ranges starting to build up . this means the current range has almost filled up . but there is still a possibility for backed up data getting merged . so we provide range_buffer . basically for every call to geteligibledata it is going to return ( n - range_buffer ) ranges to get rolled up and keep ( range_buffer ) in buildstore also note that returning the range will eventually remove them from buildstore after all rollups are completed in rollupgenerator for that range .
similar to { @link #get ( locator string ) } except this does not throw any { @link cacheexception } . instead it may return null if the cache does not contain the requested locator for the specified key .
returns true if updated .
implements the cacheloader interface .
type comparisions we use to determine how to serialize a number .
resolve a number to a long or double .
history : this used to support multiple types .
writes object to codedoutputstream .
insert a locator with key = shard long value calculated using util . getshard ()
returns the locators for a shard i . e . those that should be rolled up for a given shard . should means : 1 ) a locator is capable of rollup . 2 ) a locator has had new data in the past locator_ttl seconds .
gets the ttl for a particular locator rolluptype and granularity .
converts the map of timestamp - > { @link rollup } to { @link points } object
create all prepared statements use in this class for metrics_locator
insert a locator with key = shard long value calculated using util . getshard ()
package protect so other classes in this package can call it
returns the locators for a shard i . e . those that should be rolled up for a given shard . should means : 1 ) a locator is capable of rollup . 2 ) a locator has had new data in the past locator_ttl seconds .
this method is used to log delayed metrics if tracking delayed metrics is turned on for this blueflood service .
this method logs the delayed aggregated metrics for a particular tenant if tracking delayed metric is turned on for this blueflood service . aggregated metrics have one single timestamp for the group of metrics that are sent in one request .
read out a type - specified number .
put out a number prefaced only by a type .
convert the existing configuration values into a map including those specified in defaultprops .
idempotent other than when the month changes between two calls
provides a way for the sub class to get a { @link java . nio . bytebuffer } representation of a certain rollup object .
retrieves the {
{
only one thread should be calling in this puppy .
returns the next scheduled key . it has a few side effects : 1 ) it resets update tracking for that slot 2 ) it adds the key to the set of running rollups .
take the given slot out of the running group and put it back into the scheduled group . if { @code rescheduleimmediately } is true the slot will be the next slot returned by a call to { @link #getnextscheduled () } . if { @code rescheduleimmediately } is false then the given slot will go to the end of the line as when it was first scheduled by { @link #scheduleeligibleslots ( long long long ) } .
remove the given slot from the running group after it has been successfully re - rolled .
this method inserts a collection of { @link com . rackspacecloud . blueflood . types . imetric } objects to the appropriate cassandra column family . effectively this method is only called to write the raw metrics received during ingest requests . another method insertrollups is used by the rollup processes to write rolled up metrics .
fetches { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } objects for the specified list of { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range } from the specified column family
return the appropriate io object which interacts with the cassandra database .
inserts a collection of metrics in a batch using an unlogged { @link batchstatement }
listens on the event .
adds a one time listener for the event .
removes all listeners of the specified event .
executes each of listeners with the given args .
returns a list of listeners for the specified event .
get the remote file name .
serialize a rollup event and append it to the file .
parse the timestamp from a filename .
starts the ingest server
determine which datatype to use for serialization .
returns an instance of this class based on what configuration says our driver should be .
helper function to build the ttl mapping . only insert to the mapping if the value is a valid date .
merge simple numbers with this rollup .
merge rollups into this rollup .
for a particular rolluptype determine what is the proper class to do read / write with and return that
package protect so other classes in this package can call it
compute the maximum width for each field across a collection of formatters .
formats a header row after maximums have been established .
formats results and sets formattedstrings .
registers the different zookeeper metrics .
waits until the zookeeper connection is available .
only called from { @link #init ( timevalue ) } .
unsafe method for testing .
given the encoded slot key returns the java object of it . for the valid slot keys this function is inverse of { @link #tostring () } . @return decoded { @link slotkey } <code > null< / code > if it s an invalid slotkey .
this method creates a collection of slot keys that are within the same timespan of the current slot key but of a finer granularity . for example a slot key of granularity { @link granularity#min_20 min_20 } will have four child keys each of granularity { @link granularity#min_5 min_5 } . <p >
same as the method { @link #getchildrenkeys () } except this method returns only the children corresponding to the destination granularity .
this method would extrapolate a given slotkey to a corresponding parent slotkey of a given ( higher ) granularity .
set the threadpool name . used to generate metric names and thread names .
our own stuff .
for a given metricindex and doccount classifies the data with respect to baselevel and stores it accordingly .
compares actualdoccount and total doccount of its immediate children of an index to determine if the metric index is a complete metric name or not .
side effect : mark dirty slots as clean
this method return list of tokens with their parents for a current discovery object .
asynchronously insert a rolled up metric to the appropriate column family for a particular granularity
fetch rollup objects for a { @link com . rackspacecloud . blueflood . types . locator } from the specified column family and range .
fetch values for a list of { @link com . rackspacecloud . blueflood . types . locator } from the specified column family and range .
add a { @link com . datastax . driver . core . preparedstatement } statement to the { @link com . datastax . driver . core . batchstatement } to insert this rollup object to metrics_preaggregated_ { granularity } column family
asynchronously execute select statements against the specified column family for a specific list of { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range }
execute a select statement against the specified column family for a specific { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range }
give a {
we need to derive ranges ( actual times ) from slots ( which are fixed integers that wrap ) when we discover a late slot . these ranges can be derived from a reference point ( which is usually something like now ) .
return granularity that maps most closely to requested number of points using the algorithm specified in the { @code get_by_points_selection_algorithm } config value . see { @link #granularityfrompointsininterval ( string long long int string long ) } .
{ @code ttlcomparisonclock } defaults to { @link #default_ttl_comparison_source } .
return granularity that maps most closely to requested number of points based on provided selection algorithm
find the granularity in the interval that will yield a number of data points that are closest to the requested points but < = requested points .
find the granularity in the interval that will yield a number of data points that are close to $points in terms of linear distance .
set the server time in millis .
add a shard to be managed ( via jmx )
remove a shard from being managed ( via jmx )
for all of these { @link locator } s get a unique list of { @link token } s which are not in token cache
get all { @link locator } s corresponding to the metrics which are not current .
for a given batch of metrics insert unique tokens using { @link tokendiscoveryio } .
given a {
retrieves the set of unique cassandra hosts from configuration file . if a single host appears multiple times in the configuration only one will be listed .
retrieves a set of unique cassandra hosts with binary transport protocol enabled from configuration file . this may or may not be different than { @link #getuniquehosts () }
retrieves a set of unique cassandra hosts with binary transport protocol enabled from configuration file as a set of { @link java . net . inetsocketaddress } objects .
calculates the number of max connections per cassandra hosts
serialize without sum attribute . this is used by { @link gaugeserdes }
builds es query to grab tokens corresponding to the given query glob . for a given query foo . bar . * we would like to grab all the tokens with parent as foo . bar
for a given glob gives regex for { @code locator . metric_token_separator } separated tokens
if index () fails for whatever reason it always throws ioexception because indexing failed for elasticsearch .
iterate over all column families that store metrics .
should be populated .
provides a way for the sub class to get a { @link java . nio . bytebuffer } representation of a certain rollup object .
inserts a collection of metrics to the metrics_preaggregated_full column family
inserts a collection of metrics to the correct column family based on the specified granularity
fetches { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } objects for the specified { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range } from the specified column family
fetches { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } objects for the specified list of { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range } from the specified column family
fetches a { @link com . rackspacecloud . blueflood . types . points } object for a particular locator and rolluptype from the specified column family and range
inserts a raw metric ( not its rolled up value ) to the proper column family
constructs a { @link boundstatement } for a particular metric . the statement could be part of a batchstatement or it could be executed as is .
this methods gets locators to rollup a slot .
this method returns a list of { @link metricname } s matching the given glob query .
performs terms aggregation by metric_name which returns doc_count by metric_name index that matches the given regex .
returns regex which could grab metric names from current level to the next level for a given query .
start background storage management and uploading tasks .
stop background storage management .
merge simple numbers with this rollup .
merge rollups into this rollup .
checks if locator is recently inserted in the batch layer
checks if locator is recently inserted in the discovery layer
checks if locator is recently inserted in the token discovery layer
check if the delayed locator is recently inserted for a given slot
marks the delayed locator as recently inserted for a given slot
provides a way for the sub class to get a { @link java . nio . bytebuffer } representation of a certain rollup object .
given a start and stop time return an iterator over ranges in * this * granularity that should be rolled up into single points in the next coarser granularity .
returns a mapping of ranges in the coarser granularity to the sub - ranges in finer granularity
return the ranges for an interval at this granularity
single column updates ) .
this method inserts the locator into the metric_delayed_locator column family if the metric is delayed .
numeric only!
numeric only!
generic imetric insertion . all other metric insertion methods could use this one .
this method inserts a collection of { @link com . rackspacecloud . blueflood . service . singlerollupwritecontext } objects to the appropriate cassandra column family .
fetches { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } objects for the specified { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range } from the specified column family
fetches { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } objects for the specified { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range } from the specified column family
fetches a { @link com . rackspacecloud . blueflood . types . points } object for a particular locator and rolluptype from the specified column family and range
converts a list of { @link com . datastax . driver . core . resultsetfuture } for each { @link com . rackspacecloud . blueflood . types . locator } to { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } object .
given a map of timestamps - > rollups / simplenumbers return rolluptype or null if not a rollup .
determines if the metric is considered delayed or not
this method inserts the locator into the metric_delayed_locator column family if the metric is delayed .
returns a boundstatement if a metric needs to be inserted to the metrics_delayed_locator column family . returns null otherwise .
this method queries elasticsearch for a given glob query and returns list of { @link metricname } s .
method that returns all metadata for a given locator as a map .
todo : a better interface may be to pass the serializer in instead of the class type .
get data points for a particular { @link locator } { @link range } and { @link granularity } .
get data points for multiple { @link locator } for the specified { @link range } and { @link granularity } .
fetches a { @link com . rackspacecloud . blueflood . types . points } object for a particular locator and rolluptype from the specified column family and range
return a serializer for a specific type
checks the content - type header to see if clients specify the right media type
checks the accept header to see if clients accept the correct media type
rest call to index into es
this method is invoked by the validator automatically
marks / instruments our internal metrics that we have received short or delayed metrics
gets run by the thread .
inserts a collection of rolled up metrics to the metrics_preaggregated_ { granularity } column family . only our tests should call this method . services should call either insertmetrics ( collection metrics ) or insertrollups ()
fetches { @link com . rackspacecloud . blueflood . outputs . formats . metricdata } objects for the specified list of { @link com . rackspacecloud . blueflood . types . locator } and { @link com . rackspacecloud . blueflood . types . range } from the specified column family
return the appropriate io object which interacts with the cassandra database .
@return an available port assigned at random by the os .
returns an extractor instance appropriate based on the given configuration .
decides if the operating system matches .
<p > gets a system property defaulting to { @code null } if the property cannot be read . < / p > <p > if a { @code securityexception } is caught the return value is { @code null } and a message is written to { @code system . err } . < / p >
<p > decides if the java version matches . < / p > <p > this method is package private instead of private to support unit test invocation . < / p >
decides if the operating system matches . <p > this method is package private instead of private to support unit test invocation . < / p >
decides if the operating system version matches . <p > this method is package private instead of private to support unit test invocation . < / p >
returns the rabbitmq node port as defined by the {
starts the rabbitmq server process and blocks the current thread until the initialization is completed .
submits the command to stop rabbitmq and blocks the current thread until the shutdown is completed .
<p > start the stopwatch . < / p >
<p > stop the stopwatch . < / p >
<p > split the time . < / p >
<p > suspend the stopwatch for later resumption . < / p >
<p > resume the stopwatch after a suspend . < / p >
<p > get the time on the stopwatch in nanoseconds . < / p >
joins the elements of the provided collection into a single string containing the provided list of elements . <p > no delimiter is added before or after the list . <p > empty collections return an empty string .
retrieves the current system s erlang version to compare it to the minimum required version . <p > the system s erlang version is always retrieved but the comparison might be skipped if the rabbitmq version doesn t specify a minimum required version .
this method exposes a way to invoke { @value executable } command with any arguments . this is useful when the class methods don t expose the desired functionality . <p > for example : <pre > <code > rabbitmqplugins command = new rabbitmqplugins ( config ) ; command . execute ( list - v management ) ; < / code > < / pre >
same as {
executes the { @code rabbitmq - plugins list } command
executes the command { @code rabbitmq - plugins enable { plugin }} and blocks until the call finishes .
disables the given plugin by executing { @code rabbitmq - plugins disable { plugin }} and blocks until the call is finished .
copies bytes from the url <code > source< / code > to a file <code > destination< / code > . the directories up to <code > destination< / code > will be created if they don t already exist . <code > destination< / code > will be overwritten if it already exists .
copies bytes from the url <code > source< / code > to a file <code > destination< / code > . the directories up to <code > destination< / code > will be created if they don t already exist . <code > destination< / code > will be overwritten if it already exists .
copies bytes from an { @link inputstream } <code > source< / code > to a file <code > destination< / code > . the directories up to <code > destination< / code > will be created if they don t already exist . <code > destination< / code > will be overwritten if it already exists .
starts the rabbitmq server and blocks the current thread until the server is confirmed to have started . <p > this is useful to ensure no other interactions happen with the rabbitmq server until it s safe to do so
@param outputline as generated by the command line { @code rabbitmq - plugins groupedlist }
the default parameters for media constraints . might have to tweak in future .
append default servers to the end of given list and set as iceservers instance variable
instantiate iceservers if they are not already and add ice server to beginning of list .
todo : add a max user threshold . connect with another user by their id .
close connection ( hangup ) no a certain peer .
close connections ( hangup ) on all open connections .
send sdp offers / answers nd ice candidates to peers .
static method to generate the proper json for a user message . use this when you don t have a {
send a custom jsonobject user message to a single peer .
send a custom jsonobject user message to all peers .
gets the value of the weitereadresse property .
gets the value of the userdefinedsimplefield property .
gets the value of the userdefinedanyfield property .
sets the value of the apisuchfelder property .
gets the value of the multimediaanhang property .
gets the value of the statusvbm property .
gets the value of the statusis24 property .
gets the value of the statushp property .
gets the value of the importmodus property .
gets the value of the adressdruck property .
gets the value of the waehrung property .
start the example application .
create an { @link adtype } with some example data .
create a { @link picturetype } with some example data .
start the example application .
create an { @link agent } object with some example data .
create a { @link kyerotype } object with some example data .
create a { @link propertytype } object with some example data .
create an { @link image } object with some example data .
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link biginteger } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link stellplatz } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link stellplatz } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link stellplatz } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link stellplatz } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link stellplatz } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link biginteger } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link ausstattkategorie } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link biginteger } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
gets the value of the bodenbelag property .
sets the value of the region property .
sets the value of the area property .
sets the value of the address property .
sets the value of the description property .
sets the value of the rentcollectionperiod property .
sets the value of the furnished property .
sets the value of the phone1 property .
sets the value of the phone2 property .
sets the value of the contactname property .
sets the value of the phoneinfo property .
sets the value of the mainemail property .
sets the value of the ccemail property .
sets the value of the externalid property .
sets the value of the agentid property .
start the example application .
create an { @link hauskauf } with some example data .
create an { @link wohnungmiete } with some example data .
init common values of an { @link is24csvrecord } .
write some { @link is24csvrecord } objects into an { @link outputstream } .
write some { @link is24csvrecord } objects into a { @link string } and print the results to the console .
sets the value of the epart property .
sets the value of the jahrgang property .
sets the value of the gebaeudeart property .
sets the value of the buerotyp property .
test if a string contains a parsable number .
convert a string value into a number .
convert a string value into a number .
write a number into a string value .
write a number into a string value .
sets the value of the gebiete property .
creates a { @link filemakerresultdocument } from a { @link fmpxmlresult } object .
creates a { @link is24xmldocument } from a { @link document } .
creates a { @link marshaller } to write jaxb objects into xml .
creates a { @link unmarshaller } to read jaxb objects from xml .
returns the { @link jaxbcontext } for this format .
sets the value of the location property .
sets the value of the gruppe property .
sets the value of the type property .
sets the value of the agent property .
gets the value of the property property .
read a { @link file } into a { @link daftiedocument } and print some of its content to console .
read a { @link inputstream } into an { @link daftiedocument } and print some of its content to console .
print some content of a { @link daftiedocument } to console .
sets the value of the stand property .
gets the value of the userdefinedextend property .
checks if a { @link document } is readable as a { @link openimmotransferdocument } .
creates a { @link openimmotransferdocument } from a { @link openimmo } object .
creates a { @link openimmo } object from the contained { @link document } .
sets the value of the zeiteinheit property .
gets the value of the zimmer property .
gets the value of the haus property .
gets the value of the bueropraxen property .
gets the value of the gastgewerbe property .
gets the value of the landundforstwirtschaft property .
gets the value of the sonstige property .
gets the value of the zinshausrenditeobjekt property .
gets the value of the terrain property .
sets the value of the periode property .
downgrade &lt ; jahrgang&gt ; elements in &lt ; energiepass&gt ; to openimmo 1 . 2 . 7 . <p > the value bei_besichtigung of &lt ; jahrgang&gt ; elements in &lt ; energiepass&gt ; is not available in openimmo 1 . 2 . 7 .
creates a { @link casaitdocument } from a { @link container } object .
sets the value of the umfang property .
creates a { @link daftiedocument } from a { @link daft } object .
creates a { @link daft } object from the contained { @link document } .
sets the value of the wohnungtyp property .
return an iso - 2 country code from a country name .
create an iso - 2 country code from an iso - 3 country code .
return an iso - 3 country code from a country name .
create an iso - 3 country code from an iso - 2 country code .
return a country name in another language .
translate a country name into another language .
gets the value of the anbieter property .
sets the value of the periode property .
sets the value of the category property .
gets the value of the pdf property .
sets the value of the aktionart property .
start the example application .
read a { @link file } into an { @link idxparser } and print some of its content to console .
read an { @link inputstream } into an { @link idxparser } and print some of its content to console .
print some content of an { @link idxparser } to console .
sets the value of the realestateitems property .
sets the value of the pacht property .
gets the value of the objektkategorie2 property .
start the example application .
create an { @link uebertragung } with some example data .
downgrade an openimmo document from version 1 . 2 . 7 to 1 . 2 . 6 .
upgrade an openimmo document from version 1 . 2 . 6 to 1 . 2 . 7 .
downgrade &lt ; befeuerung&gt ; elements to openimmo 1 . 2 . 6 . <p > the attributes kohle holz fluessiggas of &lt ; befeuerung&gt ; elements are not available in openimmo 1 . 2 . 6 .
downgrade &lt ; energiepass&gt ; elements to openimmo 1 . 2 . 6 . <p > the child elements &lt ; stromwert&gt ; &lt ; waermewert&gt ; &lt ; wertklasse&gt ; &lt ; baujahr&gt ; &lt ; ausstelldatum&gt ; &lt ; jahrgang&gt ; &lt ; gebaeudeart&gt ; are copied into separate &lt ; user_defined_simplefield&gt ; elements as it was <a href = http : // www . openimmo . de / go . php / p / 44 / cm_enev2014 . htm > suggested by openimmo e . v . < / a > . <p > the child elements &lt ; primaerenergietraeger&gt ; &lt ; epasstext&gt ; are not available in openimmo 1 . 2 . 6 .
only use one &lt ; energiepass&gt ; element for each &lt ; immobilie&gt ; . <p > openimmo 1 . 2 . 6 does not allow more then one &lt ; energiepass&gt ; element for each &lt ; immobilie&gt ; ( maxoccurs = 1 ) . odd &lt ; energiepass&gt ; elements are removed by this function .
start the example application .
gets the value of the content property .
returns the names of specified fields .
sets the value of the blick property .
sets the value of the pauschalmiete property .
sets the value of the monatsmiete property .
gets the value of the parkplatz property .
create an instance of { @link container . realestateitems . realestate . images . advertismentimage }
sets the value of the lastenaufzug property .
gets the value of the objektkategorie2 property .
sets the value of the zustandart property .
read a { @link inputstream } into an { @link immobiliareitdocument } and print some of its content to console .
print some content of an { @link immobiliareitdocument } to console .
gets the value of the feld property .
receive notification of a validation warning or error .
write content of the record in a human readable form .
returns the value of the record at a certain index position .
loads data from { @link csvparser } into the record .
returns a list of values for this record as they are written into csv .
sets the value of this record at a certain index position .
sets the value of the ctype property .
read a { @link inputstream } into a { @link trovitdocument } and print some of its content to console .
print some content of a { @link trovitdocument } to console .
sets the value of the haustyp property .
read a { @link inputstream } into a { @link kyerodocument } and print some of its content to console .
print some content of a { @link kyerodocument } to console .
gets the value of the energiepass property .
sets the value of the keller property .
sets the value of the grundsttyp property .
sets the value of the geschlattr property .
sets the value of the hallentyp property .
sets the value of the type property .
gets the value of the wiederholungstermin property .
gets the value of the teilungsversteigerung property .
sets the value of the kauf property .
downgrade an openimmo document from version 1 . 2 . 3 to 1 . 2 . 2 .
upgrade an openimmo document from version 1 . 2 . 2 to 1 . 2 . 3 .
downgrade &lt ; ausricht_balkon_terrasse&gt ; elements to openimmo 1 . 2 . 2 . <p > the attributes nordost nordwest suedost suedwest for &lt ; ausricht_balkon_terrasse&gt ; elements are not available in version 1 . 2 . 2 . <p > any occurences of these values are replaced by the single components - e . g . nordost is removed and nord + ost is set .
remove unsupported children from all &lt ; flaechen&gt ; elements . <p > openimmo 1 . 2 . 2 does not support the following children for &lt ; flaechen&gt ; elements : &lt ; anzahl_balkone&gt ; &lt ; anzahl_terrassen&gt ; <p > these elements are removed by this function . if &lt ; anzahl_balkon_terrassen&gt ; is not already specified the sum values of &lt ; anzahl_balkone&gt ; and &lt ; anzahl_terrassen&gt ; are written into &lt ; anzahl_balkon_terrassen&gt ; .
replace &lt ; parken&gt ; elements with &lt ; sonstige&gt ; elements . <p > openimmo 1 . 2 . 2 does not support &lt ; parken&gt ; elements . any occurence is converted into &lt ; sonstige&gt ; elements .
upgrade &lt ; zinshaus_renditeobjekt&gt ; elements to openimmo 1 . 2 . 3 . <p > the options pflegeheim sanatorium seniorenheim betreutes - wohnen for the haustyp attribute of &lt ; haus&gt ; elements are placed in the &lt ; zinshaus_renditeobjekt&gt ; element in version 1 . 2 . 3 .
create an instance of { @link jaxbelement } { @code < } { @link virtuelleimmobiliebasetyp } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link immobiliebasetyp } { @code > }}
create an instance of { @link wohnungkauf }}
create an instance of { @link wohnungmiete }}
create an instance of { @link hauskauf }}
create an instance of { @link hausmiete }}
create an instance of { @link waz }}
create an instance of { @link jaxbelement } { @code < } { @link grundstueck } { @code > }}
create an instance of { @link grundstueckwohnenkauf }}
create an instance of { @link grundstueckwohnenmiete }}
create an instance of { @link grundstueckgewerbe }}
create an instance of { @link jaxbelement } { @code < } { @link typenhaus } { @code > }}
create an instance of { @link bueropraxis }}
create an instance of { @link einzelhandel }}
create an instance of { @link gastronomie }}
create an instance of { @link halleproduktion }}
create an instance of { @link sonstigegewerbe }}
create an instance of { @link anlageobjekt }}
create an instance of { @link garagemiete }}
create an instance of { @link garagekauf }}
create an instance of { @link zwangsversteigerung }}
create an instance of { @link wgzimmer }}
create an instance of { @link jaxbelement } { @code < } { @link apisuchfeldertyp } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link hebeanlagetyp } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link apisuchfeldertyp } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggewerbetyp . miete } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggewerbetyp . kauf } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckwohnenmietetyp . pacht } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckwohnenmietetyp . miete } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckwohnenkauftyp . kauf } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckwohnenkauftyp . erbpacht } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstuecktypalt . kauf } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstuecktypalt . pacht } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstuecktypalt . erbpacht } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckgewerbetyp . kauf } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckgewerbetyp . pacht } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckgewerbetyp . erbpacht } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link vermarktunggrundstueckgewerbetyp . miete } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link biginteger } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link object } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link stellplatz } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link byte [] } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link bigdecimal } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link calendar } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link string } { @code > }}
create an instance of { @link jaxbelement } { @code < } { @link boolean } { @code > }}
start the example application .
create an { @link anbieter } with some example data .
create an { @link immobilie } with some example data .
create an { @link uebertragung } with some example data .
start the example application .
create a { @link databasetype } with some example data .
create a { @link metadatatype } with some example data .
create a { @link producttype } with some example data .
create a { @link resultsettype } with some example data .
create a { @link org . openestate . io . filemaker . xml . result . resultsettype . row } with some example data .
write a { @link filemakerresultdocument } into a { @link string } and print the results to the console .
creates a { @link casaitdocument } from a { @link document } .
read an { @link inputstream } into an { @link is24xmldocument } and print some of its content to console .
print some content of an { @link is24xmldocument } to console .
gets the value of the bevorzugt property .
gets the value of the wunsch property .
sets the value of the art property .
sets the value of the modus property .
gets the value of the emailsonstige property .
gets the value of the telsonstige property .
sets the value of the handeltyp property .
sets the value of the erschlattr property .
downgrade an openimmo document from version 1 . 2 . 6 to 1 . 2 . 5 .
downgrade &lt ; ausblick&gt ; elements to openimmo 1 . 2 . 5 . <p > the option meer for the blick attribute of &lt ; ausblick&gt ; elements is not available in version 1 . 2 . 5 . <p > any occurence of the meer value is replaced by the see value .
start the example application .
create an { @link objecttype } with some example data .
write a { @link wisitdocument } into an { @link outputstream } .
sets the value of the apisuchfeld1 property .
sets the value of the apisuchfeld2 property .
sets the value of the apisuchfeld3 property .
gets the value of the row property .
sets the value of the distanzzusport property .
creates a { @link daftiedocument } from a { @link document } .
gets the value of the anhang property .
gets the value of the objektkategorie2 property .
gets the value of the objektzustand property .
gets the value of the hauskategorie property .
gets the value of the ausstattungsqualitaet property .
start the example application .
read a { @link file } into an { @link openimmotransferdocument } or { @link openimmofeedbackdocument } and print some of their content to console .
read a { @link inputstream } into an { @link openimmotransferdocument } or { @link openimmofeedbackdocument } and print some of their content to console .
print some content of an { @link openimmofeedbackdocument } to console .
print some content of an { @link openimmotransferdocument } to console .
gets the value of the vermarktungsart property .
gets the value of the interessent property .
sets the value of the wert property .
creates a { @link immoxmldocument } from a { @link immoxml } object .
creates a { @link immoxml } object from the contained { @link document } .
sets the value of the ackerland property .
sets the value of the bauerwartungsland property .
sets the value of the bootsstaende property .
sets the value of the buero property .
sets the value of the camping property .
sets the value of the doppelhaus property .
sets the value of the einfamilienhaus property .
sets the value of the einzelhandelgross property .
sets the value of the einzelhandelklein property .
sets the value of the garagen property .
sets the value of the garten property .
sets the value of the gastronomie property .
sets the value of the gewerbe property .
sets the value of the hotel property .
sets the value of the industrie property .
sets the value of the keinebebauung property .
sets the value of the kleingewerbe property .
sets the value of the lager property .
sets the value of the mehrfamilienhaus property .
sets the value of the obstpflanzung property .
sets the value of the parkhaus property .
sets the value of the produktion property .
sets the value of the reihenhaus property .
sets the value of the stellplaetze property .
sets the value of the villa property .
sets the value of the wald property .
downgrades the contained { @link document } to an earlier version .
upgrades the contained { @link document } to a newer version .
sets the value of the anbieter property .
gets the value of the wohnung property .
gets the value of the grundstueck property .
gets the value of the einzelhandel property .
gets the value of the hallenlagerprod property .
gets the value of the parken property .
gets the value of the freizeitimmobiliegewerblich property .
gets the value of the objektartzusatz property .
gets the value of the stellplatzart property .
sets the value of the maxdauer property .
creates a { @link filemakerdocument } from a { @link document } .
start the example application .
create an { @link idxrecord } with some example data .
write some { @link idxrecord } objects into a { @link file } .
sets the value of the erschlattr property .
gets the value of the feature property .
creates a { @link csvparser } from a { @link file } with csv data .
creates a { @link csvprinter } that writes csv data into a { @link file } .
print a { @link csvrecord } followed by a record separator ( line break ) .
print multiple { @link csvrecord } objects .
helper function to replace line breaks in a string with a custom value before printing . <p > this method may be used by inheriting classes if the particular format does not support line breaks .
creates a { @link immobiliareitdocument } from a { @link document } .
creates a { @link trovitdocument } from a { @link document } .
read a { @link areaunitvalue } value from xml .
read a { @link boolean } value from xml .
read a { @link calendar } value from xml .
read a { @link foreclosuretypevalue } value from xml .
read a { @link orientationvalue } value from xml .
read a { @link currency } value from xml .
read a { @link priceperiodvalue } value from xml .
read a { @link bigdecimal } value from xml for a price .
read a { @link bigdecimal } value from xml for a number of rooms .
read a { @link typevalue } value from xml .
write a { @link boolean } value into xml output .
write a { @link string } value for a description into xml output . <p > the description must contain at least 30 characters .
write a { @link string } value for a country code into xml output . <p > the country has to be represendet by a iso - code wirh two or three characters .
write a { @link calendar } value into xml output .
write a { @link bigdecimal } value into xml output with a valid latitude range .
write a { @link biginteger } value into xml output for a plot area .
write a { @link bigdecimal } value into xml output for a price .
write a { @link bigdecimal } value into xml output for a room number .
write an { @link uri } value into xml output .
write a { @link biginteger } value into xml output for a year number .
sets the value of the zimmertyp property .
recursively remove any comments and unnecessary white spaces from a { @link node } and its children .
count the number of nodes that are matching against an xpath expression .
count the number of nodes that are matching against an xpath expression .
return the root { @link element } of a { @link document } .
create an empty { @link document } .
create a { @link document } from a xml string .
create a { @link document } from a xml string .
create a { @link document } from an { @link inputsource } .
create a { @link document } from an { @link inputsource } .
create a { @link document } from an { @link inputstream } .
create a { @link document } from an { @link inputstream } .
create a { @link document } from a { @link file } .
create a { @link document } from a { @link file } .
create a { @link xpath } expression .
create a { @link xpath } expression .
create a { @link xpath } expression .
print nodes of a { @link document } recursively to the local logger .
replace the namespace of any { @link element } in a { @link document } .
replace the namespace of a { @link node } and its children .
replace all text values of a { @link document } with cdata values .
replace all text values of a { @link node } with cdata values .
write a { @link document } to a { @link file } .
write a { @link document } to a { @link file } .
write a { @link document } to an { @link outputstream } .
write a { @link document } to a { @link writer } .
write a { @link document } to a { @link writer } .
generate xml for the contained { @link document } .
generate xml for the contained { @link document } .
returns xml for the contained { @link document } .
creates a { @link wisitdocument } from a { @link document } .
downgrade an openimmo document from version 1 . 2 . 5 to 1 . 2 . 4 .
upgrade an openimmo document from version 1 . 2 . 4 to 1 . 2 . 5 .
downgrade &lt ; energiepass&gt ; elements to openimmo 1 . 2 . 4 . <p > the child elements &lt ; hwbwert&gt ; &lt ; hwbklasse&gt ; &lt ; fgeewert&gt ; &lt ; fgeeklasse&gt ; are copied into separate &lt ; user_defined_simplefield&gt ; elements as it was suggested by openimmo e . v ..
upgrade &lt ; energiepass&gt ; elements to openimmo 1 . 2 . 5 . <p > the &lt ; user_defined_simplefield&gt ; elements for austria that were suggested by openimmo e . v . are explicitly supported in openimmo 1 . 2 . 5 as child elements of &lt ; energiepass&gt ; . any matching &lt ; user_defined_simplefield&gt ; elements are moved into the &lt ; energiepass&gt ; element .
sets the value of the keineangabe property .
sets the value of the erdwaerme property .
sets the value of the solarheizung property .
sets the value of the pelletheizung property .
sets the value of the gas property .
sets the value of the oel property .
sets the value of the fernwaerme property .
sets the value of the strom property .
sets the value of the kohle property .
start the example application .
create a { @link property } with some example data .
create a { @link pictureproject } with some example data .
create a { @link pictureextended } with some example data .
create a { @link videoproject } with some example data .
generate a random string with ascii letters and digits .
generate a random string with ascii letters .
generate a random string with ascii digits .
gets the value of the wohnungkategorie property .
sets the value of the benutzer property .
sets the value of the objekte property .
gets the value of the feed property .
sets the value of the moeb property .
gets the value of the serviceleistungen property .
creates a { @link is24xmldocument } from a { @link immobilientransfertyp } object .
creates a { @link is24xmldocument } from a { @link immobilientransfertyp } object .
creates a { @link immobilientransfertyp } object from the contained { @link document } .
sets the value of the subadministrativearea property .
sets the value of the city property .
sets the value of the locality property .
downgrade an openimmo document from version 1 . 2 . 1 to 1 . 2 . 0 .
upgrade an openimmo document from version 1 . 2 . 0 to 1 . 2 . 1 .
downgrade &lt ; energiepass&gt ; elements to openimmo 1 . 2 . 0 . <p > the &lt ; mitwarmwasser&gt ; child element of the &lt ; energiepass&gt ; element is not available in version 1 . 2 . 0 . <p > the &lt ; energieverbrauchkennwert&gt ; &lt ; endenergiebedarf&gt ; child elements of the &lt ; energiepass&gt ; element are moved into &lt ; energiebedarf&gt ; and &lt ; skala&gt ; in version 1 . 2 . 0 .
upgrade &lt ; energiepass&gt ; elements to openimmo 1 . 2 . 1 . <p > make sure that a valid value for &lt ; art&gt ; is used . <p > remove unsupported &lt ; heizwert&gt ; element . <p > replace &lt ; energiebedarf&gt ; &lt ; skala&gt ; with &lt ; energieverbrauchkennwert&gt ; or &lt ; endenergiebedarf&gt ; according to the provided &lt ; art&gt ; .
sets the value of the miete property .
sets the value of the kauf property .
sets the value of the landtyp property .
gets the value of the field property .
start the example application .
create an { @link anbieter } with some example data .
create an { @link hauskauf } with some example data .
create an { @link hausmiete } with some example data .
create an instance of { @link feed . projects . project . lots . lot }
create an instance of { @link feed . projects . project . agent . salesoffice }
create an instance of { @link feed . projects . project . lots . lot . pictures }
create an instance of { @link feed . projects . project . agent . salesoffice . city }
create an instance of { @link feed . projects . project . agent . salesoffice . locality }
downgrade an openimmo document from version 1 . 2 . 0 to 1 . 1 .
upgrade an openimmo document from version 1 . 1 to 1 . 2 . 0 .
downgrade &lt ; mieteinnahmen_ist&gt ; &lt ; mieteinnahmen_soll&gt ; elements to openimmo 1 . 1 . <p > the periode attribute of the &lt ; mieteinnahmen_ist&gt ; and &lt ; mieteinnahmen_soll&gt ; elements is not available in version 1 . 1 . <p > any occurences of these values is removed . <p > the numeric value within the &lt ; mieteinnahmen_ist&gt ; and &lt ; mieteinnahmen_soll&gt ; elements is converted according to the value of the periode attribute .
remove unsupported children from all &lt ; ausstattung&gt ; elements . <p > openimmo 1 . 1 does not support the following children for &lt ; ausstattung&gt ; elements : &lt ; dvbt&gt ; &lt ; breitband_zugang&gt ; &lt ; umts_empfang&gt ; &lt ; abstellraum&gt ; &lt ; fahrradraum&gt ; &lt ; rolladen&gt ; <p > these elements are removed by this function .
upgrade &lt ; mieteinnahmen_ist&gt ; &lt ; mieteinnahmen_soll&gt ; elements to openimmo 1 . 2 . 0 . <p > the periode attribute with the value jahr is added to any &lt ; mieteinnahmen_ist&gt ; and &lt ; mieteinnahmen_soll&gt ; elements .
gets the value of the ad property .
sets the value of the gastgewtyp property .
sets the value of the platzart property .
gets the value of the objektkategorie2 property .
gets the value of the datenverkabelung property .
gets the value of the klimaanlage property .
gets the value of the image property .
start the example application .
create a { @link realestate } with some example data .
create an { @link advertismentimage } with some example data .
sets the value of the pricetype property .
sets the value of the newdevelopmentavailability property .
sets the value of the directions property .
sets the value of the co2rating property .
sets the value of the energyrating property .
sets the value of the viewingdetails property .
sets the value of the propertystatus property .
gets the value of the objektkategorie2 property .
sets the value of the pictures property .
creates a { @link filemakerlayoutdocument } from a { @link fmpxmllayout } object .
read an { @link inputstream } into a { @link casaitdocument } and print some of its content to console .
print some content of a { @link casaitdocument } to console .
sets the value of the type property .
sets the value of the bebaubarattr property .
downgrade an openimmo document from version 1 . 2 . 4 to 1 . 2 . 3 .
upgrade an openimmo document from version 1 . 2 . 3 to 1 . 2 . 4 .
downgrade &lt ; anhang&gt ; elements to openimmo 1 . 2 . 3 . <p > the options qrcode film filmlink for the gruppe attribute of &lt ; anhang&gt ; elements are not available in version 1 . 2 . 3 . <p > the option remote for the location attribute of &lt ; anhang&gt ; elements is not available in version 1 . 2 . 3 . <p > the the child element &lt ; check&gt ; of &lt ; anhang&gt ; elements is not available in version 1 . 2 . 3 .
remove unsupported children from all &lt ; interessent&gt ; elements in feedback xml . <p > openimmo 1 . 2 . 3 does not support more then one &lt ; bevorzugt&gt ; &lt ; wunsch&gt ; elements in feedback xml .
upgrade &lt ; anhang&gt ; elements to openimmo 1 . 2 . 4 . <p > the option remote for the location attribute of &lt ; anhang&gt ; elements is introduced with openimmo 1 . 2 . 4 . <p > if the &lt ; pfad&gt ; element of an &lt ; anhang&gt ; element contains an url ( beginning with http : // / https : // / ftp : // / ftps : // ) the value of the location attribute is changed to remote .
upgrade &lt ; anzahl_balkon_terrassen&gt ; elements to openimmo 1 . 2 . 4 . <p > the &lt ; anzahl_balkon_terrassen&gt ; is not supported anymore in version 1 . 2 . 4 . the element is replaced by &lt ; anzahl_balkone&gt ; and &lt ; anzahl_terrassen&gt ; . <p > any &lt ; anzahl_balkon_terrassen&gt ; element is removed . its content is copied into &lt ; anzahl_balkone&gt ; if this element is not already present .
upgrade &lt ; sonstige&gt ; elements to openimmo 1 . 2 . 4 . <p > the options garagen parkflache for the sonstige_typ attribute of &lt ; sonstige&gt ; elements were removed with openimmo 1 . 2 . 4 . <p > for any occurence of these values the corresponding &lt ; sonstige&gt ; element is replaced with a &lt ; parken&gt ; element .
sets the value of the parkentyp property .
sets the value of the location property .
creates a { @link openimmofeedbackdocument } from a { @link openimmofeedback } object .
creates a { @link openimmofeedback } object from the contained { @link document } .
creates a { @link kyerodocument } from a { @link root } object .
creates a { @link root } object from the contained { @link document } .
sets the value of the alterattr property .
creates a { @link kyerodocument } from a { @link document } .
sets the value of the freizeittyp property .
sets the value of the telefonart property .
read a { @link inputstream } into an { @link immoxmldocument } and print some of its content to console .
print some content of an { @link immoxmldocument } to console .
sets the value of the emailart property .
creates a record according to the object category that is provided in a { @link csvrecord } .
sets the value of the overseassales property .
sets the value of the overseasrental property .
creates a { @link openimmodocument } from an { @link inputstream } .
creates a { @link openimmodocument } from a { @link file } .
creates a { @link openimmodocument } from a { @link string } .
creates a { @link openimmodocument } from a { @link document } .
helper method to create a &lt ; user_defined_simplefield&gt ; element with a feldname attribute and a string value .
gets the value of the fehler property .
sets the value of the erbpacht property .
sets the value of the miete property .
read a { @link file } into a { @link filemakerresultdocument } or { @link filemakerlayoutdocument } and print some of their content to console .
read a { @link inputstream } into a { @link filemakerresultdocument } or { @link filemakerlayoutdocument } and print some of their content to console .
print some content of a { @link filemakerlayoutdocument } to console .
print some content of a { @link filemakerresultdocument } to console .
gets the value of the stpsonstige property .
gets the value of the valuelist property .
sets the value of the mindauer property .
sets the value of the zinstyp property .
gets the value of the photo property .
read a { @link inputstream } into a { @link wisitdocument } and print some of its content to console .
print some content of a { @link wisitdocument } to console .
sets the value of the metadata property .
sets the value of the projects property .
sets the value of the properties property .
start the example application .
create an { @link overseasrentaladtype } with some example data .
create an { @link overseasrentaladtype } with some example data .
write a { @link daftiedocument } into a { @link file } .
creates a { @link trovitdocument } from a { @link trovit } object .
downgrade a kyero document from version 3 .
upgrade a kyero document to version 3 .
downgrade &lt ; new_build&gt ; elements to kyero 2 . 1 . <p > the &lt ; new_build&gt ; elements are not available in version 2 . 1 . instead the value new_build is used in the &lt ; price_freq&gt ; element . <p > any &lt ; new_build&gt ; elements are removed . if its value is set to 1 then &lt ; price_freq&gt ; sale&lt ; / price_freq&gt ; is converted to &lt ; price_freq&gt ; new_build&lt ; / price_freq&gt ;
downgrade &lt ; type&gt ; elements to kyero 2 . 1 . <p > the &lt ; type&gt ; elements require a &lt ; en&gt ; child element in version 2 . 1 . <p > an &lt ; en&gt ; child element is created for any &lt ; type&gt ; element .
downgrade &lt ; url&gt ; elements to kyero 2 . 1 . <p > the &lt ; url&gt ; elements only support a simple text value in version 2 . 1 . version 3 allows different url s for different languages . <p > any children of &lt ; url&gt ; elements are removed . the english url or the first found url is copied as simple value into the &lt ; url&gt ; element .
remove elements with translations in unsupported languages . <p > kyero 2 . 1 does only support translation in &lt ; title&gt ; ( for images ) &lt ; desc&gt ; ( for properties ) elements for en es de nl fr .
upgrade &lt ; new_build&gt ; elements for kyero 3 . <p > the &lt ; new_build&gt ; elements are not available in version 2 . 1 . instead the value new_build is used in the &lt ; price_freq&gt ; element . <p > any occurrences of &lt ; price_freq&gt ; new_build&lt ; / price_freq&gt ; is replaced by &lt ; price_freq&gt ; sale&lt ; / price_freq&gt ; and &lt ; new_build&gt ; 1&lt ; / new_build&gt ; is added to the property .
creates a { @link wisitdocument } from a { @link wis } object .
print some content of an { @link is24csvparser } to console .
creates a { @link immobiliareitdocument } from a { @link feed } object .
creates a { @link feed } object from the contained { @link document } .
downgrade an openimmo document from version 1 . 2 . 2 to 1 . 2 . 1 .
downgrade &lt ; objektart&gt ; elements to openimmo 1 . 2 . 1 . <p > the &lt ; objektart&gt ; element does only allow the same type of child element in version 1 . 2 . 1 . <p > any child type that differs from the first child type is removed .
upgrade &lt ; energiepass&gt ; elements to openimmo 1 . 2 . 2 . <p > the &lt ; art&gt ; child element of the &lt ; energiepass&gt ; element is renamed to &lt ; epart&gt ; in version 1 . 2 . 2 .
gets the value of the immobilie property .
creates a { @link immoxmldocument } from a { @link document } .
gets the value of the objekt property .
gets the value of the fehlerliste property .
gets the value of the status property .
sets the value of the sonstigetyp property .
sets the value of the distanzzu property .
gets the value of the distanzen property .
gets the value of the distanzensport property .
------------------------------------------



master / slave
master / slave
ssdbblock <p > < / p > <b >  < / b >
 <p > < / p > <b >  < / b >
 <p > < / p > <b >  < / b >
class
class <br > 
class <br > 2013 - 10 - 21 5 : 19 : 48
class <br > 2013 - 10 - 21 5 : 19 : 48
class <br > 2013 - 10 - 21 5 : 19 : 48
get
class <br > 2013 - 10 - 21 11 : 22 : 55
 <br > 2013 - 10 - 21 11 : 03 : 13
class <br > 2013 - 10 - 21 4 : 49 : 19
classget <br > 2013 - 10 - 21 12 : 05 : 53
classset <br > 2013 - 10 - 21 12 : 05 : 53
classset <br > 2013 - 10 - 21 12 : 05 : 53
 <br > 2013 - 9 - 15 8 : 16 : 21
tostring <br > 2013 - 8 - 14 3 : 42 : 01

 <br > 2014225 3 : 25 : 46
<p > delegates to { @link #detectcodepage ( java . io . inputstream int ) } with a buffered input stream of size 10 ( 8 needed as maximum ) . < / p >

return the { @link javax . xml . stream . xmlstreamreader } for the given stax source .
return the { @link javax . xml . stream . xmleventreader } for the given stax source .
return the { @link javax . xml . stream . xmlstreamwriter } for the given stax result .
return the { @link javax . xml . stream . xmleventwriter } for the given stax result .





check whether the given exception is compatible with the exceptions declared in a throws clause .


/ * ( non - javadoc )
sets the bindings for this namespace context . the supplied map must consist of string key value pairs .
binds the given prefix to the given namespace .
removes the given prefix from this context .



parse the given string into a single { @code mimetype } .
parse the given comma - separated string into a list of { @code mimetype } objects .
sorts the given list of { @code mimetype } objects by specificity . <p > given two mime types : <ol > <li > if either mime type has a { @linkplain mimetype#iswildcardtype () wildcard type } then the mime type without the wildcard is ordered before the other . < / li > <li > if the two mime types have different { @linkplain mimetype#gettype () types } then they are considered equal and remain their current order . < / li > <li > if either mime type has a { @linkplain mimetype#iswildcardsubtype () wildcard subtype } then the mime type without the wildcard is sorted before the other . < / li > <li > if the two mime types have different { @linkplain mimetype#getsubtype () subtypes } then they are considered equal and remain their current order . < / li > <li > if the two mime types have a different amount of { @linkplain mimetype#getparameter ( string ) parameters } then the mime type with the most parameters is ordered before the other . < / li > < / ol > <p > for example : <blockquote > audio / basic &lt ; audio / * &lt ; * &#047 ; * < / blockquote > <blockquote > audio / basic ; level = 1 &lt ; audio / basic< / blockquote > <blockquote > audio / basic == text / html< / blockquote > <blockquote > audio / basic == audio / wave< / blockquote >
/ * ( non - javadoc )
detect the validation mode for the xml document in the supplied { @link java . io . inputstream } . note that the supplied { @link java . io . inputstream } is closed by this method before returning .
does the supplied content contain an xml opening tag . if the parse state is currently in an xml comment then this method always returns false . it is expected that all comment tokens will have consumed for the supplied content before passing the remainder to this method .
consumes all the leading comment data in the given string and returns the remaining content which may be empty since the supplied content might be all comment data . for our purposes it is only important to strip leading comment content on a line since the first piece of non comment content will be either the doctype declaration or the root element of the document .
consume the next comment token update the incomment flag and return the remaining content .
try to consume the supplied token against the supplied content and update the in comment parse state to the supplied value . returns the index into the content which is after the token or - 1 if the token is not found .





  :  ;  hh : mm : ss
 yyyy - mm - dd hh : mm : ss


 yyyy - mm - dd hh : mm : ss
 yyyy - mm - dd
 yyyy - mm - dd




 yyyymmddy
  hh : mm 

 jj .
 nowdate delay
 nowdate delay

 26 apr 2006


 
200223


           

0
initialize log4j from the given file location with no config file refreshing . assumes an xml file in case of a . xml file extension and a properties file otherwise .
initialize log4j from the given location with the given refresh interval for the config file . assumes an xml file in case of a . xml file extension and a properties file otherwise . <p > log4j s watchdog thread will asynchronously check whether the timestamp of the config file has changed using the given interval between checks . a refresh interval of 1000 milliseconds ( one second ) which allows to do on - demand log level changes with immediate effect is not unfeasible . <p > <b > warning : < / b > log4j s watchdog thread does not terminate until vm shutdown ; in particular it does not terminate on logmanager shutdown . therefore it is recommended to <i > not< / i > use config file refreshing in a production j2ee environment ; the watchdog thread would not stop on application shutdown there .
binds the given prefix to the given namespaces .
convert a namespace uri and dom or sax qualified name to a { @code qname } . the qualified name can have the form { @code prefix : localname } or { @code localname } .
add given iterator to this composite .








<code > orannotationclass< / code > andannotation
<code > andannotationclass< / code > 


0 <br > 2013 - 10 - 31 2 : 46 : 15
function to return a string from the set : a - za - z0 - 9 . /
linux / bsd md5crypt function
linux / bsd md5crypt function
 classpath  class
 baseclassloader  urlclassloader (  )
 package  class
 package  class
 class
 jar  class
returns an input stream that contains what will written in this application to { @link system#err } . <p > <b > caution< / b > if you do not consume the bytes to read from the result you may block the whole application . do only use this for debugging purposes or end to end test code! <p > attempting to read from the result in the same thread that called here is not recommended as it may deadlock the thread . also the thread reading from the stream result should not write anything to { @link system#err } . <p > prefer using { @link #findmatchinsystemerr ( string ) } to avoid deadlocks . <p >
returns an input stream that contains what will written in this application to { @link system#out } . <p > <b > caution< / b > if you do not consume the bytes to read from the result you may block the whole application . do only use this for debugging purposes or end to end test code! <p > attempting to read from the result in the same thread that called here is not recommended as it may deadlock the thread . also the thread reading from the stream result should not write anything to { @link system#out } . <p > prefer using { @link #findmatchinsystemout ( string ) } to avoid deadlocks . <p >
returns an instance to a runnable running in a separate thread that tries to match the expected output in { @link system#out } . <p > ensure that you found the expected string in the input stream given by calling { @link info . monitorenter . util . exceptionutil . inputstreamtracer#ismatched () } . but take into account that it is time - critical ( concurrency ) if your result was found . <p > prefer this instead of { @link #capturesystemoutfordebuggingpurposesonly ( boolean ) } as this will avoid blocking your application . <p >
returns an instance to a runnable running in a separate thread that tries to match the expected output in { @link system#err } . <p > ensure that you found the expected string in the input stream given by calling { @link info . monitorenter . util . exceptionutil . inputstreamtracer#ismatched () } . but take into account that it is time - critical ( concurrency ) if your result was found . <p > prefer this instead of { @link #capturesystemerrfordebuggingpurposesonly ( boolean ) } as this will avoid blocking your application . <p >
prints out the current thread stack to the given stream . <p >
returns the singleton instance of this class . <p > this method is useless for now as all methods are static . it may be used in future if vm - global configuration will be put to the state of the instance . <p >
add the specified option to the list of accepted options
convenience method for adding a string option .
convenience method for adding an integer option .
convenience method for adding a long integer option .
convenience method for adding a double option .
convenience method for adding a boolean option .
extract the options and non - option arguments from the given list of command - line arguments . the specified locale is used for parsing options whose values might be locale - specific .
a default delegation to { @link #detectcodepage ( java . net . url ) } that opens the document specified by the given url with the detected codepage . <p >
 <br > 2013 - 8 - 28 3 : 52 : 17
 <br > 2013 - 8 - 28 3 : 50 : 50
 <br > 2013 - 7 - 26 6 : 09 : 09
<p > < / p > abbwhoinvoke () ba
---------------------------- debug ----------------------------
fieldgetset
annotationclass
annotationclassgetset
ascii abc  aac  1234  2234  1234  123  223  1234
hashcode <br > 2013 - 10 - 25 11 : 06 : 57
 <br > 2013 - 8 - 14 1 : 20 : 06
<br > 2013 - 8 - 28 5 : 26 : 24
stringreader <br > 2013 - 9 - 2 9 : 03 : 29
high - level method for instantiation of a new instance of the class specified by the given fully qualified class name with singleton retrieval support . delegates to { @link #newinstance ( class ) } .
dynamic instantiation of the given type with singleton retrieval support as described in this class description .
singleton retrieval method . <p > be sure to configure the instance returned at a single location in your code to avoid unpredictable application - wide side effects . <p >
<p > detects the codepage by iteratively delegating the call to all internal { @link info . monitorenter . cpdetector . io . icodepagedetector } instances added by { @link #add ( info . monitorenter . cpdetector . io . icodepagedetector ) } . < / p > <p > the given inputstream has to support mark such that the call { @link java . io . inputstream#mark ( int ) } with argument length does not throw an exception . this is needed as the stream has to be resetted to the beginning for each internal delegate that tries to detect . < / p > <p > if this is impossible ( large documents ) prefer using { @link #detectcodepage ( java . net . url ) } . < / p >
 


sets a new value instance overwriting the old value which is returned . <p >



/ * ( non - javadoc )
qrcode


to be invoked before the main execution logic of concrete subclasses . <p > this implementation applies the concurrency throttle .
to be invoked after the main execution logic of concrete subclasses .
---------------------------------------------------------------------
<br > <b > <br > <br > <br > < / b > <br > <br > <br > <br > <pre > class . getdeclaredmethod ( &quot ; callback&quot ; object . class throwable . class object [] . class ) ; < / pre > 2013 - 9 - 16 9 : 30 : 29
 <br > 2013 - 9 - 16 9 : 38 : 12
json
json

delete the supplied { @link java . io . file } - for directories recursively delete any nested directories or files as well .
recursively copy the contents of the { @code src } file / directory to the { @code dest } file / directory .
actually copy the contents of the { @code src } file / directory to the { @code dest } file / directory .
<br > 2013 - 10 - 28 11 : 11 : 24
ignoreproperties <br > 2013 - 10 - 30 6 : 15 : 41
ignoreproperty <br > 2013 - 10 - 30 6 : 16 : 08
allowproperty <br > 2013 - 10 - 30 6 : 16 : 08
 <br > 2013 - 10 - 25 2 : 47 : 34
jackson <br > 2013 - 10 - 25 11 : 59 : 50
<br > 2013 - 10 - 25 12 : 29 : 58
determine whether the given method is originally declared by {
set the target object on which to call the target method . only necessary when the target method is not static ; else a target class is sufficient .
prepare the specified method . the method can be invoked any number of times afterwards .
resolve the given class name into a class . <p > the default implementations uses { @code classutils . forname } using the thread context class loader .
find a matching method with the specified name for the specified arguments .
invoke the specified method . <p > the invoker needs to have been prepared before .
algorithm that judges the match between the declared parameter types of a candidate method and a specific list of arguments that this method is supposed to be invoked with . <p > determines a weight that represents the class hierarchy difference between types and arguments . a direct match i . e . type integer - arg of class integer does not increase the result - all direct matches means weight 0 . a match between type object and arg of class integer would increase the weight by 2 due to the superclass 2 steps up in the hierarchy ( i . e . object ) being the last one that still matches the required type object . type number and class integer would increase the weight by 1 accordingly due to the superclass 1 step up the hierarchy ( i . e . number ) still matching the required type number . therefore with an arg of type integer a constructor ( integer ) would be preferred to a constructor ( number ) which would in turn be preferred to a constructor ( object ) . all argument weights get accumulated . <p > note : this is the algorithm used by methodinvoker itself and also the algorithm used for constructor and factory method selection in spring s bean container ( in case of lenient constructor resolution which is the default for regular bean definitions ) .
convert the integer to an unsigned number .


serialize the given object to a byte array .
deserialize the byte array into an object .

tostring <br > 2013 - 8 - 28 3 : 16 : 40
/ * ( non - javadoc ) it is assumed that the inputstream is at the start of the file or string ( in order to read the bom ) .
stringfalse
sn = md5 ( urlencode ( basicstring + sk )) <p >  basicstring  <p > ( 1 ) get  <p > url  http : //  { uri } <p > basicstring = uri <p > ( 2 ) post  <p > url  http : //  { uri } post key <p > k1 = v1&amp ; k2 = v2&amp ; k3 = v3&amp ; ... &amp ; kn = vn = &gt ; { params } <p > basicstring = uri + ? + params
retrieves all child elements of the given dom element that match any of the given element names . only looks at the direct child level of the given element ; do not go into further depth ( in contrast to the dom api s { @code getelementsbytagname } method ) .
retrieves all child elements of the given dom element that match the given element name . only look at the direct child level of the given element ; do not go into further depth ( in contrast to the dom api s { @code getelementsbytagname } method ) .
utility method that returns the first child element identified by its name .
utility method that returns the first child element value identified by its name .
retrieves all child elements of the given dom element
extracts the text value from the given dom element ignoring xml comments . <p > appends all characterdata nodes and entityreference nodes into a single string value excluding comment nodes . only exposes actual user - specified text no default values of any kind .
namespace - aware equals comparison . returns {
matches the given node s name and local name against the given desired name .
matches the given node s name and local name against the given desired names .
@throws java . io . ioexception
/ * ( non - javadoc )
admin@xiongyingqi . com@admin
appends the given amount of spaces to the string . <p >
if the given object is no array it s tostring - method is invoked . primitive type - arrays and object - arrays are introspected using java . lang . reflect . array . convention for creation fo string - representation : <p >
if the given object is no array it s tostring - method is invoked . primitive type - arrays and object - arrays are introspected using java . lang . reflect . array . convention for creation for string - representation : <br >
returns the singleton instance of this class . <p >
returns true if the argument is null or consists of whitespaces only . <p >
little string output - helper that modifies the given linkedlist by getting it s objects and replace them by their tostring () - representation . <p >
returns the maximum length of a { @link object#tostring () } result in characters within the given list . <p >
appends the necessary amount of spaces to the string until it has the givn length . no exception is thrown if the length of the string is shorter than the given length but nothing will happen and a message will be printed to the system . out .
modifies the given linkedlist by getting it s objects and replace them by their tostring () - representation concatenated with the necessary amount of white spaces that every string in the list will have the same amount of characters . <p >
urlencoding

unicodegb2312ascii
controller <br > 2013 - 10 - 17 1 : 02 : 45
start to monitor given handle object for becoming weakly reachable . when the handle isn t used anymore the given listener will be called .
add entry to internal map of tracked entries . internal monitoring thread is started if not already running .
check whether to keep the monitoring thread alive i . e . whether there are still entries being tracked .
public static final long db = 1024 * nb ;
 <br > 2013 - 9 - 2 9 : 08 : 51
 <br > 2013 - 9 - 6 3 : 15 : 56
url <br > 2013 - 9 - 2 2 : 57 : 15
 <br > 2013 - 9 - 2 2 : 52 : 39
url <br > 2013 - 9 - 2 10 : 07 : 14
 <br > 2013 - 9 - 2 10 : 04 : 17
string <br > 2013 - 8 - 30 5 : 26 : 55

inputstream <br > 2013 - 9 - 3 12 : 10 : 06
 <br > 2013 - 9 - 3 12 : 10 : 06
 <br > 2013 - 9 - 3 2 : 39 : 21
 <br > 2013 - 9 - 6 12 : 09 : 45
 <br > 2013 - 9 - 6 1 : 08 : 58
resolve $ { ... } placeholders in the given text replacing them with corresponding system property values . unresolvable placeholders with no default value are ignored and passed through unchanged if the flag is set to true .
----------------------------------------  ----------------------------------------

class

implements
extends
----------------------------------------  ----------------------------------------
--------------------------  --------------------------
returns the path to the my documents folder or <code > null< / code >
test the phone number from which the city is using taobao api
}
 <br > 2013 - 6 - 25 9 : 46 : 45
enable indenting for the supplied { @link javax . xml . transform . transformer } . <p > if the underlying xslt engine is xalan then the special output key { @code indent - amount } will be also be set to a value of { @link #default_indent_amount } characters .
disable indenting for the supplied { @link javax . xml . transform . transformer } .
 0<br > 0<br > 2013 - 7 - 26 6 : 21 : 40
convert a { @code qname } to a qualified name as used by dom and sax . the returned string has a format of { @code prefix : localname } if the prefix is set or just { @code localname } if not .
starts the prefix mapping for the given prefix .
ends the prefix mapping for the given prefix .
adds the given callback to this registry .
triggers a { @link listenablefuturecallback#onsuccess ( object ) } call on all added callbacks with the given result
triggers a { @link listenablefuturecallback#onfailure ( throwable ) } call on all added callbacks with the given { @code throwable } .
md5   <br > 2013 - 11 - 4 6 : 33 : 06
md5  <br > 2013 - 11 - 4 6 : 33 : 06
cuts all path information of the string representation of the given url . <p >
cuts the path information of the string that is interpreted as a filename into the directory part and the file part . the current operating system s path separator is used to cut all path information from the string . <p >
cuts a string into the part before the last dot and after the last dot . if only one dot is contained on the first position it will completely be used as prefix part . <p >
finds a filename based on the given name . if a file with the given name does not exist <tt > name< / tt > will be returned . <p >
returns the singleton instance of this class . <p >
tests wether the given input stream only contains ascii characters if interpreted by reading bytes ( 16 bit ) . <p > this does not mean that the underlying content is really an ascii text file . it just might be viewed with an editor showing only valid ascii characters . <p >
tests wether the content of the given file is identical at character level when it is opened with both different charsets . <p > this is most often the case if the given file only contains ascii codes but may also occur when both codepages cover common ranges and the document only contains values m_out of those ranges ( like the euc - cn charset contains all mappings from big5 ) . <p >
reads the content of the given file into an array . <p > this method currently does not check for maximum length and might cause a java . lang . outofmemoryerror . it is only intended for performance - measurements of data - based algorithms that want to exclude i / o - usage . <p >
removes the duplicate line breaks in the given file . <p >
returns the formatted file size to bytes kb mb or gb depending on the given value . <p >
end encode3to4
 <br > 2014 - 2 - 11 9 : 10 : 17
 <br > 2014 - 2 - 11 9 : 13 : 21
 <br > 2014 - 2 - 11 9 : 14 : 18
digitdigit digit69999991048576 ( 220 ) 20 <br > 2014 - 1 - 21 5 : 27 : 53
build a tree from the entries .
little helper that transforms ( back ) the nodes of the tree that was parsed from the entries during initialization to canonical strings for entries .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
mixinobjectmapper<p > <p > <b > mapperclearbuildermapper () < / b >
mixinobjectmapper
mixin
setmixinsaddmixinsmixin <br > 201444 12 : 08 : 15
mixin<p > < / p > <b > clear () < / b >
mixin
create and return a list of {
jackson <br > 2013 - 10 - 25 2 : 46 : 43

 <pre > // 1 . 1  // des securerandom sr = new securerandom () ; // deskeygenerator keygenerator kg = keygenerator . getinstance ( des ) ; kg . init ( sr ) ; //  secretkey key = kg . generatekey () ; //  byte rawkeydata [] = key . getencoded () ; // byte rawkeydata [] = sucretsa . getbytes () ; system . out . println (  === + rawkeydata . length ) ; system . out . println ( base64 === + base64 . encodebytes ( rawkeydata )) ;

<p > adds the given argument to the acceptance filter . the filter will only return true for a class a in the following condition :
tries to detect ( from the file path and the classloaders urls ) and load the corresponding class and delegates to { @link #accept ( class ) } .
factory method for creating a { @link gelftransport } provider within the plugin manager .
todo cache values
calculates text color for specified item based on its position and state .
sets values to choose from
calculates color for specific position on time picker
sets text size for items
calculates x scroll position that is still in range of view scroller
cleans up the path of an incoming request . repeating / s are reduced to one / . trailing / s are removed . a <code > null< / code > or empty path is converted to / .
/ * starts jrobotremoteserver with an example library and returns . the application will shutdown when all of the web server s threads exit .
the introduction is stored in a text file resource because it is easier to edit than string constants .
get an array containing the names of the keywords that the library implements .
run the given keyword and return the results .
run the given keyword and return the results .
get an array of argument specifications for the given keyword .
get documentation for given keyword .
main method for command line usage .
map the given test library to the specified path . paths must : <ul > <li > start with a / < / li > <li > contain only alphanumeric characters or any of these : / - . _ ~< / li > <li > not end in a / < / li > <li > not contain a repeating sequence of / s< / li > < / ul >
this has been deprecated . please use { @link #putlibrary } and { @link #setport } instead .
this has been deprecated . please use { @link #putlibrary } and { @link #setport } instead .
a non - blocking method for stopping the remote server that allows requests to complete within the given timeout before shutting down the server . new connections will not be accepted after calling this .
starts the remote server . add test libraries first before calling this .
configures logging systems used by <tt > remoteserver< / tt > and its dependencies . specifically <ul > <li > configure log4j to log to the console< / li > <li > set log4j s log level to info< / li > <li > redirect the jetty s logging to log4j< / li > <li > set jakarta commons logging to log to log4j< / li > < / ul > this is convenient if you do not want to configure the logging yourself . this will only affect future instances of {
removes the prefixes from all keys in this handler mapping assuming a string was used as the key and period was used as a separator . example : accountsreceivable . billing . getinvoice - > getinvoice
generate json by given path to file with properties with only included domain keys .
generate json by given file with properties with only included domain keys .
generate json by given inputstream and given filter .
generate json by given java properties
generate json by given map&lt ; string string&gt ;
generate json by given map&lt ; string object&gt ;
generate json by given map&lt ; string string&gt ; and given filter
generate json by given java properties and given filter
sets background color for this button . <p / > xml attribute : { @code app : floatingactionbuttoncolor } <p / > note : this method sets the <code > mcolorstatelist< / code > field to <code > null< / code >
sets color state list as background for this button . <p / > xml attribute : { @code app : floatingactionbuttoncolor }
inflate and initialize background drawable for this view with arguments inflated from xml or specified using {
calculates required radius of shadow .
builder to create an instance of the client .
builder to create an instance of ocspfetcher using apache httpclient for connectivity .
method for finding issuer by provided issuers in properties given an issued certificate .
builder to create an instance of the client .
execute the maven plugin .
parse attributes of the form nodename : attributename = attribute value : attributename = attribute value ...
read markdown files from directory .
replace variables with given pattern .
going through list of dtos and parsing the markdown into html . add header and footer to the big string .
get the first h1 for the title .
adds the title to the html file .
replace variables in the html file .
update relative include paths corresponding to the markdown file s location in the folder structure .
copy files from one dir to another based on file extensions .
this solves https : // issues . apache . org / jira / browse / mresources - 99 . <br / > but : <br / > this should be done different than defining those properties a second time cause they have already being defined in maven model builder ( package org . apache . maven . model . interpolation ) via buildtimestampvaluesource . but those can t be found in the context which can be got from the maven core . <br / > a solution could be to put those values into the context by maven core so they are accessible everywhere . ( i m not sure if this is a good idea ) . better ideas are always welcome . <p > the problem at the moment is that maven core handles usage of properties and replacements in the model but does not the resource filtering which needed some of the properties .
when retrieving more statements lrs will return full path .. the client will have part in the uri already so cut that off
this will wrap the view which is added to the slider into another layout so we can then overlap the small and large view
animate to the large view
animate to the small view
calculate the percentage to how many percent the slide is already visible
overlap the views and provide the crossfade effect
the intent to launch the activity .
launch the activity if needed .
gettodos retrieves all todos a user can read .
getfactsheets retrieves all fact sheets
set the connect timeout ( in milliseconds ) . a value of 0 means no timeout otherwise values must be between 1 and {
set the date format used to parse / format date parameters .
serialize the given java object into string entity according the given content - type ( only json is supported for now ) .
deserialize response body to java object according to the content - type .
download file from the given response .
invoke api by sending http request with the given options .
build the client used to make http requests .
createaccesscontrolentity creates an access control entity
updatedatamodel updates the data model for a workspace
createfullexport creates a full export of the workspace data or an export of the changelog depending on given type
getexports lists all exports of the given type in the workspace of the authorized user
get state
specifies all urls needed to get an access token based on given host name and common url naming convention .
sets your client id and client secret .
processgraphqlmultipart processes graphql requests supporting multipart documents
get params
getbookmarks retrieves all stored bookmarks a user can read .
maps jena bindings defined by a variable name and a { @link org . apache . jena . graph . node } to marklogic { @link com . marklogic . client . semantics . sparqlquerydefinition } bindings .
/ *
merges triples into a graph on the marklogic server . mergegraph () is not part of jena s datasetgraph interface .
adds permissions to a graph .
sets the permissions on a graph .
fluent setter for rulesets .
close the connection and free resources
synchronization needed because of setting of page length
if timer is turned on ( periodicflush = true in constructor ) this method puts a quad into the cache which is periodically sent to marklogic otherwise it sends the quad directly
creates a marklogicdatasetgraph from an existing { @link com . marklogic . client . databaseclient } .
creates marklogicdatasetgraph from access parameters to a rest marklogic server .
{
{
{ @inheritdoc } <p > this implementation delegates to super class but ensures that there is no other checked exception except { @link gmserviceexception } will be thrown .
{ @inheritdoc }
sets the path to graphicsmagick executable .
{
{
{ @inheritdoc }
limits the number of threads used by the graphicsmagick process during execution . note that no validation is made so ensure that the value is a non - positive integer presumably less than the maximum cpu cores on the host .
resize source to desired target dimensions using default resizing filter algorithm .
rotates the image with empty triangles back - filled using default background color .
defines the gravity for geometry - based operations . see documentation for more details as this option works in conjunction with various options in different ways .
strips out icc profiles .
defines font for text overlay .
draws text overlay on image with the upper - right corner defined by the { @code offsetx } and { @code offsety } parameters . note that { @link#gravity ( gravity ) } will affect how the offset values are interpreted .
specifies the source image to convert .
add image to operation .
add option - quality to the graphicsmagick commandline ( see the documentation of graphicsmagick for details ) .
time histogram .
http requests gauge .
bytes counter .
parse a set of arguments and populate the target with the appropriate values .
generate usage information based on the target annotations .
extracts and returns the time unit from a string . if the string doesn t include a unit it returns null .
parse properties instead of string arguments . any additional arguments need to be passed some other way . this is often used in a second pass when the property filename is passed on the command line . because of required properties you must be careful to set them all in the property file .
src : http : // stackoverflow . com / questions / 1399126 / java - util - zip - recreating - directory - structure
execute a presentation file at a given url
execute a presentation file at an url using a specific {
execute a presentation file
interpret a presentation file as a list of executable actions
detector . stop () ;
execute and wait for execution to finish
argument :
argument :
argument : something to type
end constructor
end 2007 - 09 - 12 nathan blomquist -- linux ( kde / gnome ) support added .
determine if the dragged data is a file list .
execute and wait for execution to finish
sort a list of rectangles by their sizes in ascending order
}
create an object where each field represents an { @link widget } that can be found and interacted with automatically
render the given template string as a string based on the parameter values associated with this context
get the file of the slide rel for a slide number
check the mouse action is within the screen region range .
namely if they have the same x range they would intersect
/ * ( non - javadoc )
/ * ( non - javadoc )
create a new { @link beandefinitionbuilder } for the class { @link sqsexecutor } . initialize the wrapped { @link sqsexecutor } with common properties .
create a new { @link beandefinitionbuilder } for the class { @link snsexecutor } . initialize the wrapped { @link snsexecutor } with common properties .
verifies and sets the parameters . e . g . initializes the to be used
executes the outbound sqs operation .
execute a retrieving ( polling ) sqs operation .
verifies and sets the parameters . e . g . initializes the to be used
executes the outbound sns operation .
e . g . / drivers / h2 / h2 - 1 . 3 . 162 . jar
finds ( extracts if necessary ) a named executable for the runtime operating system and architecture . the executable should be a regular java resource at the path / jne / [ os ] / [ arch ] / [ exe ] . the name of the file will be automatically adjusted for the target platform . for example on windows to find the cat application this method will actually search for cat . exe .
finds ( or extracts ) a named executable for the runtime operating system and architecture . the executable should be a regular java resource at the path / jne / [ os ] / [ arch ] / [ exe ] .
finds ( or extracts ) a named executable for the runtime operating system and architecture . the executable should be a regular java resource at the path / jne / [ os ] / [ arch ] / [ exe ] .
same as findexecutable but throws an exception if the executable was not found .
same as findexecutable but throws an exception if the executable was not found .
<p > loads a dynamic library . attempts to find ( extracts if necessary ) a named library for the runtime operating system and architecture . if the library was found as a resource and / or extracted it will then be loaded via system . load () . if the library was not found as a resource this method will simply fallback to system . loadlibrary () . thus this method should be safe as a drop - in replacement for calls to system . loadlibrary () . < / p > <p > if including the library as a java resource the resource path will be / jne / [ os ] / [ arch ] / [ lib ] . the name of the file will be automatically adjusted for the target platform . for example on windows to find the cat library this method will search for cat . dll . on linux to find the cat library this method will search for libcat . so . on mac to find the cat library this method will search for libcat . dylib . < / p >
finds ( or extracts ) a named file . will first attempt to locate the file for the runtime operating system and architecture then fallback to just the runtime operating system and finally fallback to the resource prefix . for example a file named resource . txt running on a jvm on x64 linux would search the following 3 resource paths :
same as findfile but throws an exception if the file was not found .
underlying method used by findexecutable and loadlibrary to find and extract executables as needed . although public it s not recommended to use this method unless you know what you re doing .
attempts to create a temporary directory that did not exist previously .
log for a particular level using the <code > array_marker< / code > .
log for a particular level using the <code > lists_marker< / code > .
construct an immutable map from one key - value pair . although this is more convenient than the static factory methods this method does not capture the instance being logged .
checkstyle . off : parameternumber - provided for compatibility wth immutablemap . of
create a new log event at the trace level . the provided <code > consumer< / code > populates a <code > deferredlogbuilder< / code > to define the log event . the consumer may not be invoked if it is not necessary . therefore it is important not to include side - effects in the provided <code > consumer< / code > .
log a message at the trace level . default values are used for all other parameters .
log a message with a <code > throwable< / code > at the trace level . default values are used for all other parameters .
log a message for a canonical event at the trace level . default values are used for all other parameters .
log a message for a canonical event with supporting key - value pairs at the trace level .
log a message for a canonical event with supporting key - value pairs at the trace level .
log a message for a canonical event with supporting key - value pairs and a <code > throwable< / code > at the trace level . this method is provided only for efficiency over the var - args method above as it avoids an array creation during invocation .
create a new log event at the debug level . the provided <code > consumer< / code > populates a <code > deferredlogbuilder< / code > to define the log event . the consumer may not be invoked if it is not necessary . therefore it is important not to include side - effects in the provided <code > consumer< / code > .
log a message at the debug level . default values are used for all other parameters .
log a message with a <code > throwable< / code > at the debug level . default values are used for all other parameters .
log a message for a canonical event at the debug level . default values are used for all other parameters .
log a message for a canonical event with supporting key - value pairs at the debug level .
log a message for a canonical event with supporting key - value pairs at the debug level .
log a message for a canonical event with supporting key - value pairs and a <code > throwable< / code > at the debug level . this method is provided only for efficiency over the var - args method above as it avoids an array creation during invocation .
create a new log event at the info level . the provided <code > consumer< / code > populates a <code > deferredlogbuilder< / code > to define the log event . the consumer may not be invoked if it is not necessary . therefore it is important not to include side - effects in the provided <code > consumer< / code > .
log a message at the info level . default values are used for all other parameters .
log a message for a canonical event at the info level . default values are used for all other parameters .
log a message for a canonical event with a <code > throwable< / code > at the info level . default values are used for all other parameters .
log a message for a canonical event with supporting key - value pairs at the info level .
log a message for a canonical event with supporting key - value pairs at the info level .
log a message for a canonical event with supporting key - value pairs at the info level . this method is provided only for efficiency over the var - args method above as it avoids an array creation during invocation .
log a message for a canonical event with supporting key - value pairs and a <code > throwable< / code > at the info level . this method is provided only for efficiency over the var - args method above as it avoids an array creation during invocation .
create a new log event at the warn level . the provided <code > consumer< / code > populates a <code > deferredlogbuilder< / code > to define the log event . the consumer may not be invoked if it is not necessary . therefore it is important not to include side - effects in the provided <code > consumer< / code > .
log a message at the warn level . default values are used for all other parameters .
log a message for a canonical event at the warn level . default values are used for all other parameters .
log a message for a canonical event with a <code > throwable< / code > at the warn level . default values are used for all other parameters .
log a message for a canonical event with supporting key - value pairs at the warn level .
log a message for a canonical event with supporting key - value pairs at the warn level .
log a message for a canonical event with supporting key - value pairs at the warn level .
log a message for a canonical event with supporting key - value pairs and a <code > throwable< / code > at the warn level . this method is provided only for efficiency over the var - args method above as it avoids an array creation during invocation .
create a new log event at the error level . the provided <code > consumer< / code > populates a <code > deferredlogbuilder< / code > to define the log event . the consumer may not be invoked if it is not necessary . therefore it is important not to include side - effects in the provided <code > consumer< / code > .
log a message at the error level . default values are used for all other parameters .
log a message with a <code > throwable< / code > at the error level . default values are used for all other parameters .
log a message for a canonical event at the error level . default values are used for all other parameters .
log a message for a canonical event with supporting key - value pairs at the error level .
log a message for a canonical event with supporting key - value pairs at the error level .
log a message for a canonical event with supporting key - value pairs and a <code > throwable< / code > at the error level . this method is provided only for efficiency over the var - args method above as it avoids an array creation during invocation .
/ * package private
/ * package private
/ * package private
/ * package private
/ * package private
/ * package private
/ * package private
/ * package private
serialize an event .
serialize an event .
before outputting the message inject additional context .
start writing the steno json wrapper .
complete writing the steno json wrapper .
complete writing the steno json wrapper .
write specified key - value pairs into the current block .
write a <code > throwable< / code > via <code > ithrowableproxy< / code > as json .
this function assumes the field object has already been started for this throwable this only fills in the fields in the exception or equivalent object and does not create the field in the containing object .
create a context based on the <code > stenoencoder< / code > configuration .
determine if an object represents a primitive json type . these include instances of <code > number< / code > <code > string< / code > and <code > boolean< / code > .
return a steno <code > logger< / code > for a context class .
return a rate limited steno <code > logger< / code > for a context class .
return a steno <code > logger< / code > for a context name .
return a rate limited steno <code > logger< / code > for a context name .
return a rate limited steno <code > logger< / code > for an already instantiated <code > org . slf4j . logger< / code > instance .
enables / disables redaction support when serializing complex objects . redacted fields / properties marked with the @logredact annotation will be output as a string with the value { @code <redacted > } .
enables / disables output of null for redacted fields when serializing complex objects .
create a context based on the <code > keyvalueencoder< / code > configuration .
{
determine whether the <code > marker< / code > represents an array event .
determine whether the <code > marker< / code > represents a json array event .
determine whether the <code > marker< / code > represents a map event .
determine whether the <code > marker< / code > represents a json map event .
determine whether the <code > marker< / code > represents an object event .
determine whether the <code > marker< / code > represents a json object event .
determine whether the <code > marker< / code > represents a lists event .
generate a steno log compatible representation .
serialize an event .
create a format <code > string< / code > compatible with <code > messageformatter< / code > .
escape all <code > string< / code > instances .
/ * package private
/ * package private
/ * package private
return the the message formatted with arguments . implemented as suggested in :
{ @inheritdoc }
serialize an event .
retrieve the relevant caller data adjusted for steno logger wrapping .
serialize an event .
serialize an event .
create a serialization safe context based on the <code > stenoencoder< / code > configuration .
create a serialization safe context based on the <code > stenoencoder< / code > configuration .
safely serialize a value .
/ * package private
/ * package private
/ * package private
/ * package private
/ * package private
if values size hit { @link #max } then query will be split ( size % max + [ 1 ] )
initialise the warehouse path . <p > this method can be overridden to provide additional initialisations . < / p >
create a new database with the specified name .
we should clear it
opens new sqlite connection and closes previous if it was not closed
counts number of rows in specified query . if { @link ru . noties . storm . query . selection } is null then counts all rows in class table .
the main entry point for the storm library . should be called only once - application s oncreate () is a good start this method won t open any sqlite database connections . see { @link databasemanager#open () }
registers {
registers type serializer ( aka not supported sqlite types ) { @link ru . noties . storm . sd . absserializer } as a matter of fact { @link ru . noties . storm . sd . absserializer } has only one method that indicates what sqlite type ( { @link ru . noties . storm . fieldtype } ) this type will represent . methods <code > serialize< / code > and <code > deserialize< / code > are not in the inheritance tree . this is done due to the autoboxing issue .
parses the save attr .
save data to object in context .
reload the data from context to websheet row .
parses the save attr string .
gets the save attr list from row .
gets the save attr from list .
get the columnindex from saveattr . saveattr format as : $columnindex = xxxxxxx
checks if is checks for save attr .
checks if is checks for save attr .
sets the save objects in hidden column .
sets the save attrs for sheet .
sets the save attrs for row .
prepare context and attrs for cell .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
convert string to int ( length ) .
/ * ( non - javadoc )
fmt number .
/ * ( non - javadoc )
save the cell before serialize .
recover the cell reference to the sheet .
put shift attrs .
set up workbook . also create evaluation wrapper .
return evaluation wrapper if needed .
get formulaevaluator .
recalculate max coulumn count across sheets in the workbook .
load web sheet from inputstream file with data object .
load web sheet from giving workbook with data object .
triggered when user switch the tab . this will load different tab ( sheet ) as the current sheet .
load worksheet by tab name .
download current workbook .
save the current workbooks .
submit the current workbooks .
populate component .
gets the current sheet config .
load the bean from saving .
/ * ( non - javadoc )
/ * ( non - javadoc )
gets the locale .
return picture to web front end .
gets the cell helper .
gets the pic helper .
gets the validation handler .
gets the chart helper .
convert shared formulas .
3d ( reference to other sheet ) is not supported . only 2d ( within the sheet ) is supported .
convert ptg .
convert ptg for watch list .
single ptg .
gets the rows list .
assemble rowslist from rowsmapping .
fixup ref relative row one to one .
change formula ptg by replace one ref with multiple ref . we require user follow the rule to define dynamic formula . e . g . if cell reference in formula maybe become multiple cells then should use round brackets around it .
builds the dynamic row for ref ptg base .
builds the dynamic row for area ptg base .
check is current ptg followed by valueoperationptg . valueoperationptg include : add substract multiply divide etc .
retrieve background color for plot area .
get line color of line chart from ctlineser .
find automatic fill color .
assemble xssfcolor with tint / lumoff / lummod / alpha to xcolor .
retrieve xcolor from scheme color .
get xcolor with color schema name . normally the names are accent1 to 7 . sometimes also have lumoff / lummod / alphaint setting .
get xcolor from ctsrgbcolor .
get xcolor for automatic fill setting . this is the default setting in excel for chart colors . normally the colors will be accent1 to 7 .
get automatic tint number for specified index line . the default automatic color only have 6 colors . if there are more than 6 lines then use tint for next round e . g . color7 = color1 + tint ( 0 . 25 )
convert xssf color to color .
return index number for giving index name . e . g . tx1 return 1 .
convert xssfcolor to triple let numbers .
gets the bg color from cell .
find component according it s class .
populate attributes .
match parameter of method .
set object property .
get object property value .
setup control attributes .
find cell validate attributes .
setup faces cell picture charts .
setup faces cell charts .
setup faces cell picture .
initial chart map for specified workbook .
return cell value for paredcell . parsedcell contain sheetname / row / col which normally is parsed from string like : sheet1!b2 .
create default category dataset for jfreechart with giving chartdata .
return pie chart title from chartdata .
set color of series .
create jfree bar chart .
create jfree bar chart .
create jfree bar chart .
create pie 3d chart .
finalize the style for jfreechart . the default setting is different from jfreechart and excel . we try to minimize the difference .
finalize the style for jfreechart . the default setting is different from jfreechart and excel . we try to minimize the difference .
finalize the style for barchart . this will call setupstyle common first .
create default category dataset for jfreechart with giving chartdata .
initial chart map for xssf format file . xssf file is actually the only format in poi support chart object .
gets the chart id from parent .
initial anchors map for specified workbook . excel put the chart position information in draw . xml instead of chart . xml . anchors map contains the information getting from draw . xml .
generate single xssf chart .
transform to collection object .
gets the full name from row .
re build upper level formula .
setup upper level formula .
builds the cell formula for shifted rows .
gather rows mapping by full name .
increase index number in shift map .
increase upper level final length .
change index number in hidden column .
sets the full name in hidden column .
gets the original row num in hidden column .
sets the original row num in hidden column .
find parent rows mapping from shift map .
find child rows mapping from shift map .
find item in collection .
builds the current range .
whether the row is static . this only check rowindex against original template .
whether the row is static . this check row after shifted .
remove last each command index from full name . e . g . for f . departments : e . department . 1 : e . employee . 2 will return f . departments : e . department . 1 : e . employee
100 > = 80
index merged region .
skipped region cells .
add skipped cell into the list of a region .
build sheet comment from command alias .
builds the cell comment fromalias .
builds the configuration .
gets the sheet configuration .
builds the form command from sheet config .
check last column . if it s blank then treat it as null cell .
build a sheet for configuration map .
check and repair the sheet s lastrow . if the row is blank then remove it .
initialize template for command to use . e . g . set origin row number and copy template if there s each command . create missing row as row require sequenced .
build command list from comments . after transfer the comment to command remove it from comments .
build top level configuration map from command list . user can either put tie : form command in the comments ( which will transfer to sheetconfig ) or just ignore it then use whole sheet as one form .
set up parent attribute for each command ( exclude form command ) . the top level commands have no parent .
sets the parent for child command .
check whether contain each command in the list .
assemble top level command to sheetconfiguration ( form ) . top level commands are those haven t matched from matchparentcommand function .
match command to sheet config form .
copy the each command area to seperated sheet . as it will be used for iteration .
build command list from comment .
process method line .
process command line .
change the comment .
create configuration command .
build the attributes map .
create sheet configuration from form command .
sets the footer of sheet configuration .
sets the body of sheet configuration .
sets the header of sheet configuration .
adds the row .
delete row .
removes the ranges from shift map .
find remove full name list .
gets the each command from parts name .
insert empty object in context .
delete object in context .
prepare collection data in context .
index command range .
checks if is row allow add .
insert each template .
evaluate .
evaluate normal cells .
evaluate user formula .
checks if is user formula .
evaluate .
creates the cell comment .
evaluate boolean express .
remove the rows .
removes the single row in sheet .
removes the cached cell for row .
removes the rows in body .
put picture image to session map and return the key to web .
put chart image to session map and return the key to web .
/ * ( non - javadoc )
/ * ( non - javadoc )
assemble new value .
return cell value with format .
get input cell value . none input return blank
get cell value as string but with giving type .
gets the cell string value with number type .
set cell value with giving string value .
sets the cell value string .
sets the cell value boolean .
sets the cell value date .
sets the cell value number .
copy rows .
copy single row .
copy cell .
set cell value .
set up cell style .
clone existing comments into new cell comment .
creates the comment anchor .
creates the or insert comment .
use low level api to match the comments setting .
find vmldrawing part according to cell .
find ctshape from vml object . this class use reflection to invoke the protected method in poi .
create cell style from source cell .
return cell index number key . e . g . $0$0 for a1 cell .
return cell index number key . e . g . $0$0 for a1 cell .
return cell index key with column letter and row index . e . g . $a$0 for a1 cell .
return cell index key with column and row index . e . g . $a$0 for a1 cell .
set up facescell s attribute from poicell and others .
gets the row col from component attributes .
gets the inits the rows from config .
gets the faces row from body row .
gets the faces cell from body row .
gets the poi cell with row col from current page .
gets the poi cell from sheet .
gets the skey from poi cell .
gets the or add tie cell in map .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
gets the current data context name .
evaluate the expression .
evaluate from giving context .
save the row before serialize .
adds the row .
removes the row .
merge map .
recover rows mapping by using it s address .
return chart type from ctchart object .
convert style string to stroke object .
init chart data .
build chartdata for line chart . chartdata include categorylist and serieslist which used for generate jfreechart .
retrieve anchor information from draw . xml for all the charts in the workbook . then save them to anchors map .
inits the xssf anchors map for sheet .
gets the anchor associate chart id .
gets the chart id from child node attributes .
save the workbook before serialize .
recover the cell reference to the sheet .
/ * ( non - javadoc )
builds the each objects .
save data in context .
recalc whole workbook .
gets the poi cell with row col from current page .
gets the poi cell with row col from tab .
gets the faces cell with row col from current page .
restore data context .
get last collect object from full name .
checks if is need restore .
start restore data context .
shift row ref .
set first cell also set static relative address firstcelladdress .
set last cell also set static relative address lastcelladdress .
build the config range at specified point ( start row ) . context include the data objects for evaluation . build sequence is inside - out . e . g . first build all the command area the range included . each command will hold the final length after data populated . then buildcells build all cells in the range except those commands . and update the formulas .
build all the static cells in the range ( exclude command areas ) .
builds the cells for row .
builds the single cell .
recover by using it s address .
save the workbook before serialize .
load the workbook from saving .
build categotry list .
build series list .
builds the chart series in list .
get color list from dpt .
get dpt from list .
sets the command index map .
recover the cell reference to the sheet .
gets the pictrues map .
gets the xssf pictrues map .
save pciture in map with index .
generate picture style .
generate chart style .
gets the anchor size .
put .
put .
checks if is value changed .
checks if is value changed .
gets the pattern .
/ * ( non - javadoc )
return real chart picture when browser requesting the image .
save the cell before serialize .
recover cell by using it s address .
gets the row style .
gets the cell font style .
get cell font color .
get font decoration .
gets the cell style .
gets the column style .
gets the alignment from cell .
gets the vertical alignment from cell .
e . g . linenumbercolumnwidth and addrowcolumnwidth
calc total height .
setup cell style .
set up input style parameter for input number component which need those parameters to make it work . e . g . symbol symbol position decimal places .
gets the input type from cell type .
get decimal places from format string e . g . 0 . 00 will return 2
get symbol from format string e . g . [ $cad ] # ##0 . 00 will return cad . while $# ##0 . 00 will return $
get symbol position from format string e . g . [ $cad ] # ##0 . 00 will return p . while # ##0 . 00 $ will return s
return faces context resource path .
get resource file as stream .
evaluate expression .
remove prefix path of the full path .
evaluate input type .
find bean in context .
evaluate expression .
evaluate expression .
join string .
round number according to decimal places .
get tab type .
get tab style .
gets the default date pattern .
gets the decimal separator by default locale .
gets the thousand separator by default locale .
sets the tie command alias list .
watch list serve for formula changes . basically all the rows appeared in the formula in the current sheet will be watched . note if the cell reference is from other sheet or workbooks it will be ignored .
builds the watch list for cell .
only rows in dynamic area will be added to watch list .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
check it s a command comment .
method string is start as $ follow by method name then with { and } . i . e . $init { department . name }
empty method string is start as $ follow with { and } . i . e . $ { department . name }
widget method start with $widget . e . g . $widget . calendar { ....
validate method start with $validate { rule = ... error = ... } .
parses the widget attributes .
get attribute key in map by cell .
parses the validate attributes .
get the string between two bracket . . e . g . $save { employee . name } return employee . name .
find pair bracket position .
parse the attributes from string .
parse input attributes .
parse validate attributes .
extractvalidationattributes .
split string by = sign .
parse select item attributes .
process calendar attributes .
process select item attributes .
gather special attributes .
parse comment to map
find first non letterordigit position from string .
removes the chars from string .
gets the excel column name .
return full name for cell with sheet name and $ format e . g . sheet1$a$1
return full name for cell with sheet name and $ format e . g . sheet1$a$1
return sheet name from cell full name e . g . return sheet1 from sheet1$a$1
remove sheet name from cell full name e . g . return $a$1 from sheet1$a$1
convert col to int .
gets the cell by reference .
pixel units to excel width units ( units of 1 / 256th of a character width ) .
excel width units ( units of 1 / 256th of a character width ) to pixel units .
height units 2 pixel .
checks if is date .
parses the date .
checks if is numeric .
should continue .
sets the object property .
cell compare to .
inside range .
return the last column of the sheet .
clear hidden columns .
delete hidden columns in row .
delete cell from row .
return the last column of the sheet .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
process event .
refresh after status changed .
validate with row col in current page .
validate by tie web sheet validation bean .
check error message from object in context .
validate all rules for single cell .
do validation .
validate cell .
validate current page .
validate row in current page .
validate row .
triggered when value in cells changed . e . g . user edit cell .
refresh cached cells in current page .
refresh cached cells in row .
set submit mode flag with javascript for holding in client side .
triggered validation process before actions like save or submit .
clear all the related maps .
load header rows .
load header row without configuration tab .
fill to max columns .
gets the header column style .
gets the width style .
load header row with configuration tab .
gets the column width style .
clear workbook .
load workbook .
load workbook .
inits the tabs .
load data process . unfinished .
refresh data .
refresh data for row .
refresh data for single cell .
find tab index with name .
load work sheet .
prepare worksheet for loading . this only load at backend without refresh gui .
sets the data table page .
save objs .
setup row info .
load body rows .
assemble faces body row .
refresh cached cell .
process refresh cell .
creates the dynamic columns .
adds the repeat row .
refresh body rows in range .
sets the unsaved status .
checks if is unsaved status .
recover by using it s address .
<p > converts a cef formatted string into a {
converts a cef formatted string into a {
by convention {
does this resource provide the instance wanted by the given {
removes those bindings that are ambiguous but also do not clash because of different {
as long as there is a clear contract : namely that failure is always indicated by a eventeception
registers the given event type so that it is handled by the { @link eventprocessor } system .
add ( accumulate ) a binding described by the 4 - tuple given .
uses the given { @link macro } and derives the { @link #with ( class macro ) } type from its declaration . this is a utility method that can be used as long as the { @link macro } implementation is not generic .
uses the given { @link macro } for the given exact ( no super - types! ) type of values .
a generic version of { @link macro#expand ( object binding bindings ) } that uses the matching predefined { @link macro } for the actual type of the value and expands it .
example - <i > typeof< / i >
/ * arrays
this is a special form of flatmap where the mapping does not return zero to n bs but always returns a b . if {
/ * annotations
@return a { @link class } counts as virtual when it is known that its not a type handled by an { @link injector } context either because it cannot be constructed at all or it does not make sense to let the { @link injector } take care of it . this includes value types enums collection types ( including arrays ) or any type than cannot be instantiated by its nature ( abstract types ) .
@return a { @link class } is monomodal if it there is just a single possible initial state . all newly created instances can just have this similar initial state but due to internal state they could ( not necessarily must ) develop ( behave ) different later on .
/ * members
returns the constructor with most visible visibility and longest argument list . self - referencing constructors are ignored .
/ * sequences
/ * exception handling
<pre > foo . bar . baz - > foo . bar foo . bar . - > foo . < / pre >
todo maybe extract a plugins extension
utility method for transferring input stream to output .
write next line as a long .
write next line to the output .
make workarounds for post requests via {
writes { @code count } bytes from the byte array { @code buffer } starting at { @code offset } to this stream . if there is room in the buffer to hold the bytes they are copied in . if not the buffered bytes plus the bytes in { @code buffer } are written to the target stream the target is flushed and the buffer is cleared .
writes one byte to this stream . only the low order byte of the integer { @code onebyte } is written . if there is room in the buffer the byte is copied into the buffer and the count incremented . otherwise the buffer plus { @code onebyte } are written to the target stream the target is flushed and the buffer is reset .
set network stats tag . converts string tag to integer one .
setup binary content with the local file .
setup binary content with the local file .
setup binary content with the bitmap .
setup binary content with the file descriptor .
remove parameter with the specified name from request description .
add header to request description .
clear the builder .
play the track .
stop playback .
bind to the streaming service .
unbind from the streaming service .
drop streaming service listener .
store image to the disk cache . if max allowed size is set image may be rescaled on disk .
plan an image on loading .
plan an image on loading .
composes uri builder using {
read all the bytes from input stream and convert them to a string . input stream is closed after this method invocation .
read all the bytes from input stream and convert them to a string using utf - 8 charset . input stream is closed after this method invocation .
transfers all the bytes from input to output stream . if read / write operations are successful output stream will be flushed . input stream is always closed after this method invocation .
consume the stream and close it . this implementation calls { @link inputstream#read ( byte [] ) } method and ignores any read bytes .
gets stream of uncompressed bytes for the { @link urlconnection } wrapping its input stream according to what is defined in its content encoding . supported encodings : { @link #encoding_gzip } { @link #encoding_deflate } .
wraps the supplied stream into either { @link gzipinputstream } or { @link inflaterinputstream } depending on { @code encoding } parameter value .
throw {
writes the data to the given outputstream .
returns the number of bytes that are available before this stream will block . this method returns the number of bytes available in the buffer plus those available in the source stream .
closes this stream . the source stream is closed and any resources associated with it are released .
reads a single byte from this stream and returns it as an integer in the range from 0 to 255 . returns - 1 if the end of the source string has been reached . if the internal buffer does not contain any available bytes then it is filled from the source stream and the first byte is returned .
reads at most { @code length } bytes from this stream and stores them in byte array { @code buffer } starting at offset { @code offset } . returns the number of bytes actually read or - 1 if no bytes were read and the end of the stream was encountered . if all the buffered bytes have been used a mark has not been set and the requested number of bytes is larger than the receiver s buffer size this implementation bypasses the buffer and simply places the results directly into { @code buffer } .
resets this stream to the last marked location .
skips { @code amount } number of bytes in this stream . subsequent { @code read () } s will not return these bytes unless { @code reset () } is used .
write the start to the specified output stream .
write the content disposition header to the specified output stream .
write the content type header to the specified output stream .
write the content transfer encoding header to the specified output stream .
write the end of the header to the output stream .
write the end data to the output stream .
write all the data to the output stream . if you override this method make sure to override #length () as well
return the full length of all the data . if you override this method make sure to override #send ( outputstream ) as well
write all parts and the last boundary to the specified output stream .
gets the length of the multipart message including the given parts .
if it is it returns the url parameter
when file timestamp is the same as what the browser is sending up send a 304 not modified
sets the date header for the http response
sets the date and cache headers for the http response
sets the content type header for the http response
closes the specified channel after all queued write requests are flushed .
write the disposition header to the output stream .
write the data in source to the specified stream .
setup cache . this operation causes disk reads .
this method is synchronized in order to avoid concurrent calls to mkdir
read cache for the specified cache entry .
returns an input stream that reads the body of a snapshot closing the snapshot when the stream is closed .
prepare for new width and hight .
returns the singleton instance for this class
validates that a keystore with the given parameters exists and can be used for an ssl context .
this method replaces the scale type of an image view without call to layout requests .
set a scale type and store a previous one that will be restores after the next call to {
please call it from the main thread ( with looper ) .
stop updates .
construct a pending intent that can be used for starting request processing . note that after this method is executed executor of the request builder is always null .
perform disconnect actions .
create the service connection .
destroy the service connection .
method should be called when wrapped view gets changes related to this consumer .
the client won t send any message so connect directly on channel open
data loading has been successful we are going to accept data . here we can implement some accumulation logic .
request to completely reset the loader
for testing only .
main thread
main thread
worker thread
main thread
set text view value or set its visibility to {
set text view value or change its visibility in case of empty value .
hide soft keyboard .
show soft keyboard .
toggles keyboard visibility .
converts device independent points to actual pixels .
find view by id .
find view by id .
cancel the timer if exception is caught - prevents useless stack traces
returns an opaque token representing the current position in the stream . call {
makes sure that the underlying stream can backtrack the full range from {
resets the stream to the position recorded by {
skips {
clear the cached entities .
populate the requested image to the specified view . called from the gui thread .
cancel image loading for a view .
create an image holder instance for the defined view .
it must be executed in the main thread .
set preloader .
executed in the main thread .
add image to memory cache .
checks the raw type provided by the token an presence of {
recycle the buffer .
a good place to set custom request headers .
build {
add string parameter .
xxx on 2 . 3 we get np exception in case of https connection and cache
calculate 32 bytes length md5 digest .
check whether activity contains a sharing intent previously set with {
/ * from multipartentity
returns a string representation of the given constant
returns the string identifying the given cublasstatus
if the given result is different to cublasstatus . cublas_status_success and exceptions have been enabled this method will throw a cudaexception with an error message that corresponds to the given result code . otherwise the given result is simply returned .
<pre > cublasstatus_t cublassetvector ( int n int elemsize const void * x int incx void * y int incy )
<pre > cublasstatus_t cublasgetvector ( int n int elemsize const void * x int incx void * y int incy )
<pre > cublasstatus_t cublassetmatrix ( int rows int cols int elemsize const void * a int lda void * b int ldb )
<pre > cublasstatus_t cublasgetmatrix ( int rows int cols int elemsize const void * a int lda void * b int ldb )
<pre > cublasstatus cublassetvectorasync ( int n int elemsize const void * x int incx void * y int incy cudastream_t stream ) ;
<pre > cublasstatus cublasgetvectorasync ( int n int elemsize const void * x int incx void * y int incy cudastream_t stream )
<pre > cublasstatus_t cublassetmatrixasync ( int rows int cols int elemsize const void * a int lda void * b int ldb cudastream_t stream )
<pre > cublasstatus_t cublasgetmatrixasync ( int rows int cols int elemsize const void * a int lda void * b int ldb cudastream_t stream )
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
host or device pointer
obtain the current cublas status by calling cublasgeterrornative and store the result as the lastresult . if the obtained result code is not cublasstatus . cublas_status_success and exceptions have been enabled an cudaexception will be thrown .
wrapper for cublas function . <br / > <br / > cublasstatus cublasalloc ( int n int elemsize void ** deviceptr ) <br / > <br / > creates an object in gpu memory space capable of holding an array of n elements where each element requires elemsize bytes of storage . if the function call is successful a pointer to the object in gpu memory space is placed in deviceptr . note that this is a device pointer that cannot be dereferenced in host code . <br / > <br / > return values<br / > ------------- <br / > cublas_status_not_initialized if cublas library has not been initialized<br / > cublas_status_invalid_value if n < = 0 or elemsize < = 0<br / > cublas_status_alloc_failed if the object could not be allocated due to lack of resources . <br / > cublas_status_success if storage was successfully allocated<br / >
extended wrapper for arrays of cucomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a float array containing the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cucomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a float array that may store the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cucomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a float array containing the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cucomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a float array that may store the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cudoublecomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a double array containing the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cudoublecomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a double array that may store the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cudoublecomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a double array containing the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
extended wrapper for arrays of cudoublecomplex values . note that this method only exists for convenience and compatibility with native c code . it is much more efficient to provide a pointer to a double array that may store the complex numbers where each pair of consecutive numbers in the array describes the real - and imaginary part of one complex number .
wrapper for cublas function . <pre > void cublassrotm ( int n float * x int incx float * y int incy const float * sparam )
wrapper for cublas function . <pre > void cublassrotmg ( float * psd1 float * psd2 float * psx1 const float * psy1 float * sparam )
wrapper for cublas function . <pre > void cublasdrotm ( int n double * x int incx double * y int incy const double * sparam )
wrapper for cublas function . <pre > void cublasdrotmg ( double * psd1 double * psd2 double * psx1 const double * psy1 double * sparam )
<pre > int cublasisamax ( int n const float * x int incx )
<pre > int cublasisamin ( int n const float * x int incx )
<pre > float cublassasum ( int n const float * x int incx )
<pre > void cublassaxpy ( int n float alpha const float * x int incx float * y int incy )
<pre > void cublasscopy ( int n const float * x int incx float * y int incy )
<pre > float cublassdot ( int n const float * x int incx const float * y int incy )
<pre > float cublassnrm2 ( int n const float * x int incx )
<pre > void cublassrot ( int n float * x int incx float * y int incy float sc float ss )
<pre > void cublassrotg ( float * host_sa float * host_sb float * host_sc float * host_ss )
<pre > void sscal ( int n float alpha float * x int incx )
<pre > void cublassswap ( int n float * x int incx float * y int incy )
<pre > void cublascaxpy ( int n cucomplex alpha const cucomplex * x int incx cucomplex * y int incy )
<pre > void cublasccopy ( int n const cucomplex * x int incx cucomplex * y int incy )
<pre > void cublaszcopy ( int n const cudoublecomplex * x int incx cudoublecomplex * y int incy )
<pre > void cublascscal ( int n cucomplex alpha cucomplex * x int incx )
<pre > void cublascrotg ( cucomplex * host_ca cucomplex cb float * host_sc cucomplex * host_cs )
<pre > void cublascrot ( int n cucomplex * x int incx cucomplex * y int incy float sc cucomplex cs )
<pre > void csrot ( int n cucomplex * x int incx cucumplex * y int incy float c float s )
<pre > void cublascsscal ( int n float alpha cucomplex * x int incx )
<pre > void cublascswap ( int n const cucomplex * x int incx cucomplex * y int incy )
<pre > void cublaszswap ( int n const cudoublecomplex * x int incx cudoublecomplex * y int incy )
<pre > cucomplex cdotu ( int n const cucomplex * x int incx const cucomplex * y int incy )
<pre > cucomplex cublascdotc ( int n const cucomplex * x int incx const cucomplex * y int incy )
<pre > int cublasicamax ( int n const float * x int incx )
<pre > int cublasicamin ( int n const float * x int incx )
<pre > float cublasscasum ( int n const cudouble * x int incx )
<pre > float cublasscnrm2 ( int n const cucomplex * x int incx )
<pre > void cublaszaxpy ( int n cudoublecomplex alpha const cudoublecomplex * x int incx cudoublecomplex * y int incy )
<pre > cudoublecomplex zdotu ( int n const cudoublecomplex * x int incx const cudoublecomplex * y int incy )
<pre > cudoublecomplex cublaszdotc ( int n const cudoublecomplex * x int incx const cudoublecomplex * y int incy )
<pre > void cublaszscal ( int n cucomplex alpha cucomplex * x int incx )
<pre > void cublaszdscal ( int n double alpha cudoublecomplex * x int incx )
<pre > double cublasdznrm2 ( int n const cudoublecomplex * x int incx )
<pre > void cublaszrotg ( cudoublecomplex * host_ca cudoublecomplex cb double * host_sc double * host_cs )
<pre > cublaszrot ( int n cudoublecomplex * x int incx cudoublecomplex * y int incy double sc cudoublecomplex cs )
<pre > void zdrot ( int n cudoublecomplex * x int incx cucumplex * y int incy double c double s )
<pre > int cublasizamax ( int n const double * x int incx )
<pre > int cublasizamin ( int n const cudoublecomplex * x int incx )
<pre > double cublasdzasum ( int n const cudoublecomplex * x int incx )
<pre > void cublassgbmv ( char trans int m int n int kl int ku float alpha const float * a int lda const float * x int incx float beta float * y int incy )
<pre > cublassgemv ( char trans int m int n float alpha const float * a int lda const float * x int incx float beta float * y int incy )
<pre > cublassger ( int m int n float alpha const float * x int incx const float * y int incy float * a int lda )
<pre > void cublasssbmv ( char uplo int n int k float alpha const float * a int lda const float * x int incx float beta float * y int incy )
<pre > void cublassspmv ( char uplo int n float alpha const float * ap const float * x int incx float beta float * y int incy )
<pre > void cublassspr ( char uplo int n float alpha const float * x int incx float * ap )
<pre > void cublassspr2 ( char uplo int n float alpha const float * x int incx const float * y int incy float * ap )
<pre > void cublasssymv ( char uplo int n float alpha const float * a int lda const float * x int incx float beta float * y int incy )
<pre > void cublasssyr ( char uplo int n float alpha const float * x int incx float * a int lda )
<pre > void cublasssyr2 ( char uplo int n float alpha const float * x int incx const float * y int incy float * a int lda )
<pre > void cublasstbmv ( char uplo char trans char diag int n int k const float * a int lda float * x int incx )
<pre > void cublasstbsv ( char uplo char trans char diag int n int k const float * a int lda float * x int incx )
<pre > void cublasstpmv ( char uplo char trans char diag int n const float * ap float * x int incx ) ;
<pre > void cublasstpsv ( char uplo char trans char diag int n const float * ap float * x int incx )
<pre > void cublasstrmv ( char uplo char trans char diag int n const float * a int lda float * x int incx ) ;
<pre > void cublasstrsv ( char uplo char trans char diag int n const float * a int lda float * x int incx )
<pre > void cublasztrmv ( char uplo char trans char diag int n const cudoublecomplex * a int lda cudoublecomplex * x int incx ) ;
<pre > void cublaszgbmv ( char trans int m int n int kl int ku cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * x int incx cudoublecomplex beta cudoublecomplex * y int incy ) ;
<pre > void cublasztbmv ( char uplo char trans char diag int n int k const cudoublecomplex * a int lda cudoublecomplex * x int incx )
<pre > void cublasztbsv ( char uplo char trans char diag int n int k const cudoublecomplex * a int lda cudoublecomplex * x int incx )
<pre > void cublaszhemv ( char uplo int n cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * x int incx cudoublecomplex beta cudoublecomplex * y int incy )
<pre > void cublaszhpmv ( char uplo int n cudoublecomplex alpha const cudoublecomplex * ap const cudoublecomplex * x int incx cudoublecomplex beta cudoublecomplex * y int incy )
<pre > cublaszgemv ( char trans int m int n cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * x int incx cudoublecomplex beta cudoublecomplex * y int incy )
<pre > void cublasztpmv ( char uplo char trans char diag int n const cudoublecomplex * ap cudoublecomplex * x int incx ) ;
<pre > void cublasztpsv ( char uplo char trans char diag int n const cudoublecomplex * ap cudoublecomplex * x int incx )
<pre > cublascgemv ( char trans int m int n cucomplex alpha const cucomplex * a int lda const cucomplex * x int incx cucomplex beta cucomplex * y int incy )
<pre > void cublascgbmv ( char trans int m int n int kl int ku cucomplex alpha const cucomplex * a int lda const cucomplex * x int incx cucomplex beta cucomplex * y int incy ) ;
<pre > void cublaschemv ( char uplo int n cucomplex alpha const cucomplex * a int lda const cucomplex * x int incx cucomplex beta cucomplex * y int incy )
<pre > void cublaschbmv ( char uplo int n int k cucomplex alpha const cucomplex * a int lda const cucomplex * x int incx cucomplex beta cucomplex * y int incy )
<pre >
<pre > void cublasctbmv ( char uplo char trans char diag int n int k const cucomplex * a int lda cucomplex * x int incx )
<pre > void cublasctpmv ( char uplo char trans char diag int n const cucomplex * ap cucomplex * x int incx ) ;
<pre > void cublasctrsv ( char uplo char trans char diag int n const cucomplex * a int lda cucomplex * x int incx )
<pre > void cublasctbsv ( char uplo char trans char diag int n int k const cucomplex * a int lda cucomplex * x int incx )
<pre > void cublasctpsv ( char uplo char trans char diag int n const cucomplex * ap cucomplex * x int incx )
<pre > cublascgeru ( int m int n cucomplex alpha const cucomplex * x int incx const cucomplex * y int incy cucomplex * a int lda )
<pre > cublascgerc ( int m int n cucomplex alpha const cucomplex * x int incx const cucomplex * y int incy cucomplex * a int lda )
<pre > void cublascher ( char uplo int n float alpha const cucomplex * x int incx cucomplex * a int lda )
<pre > void cublaschpr ( char uplo int n float alpha const cucomplex * x int incx cucomplex * ap )
<pre > void cublaschpr2 ( char uplo int n cucomplex alpha const cucomplex * x int incx const cucomplex * y int incy cucomplex * ap )
<pre > void cublascher2 ( char uplo int n cucomplex alpha const cucomplex * x int incx const cucomplex * y int incy cucomplex * a int lda )
<pre > void cublassgemm ( char transa char transb int m int n int k float alpha const float * a int lda const float * b int ldb float beta float * c int ldc )
<pre > void cublasssymm ( char side char uplo int m int n float alpha const float * a int lda const float * b int ldb float beta float * c int ldc ) ;
<pre > void cublasssyrk ( char uplo char trans int n int k float alpha const float * a int lda float beta float * c int ldc )
<pre > void cublasssyr2k ( char uplo char trans int n int k float alpha const float * a int lda const float * b int ldb float beta float * c int ldc )
<pre > void cublasstrmm ( char side char uplo char transa char diag int m int n float alpha const float * a int lda const float * b int ldb )
<pre > void cublasstrsm ( char side char uplo char transa char diag int m int n float alpha const float * a int lda float * b int ldb )
<pre > void cublascgemm ( char transa char transb int m int n int k cucomplex alpha const cucomplex * a int lda const cucomplex * b int ldb cucomplex beta cucomplex * c int ldc )
<pre > void cublascsymm ( char side char uplo int m int n cucomplex alpha const cucomplex * a int lda const cucomplex * b int ldb cucomplex beta cucomplex * c int ldc ) ;
<pre > void cublaschemm ( char side char uplo int m int n cucomplex alpha const cucomplex * a int lda const cucomplex * b int ldb cucomplex beta cucomplex * c int ldc ) ;
<pre > void cublascsyrk ( char uplo char trans int n int k cucomplex alpha const cucomplex * a int lda cucomplex beta cucomplex * c int ldc )
<pre > void cublascherk ( char uplo char trans int n int k float alpha const cucomplex * a int lda float beta cucomplex * c int ldc )
<pre > void cublascsyr2k ( char uplo char trans int n int k cucomplex alpha const cucomplex * a int lda const cucomplex * b int ldb cucomplex beta cucomplex * c int ldc )
<pre > void cublascher2k ( char uplo char trans int n int k cucomplex alpha const cucomplex * a int lda const cucomplex * b int ldb float beta cucomplex * c int ldc )
<pre > void cublasctrmm ( char side char uplo char transa char diag int m int n cucomplex alpha const cucomplex * a int lda const cucomplex * b int ldb )
<pre > void cublasctrsm ( char side char uplo char transa char diag int m int n cucomplex alpha const cucomplex * a int lda cucomplex * b int ldb )
<pre > double cublasdasum ( int n const double * x int incx )
<pre > void cublasdaxpy ( int n double alpha const double * x int incx double * y int incy )
<pre > void cublasdcopy ( int n const double * x int incx double * y int incy )
<pre > double cublasddot ( int n const double * x int incx const double * y int incy )
<pre > double dnrm2 ( int n const double * x int incx )
<pre > void cublasdrot ( int n double * x int incx double * y int incy double sc double ss )
<pre > void cublasdrotg ( double * host_sa double * host_sb double * host_sc double * host_ss )
<pre > void cublasdscal ( int n double alpha double * x int incx )
<pre > void cublasdswap ( int n double * x int incx double * y int incy )
<pre > int idamax ( int n const double * x int incx )
<pre > int idamin ( int n const double * x int incx )
<pre > cublasdgemv ( char trans int m int n double alpha const double * a int lda const double * x int incx double beta double * y int incy )
<pre > cublasdger ( int m int n double alpha const double * x int incx const double * y int incy double * a int lda )
<pre > void cublasdsyr ( char uplo int n double alpha const double * x int incx double * a int lda )
<pre > void cublasdsyr2 ( char uplo int n double alpha const double * x int incx const double * y int incy double * a int lda )
<pre > void cublasdspr ( char uplo int n double alpha const double * x int incx double * ap )
<pre > void cublasdspr2 ( char uplo int n double alpha const double * x int incx const double * y int incy double * ap )
<pre > void cublasdtrsv ( char uplo char trans char diag int n const double * a int lda double * x int incx )
<pre > void cublasdtrmv ( char uplo char trans char diag int n const double * a int lda double * x int incx ) ;
<pre > void cublasdtbmv ( char uplo char trans char diag int n int k const double * a int lda double * x int incx )
<pre > void cublasdtpmv ( char uplo char trans char diag int n const double * ap double * x int incx ) ;
<pre > void cublasdtpsv ( char uplo char trans char diag int n const double * ap double * x int incx )
<pre > void cublasdtbsv ( char uplo char trans char diag int n int k const double * a int lda double * x int incx )
<pre > void cublasdsymv ( char uplo int n double alpha const double * a int lda const double * x int incx double beta double * y int incy )
<pre > void cublasdsbmv ( char uplo int n int k double alpha const double * a int lda const double * x int incx double beta double * y int incy )
<pre > void cublasdspmv ( char uplo int n double alpha const double * ap const double * x int incx double beta double * y int incy )
<pre > void cublasdtrsm ( char side char uplo char transa char diag int m int n double alpha const double * a int lda double * b int ldb )
<pre > void cublasztrsm ( char side char uplo char transa char diag int m int n cudoublecomplex alpha const cudoublecomplex * a int lda cudoublecomplex * b int ldb )
<pre > void cublasdtrmm ( char side char uplo char transa char diag int m int n double alpha const double * a int lda const double * b int ldb )
<pre > void cublasdsymm ( char side char uplo int m int n double alpha const double * a int lda const double * b int ldb double beta double * c int ldc ) ;
<pre > void cublaszsymm ( char side char uplo int m int n cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * b int ldb cudoublecomplex beta cudoublecomplex * c int ldc ) ;
<pre > void cublasdsyrk ( char uplo char trans int n int k double alpha const double * a int lda double beta double * c int ldc )
<pre > void cublaszsyrk ( char uplo char trans int n int k cudoublecomplex alpha const cudoublecomplex * a int lda cudoublecomplex beta cudoublecomplex * c int ldc )
<pre > void cublaszsyr2k ( char uplo char trans int n int k cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * b int ldb cudoublecomplex beta cudoublecomplex * c int ldc )
<pre > void cublaszher2k ( char uplo char trans int n int k cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * b int ldb double beta cudoublecomplex * c int ldc )
<pre > void cublaszher ( char uplo int n double alpha const cudoublecomplex * x int incx cudoublecomplex * a int lda )
<pre > void cublaszhpr ( char uplo int n double alpha const cudoublecomplex * x int incx cudoublecomplex * ap )
<pre > void cublaszhpr2 ( char uplo int n cudoublecomplex alpha const cudoublecomplex * x int incx const cudoublecomplex * y int incy cudoublecomplex * ap )
<pre > void cublaszher2 ( char uplo int n cudoublecomplex alpha const cudoublecomplex * x int incx const cudoublecomplex * y int incy cudoublecomplex * a int lda )
<pre > void cublasdsyr2k ( char uplo char trans int n int k double alpha const double * a int lda const double * b int ldb double beta double * c int ldc )
<pre > void cublaszgemm ( char transa char transb int m int n int k cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * b int ldb cudoublecomplex beta cudoublecomplex * c int ldc )
<pre > void cublasztrmm ( char side char uplo char transa char diag int m int n cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * b int ldb )
<pre > cublaszgeru ( int m int n cudoublecomplex alpha const cudoublecomplex * x int incx const cudoublecomplex * y int incy cudoublecomplex * a int lda )
<pre > cublaszgerc ( int m int n cudoublecomplex alpha const cudoublecomplex * x int incx const cudoublecomplex * y int incy cudoublecomplex * a int lda )
<pre > void cublaszherk ( char uplo char trans int n int k double alpha const cudoublecomplex * a int lda double beta cudoublecomplex * c int ldc )
<pre > void cublaszhemm ( char side char uplo int m int n cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * b int ldb cudoublecomplex beta cudoublecomplex * c int ldc ) ;
<pre > void cublasztrsv ( char uplo char trans char diag int n const cudoublecomplex * a int lda cudoublecomplex * x int incx )
<pre > void cublaszhbmv ( char uplo int n int k cudoublecomplex alpha const cudoublecomplex * a int lda const cudoublecomplex * x int incx cudoublecomplex beta cudoublecomplex * y int incy )
tiek pieemts ka izsauco funkcija nodroina ka vrds tiem beidzas ar o galotni .
/ * returned lexemes shouldn t be modified to avoid changing recognition of other words! not cloned due to performance and memory usage concerns .
add one occurrence of one lexeme .
add one occurrence of one ending .
convert frequency data in xml format .
cumulative frequency estimate for given wordform .
determine if given char is a whitespace char ( space tab newline ) .
/ * tokenizes the string ( sentence? ) and runs morphoanalysis on each word .
* tokenizes some text ( usually a sentence )
* tokenizes a paragraph and splits it into sentences .
/ * public string getdemo () { return this . getvalue ( locjumudemo ) ; todo : apskatt kur lieto un vai vajag } //
for debugging purposes only .
check if attribute - value structure has attribute matching given attributevalue and if so then set corresponding position in the tag .
convert internal attribute - value structure to semti - kamols tag .
convert internal attribute - value structure to semti - kamols tag . usage of default tags given as parameter . no additional defaults used .
check if tag has given value in specified position and if so then set corresponding attribute - value pair in the given attribute - value structure .
remove formating from kamols - style tag .
convert semti - kamols markup tag to internal attribute - value structure .
converts kamols - style markup to prolog list .
converts kamols - style markup to prolog list .
converts word object to prolog format necessary for chunker ( a - table record ) .
perform retrieval of metrics from appdynamics using specified parameters .
generate querystring for the request .
process the json response from the request .
parse json string as configurations that the task should query from appdynamics .
process { @link metrictimeseries } and { @link metricvalue } filtering out data point earlier or equal to timestamp that was marked as already sent .
retrieve configurations by looking up in property param first then environment variable .
perform reading and reporting of appdynamics metrics to signalfx
create a { @link metrictimeseries } for a given metric path . it will use the given metric path as dimensions mapping and add extra dimensions as specified in the metricinfo .
create a reader builder for com . helger . genericode . v04 . codelistdocument .
create a reader builder for com . helger . genericode . v04 . codelistsetdocument .
create a reader builder for com . helger . genericode . v04 . columnsetdocument .
create a reader builder for com . helger . genericode . v10 . codelistdocument .
create a reader builder for com . helger . genericode . v10 . codelistsetdocument .
create a reader builder for com . helger . genericode . v10 . columnsetdocument .
get the id of the passed column element .
get the value of a column identified by an id within a specified row . this method only handles simple values .
get all contained columns
get all contained columns
get the ids of all contained columns
get the ids of all contained columns
get the column with the specified id .
get all contained keys
get all contained keys
get the ids of all contained keys
get the key with the specified id .
check if the passed column id is a key column in the specified column set
create a { @link shortname } object
create a { @link longname } object
create a { @link simplevalue } object
create a { @link keycolumnref } object
create a new column to be added to a column set
create a new key to be added to a column set
set the number of lines to skip before the header row starts
add a single column definition .
create a writer builder for com . helger . genericode . v04 . codelistdocument .
create a writer builder for com . helger . genericode . v04 . codelistsetdocument .
create a writer builder for com . helger . genericode . v04 . columnsetdocument .
create a writer builder for com . helger . genericode . v10 . codelistdocument .
create a writer builder for com . helger . genericode . v10 . codelistsetdocument .
create a writer builder for com . helger . genericode . v10 . columnsetdocument .
create a validator builder for com . helger . genericode . v04 . codelistdocument .
create a validator builder for com . helger . genericode . v04 . codelistsetdocument .
create a validator builder for com . helger . genericode . v04 . columnsetdocument .
create a validator builder for com . helger . genericode . v10 . codelistdocument .
create a validator builder for com . helger . genericode . v10 . codelistsetdocument .
create a validator builder for com . helger . genericode . v10 . columnsetdocument .
@param pair of exchange / coin
send logs to server
/ *
context object must be set in order to use the logger api . this is called automatically by bmsclient .
set the level and above at which log messages should be saved / printed . for example passing level . info will log info warn error and fatal . a null parameter value is ignored and has no effect .
get the current logger . level .
global setting : turn persisting of log data passed to this class s log methods on or off .
get the current value of the capture flag indicating that the logger is recording log calls persistently .
@exclude global setting : turn persisting of analytics data passed to this class s analytics methods on or off .
@exclude get the current value of the analyticscapture flag indicating that the logger is recording analytics calls persistently .
set the maximum size of the local log file . once the maximum file size is reached no more data will be appended . consider that this file is sent to a server .
see { @link #send () }
@exclude send the accumulated log data when the persistent log buffer exists and is not empty . the data accumulates in the log buffer from the use of { @link logpersister } with capture ( see { @link logpersister#setanalyticscapture ( boolean ) } ) turned on .
ask the logger if an uncaught exception which often appears to the user as a crashed app is present in the persistent capture buffer . this method should not be called after calling { @link com . ibm . mobilefirstplatform . clientsdk . android . core . api . bmsclient#initialize ( context string string string ) } . if it is called too early an error message is issued and false is returned .
@exclude
if we have callstack metadata prepend it to the message
get stack trace caused by logger exceptions
will create jsonobject with the passed parameters and other relevant information . see class - level documentation .
append the full stacktrace to a $stacktrace key jsonarray in the passed jsonmetadata object and return it .
we only persist ( append ) to the log file if the passed jsonobject parameter has data the logger capture flag is set to true and the log file size is less than file_size_log_threshold .
initialize bmsanalytics api . this must be called before any other bmsanalytics . * methods
initialize mfpanalytics api . this must be called before any other mfpanalytics . * methods
log location event
specify current application user . this value will be hashed to ensure privacy . if your application does not have user context then nothing will happen .
callers should pass a jsonobject in the format described in the class - level documentation . it will be placed as - is using jsonobject . tostring () with no additional contextual information automatically appended . we use java . util . logging simply to take advantage of its built - in thread - safety and log rollover .
public for testing only
starting the location updates
calculates and logs the size of first numentries in the region .
sizes numentries of a partitioned region or all the entries if numentries is 0 .
sizes numentries of a replicated or local region or all the entries if numentries is 0 .
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
reads a snapshot entry . if the last entry has been read a null value will be returned .
------------------------------------------------
------------------------------------------------
elapsed millis from base
returns an array of time stamp values the first of which has the specified index . each returned time stamp is the number of millis since midnight jan 1 1970 utc .
------------------------------------------------
accepts a file or directory contain the statistics files
/ * calculates each stat given the result of calling getsnapshots
*
--------------------------------------------------------
dynamically create a gemfire pool with just the server
this methods create a pool for connecting to a locator
get region based on a given name ( create the region if it exists on the server but not on the client ) .
<pre > list all regions that match a wildcard expression ( ex : r * ) . note that special internal regions that begin with the name __ will be skipped . < / pre >
return the client cache based on the jmx connection ( if no cache instance )
determine if a given region exists
--------------------------------------------------------
obtain a gemfire jmx client
--------------------------------------------------------
--------------------------------------------------------
determines the unique set of the host names for the distributed system
supports resolving host network lookup issues
--------------------------------------------------------
determine if the data should be sent
execute a function with the given execution settings
used to flatten results from multiple servers
--------------------------------------------------------
select results for oql
factory method for put events registration
factory method for delete events registration
------------------------------------------------
------------------------------------------------
put a new records
delete a region entry by a key
get a value by a given key
handling exceptions in general for rest responses
------------------------------------------------
on region filter facts determine how to parse the inputs typically for cics to grid calls
this function will use the jsonexportfunction function to export json data and read the results to be returned to callers
--------------------------------------------------------
------------------------------------------------
--------------------------------------------
------------------------------------------------
------------------------------------------------
list the unique set of host name
--------------------------------------------------------
execute the search on region
--------------------------------------------------------
current supports get cache server name determine the logic name of app
initialize security properties
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
this is an example to get or create a region
create a proxy region
------------------------------------------------
add the observer as a listener for put / create events
add the observer as a listener for remove / invalidate events
build the regionsyncreport the given
export region data in json format
--------------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
return true if the current ts must be inserted instead of being mapped to the tsatinsertpoint
returns true if the timestamp at curidx is the one that ts is the closest to . we know that timestamps [ curidx - 1 ] if it exists was not the closest .
/ * returns the approximate amount of memory used to implement this object .
/ * returns true if sample was added .
/ * frees up any resources no longer needed after the archive file is closed . returns true if this guy is no longer needed .
/ * gets the value of the stat in the current instance given the stat name .
checks to see if the archive has changed since the statarchiverreader instance was created or last updated . if the archive has additional samples then those are read the resource instances maintained by the reader are updated . <p > once closed a reader can no longer be updated .
closes the archive .
finds and converts all statistics files in a given directory to csv
main method to extract gf stats to file
close and recreate the jmx connect
connect / reconnect to a locator host / port
--------------------------------------------------------
stops all cache servers followed by locators on a given server
shut down a given member by its name
--------------------------------------------------------
does not stop locators
--------------------------------------------------------
shut down each member in a given redundancyzone
store the pagination search result details
*
------------------------------------------------
read results from region by keys in pageregion
------------------------------------------------
--------------------------------------------------------
------------------------------------------------
import exported data from a given
parse the remote locators and locator and assert that they match
--------------------------------------------------------
--------------------------------------------------------
------------------------------------------------
--------------------------------------------------------
/ * returns the amount of memory used to implement this series .
/ * gets the first resultsize values of this series skipping over the first samplestoskip ones . the first value in a series is at index 0 . the maximum result size can be obtained by calling getsize () .
/ * free up any unused memory
export region data in json format
------------------------------------------------
export region data in json format
--------------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
------------------------------------------------
--------------------------------------------------------
------------------------------------------------
<pre > this method will start a single locator and cache server .
------------------------------------------------
wait for a given member to startup
wait for a given member to startup
------------------------------------------------
------------------------------------------------
this function gets hashmap key = serializable value = biginteger
build check sum map
execute a gemfire query with no limit
execute a gemfire query
/ * frees up any resources no longer needed after the archive file is closed . returns true if this guy is no longer needed .
forces the value to be wrapped with if it isequalto for a string field .
checks if a typemirror is mapped to sqlite integer type
takes an object and serializes it to a byte array . don t enforce that it extends serializable to allow for lists and maps to be passed in .
de - serialize a byte array back to it s original object .
takes a class type and constructs it . if the class does not have an empty constructor this will find the parametrized constructor and use nulls and default values to construct the class .
check if the element has the
check if the element has a
checks for a supertype returns true if element has a supertype
get table schema
create the java functions required for the internal class
create a way to get an id for foreign keys
creates the function for creating the table
creates the function dropping the table
creates the function for inserting a new value into the database
creates the function for updating an object
updates the id of the object to the last insert
creates the function for deleting an object by id
creates the function for deleting an object from the table
creates the function for mapping a cursor to the object after executing a sql statement
creates function for getting an object by value
executes a query and returns the results wrapped in an observable
check to ensure that the column name provided is valid
checks if a string there if not returns the default string
capitalizes the first letter of the string passed in
checks if a typemirror is mapped to sqlite type
order the results in descending order
read temperature from the sensors .
maps a type to the corresponding cursor get function . for mapping objects between the database and java . if a type is not found getblob is returned
print out debug logs will only print if {
print out notes
print out errors this will stop the build from succeeding
returns all icon fonts from bundle .
returns all icons from bundle .
return the next data point in the approximation of the solution .
add new data point : augment the divided difference table by appending a new entry at the bottom of each column .
return the value of the polynomial interpolation function at x . ( implementation of evaluatable . )
create the sld editor layout and attach handlers to the actions .
create background content decoration for the widget tab .
compute and return x^power .
copy the values of this matrix .
set this column vector from an array of values .
compute the euclidean norm .
print the vector values .
compute x^exponent to a given scale . uses the same algorithm as class numbercruncher . mathutils . intpower .
compute the integral root of x to a given scale x &ge ; 0 . use newton s algorithm .
compute e^x to a given scale . break x into its whole and fraction parts and compute ( e^ ( 1 + fraction / whole )) ^whole using taylor s formula .
compute e^x to a given scale by the taylor series .
compute the natural logarithm of x to a given scale x &gt ; 0 .
compute the natural logarithm of x to a given scale x > 0 . use newton s algorithm .
compute the arctangent of x to a given scale |x| &lt ; 1
compute the arctangent of x to a given scale by the taylor series |x| < 1
compute the square root of x to a given scale x &ge ; 0 . use newton s algorithm .
print the string containing the digits of pi .
return a timestamp string that contains the elapsed time period .
set the minimum and maximum random values .
determine a random value s interval and count it .
print the counter values as a horizontal bar chart . scale the chart so that the longest bar is max_bar_size .
add another complex number to this one .
subtract another complex number from this one .
multiply this complex number by another one .
divide this complex number by another one .
copy the values of this matrix .
set this row vector from a matrix . only the first row is used .
compute the euclidean norm .
print the vector values .
get the value of element [ r c ] in the matrix .
get a row of this matrix .
get a column of this matrix .
copy the values of this matrix .
set the value of element [ r c ] .
set this matrix from a 2 - d array of values . if the rows do not have the same length then the matrix column count is the length of the shortest row .
set a row of this matrix from a row vector .
set a column of this matrix from a column vector .
return the transpose of this matrix .
add another matrix to this matrix .
subtract another matrix from this matrix .
multiply this matrix by a constant .
multiply this matrix by another matrix .
multiply this matrix by a column vector : this * cv
multiply a row vector by this matrix : rv * this
print the matrix values .
compute the next position of x [ n + 1 ] .
check the position of x [ n + 1 ] .
attach an imageresource to the button .
add a new data point : update the sums .
validate the coefficients .
compute the next position of xn .
does not clear templatenames .
convert styledlayerdescriptorinfo to raw xml .
convert raw xml to styledlayerdescriptorinfo .
test by marshalling .
test by unmarshalling .
---------------------------------------------------------------
return the next data point in the approximation of the solution .
integrate the function from a to b using the trapezoidal algorithm and return an approximation to the area . ( integrator implementation . )
compute the area of the ith trapezoidal region .
set this square matrix from another matrix . note that this matrix will reference the values of the argument matrix . if the values are not square only the upper left square is used .
set this square matrix from a 2 - d array of values . if the values are not square only the upper left square is used .
fires a { @link sldcloseevent } that will save the current sld and close it . if not successful the current sld remains open .
fires a { @link sldcloseevent } that will close the current sld regardless of changes .
compute the inverse of this matrix .
compute the determinant .
compute the euclidean norm of this matrix .
set the value of element [ r c ] in the matrix .
set a row of this matrix from a row vector .
set a column of this matrix from a column vector .
solve ax = b for x using the gaussian elimination algorithm .
print the decomposed matrix lu .
compute the upper triangular matrix u and lower triangular matrix l such that a = l * u . store l and u together in matrix lu . compute the permutation vector permutation of the row indices .
do forward elimination with scaled partial row pivoting .
solve ly = b for y by forward substitution .
solve ux = y for x by back substitution .
iteratively improve the solution x to machine accuracy .
convert a square matrix into an identity matrix .
compute the next randomn value using the von neumann algorithm . requires sequences of uniformly - distributed random values in [ 0 1 ) .
return the next data point in the approximation of the solution .
do the regula falsi iteration procedure .
compute the next position of x - false .
check the position of x - false .
compute the next position of xfalse .
check the interval .
add the value of an addend to the running sum .
multiply two integer values a and b modulo m .
raise a to the b power modulo m .
do the secant iteration procedure .
compute the next position of x [ n + 1 ] .
create an instance of the sldmanager .
convert a long value into a character array of 0 and 1 that represents the value in base 2 .
decompose a floating - point value into its parts .
print the decomposed parts of the value .
validate the value of the float biased exponent value .
validate the value of the float unbiased exponent value .
validate the value of the double biased exponent value .
validate the value of the double unbiased exponent value .
sldeditorservicefactory constructor .
compute the next random value using the central limit theorem which states that the averages of sets of uniformly - distributed random values are normally distributed .
compute the next randomn value using the polar algorithm . requires two uniformly - distributed random values in [ - 1 + 1 ) . actually computes two random values and saves the second one for the next invokation .
compute the next random value using the ratio algorithm . requires two uniformly - distributed random values in [ 0 1 ) .
compute the sieve of eratosthenes .
compute the prime factors of an integer value .
do the bisection iteration procedure .
compute the next position of xmid .
check the position of xmid .
sets the javafx application instance to be provided by the cdi beanmanager .
settings from a custom calabash . xml
settings to be always applied
retrieves a {
create a cdi - aware fxmlloader . if an annotation of type @fxmlloaderparams can be found use it s parameters to configure the fxmlloader instance that shall be used to perform the loading of the fxml file .
initializes the given fxmlloader instance using the provided parameters .
checks the location that has been specified ( if any ) and uses the default class loader to create an url that points to a fxml file on the classpath .
todo refactor hateoas link building . time for resourceassembler or moving this stuff up the service . although moving it up will create a circular dep .
your business application s api key . this key identifies your application for purposes of quota management .
the location latitude and longitude .
one or more address types separated by a pipe ( | ) .
safely get the information from our convention
find an attribute definition that applies to a particular attribute filter .
evaluate single attribute filter
todo i d like to push a lot of this down into nicknack - core .
helpers
todo : switch to iterator .
1 .. 55 chars . anything goes .
todo refactor hateoas link building . time for resourceassembler or moving this stuff up the service . although moving it up will create a circular dep .
your business application s api key . this key identifies your application for purposes of quota management .
the address that you want to geocode .
in a geocoding response the google geocoding api can return address results restricted to a specific area .
serviceinstance<t > instances required by the curator interfaces .
serviceinstance<t > instances required by the curator interfaces .
return all distinct names registered by this discovery type .
return all instances registered to this particular name for this discovery type
todo refactor hateoas link building . time for resourceassembler or moving this stuff up the service . although moving it up will create a circular dep .
taken from spark ( https : // github . com / perwendel / spark )
taken from spark ( https : // github . com / perwendel / spark )
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
create a new form container / electronic forms .
retrieve all collaboration items to where logged in user .
retrieve all collaboration items to where { @code form } is { @code formparam } .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
construct the correct meta - data from parameters .
creates a new { @code user } with the email fields and roles inside the { @code userparam } .
updates an existing { @code user } with the email fields and roles inside the { @code userparam } .
activate an existing { @code user } that is currently deactivated .
deactivate an existing { @code user } that is currently active .
increment the invalid login count for { @code userparam } .
change the password for the currently logged in user .
deletes the { @code user } provided . id must be set on the { @code user } .
retrieves user information for the logged in { @code user } .
retrieves user information for the provided { @code usernameparam } .
retrieves user information for the provided { @code emailaddressparam } .
retrieves user information for the provided { @code useridparam } .
retrieves all user information .
retrieves all users by { @code jobviewparam } .
retrieves all users by { @code roleparam } .
retrieves all users by { @code roleparam } .
retrieves all user field values information by the { @code userparam } .
retrieve the gravatar bytes by email .
retrieve the gravatar bytes for fluid user .
check whether { @code this } { @code user } has access to role { @code roleparam } .
check whether { @code this } { @code user } has access to role with name { @code roleparam } .
conversion to { @code jsonobject } from java object .
<p > returns the value of the { @code fieldnameparam } requested .
gets the value of { @code this } { @code field } as a { @code multichoice } .
conversion to { @code jsonobject } from java object .
gets the value of { @code this } { @code field } as a { @code string } .
gets the value of { @code this } { @code field } as a { @code double } .
gets the value of { @code this } { @code field } as a { @code long } .
gets the value of { @code this } { @code field } as a { @code integer } .
gets the value of { @code this } { @code field } as a { @code number } .
gets the value of { @code this } { @code field } as a { @code boolean } .
gets the value of { @code this } { @code field } as a { @code date } .
gets the value of { @code this } { @code field } as a { @code multichoice } .
gets the value of { @code this } { @code field } as a { @code tablefield } .
sets the value of { @code this } { @code field } .
sets the type of { @code this } { @code field } as { @code enum } .
gets the type of { @code this } { @code field } as { @code enum } .
conversion to { @code jsonobject } from java object .
creates the mapping object required by elastic search when making use of enhanced data - types .
conversion to { @code jsonobject } for storage in elasticsearch .
populate the object based on the elasticsearch json structure .
not allowed to call this method .
returns the elasticsearch equivalent data field - type from the fluid datatype .
checks whether the provided { @code fieldparam } qualifies for insert into elastic search .
conversion to { @code jsonobject } from java object .
sets the property value of the step with property name { @code nameparam } .
gets the step property with name { @code nameparam }
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
creates a new flow step .
updates an existing flow step .
retrieves an existing flow step via primary key .
retrieves an existing flow step via step .
retrieves all assignment { @link com . fluidbpm . program . api . vo . flow . jobview } s via flow step name key .
retrieves all assignment { @link com . fluidbpm . program . api . vo . flow . jobview } s via flow step name key .
retrieves all assignment { @link com . fluidbpm . program . api . vo . flow . jobview } s via flow step primary key .
retrieves all assignment { @link com . fluidbpm . program . api . vo . flow . jobview } s via logged in { @code user } .
retrieves all assignment { @link com . fluidbpm . program . api . vo . flow . jobview } s for { @code user } .
retrieves all assignment { @link com . fluidbpm . program . api . vo . flow . jobview } s for { @code flow } .
retrieves all steps via flow .
delete an existing flow step .
forcefully delete an existing flow step .
performs a search against the elasticsearch instance with the { @code qbparam } .
performs a search against the elasticsearch instance with the { @code qbparam } .
performs a search against the elasticsearch instance with the { @code qbparam } .
retrieves the { @code form } s via the provided { @code formidsparam } .
performs a search against the elasticsearch instance with the { @code qbparam } .
performs a search against the elasticsearch instance with the { @code qbparam } .
populate all the table field values from the table index .
confirms whether index with the name { @code indextocheckparam } exists .
close the sql and elasticsearch connection .
checks to see whether { @code this } { @code attachment } name contains the value { @code containingtextparam } .
conversion to { @code jsonobject } from java object .
retrieves all the table records ( forms ) for the { @code formtogettableformsforparam } .
retrieves all descendants for the { @code formtogettableformsforparam } .
retrieves the ancestor for the { @code formtogetancestorforparam } .
retrieves all fields for the { @code formtogetfieldsforparam } .
utility method for creating camel - case - upper from { @code inputparam }
extract and returns latitude from { @code texttocheckparam } applicable to fluid .
extract and returns latitude from { @code texttocheckparam } applicable to elasticsearch .
extract and returns longitude from { @code texttocheckparam } applicable to elasticsearch .
convert the { @code toparseparam } to a double .
convert the { @code toparseparam } to a double .
decodes the { @code base64stringparam } as { @code byte [] } .
encodes the { @code bytesparam } as { @code java . lang . string } .
encodes the { @code stringparam } as { @code byte [] } .
encodes the { @code bytesparam } as { @code java . lang . string } .
sets the flat value on the { @code objecttosetfieldonparam } json object .
checks whether { @code this } message handler can process the message { @code messageparam }
handles the message . if there was an error the object will be error if there was no error the object will be jsonobject
event for when connection is closed .
adds the { @code expectedmessageechoparam } echo to expect as a return value before the web socket operation may be regarded as complete .
gets a list of echo messages of the current return values .
checks the local return value echo messages if all of them contain { @code echomessageparam } .
uncompress the raw { @code compressedbytesparam } .
retrieves all personal inventory items for the logged in user .
remove the item { @code formtoremoveparam } from the personal inventory .
conversion to { @code jsonobject } from java object .
create a new form container / electronic forms .
create a new table record .
update a form container / electronic form . the table record forms may also be updated with
execute the custom program with action alias { @code customwebactionparam } . this method may be used for form and table records .
execute the custom program with action alias { @code customwebactionparam } . this method may be used for form and table records .
deletes the form container provided . id must be set on the form container .
retrieves electronic form workflow historic information .
retrieves electronic form and field historic information .
retrieves electronic form and field historic information for the most recent modification .
retrieves the form container by primary key .
lock the provided form container for logged in user .
lock the provided form container for logged in user . if { @code usertolockasparam } is provided and valid that user will be used instead .
unlock the provided form container from the logged in user . item will not be removed from users personal inventory .
unlock the provided form container from the logged in user . the unlock will be performed asynchronous . item will not be removed from users personal inventory .
unlock the provided form container from the logged in user . the unlock will be performed asynchronous . item will not be removed from users personal inventory .
unlock the provided form container from the logged in user .
retrieves the table field records as { @code list<form > } .
gets the descendants for the { @code electronicformidsparam } forms .
gets the ancestor for the { @code electronicformidparam } form .
maps the form to the provided definition - id and title .
maps the form states with the { @code resultsetparam } .
convert the comma separated list of roles as objects .
conversion to { @code jsonobject } from java object .
creates a new form definition with the fields inside the definition .
updates an existing form definition with the fields inside the definition .
retrieves the form definition by primary key .
retrieves the form definition by name .
retrieves all form definitions by logged in user .
retrieves all form definitions where the logged in user can create a new instance of the { @code form } .
deletes the form definition provided . id must be set on the form definition .
retrieves the { @code cachedfieldvalue } value stored under the params .
converts the { @code objwithkeyparam } object to { @code cachedfieldvalue } .
retrieves the java method from class { @code clazzparam } .
invokes the { @code methodparam } method on { @code objparam } .
generates the storage key the provided parameters .
creates an instance of memcachedclient .
closes the memcached client connection .
conversion to { @code jsonobject } from java object .
retrieves all the descendants ( forms ) for the { @code formtogettableformsforparam } .
retrieves a property and returns the value as { @code java . lang . string } .
retrieves a property and returns the value as { @code int } .
returns - 1 if there is a problem with conversion .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
gets a comma seperated list of providers from { @code identity } s .
conversion to { @code jsonobject } from java object .
makes use of the fluid core to convert a document into a pdf file .
retrieves the ancestor for the { @code formtogetancestorforparam } .
retrieves all the descendants ( forms ) for the { @code formstogetdescforparam } .
retrieves all the table ( forms ) for the { @code formstogetdescforparam } .
retrieves all the ( fields ) for the { @code formstogetdescforparam } .
retrieves all the ( fields ) for the { @code formstogetdescforparam } .
populate the field values from the cache .
close any clients used during lifetime of {
conversion to { @code jsonobject } from java object .
<p > base { @code tojsonobject } that creates a { @code jsonobject } with the id and serviceticket set . < / p >
converts the { @code long } timestamp into a { @code date } object .
retrieves the value of field { @code fieldnameparam } as a timestamp .
converts the { @code date } object into a { @code long } timestamp .
create a new flow step entry rule .
create a new flow step exit rule .
create a new flow step view rule .
update an existing flow step entry rule .
update an existing flow step exit rule .
update an existing flow step view rule .
compiles the { @code viewrulesyntaxparam } text within the fluid workflow engine .
retrieves the exit rules by step { @code flowstepparam } . name or id can be provided .
compiles and executes the { @code viewrulesyntaxparam } text within the fluid workflow engine .
compiles the { @code entryrulesyntaxparam } text within the fluid workflow engine .
compiles and executes the { @code entryrulesyntaxparam } text within the fluid workflow engine .
moves an entry rule order one up from the current location .
moves an entry rule order one down from the current location .
deletes an step entry rule .
deletes an step exit rule .
deletes an step view rule .
retrieves the next valid syntax rules for { @code inputruleparam } .
performs the necessary login actions against fluid .
performs the necessary login actions against fluid .
performs hmac and encryption to initialize the session .
issue a new { @code apprequesttoken } from provided params .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
combine { @code listtocombineparam } into a single { @code string } .
creates a new { @code userquery } .
updates an existing { @code userquery } .
deletes the { @code userquery } provided . id must be set on the { @code userquery } .
retrieves user query information for the provided { @code userqueryidparam } .
retrieves all user query information .
executes the { @code userquery } { @code querytoexecuteparam } and returns the result information .
executes the { @code userquery } { @code querytoexecuteparam } and returns the result information .
retrieve the form field mappings for electronic form { @code electronicformidparam } .
retrieve the form field mappings for form definition { @code electronicformdefinitionidparam } .
retrieves the form definition id for the electronic form with id { @code electronicformidparam } .
retrieves the form fields { @code values } for the electronic form with id { @code electronicformidparam } .
retrieves the form field value for electronic form { @code formcontaineridparam } .
maps a { @code resultset } to a new instance of { @code formfieldmapping } .
creates a new { @code role } with the privileges inside the { @code roleparam } .
updates an existing { @code role } with the privileges inside the { @code roleparam } .
deletes the { @code role } provided . id must be set on the { @code role } .
retrieves role information for the provided { @code roleidparam } .
retrieves all role information .
conversion to { @code jsonobject } from java object .
executes the { @code commandparams } and returns the result .
executes the { @code objectcommandparam } and returns the result .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > returns the value of the { @code fieldnameparam } requested .
<p > sets the value of the { @code fieldnameparam } requested . <p > if there is an existing value the value will be override with the value of { @code fieldvalueparam } .
<p > sets the value of the { @code fieldnameparam } requested .
<p > determine whether the current { @code form } type / definition is of type { @code formtypeparam }
conversion to { @code jsonobject } from java object .
creates the mapping object required by elastic search when making use of enhanced data - types .
conversion to { @code jsonobject } for storage in elasticcache for { @code form } .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
sends the { @code formtosendtoflowparam } to a { @code flow } in fluid . the return value is the { @code fluiditem } created as a result .
gets the service ticket associated with the fluid session as hex .
convert the byte [] to a hex string as upper case .
conversion to { @code jsonobject } from java object .
create a new text masked field .
create a new text barcode field .
create a new multi choice field .
create a new decimal spinner field .
create a new decimal slider field .
creates a new table field .
update an existing masked text field .
update an existing barcode text field .
update an existing paragraph text field .
update an existing multi choice field .
updates the decimal spinner field .
updates the decimal slider field .
updates a table field .
retrieve a form field via name .
retrieve the form fields via form definition name .
retrieve the form fields via form definition id .
deletes the provided field .
forcefully deletes the provided field .
generates the meta data for a table field .
conversion to { @code jsonobject } from java object .
create a new true false field .
create a new date and time field .
create a new decimal field .
update an existing true false field .
update an existing multi choice field .
update an existing date field .
update an existing user field value .
retrieves field information by { @code fieldidparam } .
deletes a field from fluid .
forcefully deletes a field from fluid .
creates / updates the index { @code indexparam } with mappings provided in { @code fluidformmappingtoupdateparam } .
set the additional properties on the { @code existingpropstoupdateparam } json object .
creates a new index or fetches existing index .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
add a sql input parameter . if the sql inputs is { @code null } a new instance of { @code arraylist } will be created prior to adding the parameter .
creates a new flow with an introduction and exit basic rule .
updates an existing flow .
retrieves a flow by primary key .
retrieves a flow by unique name .
delete an existing flow .
forcefully delete an existing flow .
update an existing global field value .
retrieves field value by { @code fieldnameparam } .
retrieves field value by { @code fieldparam } .
retrieve all the global field values .
gets the ancestor for the { @code electronicformidparam } form .
gets the descendants for the { @code electronicformidparam } form .
gets the descendants for the { @code electronicformidsparam } forms .
retrieves the table field records as { @code list<form > } .
retrieves the form definition and title mapping currently stored in fluid .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
check the { @code getexpirationtime } to confirm whether the ticket has expired .
creates a new { @code usernotification } for a user . the user will be notified through the fluid user dashboard or 3rd party application .
creates a new { @code usernotification } for a user . the user will be notified through the fluid user dashboard or 3rd party application .
marks the { @code usernotificationparam } notification as read .
deletes the { @code usernotification } provided . id must be set on the { @code usernotification } .
deletes the { @code usernotification } provided . id must be set on the { @code usernotification } .
retrieves all { @code read } user notification items for the logged in user .
retrieves all user notification items for user { @code userparam } between date { @code fromdateparam } and { @code todateparam } .
retrieves all user notification items for user { @code userparam } between date { @code fromdateparam } and { @code todateparam } .
generate a new initialization vector with a { @code seedparam } byte count .
generates an hmac from { @code encrypteddataparam } .
generate a derived hmac from { @code encrypteddataparam } using other params .
generate a derived hmac from { @code encrypteddataparam } using { @code keyparam } .
creates a derived version of { @code bytestopoisonparam } .
decrypts the encrypted data .
decrypt { @code datatodecryptparam } using the { @code keyparam } key .
encrypts the { @code datatoencryptparam } data using key { @code keyparam } .
compute sha256 digest from { @code dataparam } .
send the { @code basefluidjsonobjectparam } via web socket .
if the http client is set this will close and clean any connections that needs to be closed .
initiate a new request process .
retrieves the web service url from { @code webserviceurlparam } .
set the { @code echo } value if not set .
generate a verbose exception message .
create a new administrator user for fluid . this function only works if there are no pre - existing admin user .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
gets a access token from auth0 .
gets auth0 normalized user profile info .
retrieves the form fields { @code values } for the electronic form with id { @code electronicformidparam } .
conversion to { @code jsonobject } from java object .
performs an http request with { @code postfixurlparam } on { @code httpclientparam } .
performs an http - get request with { @code postfixurlparam } .
performs an http - get request with { @code postfixurlparam } .
performs an http - post request with { @code postfixurlparam } .
performs an http - post request with { @code postfixurlparam } .
performs an http - post request with { @code postfixurlparam } .
performs an http - delete request with { @code postfixurlparam } .
performs an http - delete request with { @code postfixurlparam } .
performs an http - post request with { @code postfixurlparam } making use of form params as { @code formnamevaluesparam } .
performs an http - put request with { @code postfixurlparam } .
performs an http - put request with { @code postfixurlparam } .
submit a json based http request body with json as a response .
submit a html form based http request body with json as a response .
submit the { @code stringparam } as http request body with json as a response .
submit the { @code stringparam } as http request body with json as a response .
add params to the { @code builderparam } and returns { @code builderparam } .
get a text based response handler used mainly for json .
translates a string into { @code application / x - www - form - urlencoded } format using a specific encoding scheme . this method uses the supplied encoding scheme to obtain the bytes for unsafe characters .
performs a http get against the connection test web service to confirm whether the connection is valid .
inspects the { @code basedomainparam } to confirm whether the base domain is of type { @code error } .
creates a new http client .
retrieves the system property for the fluid specific trust store .
close the sql and elasticsearch connection but not in a separate {
close the sql connection .
retrieves sqltype from the local { @code connection } .
closes the { @code preparedstatementparam } and { @code resultsetparam } .
closes the { @code preparedstatementparam } .
retrieves the form container by primary key .
creates a new fluid item that will be sent to the { @code flowjobitemparam } flow .
retrieves items for the provided jobview .
send a workflow item currently in an { @code assignment } step to
send a form item to be part of a workflow .
callback hook for connection close events .
callback hook for message events . this method will be invoked when a client sends a message .
send a message .
send a message as text .
closes the web socket user session .
<p > base { @code tojsonobject } that creates a { @code jsonobject } with the id and serviceticket set . < / p >
retrieves all the ancestors ( forms ) for the { @code formtogetancestorsforforparam } .
conversion to { @code jsonobject } from java object .
executes a native sql query on the remote fluid instance .
gets the single instance of the { @code syntaxfactory } .
returns the { @code isyntax } from the { @code sqltypeparam } and { @code aliasparam } .
returns the { @code isyntax } from the { @code sqltypeparam } and { @code formfieldmappingparam } .
checks whether { @code texttocheckparam } is plain .
checks whether { @code texttocheckparam } is select many .
conversion to { @code jsonobject } from java object .
conversion to { @code jsonobject } from java object .
request a new license based on the license request input .
applies a generated license for the server .
conversion to { @code jsonobject } from java object .
create a new plain text field .
create a new true false field .
create a new paragraph text field .
create a new paragraph html field .
create a new multi choice field .
create a new multi choice select many field .
create a new date only field .
create a new date and time field .
create a new decimal field .
update an existing text field .
update an existing true false field .
update an existing paragraph text field .
update an existing paragraph html field .
update an existing multi choice field .
update an existing date field .
update an existing date and time field .
update an existing decimal field .
update an existing route field value .
create an new route field value .
retrieves field information by { @code fieldidparam } .
retrieve the route field values for { @code fluiditemparam } .
deletes a field from fluid .
forcefully deletes a field from fluid .
convert the { @code sqlformfieldutil . formfieldmapping } to { @code field } .
utility method to convert from a { @code sqlformfieldutil . formfieldmapping } to a { @code field } .
retrieves a configuration by key .
retrieves all configurations .
conversion to { @code jsonobject } from java object .
creates a new ( form ) for the { @code formtocreateparam } .
gets a comma seperated list of providers from { @code identity } s .
uploads a new attachment . if there is an existing attachment with the same name a new version will be uploaded .
retrieves a attachment by primary key .
retrieves all the attachments associated with form { @code formparam } .
delete an existing attachment .
forcefully delete an existing attachment .
compares two different objects of this type .
tries to match the received {
replaces possible {
parses the xsd file represented by the received inputstream .
creates a new class loader replacing the current one having another path added to the classpath . the new path is the path to the jar received in this class constructor .
this method is used to parse {
verifies if a given {
this method resolves all the remaining {
replaces a single {
saves an occurrence of an element which couldn t be resolved in the {
adds a new file to the parsing queue . this new file appears by having xsd : import or xsd : include tags in the original file to parse .
asserts if the current object has the name attribute when not being a direct child of the xsdschema element which is not allowed throwing an exception in that case .
asserts if the current has no value for its name attribute while being a direct child of the top level xsdschema element which is required . throws an exception if no name is present .
compares two different objects of this type .
this method obtains all the restrictions for the current {
joins two distinct {
updates the existing {
checks for any restriction overlap between two different {
asserts if the current object has a ref attribute at the same time as either a simpletype as children a form attribute or a type attribute . throws an exception in that case .
receives a {
parses a xsd file and all its containing xsd elements . this code iterates on the nodes and parses the supported ones . the supported types are all the xsd types that have their tag present in the {
this function uses dom to obtain a list of nodes from a xsd file .
asserts if the current object has a form attribute while being a direct child of the top level xsdschema element which isn t allowed throwing an exception in that case .
asserts if the current object has a ref attribute while being a direct child of the top level xsdschema element which isn t allowed throwing an exception in that case .
this method aims to replace the previously created {
the base code for parsing any {
converts a {
this method iterates on the current element children and replaces any {
in special cases such as {
compares two different objects of this type .
verifies if a given value is present in a given {
checks if the maxoccurs attribute is unbounded or an {
validates if a given string is a non negative {
validates if a given string is a non negative {
validates if a given string is a positive {
validates if a given {
validates if a given {
obtains the default value of the {
obtains the default value of the {
obtains the default value of the {
this method creates a referencebase object that serves as a wrapper to {
this method should always receive two elements one to replace the {
if t is assignable from value then return the value . otherwise tries to create an instance of this type using the provided argument .
construct a cli from an annotated interface definition
construct a cli from an annotated class
parse arguments from an annotated interface definition
parse arguments from an annotated class instance
{
note : the following methods are used to get a string representation of the different pojo ( while handling null value )
package protected for testing purposess
add a fixed view to appear at the top of the list . if this method is called more than once the views will appear in the order they were added . views added using this call can take focus if they want . <p > note : when first introduced this method could only be called before setting the adapter with { @link #setadapter ( listadapter ) } . starting with { @link android . os . build . version_codes#kitkat } this method may be called at any time . if the listview s adapter does not extend { @link footerviewgridadapter } it will be wrapped with a supporting instance of { @link android . widget . wrapperlistadapter } .
removes a previously - added footer view .
sets the position ( @a x @a y @a z ) of the start of the line segment to choose values along .
sets the position ( @a x @a y @a z ) of the end of the line segment to choose values along .
returns the output value from the noise module given the one - dimensional coordinate of the specified input value located on the line segment .
returns the output value from the noise module given the ( @a x @a z ) coordinates of the specified input value located on the surface of the plane .
generates a gradient - coherent - noise value from the coordinates of a three - dimensional input value .
generates a gradient - noise value from the coordinates of a three - dimensional input value and the integer coordinates of a nearby three - dimensional value .
generates an integer - noise value from the coordinates of a three - dimensional input value .
generates a value - noise value from the coordinates of a three - dimensional input value .
returns the output value from the noise module given the ( angle height ) coordinates of the specified input value located on the surface of the cylinder .
returns the output value from the noise module given the ( latitude longitude ) coordinates of the specified input value located on the surface of the sphere .
performs cubic interpolation between two values bound between two other values
maps a value onto a quitnic s - curve
/ * calculate the scale and biased to be a applied during range#getvalue ( int x int y int z ) should be called when the bounds are modified
configure bounds for range module
processes an single event by looping available plugins .
processes a specific event on specified plugin .
extracts list of instanceids from {
extracts the accountid .
reads the given responseelements and extracts information based on given pattern . <br / > if responseelements is null or empty you can handle the {
reads the given responseelements and extracts information based on given pattern . <br / > if responseelements is null or empty raises {
true if rule matches a violation and should be whitelisted .
builds the prefix that will be prepended to the bucketname <br / > something like 123456789 / eu - west - 1 / 2015 / 06 / 12 /
get the eventserializer based on user s configuration .
{
configure scopes for specific controller / httpmethods / roles here .
does this extension support injection for parameters of the type described by the given { @code parametercontext } ?
provides a value for any parameter context which has passed the { @link #supportsparameter ( parametercontext extensioncontext ) } gate .
maps the random requirements expressed by the given { @code annotation } to invocations on { @link #random } .
create a file within the temporary folder root .
create a directory within the temporary folder root .
deletes the { @link #rootfolder } and all of its contents . this is package protected because a { @link temporaryfolder } s lifecycle is expected to be controlled by its associated extension .
does this extension support injection for parameters of the type described by the given { @code parametercontext } ?
provides a value for any parameter context which has passed the { @link #supportsparameter ( parametercontext extensioncontext ) } gate .
maps the expectations expressed in the given { @code annotation } to a { @link predicate } .
creates a { @link extensioncontext . store } for a given { @code extensioncontext } . a { @link extensioncontext . store } is bound to an { @link extensioncontext } so different test invocations do not share the same store . for example a test invocation on { @code classa . testmethoda } will have a different { @link extensioncontext . store } instance to that associated with a test invocation on { @code classa . testmethodb } or test invocation on { @code classc . testmethodc } .
creates a { @link extensioncontext . namespace } in which extension state is stored on creation for post execution destruction . storing data in a custom namespace prevents accidental cross pollination of data between extensions and between different invocations within the lifecycle of a single extension .
if the current test class has a system property annotation ( s ) then create a { @link restorecontext } representing the annotation ( s ) . this causes the requested system properties to be set and retains a copy of pre - set values for reinstatement after test execution .
if a { @link restorecontext } exists for the given { @code extensioncontext } then restore it i . e . unset any system properties which were set in { @link #beforeall ( extensioncontext ) } for this { @code extensioncontext } and reinstate original value if applicable .
get a collection of { @link systemproperty } for the given { @code annotatedelement } . if the given { @code annotatedelement } has no such annotations then an empty list is returned if the given { @code annotatedelement } is annotated with { @link systemproperty } then a list with one element is returned if the given { @code annotatedelement } is annotated with { @link systemproperties } then a list with one element for each of the repeated { @link systemproperty } values is returned .
reverse the system property sets performed on behalf of this restore context .
}
/ * public static set<string > getdependenciesofjar ( final inputstream pinputstream ) throws ioexception {
__ / __ / __ / __ / __ / __ / __ / __ / __ / __ /
__ / __ / __ / __ / __ / __ / __ / __ / __ / __ /
__ / __ / __ / __ / __ / __ / __ / __ / __ / __ /
__ / __ / __ / __ / __ / __ / __ / __ / __ / __ /
create the map implementation
add an object to the collection .
create a <tt > softobject< / tt > for the given object .
set a property
get a property
get an array style property
transition to the next state given the name of a valid transition .
iterate through the gcqueue for for any cleared reference remove the associated value from the underlying set .
get the information for a type
get the information for a class
get the information for a parameterized type
get the information for a type variable
peek into the cache
put a result into the cache
get the information for a class
peek into the cache
put a result into the cache
get the cache for the classloader
prints the composite message and the embedded stack trace to the specified print stream .
prints the composite message and the embedded stack trace to the specified print writer .
build a class [] from a comma / whitespace seperated list of classes
override replaceobject to check for remote objects that are not remotestubs .
called by the thread pool executor
set thetask for this wrapper
notify the task it has been accepted
notify the task it has been rejected
notify the task it has started
notify the task it has completed
stop the task
called by a thread that is not the workerqueue thread this method queues the job and if necessary wakes up this worker queue that is waiting in {
never call this method only override in subclasses to perform job getting in a specific way normally tied to the data structure holding the jobs .
never call this method only override in subclasses to perform job adding in a specific way normally tied to the data structure holding the jobs .
a utility method to convert a string name to a blockingmode
overriden to return the indentity instance of blockingmode based on the stream type int value . this ensures that blockingmode enums can be compared using == .
create a <tt > weakobject< / tt > for the given object .
public --------------------------------------------------------
starting from baseurl that should point to a directory populate the resultlist with the contents that pass the filter ( in the form of urls ) and possibly recurse into subdris not containing a . in their name .
create a url by concatenating the baseurlstring that should end at / the filename and a trailing slash if it points to a directory
setup readers .
add a new catalogreader to the catalog .
copies the reader list from the current catalog to a new catalog .
create a new catalog object .
load the system catalog files .
parse a catalog file augmenting internal data structures .
parse a catalog file augmenting internal data structures .
parse a catalog document augmenting internal data structures .
parse all of the pending catalogs .
parse a single catalog file augmenting internal data structures .
cleanup and process a catalog entry .
handle unknown catalogentry types .
parse all subordinate catalogs .
return the applicable doctype system identifier .
return the applicable document entry .
return the applicable public or system identifier .
return the applicable public or system identifier .
return the applicable system system identifier .
return the applicable system system identifier in this catalog .
return the applicable uri .
return the applicable uri in this catalog .
search the subordinate catalogs in order looking for a match .
construct an absolute uri from a relative one using the current base uri .
perform character normalization on a uri reference .
perform % - encoding on a single byte .
add to the current list of delegated catalogs .
create a server socket on the specified port ( port 0 indicates an anonymous port ) .
build a int [] from comma or eol seperated elements
safely create a new softvalueref
returns a properties object initialized with current getastext value interpretted as a . properties file contents . this replaces any references of the form $ { x } with the corresponding system property .
fire onthrowable to all registered listeners .
add a throwable that is to be handled .
create the list implementation
add an element to the set .
create a server socket on the specified port ( port 0 indicates an anonymous port ) .
create a server socket on the specified port ( port 0 indicates an anonymous port ) .
a timertask is less than another if it will be scheduled before .
returns a inetaddress for the input object converted to a string .
check if a file is acceptible .
dereference the object at the given index .
replaces the element at the specified position in this list with the specified element .
inserts the specified element at the specified position in this list ( optional operation ) . shifts the element currently at that position ( if any ) and any subsequent elements to the right ( adds one to their indices ) .
removes the element at the specified position in this list ( optional operation ) . shifts any subsequent elements to the left ( subtracts one from their indices ) . returns the element that was removed from the list .
maintains the collection by removing garbage collected objects .
adds a new catalog entry type .
lookup an entry type
find out how many arguments an entry is required to have .
get an entry argument .
inserts the given element in this heap . @param obj
removes and returns the least element of this heap . @return the extracted object
map the argument text into and byte using byte . decode .
set the context classloader for the given thread
a new node has been added at index <code > index< / code > . normalize the tree by moving the new node up the tree .
swap two nodes in the tree .
remove a node from the tree and normalize .
recursive cleanup of a timeoutimpl
check invariants of the queue .
load a class by asking the parent
preload the jboss specific protocol handlers so that url knows about them even if the handler factory is changed .
search the handlerpkgs for urlstreamhandler classes matching the pkg + protocol + . handler naming convention .
see if the java . protocol . handler . pkgs system property has changed and if it has parse it to update the handlerpkgs array .
returns a class for the input object converted to a string .
create the set implementation
attempt to close an array of <tt > inputstream< / tt > s .
return a synchronized counter .
returns a directional counter .
are we in an extension namespace?
the sax <code > startdocument< / code > method does nothing .
the sax <code > startelement< / code > method recognizes elements from the plain catalog format and instantiates catalogentry objects for them .
the sax <code > endelement< / code > method does nothing .
checks whether a notification is required and notifies as appropriate
lookup a value from the nonserializablefactory map .
lookup a value from the nonserializablefactory map .
a convenience method that simplifies the process of rebinding a non - serializable object into a jndi context .
a convenience method that simplifies the process of rebinding a non - serializable object into a jndi context .
a convenience method that simplifies the process of rebinding a non - serializable object into a jndi context . this version binds the target object into the default intitialcontext using name path .
transform the obj reference bound into the jndi namespace into the actual non - serializable object .
substitute sub - strings in side of a string .
split up a string into multiple strings based on a delimiter .
convert and join an array of bytes into one string .
the default tostring implementation of an object
trim all occurences of the supplied leading character from the given string .
trim all occurences of the supplied leading character from the given string .
returns a blockingmode for the input object converted to a string .
check if a file is acceptible .
initializes the cache for use . prior to this the cache has no store .
get the cache value for key if it has not expired . if the timedentry is expired its destroy method is called and then removed from the cache .
get the cache value for key . this method does not check to see if the entry has expired .
insert a value into the cache . in order to have the cache entry reshresh itself value would have to implement timedentry and implement the required refresh () method logic .
remove the entry associated with key and call destroy on the entry if found .
remove all entries from the cache .
get the list of keys for entries that are not expired .
set the cache timer resolution
get the raw timedentry for key without performing any expiration check .
returns an iterator over the children of the given element with the given tag name .
gets the child of the specified element having the specified unique name . if there are more than one children elements with the same name and exception is thrown .
gets the child of the specified element having the specified name . if the child with this name doesn t exist then null is returned instead .
get the content of the given element .
macro to get the content of a unique child element .
macro to get the content of an optional child element .
threadpool ----------------------------------------------------
this resets the work queue capacity . this requires recreating the work queue and threadpoolexecutor so this needs to be called before doing any work with the pool .
for backward compatibility with the previous string based mode
for backward compatibility with the previous string based mode this is needed for microcontainer as it gets confused with overloaded setters .
execute a task
the sax <code > startelement< / code > method recognizes elements from the plain catalog format and instantiates catalogentry objects for them .
schedule the given timertask to be executed after <code > delay< / code > milliseconds .
workerqueue overrides ---------------------------------------------------
map the argument text into and integer using integer . valueof .
cleanup and process a catalog entry .
return the applicable uri .
return the applicable system system identifier resorting to external resolvers if necessary .
return the applicable public or system identifier resorting to external resolvers if necessary .
query an external rfc2483 resolver for a system identifier .
query an external rfc2483 resolver for a public identifier .
query an external rfc2483 resolver .
append two vectors returning the result .
find the urns for a given system identifier in all catalogs .
find the urn for a given system identifier .
return the applicable system system identifiers .
return all applicable system system identifiers in this catalog .
search the subordinate catalogs in order looking for all match .
set the saxcatalogparser class for the given namespace / root element type .
get the saxcatalogparser class for the given namespace / root element type .
parse an xml catalog file .
parse an xml catalog stream .
the sax <code > startelement< / code > method .
the sax2 <code > startelement< / code > method .
the sax2 <code > endelement< / code > method . does nothing .
the sax <code > processinginstruction< / code > method . does nothing .
the sax <code > startprefixmapping< / code > method . does nothing .
entity resolver
sync implementation ----------------------------------------------
protected -----------------------------------------------------
checks if the underlying file for this connection exists .
we should probably disallow this?
provides support for the following headers :
compareandset next field
helps out a deletion by appending marker or unlinking from predecessor . this is called during traversals when value field seen to be null .
return value if this node contains a valid key - value pair else null .
create and return a new snapshotentry holding current mapping if this node holds a valid value else null
compareandset right field
tries to cas right field to skip over apparent successor succ . fails ( forcing a retraversal by caller ) if this node is known to be deleted .
create logger .
list the set of jbossobjects
get the class short name
implementation of string
get the default <tt > propertymap< / tt > .
add a property listener .
add an array of property listeners .
load properties from a map .
load properties from a map .
load properties from a <tt > propertyreader< / tt > .
load properties from a <tt > propertyreader< / tt > specifed by the given class name .
set a property .
remove a property .
get an array style property .
return an iterator over all contained property names .
get a property group for the given property base .
get a compatible constructor for the given value type
copy an serializable object deeply .
dereference the given object if it is <i > non - null< / i > and is an instance of <code > reference< / code > . if the object is <i > null< / i > then <i > null< / i > is returned . if the object is not an instance of <code > reference< / code > then the object is returned .
dereference an object
@return an object array for the given object .
initialized listener lists and the jndi properties cache map
called by setproperty to update the jndimap cache values .
set a property .
remove a property .
returns a set of keys for all entries in this group and optionally all of the keys in the defaults map .
returns a set of entrys for all entries in this group and optionally all of the entrys in the defaults map .
add a property listener .
add an array of property listeners .
remove a property listener .
fire a property added event to the given list of listeners .
fire a property removed event to the given list of listeners .
fire a property changed event to the given list of listeners .
fire a property changed event to all listeners .
make a optionaly prefixed property name .
load properties from a map .
load properties from a propertyreader .
load properties from a propertyreader specifed by the given class name .
set a property .
get an array style property .
get a property group for the given property base at the given index .
register the mapping from the public id / system id to the dtd / xsd file name . this overwrites any existing mapping .
returns dtd / schema inputsource . the resolution logic is :
returns the boolean value to inform id dtd was found in the xml file or not
load the schema from the class entity to schema file mapping . @see #registerentity ( string string )
attempt to use the systemid as a url from which the schema can be read . this checks to see whether the systemid is a key to an entry in the class entity map .
attempt to use the systemid as a url from which the schema can be read . this uses the systemid as a url .
resolve the systemid as a classpath resource . if not found the systemid is simply used as a classpath resource name .
look for the resource name on the thread context loader resource path . this first simply tries the resource name as is and if not found the resource is prepended with either dtd / or schema / depending on whether the resource ends in . dtd or . xsd .
sets as an element created by a string .
normalize a public identifier .
encode a public identifier as a publicid urn .
decode a publicid urn into a public identifier .
replace one string with another .
start the watch .
stop the watch .
return a synchronized stop watch .
compares this object with the specified object for order .
generate a hash code for a byte array .
generate a hash code for an object array .
initializes the cache creating all required objects and initializing their values .
coerce and set specified value to field .
notifies that this listener was bound to a property .
start parsing a text catalog file . the file is actually read and parsed as needed by <code > nextentry< / code > . < / p >
return the next token in the catalog file .
returns an iterator containing the <i > union< / i > of all of the elements in the given iterator array .
setup the parsing formats . offered as a separate static method to allow testing of locale changes since simpledateformat will use the default locale upon construction . should not be normally used!
parse the text into a java . util . date by trying one by one the registered dateformat ( s ) .
add a vertex to the graph
set a root vertex . if root does no exist in the graph it is added .
insert a directed weighted edge<t > into the graph .
insert a bidirectional edge<t > in the graph
remove a vertex from the graph
remove an edge<t > from the graph
perform a depth first serach using recursion .
perform a depth first serach using recursion . the search may be cut short if the visitor throws an exception . @param <e > exception type
perform a breadth first search of this graph starting at v . the vist may be cut short if visitor throws an exception during a vist callback . @param <e > exception type
find the spanning tree using a dfs starting from v .
search the verticies for one with data .
search the graph for cycles . in order to detect cycles we use a modified depth first search called a colored dfs . all nodes are initially marked white . when a node is encountered it is marked grey and when its descendants are completely visited it is marked black . if a grey node is ever encountered then there is a cycle .
the sax <code > startelement< / code > method recognizes elements from the plain catalog format and instantiates catalogentry objects for them .
the sax <code > endelement< / code > method does nothing .
normalizes the given string .
parse the given xml string and return the root element
parse the given xml stream and return the root element
parse the given input source and return the root element
create an element for a given name
transform the giveen qualified name into a qname
get the value from the given attribute @param el @param attrname
get the value from the given attribute @param el @param attrname
copy attributes between elements
true if the node has child elements
gets child elements
get the concatenated text content or null .
gets the child elements for a given local name without namespace
gets parent element or null if there is none
add a transaction waiting for a lock
read a catalog from an input stream .
read the catalog behind the specified url .
return the current host internet address .
tries to resolve the entity using the thread specific catolog resolvers
seach the path for oasis catalog files . the classpath of <code > thread . currentthread () . getcontextclassloader () < / code > is used for the lookup . @return the url where the <code > jax - ws - catalog . xml< / code > is located @throws ioexception if the catalog files cannot be loaded
jboss lifecycle
sets the system property to a class when the class is available .
format a string buffer containing the class interfaces codesource and classloader information for the given object clazz .
use reflection to access a url [] geturls or url [] getclasspath method so that non - urlclassloader class loaders or class loaders that override geturls to return null or empty can provide the true classpath info .
describe the class of an object
describe the class of an object
describe the class
get the short name of the specified class by striping off the package name .
get the package name of the specified class .
force the given class to be loaded fully .
get the wrapper class for the given primitive type .
populates a list with all the interfaces implemented by the argument class c and all its superclasses .
returns an array containing all the unique interfaces implemented by the argument class c and all its superclasses . interfaces that appear multiple times through inheritence are only accounted for once .
check if the given class is a primitive wrapper class .
instantiate a java class object
this method acts equivalently to invoking <code > thread . currentthread () . getcontextclassloader () . loadclass ( classname ) ; < / code > but it also supports primitive types and array classes of object types or primitive types .
this method acts equivalently to invoking classloader . loadclass ( classname ) but it also supports primitive types and array classes of object types or primitive types .
convert a list of strings from an interator into an array of classes ( the strings are taken as classnames ) .
returns attribute s getter method . if the method not found then nosuchmethodexception will be thrown .
returns attribute s setter method . if the method not found then nosuchmethodexception will be thrown .
convert a given string into the appropriate class .
get a system property
map the argument text into and byte using byte . decode .
get an array of filenames to load .
check if a file is acceptible .
maintain the elements in the set . removes objects from the set that have been reclaimed due to gc .
return an iteration over the elements in the set .
add an element to the set .
create a url lister for the supplied protocol
check if a file is acceptible .
print debug message ( if the debug level is high enough ) .
print debug message ( if the debug level is high enough ) .
set a property .
get a property
remove a property .
returns an entry set for all properties in this group .
add a bound property listener .
remove a bound property listener .
creates a { @link fieldboundpropertylistener } for the field and property name and adds it the underlying property group .
creates a { @link methodboundpropertylistener } for the method and property name and adds it the underlying property group .
start parsing an oasis tr9401 open catalog file . the file is actually read and parsed as needed by <code > nextentry< / code > .
get the information for a class
get the cache for the classloader
whether a string is interpreted as the null value
locate a value editor for a given target type .
get a value editor for a given target type .
get a value editor for a given target type .
register an editor class to be used to editor values of a given target class .
convert a string value into the true value for typename using the propertyeditor associated with typename .
this method takes the properties found in the given beanprops to the bean using the property editor registered for the property . any property in beanprops that does not have an associated java bean property will result in an introspectionexception . the string property values are converted to the true java bean property type using the java bean propertyeditor framework . if a property in beanprops does not have a propertyeditor registered it will be ignored .
this method takes the properties found in the given beanprops to the bean using the property editor registered for the property . any property in beanprops that does not have an associated java bean property will result in an introspectionexception . the string property values are converted to the true java bean property type using the java bean propertyeditor framework . if a property in beanprops does not have a propertyeditor registered it will be ignored .
create a server socket on the specified port ( port 0 indicates an anonymous port ) .
retrieve the context classloader for the given thread
detects exception contains is or a applicationdeadlockexception .
schedules a new timeout .
timeout worker method .
create a subcontext including any intermediate contexts .
unbinds a name from ctx and removes parents if they are empty
lookup an object in the default initial context
lookup an object in the given context
lookup an object in the given context
create a link
create a link
remove the link ref
remove the link ref
checks an object implements the given class
append class info
lookup an allowed transition given its name .
load the properties from the propertyfile and build the resources from it .
obtain the verbosity setting from the properties .
obtain the relativecatalogs setting from the properties .
obtain the list of catalog files from the properties .
return the current list of catalog files .
obtain the preferpublic setting from the properties .
obtain the static - catalog setting from the properties .
@return a new catalog instance .
@return a catalog instance .
<p > obtain the oasisxmlcatalogpi setting from the properties . < / p >
obtain the catalog class name setting from the properties . @return the name
sax resolveentity api .
transformer resolve api .
attempt to construct an absolute uri
use the thread context class loader to resolve the class
get the <tt > propertydescriptor< / tt > for the given bean property name .
coerce and invoke the property setter method on the instance .
notifies that this listener was bound to a property .
returns the prefix part of a qname or the empty string ( not null ) if the name has no prefix .
returns the localname part of a qname which is the whole name if it has no prefix .
returns the namespace uri for the specified prefix at the specified context node .
returns the namespace uri for the namespace to which the element belongs .
map the argument text into and integer using integer . valueof .
create a list from an enumeration
get an input stream for the given filename .
load properties from a file into a properties map .
read properties from each specified filename
add an edge to the vertex . if edge . from is this vertex its an outgoing edge . if edge . to is this vertex its an incoming edge . if neither from or to is this vertex the edge is not added .
add an outgoing edge ending at to .
add an incoming edge starting at from
check the vertex for either an incoming or outgoing edge mathcing e .
remove an edge from this vertex
search the outgoing edges looking for an edge whose s edge . to == dest .
search the outgoing edges for a match to e .
what is the cost from this vertext to the dest vertex .
<p > this function will create a jar archive containing the src file / directory . the archive will be written to the specified outputstream . < / p >
<p > this function will create a jar archive containing the src file / directory . the archive will be written to the specified outputstream . directories are processed recursively applying the specified filter if it exists .
<p > this function will create a jar archive containing the src file / directory . the archive will be written to the specified outputstream . directories are processed recursively applying the specified filter if it exists .
this recursive method writes all matching files and directories to the jar output stream .
given a url check if its a jar url ( jar : <url > ! / archive ) and if it is extract the archive entry into the given dest directory and return a file url to its location . if jarurl is not a jar url then it is simply returned as the url for the jar .
check if there are more elements .
forwards an event into state machine . state machine will deliver the event to a handler methods responsible for its processing . if there is no handler method found then event gets silently ignored and this call has no effect .
moves state machine in a new given state . if state machine is already in that state then this method has no effect . otherwise if exists <code > type . onexit< / code > event handler for the current state is called first and then <code > type . onentry< / code > event handler for new state is called .
enables traces and sets tag to be used for <code > log . d () < / code > output . <code > tinymachine< / code > will trace all processed events and state transitions including events for which handlers in current state are missed .
-- implementation
installs the complete jvmtypeprovider including index access into the { @link resourceset } . the lookup classpath is enhanced with the given tmp directory .
installs the jvmtypeprovider optionally including index access into the {
performs the actual installation of the jvmtypeprovider .
version 2 . 2 . x
dispatch the given action . dispatching is always done on the javafx application thread even if this method is called from another thread .
a filtered event - stream of actions of the given type .
taken from mvvmfx
update all views by invoking the update function ( {
update all views that match the given predicate by invoking the update function ( {
this method can be used to subscribe to actions of a given type . the subscription is managed by the { @link dispatcher } .
return an appropriate {
log a message at level verbose according to the specified format and argument . <p > <p > this form avoids superfluous object creation when the logger is disabled for level verbose . < / p >
log a message at level verbose according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the verbose level . < / p >
log a message at level verbose according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the verbose level . < / p >
log an exception ( throwable ) at level verbose with an accompanying message .
log a message at level debug according to the specified format and argument . <p > <p > this form avoids superfluous object creation when the logger is disabled for level debug . < / p >
log a message at level debug according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the debug level . < / p >
log a message at level debug according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the debug level . < / p >
log an exception ( throwable ) at level debug with an accompanying message .
log a message at level info according to the specified format and argument . <p > <p > this form avoids superfluous object creation when the logger is disabled for the info level . < / p >
log a message at the info level according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the info level . < / p >
log a message at level info according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the info level . < / p >
log an exception ( throwable ) at the info level with an accompanying message .
log a message at the warn level according to the specified format and argument . <p > <p > this form avoids superfluous object creation when the logger is disabled for the warn level . < / p >
log a message at the warn level according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the warn level . < / p >
log a message at level warn according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the warn level . < / p >
log an exception ( throwable ) at the warn level with an accompanying message .
log a message at the error level according to the specified format and argument . <p > <p > this form avoids superfluous object creation when the logger is disabled for the error level . < / p >
log a message at the error level according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the error level . < / p >
log a message at level error according to the specified format and arguments . <p > <p > this form avoids superfluous object creation when the logger is disabled for the error level . < / p >
log an exception ( throwable ) at the error level with an accompanying message .
one to many
strict one to many
many to one
strict many to one
strict one to many
strict one to one
bootstrap the slf4j root logger with a configured { @link com . getsentry . raven . logback . sentryappender } .
bootstrap the slf4j root logger with a configured { @link com . getsentry . raven . logback . sentryappender } .
bootstrap the slf4j root logger with a configured { @link com . getsentry . raven . logback . sentryappender } .
the last modified time of a page is the most recent of : <ol > <li > {
uses the page settings .
assert that the generated command matches the specified command .
attempt to retrieve the parameter ( <code >
 sogou  rmmseg 
- dmode = simple default is complex
 wordsxxx . dic

 str char
 wordsfile  .

<p / >  50m /   oom
word 
sen [ offset ]  taillen  .
 words . dic  jar   defalut 
 bufsentence  .
 stringbuilder  char []

- dmode = simple default is complex - dfile . encode = utf - 8 or other
word length
3
variance of word lengths  
sum of degree of morphemic freedom of one - character
 chunks  .
chs [ offset ]  taillenchar .
 .
<br / >  chs [ offset ]   chs [ offset ]  cns [ cnidx ]
  . <br / >  chs [ offset ]   taillens [ taillensidx ]  . <br / >  chs [ offset ]  cns [ cnidx ] .

you can take this and extend for your setup if you need more .
overloaded method that uses for host : {
you can take this and extend for your setup if you need more .
overloaded method that uses for host : {
returns a map which contains only those arguments that the superclass understands .
load words from jdbc
check if the datasource is able to provide connections .
{
{
inform { @link searcheraware } about a new searcher .
inform { @link searcheraware } filter factories in a { @link tokenizerchain } about a new searcher .
lookup data source .
initializes the database and lookups a { @linkplain datasource } in jndi .
create the { @link jdbcreader } from configuration .
iterables - complete
arrays - complete
lists - complete
collections - complete
todo variations
todo ut
queues : incomplete
todo ut
deques : incomplete
todo ut
sorted sets : incomplete
todo ut
todo variations and ut
todo variations
/ optionals
todo rethink putting this into the fixture class
todo check case when new x<integer > () . getvalue () and new x<string > () . getvalue () afterwards - does this work?
todo add generics checks
///////////// arrays
///////////// hashsets
////// tree sets
////// sets
///// sorted sets
///////////////////////////// hash maps
///////////////////////////// maps
////////////////// queues
options
eithers - left
eithers - right
validations - failures
validations - successful
try - successful
registers a database to further execute sql commands
simply runs a sql command used for udpates inserts which the result doesn t matter .
used generally when the result is assigned to a variable
interprets a strongly - typed number array to array of booleans . if a value found in the array is greater than 0 return true false otherwise .
executes a query which returns all rows in the entity table that match the fields of the example object having values other than the defaults .
/ * convenience methods for comparing equality of each wrapper type
upgrades the table that represents the associated entity . this will typically be an alter table statement .
backs up the current table to a csv file .
restores a table from a text file .
/ * cursor wrapper methods which bind to primitive type columns and return the corresponding wrapper type which may be null
the default content for this activity has a textview that is shown when the list is empty . if you would like to change the text call this method to supply the text it should use .
dumps a database table to a csv file in the default location . returns the number of rows written to the file .
adds an expression to this select clause with support for constructor expressions .
adds an expression to this select clause with support for constructor expressions .
adds expressions to this select clause with support for constructor expressions .
adds expressions to this select clause with support for constructor expressions .
returns a { @link string } for a csv column enclosed in double quotes if required .
removes enclosing quotes and unescapes double quotes
returns values from a csv string .
obtains the next value from a { @link stringreader } .
parses a csv row containing name = value pairs .
returns a string containing a comma - separated list of name = value pairs from a map .
joins items of a text list separating items by comma .
joins items of a text array separating items by comma .
renders this object as { @literal jpql } fragment .
populate the model of a database and its associated tables from a file in support of incremental compilation .
write the database info and associated tables to a file in support of incremental compilation .
verifies that the entity has exactly one id field of type long .
trying to get class<? > from an annotation raises an exception see http : // stackoverflow . com / questions / 7687829 / java - 6 - annotation - processing - getting - a - class - from - an - annotation
builds a basedaomodel from the class passed as attribute basedaoclass of the annotation entity
morph bind type like int == > int so it can be used in a cursor getxxx method name . never called at runtime .
capitalizes the first letter to create a valid getter / setter name .
attempts to import a database table from a csv file in the default location .
attempts to import a database table from an { @link inputstream } formatted as a csv file . does all inserts in a single transaction for efficiency and so that all inserts will succeed or fail together .
parse the values in a csv row map them to the table column order and insert . uses { @link inserthelper } so it may be called repeatedly within a transaction for max performance .
calls { @link tablehelper#oncreate ( sqlitedatabase ) } for each tablehelper .
calls a method on each tablehelper depending on the { @link upgradestrategy } . in order to prevent recursive calls to getdatabase () this method must pass the db parameter through to any other methods that need it .
calls { @link tablehelper#onupgrade ( sqlitedatabase int int ) } for each tablehelper . override this method to implement your own upgrade strategy .
backs up all tables to csv drops and recreates them then restores them from csv . by default creates csv filenames with no suffix . you could override this method to supply a timestamp suffix ( make sure it s the same for both backup and restore ) but beware that this could cause backup files to proliferate . ideally this method should clean up backup files after the database has been restored .
backup all tables to csv files one per table
restore all tables from csv files one per table
read the current model state from a file in support of incremental compilation . this is necessary because the annotation processor has access to only classes which have been annotated ( and any resulting generated classes on subsequent rounds ) but databasehelper classes aren t available when doing incremental compilation on a new @entity .
write the current model state to a file in support of incremental compilation .
register a custom { @link typeconverter } for a given data ( field ) type . this method is called at compile time by the annotation processor . in order for the typeconverter to be visible it must be in a jar on the client project s annotation factory classpath .
returns a jpa query with all previously specified parameters added .
returns a jpa typedquery with all previously specified parameters added .
adds the given parameter to the builder . all parameters will added to the jpa query returned by a call to { @link #createquery ( entitymanager ) } or { @link #createquery ( entitymanager class ) } .
adds the given parameter to the builder . all parameters will added to the jpa query returned by a call to { @link #createquery ( entitymanager ) } or { @link #createquery ( entitymanager class ) } .
adds the given parameter to the builder . all parameters will added to the jpa query returned by a call to { @link #createquery ( entitymanager ) } or { @link #createquery ( entitymanager class ) } .
adds given parameter to the builder . all parameters will added to the jpa query returned by a call to { @link #createquery ( entitymanager ) } or { @link #createquery ( entitymanager class ) } .
adds all given parameters to the builder . all parameters will added to the jpa query returned by a call to { @link #createquery ( entitymanager ) } or { @link #createquery ( entitymanager class ) } .
renders this object as jpql query string .
deletes a single row by id . returns the number of rows deleted or 0 if unsuccessful .
returns a single object by id or null if no match found . if more than one match is found throws { @link toomanyresultsexception } .
inserts a row for the provided entity . if the entity s id is the default long ( 0 ) the database generates an id and populates the entity s id field . returns the generated id or - 1 if error .
efficiently insert a collection of entities using { @link inserthelper } .
insert or update .
update all columns for the row having the id matching the provided entity s id .
convenience method queries the entity table using the provided where clause and parameters and returns a { @link cursor } .
convenience method queries the entity table using the provided where clause and parameters and returns a { @link cursor } .
converts all rows in a { @link cursor } to a list of objects .
converts a { @link cursor } to an object . if there is more than one row in the cursor throws { @link toomanyresultsexception } .
associate given { @link querybuilder } with this object and all of its items .
add a { @link whereitem } to this object .
adds an { @literal sql } { @code and } clause .
adds an { @literal sql } { @code or } clause .
adds an { @literal sql } { @code in } predicate .
adds an { @literal sql } { @code in } predicate .
adds a { @code not in } predicate .
adds a not in predicate .
adds a sub - query predicate .
{
/ * package
makes the next intentions stack active using a round robin scheme .
returns an empty intentions stack . creates a new intentions stack and adds it to the list of stacks if needed .
add the set of bindings for a given plan to this store . any previously stored bindings for this plan will be replaced .
selects a plan instance from the set of plan bindings using the given policy .
selects a plan instance at random from the set of plan bindings .
sets the plan instance variables using the given results set .
gets the result at the given index from the results set .
gets the parents of this object in the goal - plan tree .
gets all the children of this object in the goal - plan tree .
grows the given array by the given size .
creates a new logger .
performs a single step of this plan i . e . progresses this intention .
sets the list of goals for this agent .
<p > addgoal . < / p >
waits for user to press a key before continuing . useful for connecting to a profiler
initialises the intention selection pools .
starts the intention selection threads that each handle a pool of agents .
starts the intention selection threads .
stops the intention selection threads .
loads any configured extensions ( see { @link jillextension } ) .
registers a new jill extension .
{
parses the command line arguments .
resets the global state .
creates a given number of agents of a given class and adds the newly created agents to the given store .
loads the given plan classes and sets up parent - child links with the given goal type .
completes the goal - plan hierarchy linkages between all { @link globalstate#goaltypes } and { @link globalstate#plantypes } .
creates the specified number of agent instances of the given type and adds them to the catalog .
gets the list of goals specified in the @agentinfo annotation of the given agent class .
gets the list of plans specified in the @goalinfo annotation of the given goal class .
gets the list of goals specified in the @planinfo annotation of the given plan class .
loads the class of given name and type .
loads a jill extension .
checks if two objects have the same name . the check is case sensitive .
returns a usage string for the jill command line arguments .
parses the given command line arguments .
parses the given command line argument and associated option . will abort if an unrecoverable error occurs .
loads the jill startup configuration object . <p > configuration is specified at run time via one of the following two options : <ul > <li > { @code -- config <string > } < / li > <li > { @code -- configfile <file > } < / li > < / ul > the contents of { @code <string > } or { @code <file > } are parsed in exactly the same way . the expected syntax is json format . if both options are specified then last specified option will overrule . < / p >
sample program to test belief base evaluation speeds .
evaluates the given query on the given belief base for the agent .
gets the object at the given index of the catalog .
find an object by name . can be very expensive for large catalogs since a name comparison is performed in sequence on the objects in the catalog until a match is found . search is case sensitive .
pushes a new object to the top of the catalog .
pops ( removes ) the object at the top of the catalog .
grows the catalog by a factor of {
{
{
gets the object at the given index in the catalog .
pushes an object on to the top of the stack .
pops the object at the top of the stack .
grows the stack capacity by { @link #increment } up to the maximum capacity of 255 ( byte size ) .
{
{
{
{
{
gets the type of the given object .
checks if the given query run on the given belief returns a match .
sample program to test pattern matching .
gets the belief set field name ( see { @link io . github . agentsoz . jill . core . beliefbase . beliefsetfield } ) for the given belief set for the given agent .
encodes the string str into a sequence of bytes using the character set specified in charset storing the result into a new byte array .
push the given goal to the given stack .
send a message to an agent .
send a message to this agent .
<p > start . < / p >
returns this agent s top level goals .
set s this agent s top level goals i . e . { @link #goals } .
creates a new belief set with the given fields .
adds a new belief to the specified belief set .
evaluates the given query against this agent s belief base .
forces this agent to enter an idle state irrespective of whether it has any active intentions or not . the agent will continue to remain in the suspected state until some event forces it to become active again at which point it will resume operation .
{
gets the field of this belief set that has the given name .
gets the index ( column ) of the given field in this belief set .
{
parses the command line arguments .
{
helper function to add beliefs about neighbours .
builds a new name .
parses the command line arguments .
runs this intentions selction thread .
checks if this agent s execution stack is valid . the stack is valid if it is not null or empty and has not exceeded the maximum size limit of 255 .
removes the given list of agents from the list of active agents .
manages the goal at the top of the execution stack of an agent . all relevant plans are evaluated to see if their context conditions hold . plans deemed applicable are then added to the list of bindings from which a plan instane will be eventually selected .
manages the plan at the top of this agent s execution stack . if the plan has finished it is removed else it is progresses by a single { @link planstep } .
removes from {
adds to {
waits on {
terminates this intention selector thread .
and this thread is still iterating over activeagents
move a disc from pin a to pin b .
program entry
initialises the jill engine .
starts the jill engine . must have previously been initialised ( see { @link #init ( config ) } ) .
blocks until all agents have finished executing plans and have gone idle .
termiantes the jill engine .
checks if the system is idle i . e . all the agents pools are idle
checks if the { @link io . github . agentsoz . jill . core . intentionselector } pools have finished i . e . all agents in the pools are idle .
sets a bit in the agentsidle cache to mark if this agent is idle ( or not ) .
gets the id of the intention selection pool to which the given agent belongs .
returns the expression currently active in the building context .
sets the expression currently active in the building context .
create a new join or find an existing join on the specified attribute .
join recursively using the split property path .
find an existing join for the property or create a new join .
dump managed instance of { @link instancetype#proxy } type and with { @link instancescope#application } scope to container logger . for managed instance of other scope / type combinations this method does nothing .
indicates whether the response reaches the end of the elements available on the server .
parse multipart form from http request create object instance of requested type and fill it with form field value ( s ) . if formal type is a stream store it to local thread so that to be able to close it after arguments processed by application code .
get upload stream from given http request . this method expects on http request a multipart form with a single part of byte stream type . returns an upload stream instance wrapping the form stream part .
looks up a class in the alias map . if <code > classname< / code > exists as an alias it is resolved and returned . if the alias doesn t exist the original string is returned .
performed super - initialization by { @link appservlet#init ( servletconfig ) } and loads rest methods cache . a rest method is a remotely accessible method that does not return a { @link resource } . map storage key is generated by { @link #key ( managedmethodspi ) } based on managed class and rest method request paths and is paired with retrieval key - { @link #key ( string ) } generated from request path info when method invocation occurs .
handle request for a rest resource . locate rest method based on request path info execute method and serialize back to client returned value if any . see class description for general behavior .
generate retrieval key for rest methods cache . this key is used by request routing logic to locate rest method about to invoke . it is based on request path extracted from request uri see { @link requestpreprocessor } and { @link requestcontext#getrequestpath () } - and should be identical with storage key . <p > retrieval key syntax is identical with storage key but is based on request path that on its turn is extracted from request uri . in fact this method just trim query parameters and extension if any .
create a content type instance suitable to represent requested file . it is a trivial a approach using a map of common used file extension . recognizes only couple most used types ; if extension is not recognized returns { @link #text_html } .
parses content type value and returns newly created instance . given value should obey syntax described by this class . this factory method just delegates { @link #contenttype ( string ) } . if <code > value< / code > argument is null uses { @link #application_json } as default .
test if content type has a parameter with requested name and value .
get parameter value or null if parameter does not exist .
parse content type parameters . given parameters expression should be valid accordingly grammar from class description ; it should not start with parameters separator that is semicolon .
configure underlying transaction manager .
returns the target file for a given artifact type and filename . this method takes care about eventually creating non existing directories or protect existing files to be overridden .
writes a generated artifact to a file .
initialize instance fields from managed class configuration object .
scan annotations for managed classes that requires implementation . annotations are processed only for managed classes that have { @link #implementationclass } that is primary source scanned for annotation . if an annotation is not present into implementation class try to find it on interface ( s ) . see <a href = #annotations > annotations< / a > section from class description .
load optional implementation class from class descriptor and applies insanity checks . load implementation class from <code > class< / code > attribute from descriptor . if <code > class< / code > attribute not present return null . <p > beside loading implementation class this utility method performs sanity checks and throws configuration exception if : <ul > <li > instance type requires implementation but <code > class< / code > attribute is missing <li > instance type does not require implementation but <code > class< / code > attribute is present <li > class not found on run - time class path <li > implementation class is a java interface <li > implementation class is abstract <li > implementation class implements managed life cycle but instance scope is not { @link instancescope#application } . < / ul >
load interface classes from class descriptor . attempt to load interface classes from <code > interface< / code > attribute or child elements . if none found returns implementation class that should be already initialized . <p > perform sanity checks on loaded interface classes and throws configuration exception is : <ul > <li > instance type requires interface but none found <li > <code > name< / code > attribute is missing from child element <li > interface class not found on run - time class path <li > implementation class is not implemented by already configured implementation class . < / ul > <p > this utility method should be loaded after { @link #loadimplementationclass ( config ) } otherwise behavior is not defined .
return instance scope loaded from class descriptor <code > scope< / code > attribute . if scope is not defined use { @link instancescope#application } as default value .
return instance type loaded from class descriptor <code > type< / code > attribute . if type is not defined uses { @link instancetype#pojo } as default value .
load remote class url from class descriptor <code > url< / code > attribute . this getter does not perform url validation ; it returns url value as declared by attribute .
get implementation class constructor . managed class mandates a single constructor with parameters no matter if private or formal parameters count . if both default constructor and constructor with parameters are defined this method returns constructor with parameters . returns null if implementation class is missing .
scan class dependencies declared by { @link inject } annotation . this method scans all fields no matter private protected or public . anyway it is considered a bug if inject annotation is found on final or static field . <p > returns a collection of reflective fields with accessibility set but in not particular order . if given class argument is null returns empty collection .
initialize implementation class static not final fields . static initializer reads name / value pairs from <code > static - field< / code > configuration element see sample below . string value is converted to instance field type using { @link converter#asobject ( string class ) } utility . this means that configured value should be convertible to field type otherwise { @link converterexception } is thrown . <p > in sample there is a <code > person< / code > managed instance that has a configuration section . configuration declares three static fields that will be initialized with defined values when managed class is created .
build and return this managed class string representation .
get class annotation or null if none found . this getter uses extended annotation searching scope : it searches first on given class then tries with all class interfaces . note that only interfaces are used as alternative for annotation search . super class is not included . <p > returns null if no annotation found on base class or interfaces .
test if class has requested annotation . this predicate uses extended annotation searching scope : it searches first on given class then tries with all class interfaces . note that only interfaces are used as alternative for annotation search . super class is not included . <p > returns false if no annotation found on base class or interfaces .
get method annotation or null if none found . this getter uses extended annotation searching scope : it searches first on given method declaring class then tries with all class interfaces . note that only interfaces are used as alternative for method annotation search . super class is not included . <p > returns null if no method annotation found on base class or interfaces .
get java reflective method from interface . this getter attempt to locate a method with the same signature as requested base class method in any interface the declaring class may have . if no method found in interfaces or no interface present return given base class method . if requested base class method is declared in multiple interfaces this getter returns the first found but there is no guarantee for order .
get class value of intercepted annotation of a given class . returns null if given class has no { @link intercepted } annotation .
get class value of intercepted annotation of a given method . returns null if given method has no { @link intercepted } annotation .
returns a new instance of <class > typeadapter< / class > passing <class > basetypeadapter< / class > as the only constructor argument .
instantiates a new { @code typeadapter } which is capable of handling { @code type } . <p > if no such adapter exists the old one is returned .
registers a new { @code abstracttypeadapter } . <p > after registering an adapter { @link #gethandler ( class string ) } is able to return it .
processes { @code inputfile } write output to { @code outputfile } and return the resulting counts using most of fit s default components .
set value to object field identified by object property path . form this class perspective an object is a graph of value types . a value type is a primitive value or a related boxing class . also any class that can be converted to a primitive are included ; for example { @link file } or { @link url } are value types since can be converted to / from strings . opposite to value types are compound entities that is objects arrays and collections that aggregates value types or other compound entities . <p > to sum up an object is a graph with compound entities and value types as nodes where value types are leafs . the <code > propertypath< / code > is the path through graph nodes till reach the value type and basically is a dot separated field names list .
return field class or actual type argument if given field is a list .
get dependency value of requested type . see class description for a discussion about supported types and circular dependencies .
compare host and dependency managed classes scope and decide if scope proxy is required . current implementation enable scope proxy only when dependency has { @link instancescope#session } scope .
compares the content of the temporary file with the possibly existing target file . if both are equal the temporary file is deleted . otherwise the old target file is deleted and the new generated file is renamed . this prevents time stamp changes for the target file if nothing changed since the last generation .
provides an observable stream of element states . compares entities using { @link object#equals ( java . lang . object ) } to detect changes .
registers one or more default links for a specific relation type . these links are used when no links with this relation type are provided by the server .
registers a default link template for a specific relation type . this template is used when no template with this relation type is provided by the server .
executes a rest request and wraps http status codes in appropriate { @link exception } types .
executes a rest request adding any configured { @link #defaultheaders } .
handles the response of a rest request and wraps http status codes in appropriate { @link exception } types .
wraps http status codes in appropriate { @link exception } types .
handles links embedded in an http response .
handles links embedded in http response headers .
handles links embedded in json response bodies .
parses a json object for link information .
returns the element with the specified key from the map . creates adds and returns a new element if no match was found .
handles allowed http methods and other capabilities reported by the server .
shows whether the server has indicated that a specific http method is currently allowed .
generates an array which represents the whole { @code resultset } . each element equates to one row in the { @code resultset } . the elements have public fields with the same name as the { @code resultset } columns . the { @link scientificdouble } class is automatically used . they can be read them using reflections .
concatenates the { @link throwable#getlocalizedmessage () } s of the entire { @link throwable#getcause () } tree .
create a new instance for given remote managed class . managed class should be declared as remote into class descriptor . also { @link managedclassspi#getimplementationurl () } should be not null that is implementation url should be present into class descriptor . returned value is a java proxy that delegates a http - rmi client . <p > this factory method does not check managed class argument validity . it should be not null and configured for remote invocation .
alternative to { @link #newinstance ( managedclassspi object ... ) } when implementation url is obtained at run - time perhaps from user interface . returned value is a java proxy that delegates a http - rmi client . this method is designed specifically for { @link appfactory#getremoteinstance ( string class ) } . <p > this factory method does not check arguments validity . both should be not null and interface class should be an actual java interface .
register all instance post - processors .
register scope factory for the instance scope returned by { @link scopefactory#getinstancescope () } .
register instance factory to requested instance type .
register instance processor . only a single instance per processor class is allowed .
register global processors for managed classes . post - processors are singletons and only one post - processor instance of a type is allowed .
create all managed instances registered to this container via external application descriptor . see <a href = #descriptors > descriptors< / a > for details about application and class descriptors .
ensure all managed classes with managed life cycle are instantiated . invoked at a final stage of container initialization this method checks every managed class that implements {
destroy container and release caches factories and processors . this is container global clean - up invoked at application unload ; after executing this method no managed instance can be created or reused . attempting to use {
instance retrieval algorithm
utility method that implements the core of managed instances retrieval algorithm . this method gets existing managed instance from container caches or creates a new instance . if instance is fresh created add instance services via registered instance processors . <p > here is managed instance retrieval algorithm part implemented by this method . <ol > <li > get scope and instance factories for managed class instance scope and type ; if managed class instance scope is local there is no scope factory <li > if scope factory is null execute local instance factory that creates a new instance and returns it ; applies arguments processing on local instance but not instance processors <li > if there is scope factory do next steps into synchronized block <li > try to retrieve instance from scope factory cache <li > if no cached instance pre - process arguments create a new instance using instance factory and persist instance on scope factory <li > end synchronized block <li > arguments pre - processing takes care to inject constructor dependencies <li > if new instance is created execute instance post - processors into registration order . < / ol >
declarative converters registration . this utility scans for <code > converters< / code > section into given configuration object and register converters via { @link converterregistry#registerconverter ( class class ) } . <p > configuration converter section should respect below syntax .
plain java objects static initialization . inject static fields value into arbitrary java classes . note that this mechanism is not related to managed classes ; it acts on regular java classes and only on static fields . <p > here is a sample configuration for java objects static injection . there is <code > pojo - classes< / code > section that list all involved classes with aliases . for every java class alias there is a section with the same name that has <code > static< / code > name / value elements related by name to class static fields .
adds an argument to the template . if the list of arguments does not exist it will be created .
returns the list of target files . either by using the producer or by simply returning the internal list .
marshals the object to xml .
marshals the object to an xml string .
marshals the object to xml .
initializes the model .
checks if this model has a reference to the given template file .
creates an instance by reading the xml from a reader .
creates an instance by reading the xml from a file .
inject dependencies described by given managed class into related managed instance . for every dependency field retrieve its value using { @link dependencyprocessor#getdependencyvalue ( managedclassspi class ) } and inject it reflexively .
set this method request uri path that is the path component by which this method is referred into request uri . if given request uri path is null uses method name converted to dashed case .
invoke managed method and applies method level services . delegates this managed method { @link #invoker } ; accordingly selected strategy invoker can be { @link defaultinvoker } or { @link interceptedinvoker } if this managed method is annotated with { @link interceptor } . also takes care to update { @link #meter } .
invokes the method multiple times either until it returns true or until maxtime is over . after each invoke the class waits { @code sleeptime } milliseconds .
test if there are more parts on this form iterator . this implementation has side effects : it takes care to close form parts while traversing form iterator .
get arguments reader able to process arguments from http request accordingly expected argument types . if http request has no content type returns { @link encoderkey#application_json } reader that is tiny container default content type is json . this departs from http standard that mandates using bytes stream when no content type is provided on request . <p > if formal parameters are empty returns { @link emptyargumentsreader } . if formal parameters are provided attempts to retrieve a reader for expected argument types . if none found try using content type solely .
get arguments reader for requested content and parameter types . this factory method tries to retrieve a reader for expected parameter type . if none found it tries using content type solely . <p > if content type is null this utility method returns { @link encoderkey#application_json } reader since tiny container default content type is json . this departs from http standard that mandates using bytes stream when no content type is provided on request .
determine content type usable to retrieve a writer able to handle given object value . this method is used in tandem with { @link #getvaluewriter ( contenttype ) } . <p > there is a heuristic to determine content type based on object value class . if no suitable content type found returns { @link contenttype#application_json } .
get return value writer able to handle requested content type . content type argument should identify a registered value writer . if no writer found throws bug error . <p > recommend way to use this method is to provide content type instance returned by { @link #getcontenttypeforvalue ( object ) } .
answer comparisons ///////////////////////
provides an observable stream of elements .
create a scope instance from its string value .
parses a string and converts it into a { @code java . util . date } object .
initialize field from named context parameter .
save dialog requested ( unsupported content ) .
adds a new captureappender to an existing logger .
returns the captureappender which captures <code > appendername< / code > .
removes a captureappender from a logger .
deletes all cached log entries .
read mixed body entities from http request creating and initializing arguments accordingly given formal parameters . the number and order of arguments from multipart mixed message should respect formal parameter types . also stream argument if present should be a single one and the last on arguments list .
autocloseable
parses all model files in the directories and all resources . y
tries to resolve all proxies .
returns files that end with java and all directories . files and directories started with a . are excluded .
parse the directory and it s sub directory .
determines if all proxies in the model are resolved .
returns a list of all objects .
sets the model directories to parse . if no list exists internally it will be created if necessary .
sets the list of file extensions . if no list exists internally it will be created if necessary .
sets the model resources to parse . if no list exists internally it will be created if necessary .
reads the next row .
sorts and compare two lists . it is assumed that all items in {
groups both lists by column {
compares two lists . <ul > <li > if { @code expectedlist } is empty all { @code computedlist } items are surplus< / li > <li > if { @code computedlist } is empty all { @code expectedlist } items are missing< / li > <li > otherwise match the first rows and compare the rest recursively< / li > < / ul >
compares two rows item by item using {
<p > this method performs property variable substitution on the specified value . if the specified value contains the syntax <tt > $ { &lt ; prop - name&gt ; } < / tt > where <tt > &lt ; prop - name&gt ; < / tt > refers to either a configuration property or a system property then the corresponding property value is substituted for the variable placeholder . multiple variable placeholders may exist in the specified value as well as nested variable placeholders which are substituted from inner most to outer most . configuration properties override system properties . < / p >
converts a { @code string } into a { @code array } .
checks whether two arrays { @code a } and { @code b } are equal . <p > a type specific { @code typeadapter } is used to compare the items .
creates a logeventanalyzer which is capable to analyze the events { @code events } using the condition defined in { @code conditioncell } .
uses template engine to inject model and serialize view on http response . if meta - view contains { @link #operator_serialization } property enable engine operators serialization .
execute results
type in (
set nullable parameters
java . sql . statement
checks if the arguments contains the argument <code > arg< / code > .
gets the argument value . <ul > <li > for arg = value it returns value < / li > <li > for arg value it returns value < / li >
create an instance type from its string value .
merges the template and context into a file . if the directory of the file does not exists the full directory path to it will be created .
handle xml input stream from http request . this method expects a single formal parameter current implementation supporting { @link document } and { @link inputstream } .
process xml input stream accordingly requested type . current implementation supports two type : xml { @link document } and xml input stream .
returns the model directory .
returns the template directory .
number of seconds from 1970 - 01 - 01t00 : 00 : 00z utc until the specified utc date / time
serialize xml document to output stream of given http response .
configuration property : set the initial url . this property is <b > mandatory< / b > . if the browser is already created this web view loads this new url .
starts the browser and loads the set url in the web view .
configures the application : <ul > <li > sets the application name ( default : akquinet chameria ) < / li > <li > sets the application version ( default : current web view factory version ) < / li > <li > sets the application icon ( default : no icon ) < / li > < / ul >
configures the browser window .
print callback . checks if the print feature is enabled . if so launch the system print job .
save callback ( for unsupported content ) . checks if the save feature is enabled . if so launch the system save dialog .
utility method to copy a stream to another stream .
open callback ( <code > window . open< / code > ) . checks if the open new window feature is enabled . if so creates the web view
retrieve managed instance from application factory and invoke given method on that instance .
attach this instance to http servlet request . load this instance state from http servlet request and mark it as attached .
detach request context instance from http servlet request . invoking getters on this instance after detaching is considered a bug .
get request cookies .
get http session this request context is part of or null if session is not or could not be created . if <code > create< / code > flag is not provided this method return current http session as it is that is return it if already created or null if not . <p > if <code > create< / code > flag is present and is true this method returns current http session if there is one associated with current request or create a new one . this method never returns null if requested to create session but can throw illegal state exception if attempt to create session after response commit .
dump this request context state to error logger . if this instance is not attached this method is nop .
registers the { @link typehandler } which is provided by { @code classname } . after processing this row the typeadapter will be automatically used when the destination type matches { @link typehandler#gettype () } .
collect invocation meters from application managed classes .
configure events stream instance from configuration object .
push event to this events stream client . this method just stores the event on { @link #eventsqueue events queue } being executed into invoker thread . this events stream thread is blocked on the events queue ; after this method execution it will unblock and process the event see { @link #loop () } method . <p > queue offer operation is guarded by { @link #events_queue_push_timeout } . this timeout can occur only in a very improbable condition of events flood combined with system resources starvation . for this reason there is no attempt to recover ; event is simple lost with warning on application logger .
close this event stream loop and waits for associated {
set the host address for client connected to this event stream .
event stream main loop repeated for every event . waits for an event and push it to the client via { @link #writer } writer initialized by { @link eventstreamservlet } on this event stream creation . note that this logic is executed into http request thread ; it blocks the thread till an event become available . this method always returns true allowing event stream to continue . it returns false only when got { @link shutdownevent } pushed on queue by { @link #close () } method or there is an error on print writer . checking for print writer errors is especially useful to detect that remote client closes its socket and to gracefully close this stream and release parent servlet instance . <p > also this method takes care to periodically send keep alive events see { @link #keepaliveperiod } . keep alive is used to ensure server side and client logic that peer is still running and to avoid connection drop due to routers idle connection timeout .
get named parameter throwing exception if not found .
send event instance to this event stream consumer . compile a w3c server - sent event from <code > event< / code > instance argument and write it to this { @link #writer } . this event stream implementation does not use all w3c server - sent event fields : only <code > event< / code > and <code > data< / code > as folows : <ul > <li > event field stores event argument canonical class name <li > data field value is event argument instance serialized json . < / ul > just for those curious here is an sample of a serialized hypothetical event as it is on wire :
removes a prefix from a path . if the path does not start with the prefix the unchanged path is returned .
checks whether { @code subdir } is a sub directory of { @code parentdir } . note : the comparison is case sensitive .
returns all directory paths between { @code fromdir } and { @code todir } .
gets the longest common parent directory path of two paths .
converts an absolute path into a relative one .
converts an relative path into an absolute one .
counts the number of directories in a given path .
servlet life cycle callback executed at this servlet instance initialization . mainly takes care to initialize parent container reference . if there is no servlet context attribute with the name { @link tinycontainer#attr_instance } this initialization fails with servlet permanently unavailable . <p > parent container instance has application life span and its reference is valid for entire life span of this servlet instance .
prepare execution context and delegates the actual http request processing to abstract handler . initialize request context bound to current thread and delegates { @link #handlerequest ( requestcontext ) } . after request handler execution takes care to cleanup request context . <p > this method also initialize logger context see { @link #logcontext } with remote address of current request so that logging utility can include contextual diagnostic data into log messages . just before exiting this service request cleanups the logger context .
detect self - referenced request uri . it seems there are browsers considering empty string as valid url pointing to current loaded page . if we have an <code > img< / code > element with empty <code > src< / code > attribute browser will try to load that image from current url that is the content of current page . this means is possible to invoke a controller many times for a single page request . <p > to avoid such condition check if this request comes from the same page i . e . referrer is current request . note that this is also true for <code > link< / code > and <code > script< / code > with empty <code > href< / code > . finally worthy to mention is that this check is not performed on request accepting <code > text / html< / code > .
send unauthorized access response . this method send back a response with status code { @link httpservletresponse#sc_unauthorized } and response header { @link httpheader#www_authenticate } set to basic authentication method and { @link containerspi#getloginrealm () } authentication realm . <p > if request is from an agent using xhr this method behaves a little different . xhr specification mandates that unauthorized access to be handled transparently by client agent that usually displays client agent login form not very well integrated with application . below is a snippet from this framework script library . <p > for not authorized xhr requests this method sends { @link httpservletresponse#sc_ok } and custom response header { @link httpheader#x_header_location } set to application login page see { @link containerspi#getloginpage () } . client script can handle this response and redirect to given login page .
send response for bad request with request uri as message . this utility method is used when a request uri is not well formed as expected by concrete servlet implementation . it dumps request context and delegates servlet container { @link httpservletresponse#senderror ( int string ) } to send { @link httpservletresponse#sc_bad_request } .
send response for resource or service not found containing the exception that describes missing entity . this method sends back exception object wrapped in { @link remoteexception } . response is encoded json and status code is { @link httpservletresponse#sc_not_found } .
send server error response with given exception serialized json . this utility method dumps stack trace and request context to application logger and send back throwable object . response is encoded json and status code is { @link httpservletresponse#sc_internal_server_error } . if given exception argument is { @link invocationexception } or { @link invocationtargetexception } extract the cause . <p > there is a special case for { @link businessexception } . this exception signals broken business constrain and is send back also as json object but with status code { @link httpservletresponse#sc_bad_request } . also does not dump exception stack trace or request context .
dump throwable stack trace and request context to application logger .
send object back to client encoded json with given http status code . take care to set content type length and language . content language is extracted from request context locale .
adds another template to the list . if the list does not exist it will be created .
adds all templates to the list . if the list does not exist it will be created .
initalizes the object .
returns a list that contains all models that reference the given template .
checks whether two stringbuilder { @code a } and { @code b } are equal . <p > this method removes whitespaces around both strings first .
write bytes to output stream of http response . this method invokes { @link streamhandler#invokehandler ( outputstream ) } with http response output stream . stream handler instance is created by application and allows application logic access to http response stream .
controls whether a save button is shown and fields are editable .
deletes the element .
handler for deleting the element .
replaces variables ( if defined ) in the path name and arguments .
opens the file and returns a { @code bufferedreader } object using the given encoding .
uses managed class constructor to create new instance with provided arguments . arguments should be in order types and number required by constructor signature .
creates and initializes a srcgen4j configuration from a configuration file that contains only generators / parsers of type { @link parameterizedtemplateparser } and { @link parameterizedtemplategenerator } .
pem : privacy - enhanced electronic mail
returns all link headers listed in an { @link httpresponse } .
reads invocation arguments from http request url parameters accordingly formal parameters list . this arguments reader implementation delegates { @link queryparametersparser } for url parameters parsing .
saves the result <code > result< / code > of the file { @code file } .
returns the { @code counts } of a filename .
returns all saved filenames .
returns the sum of all results .
returns a single html table row representing the results of the file { @code file } .
returns a summary row for a whole test run .
prints out a table to { @code stream } which contains all saved results including all summary rows .
generates a html summary row for a subdirectory .
serialize return value to http response using json encoding . this method delegates { @link json#stringify ( java . io . writer object ) } for value serialization .
delegates { @link appfactory#getinstance ( class object ... ) } .
delegates { @link appfactory#getinstance ( string class object ... ) } .
delegates { @link appfactory#getoptionalinstance ( class object ... ) } .
delegates { @link appfactory#getremoteinstance ( string class ) } .
helper method to retrieve application factory bound to current thread . retrieve application factory from current thread local storage . in order to be successfully this method must be preceded by { @link #bind ( appfactory ) } called from current thread ; otherwise bug error is thrown .
adds a row of filter text boxes to a vaadin { @link grid } .
load service defined by managed class interface and return service instance . this factory does not support arguments . service provider should be present into run - time otherwise no provider exception is thrown .
returns the setup class .
returns a list of model directories to parse .
returns a list of model resources to parse .
reads a row which contains two cells and registers an alias . <p > the first cell must contain the alias the second one must contains the fully qualified class name . using another alias as class name is not permitted . <p > cross references are resolved .
sets a set of candidates for selection .
runs the file { @code filename } using the current runner and replaces the current row with the results .
todo : not tested?
load configuration document from file .
handler for errors reported by rest endpoints .
parse url query parameters provided by source reader . detect query parameters name and and value and update a list of parsed parameters . takes care to decode escaped characters from both parameter names and values . <p > this parser expect utf - 8 for text encoding and throws unsupported encoding for different codes .
get an array of arguments suitable for a method invocation . this method did its best to fill the arguments array . the logic is simple : ignore query extra parameters and set to null the missing ones . both cases are recorded to debug log . returned arguments array has the same size as requested formal parameters array . <p > parameter values from parsed { @link #parameters } are converted to requested type using { @link #asobject ( string type ) } utility method . if formal parameters has a single type that has no converter uses reflection to map query parameters to object field by name . <p > note that because parameter names are not preserved on run - time query parameters are mapped by position to invocation arguments . this means is caller responsibility to match formal parameters order and type with actual query string parameters .
helper method to convert string parameter to an instance of a given type . requested <code > type< / code > should be a value type as accepted by converter package or an array / collection of value types . in the later case <code > value< / code > should be a comma separated string of items . if given <code > value< / code > is null returns an empty value as defined by { @link types#getemptyvalue ( type ) } .
test if method formal parameters designates a strict object that is is not primitive array collection or map .
uses json deserializer to parse method invocation arguments accordingly formal parameters list .
parse json from input stream accordingly given type . return parsed object .
pre - process constructor arguments for local managed classes . a managed class is <code > local< / code > if is of { @link instancetype#pojo } or { @link instancetype#proxy } type . attempting to pre - process arguments for other managed class types is silently ignored . this method delegates { @link #preprocessarguments ( managedclassspi member class [] object ... ) } .
pre - process managed method invocation arguments . this processor prepares invocation arguments for given managed method ; it just delegates { @link #preprocessarguments ( managedclassspi member class [] object ... ) } .
update and validate invocation arguments against given formal parameter types . if formal parameters is not empty but no invocation arguments this method will inject dependency using { @link #getdependencyvalue ( managedclassspi class ) } . this method also performs arguments validity check against formal parameters throwing illegal arguments if validation fails .
extracts and removes parameters from a cell .
javax . persistence . query & javax . persistence . typedquery
/ * altered by rick mugridge to dispatch on the first fixture
/ * added by rick mugridge
/ * added from fitnesse
loads a fixutre by its fully quallified { @code classname } . if the { @code classname } is an alias the referenced class is used .
sets the ssl parameter of the mail { @link setuphelper } .
sets the port parameter of the mail { @link setuphelper } .
test if given http request is performed via xmlhttprequest .
test if http request is from android .
this method is enacted for empty formal parameters . it just return { @link #empty_arguments } .
traversal ////////////////////////////////
fixme : test!
fixme : test!
this method is a this wrapper for { @link streamfactory#getinstance ( inputstream type ) } .
persist instance bound to given managed instance key . this method simply uses provided <code > instancekey< / code > argument to add instance to { @link #instancespool } . both arguments should to be not null .
refresh when child elements are created or updated
processes the content of { @code cells } .
lists all properties on a bean type . ensures properties annotated with { @link id } or called name are always listed first .
lists all properties on a bean type that have a specific annotation on their getter or backing field .
returns an annotation of a specific type on a property s getter or its backing field .
sets the filename pattern to { @code pattern } .
sets the directory to { @code directory } .
sets the encoding to { @code encoding } .
log formatted message to java logger since framework logger is not yet initialized .
uses the ruby whois gem to perform a whois lookup
check if ruby whois gem has a parser for a specific registrar
http - rmi request service . this is the implementation of the { @link appservlet#service ( javax . servlet . servletrequest javax . servlet . servletresponse ) } abstract method . it locates remote managed method addressed by request path deserialize actual parameters from http request reflexively invoke the method and serialize method returned value to http response . <p > actual parameters are transported into http request body and are encoded accordingly <code > content - type< / code > request header ; for supported parameters encodings please see { @link serverencoders#getargumentsreader ( httpservletrequest type [] ) } factory method . on its side returned value is transported into http response body too and is encoded accordingly its type - see { @link serverencoders#getvaluewriter ( contenttype ) } for supported encodings for returned value .
get remotely accessible managed class registered to a certain interface class .
get managed method that is remotely accessible and has requested name .
extract qualified class name including inner classes from class path part of the request path . class path parameter is the class name but with slash as separator e . g . <code > / sixqs / site / controller / participantcontroller< / code > . this helper handles inner classes using standard notation with $ separator ; for example <code > / js / test / net / rmicontroller / query< / code > is converted to <code > js . test . net . rmicontroller$query< / code > . <p > class nesting is not restricted to a single level . for example <code > / js / test / net / rmicontroller / query / item< / code > is converted to <code > js . test . net . rmicontroller$query$item< / code > . <p > it is expected that class path argument to be well formed . if class path argument is not valid this method behavior is not defined .
checks whether the log messages contain the expected exception .
checks whether the log messages do not contain the expected text .
get primitive wrappers
java . sql . wrapper
replaces variables ( if defined ) in the value .
set common http response headers and delegates actual serialization to subclass . this method disables cache and set content type to value returned by subclass .
get value of the named cookie or null if cookie does not exist .
add cookie to http response of the current request context . override cookie value if already exists .
convert value object to string and delegates { @link #add ( string string ) } . string conversion is performed by { @link converter } and may throw { @link converterexception } .
remove cookie from http response . if named cookie does not exist this method does nothing .
get cookies iterator . return empty iterator if not cookies on http request .
configure instance with configuration object provided by instance managed class . in order to perform instance configuration instance should implement { @link configurable } and managed class should have configuration object see { @link managedclassspi#getconfig () } . if both conditions are satisfied this method executes { @link configurable#config ( config ) } on instance .
returns an existing target file list producer instance or creates a new one if it s the first call to this method .
adds a public field to the constructed class .
compiles the class and returns a class object which contains all added fields .
test that selected image identified by given token is the right response .
challenge value associated with image file . file name is converted to lower case extension removed and non letter characters replaces with space that is non letters are considered words separators .
adds a trailing slash to the uri if it does not already have one .
generates a properties object which can be used by { @link de . cologneintelligence . fitgoodies . mail . providers . javamailmessageprovider } . default values are not set .
implements tiny container boostrap logic . see class description for overall performed steps . also loads context parameters from external descriptors using { @link servletcontext#getinitparameter ( string ) } . <p > context initialized listener is not allowed to throw exceptions and it seems there is no standard way to ask servlet container to abort launching the web application . tiny container solution is to leave servlet context attribute { @link #attr_instance } null . on { @link appservlet#init ( javax . servlet . servletconfig ) } mentioned attribute is tested for null and if so permanently mark servlet unavailable . <p > <b > implementation note : < / b > bootstrap process logic is based on assumption that this <code > contextinitialized< / code > handler is called before servlets initialization . here is the relevant excerpt from api - doc : <em > all servletcontextlisteners are notified of context initialization before any filter or servlet in the web application is initialized . < / em >
release resources used by this tiny container instance . after execution this method no http requests can be handled . <p > <b > implementation note : < / b > tiny container destruction logic is based on assumption that this <code > contextdestroyed< / code > handler is called after all web application s servlets destruction . here is the relevant excerpt from api - doc : <em > all servlets and filters have been destroy () ed before any servletcontextlisteners are notified of context destruction . < / em >
security context interface
get http request from current request context .
invocation handler implementation . every method invocation on managed class interface is routed to this point . here actual container services are implemented and method is invoked against wrapped instance .
helper method for mutable transaction execution .
helper method for immutable transaction execution .
prepare given throwable and dump it to logger with formatted message . return prepared throwable . if throwable is { @link invocationtargetexception } or its unchecked related version { @link invocationexception } replace it with root cause .
returns the only file that matches the pattern . if no file matches a <code > null< / code > . if more than one file matches a { @link filenamenotuniqueexception } is thrown .
returns a list of all matching files .
returns the last matching file .
processes the table row { @code cells } .
retrieve instance from current thread bound to given managed class or null if none found . uses provided managed instance key to get instance from { @link #instancespool } . instance key argument should be not null .
persist instance on current thread bound to given managed class . this method simply uses provided instance key argument to add instance to { @link #instancespool } . both arguments should to be not null .
clear all threads local storage and {
beside initialization inherited from { @link appservlet#init ( servletconfig ) } this method takes care to initialize event stream manager reference .
create { @link eventstream } for session id from request uri and run { @link eventstream#loop () } as far it returns true . this method takes also care to handle connections errors due to network or client failure . at event stream loop exit graceful or due to error unbind event stream from manager . <p > if event stream cannot be created due to bad session id responds with bad request error code 400 . <p > note that this method does not return as long client requesting for event stream is connected keeping http request thread and servlet allocated even there is no event to send for this particular client .
extract event stream session id from request path . this method extracts last path component from request path with extension removed if present . it is a sort of <code > basename< / code > from file path . all next request paths with return the same session id <code > 1234< / code > : <ul > <li > / 1234 . event <li > / event / 1234 <li > / 1234 <li > / admin / 1234 . event <li > / admin / event / 1234 < / ul > this allows for flexible event stream servlet mapping on deployment descriptor . both mapping by path and extension can be used . also extension can be anything . anyway this flexibility comes with a constraint : session id cannot contain slash ( / ) or dot ( . ) . <p > session id is generated by event stream manager when client subscribes see { @link eventstreammanager#subscribe ( eventstreamconfig ) } then client sends session id back to this servlet as a http request .
saves the input and closes the {
sets the database driver . { @code drivername } must be a fully qualified class name and the class must be in java s class path . unless the driver is already registered { @code setprovider } registers it at the { @code java . sql . drivermanager } .
returns the parser configuration .
load locale codes and security domains lists from filter parameters . filter parameter is a list of command separated items . if related filter parameter is not declared field is initialized to empty list . <p > this filter loads tiny container reference from servlet context attribute { @link tinycontainer#attr_instance } . if there is no servlet context attribute with the that name this initialization fails with filter permanently unavailable .
search request uri for locale and security domain by comparing with internal lists and remove found values . update locale security domain and request path on context request from current thread see { @link requestcontext#setlocale ( locale ) } { @link requestcontext#setsecuritydomain ( string ) } and { @link requestcontext#setrequestpath ( string ) } . <p > remove locale and security context from current request uri and forward it . if current request uri is for a static resource that is an existing file this filter does nothing . <p > it is considered a resource not found and rejected with 404 if a request uri contains a locale code that is not listed into filter parameter . if <code > locale< / code > filter parameter is not declared all locale code that may be present into request uri are passed unprocessed . if request uri contains a security domain that is not listed into <code > security - domain< / code > filter parameter it is forwarded unprocessed .
test if request path starts with path component . this predicate returns true if first path component from given request path equals requested path component . comparison is not case sensitive . request path should start with path separator otherwise this predicate returns false .
returns a list of factories for the given model type .
parses { @code string } and returns a valid date object . for parsing a { @link simpledateformat } object is used .
parses { @code string } and returns a valid date object . for parsing a { @link simpledateformat } object is used .
wraps the control in a { @link window } .
retrieve instance from current http session bound to given instance key or null if none found . uses provided instance key argument as http session attribute name . managed instance key argument should be not null . <p > access to http session is obtained from http request ; therefore it is considered a bug if attempt to use this method outside a http request thread . <p > implementation note : this method could have side effect . it <b > creates the http session< / b > if there is none on current http request .
persist instance on current http session bound to given managed instance key . this method simply uses <code > instancekey< / code > to add instance as http session attribute . both arguments should to be not null . <p > access to http session is obtained from http request ; therefore it is considered a bug if attempt to use this method outside a http request thread . <p > implementation note : this method could have side effect . it <b > creates the http session< / b > if there is none on current http request .
get http session from current request creating it if necessary . this method should be call inside a request context otherwise bug error is thrown .
serialize this file resource to http response . disable cache and set content type and content length .
replacement of { @code dorows ( parse ) } which resolves question marks in the first row and calls fit . columnfixture . dorows ( parse ) . <p > question marks represent method calls so getvalue () and getvalue? are equivalent .
replacement of { @code docell } which resolves cross - references before calling the original { @code docell } method of fit .
utility //////////////////////////////////
fetches meta data such as links from the server .
implements serializable
beside initialization performed by { @link appservlet#init ( servletconfig ) } this method takes care to load resource methods cache . a resource method is a remotely accessible method that returns a { @link resource } . map storage key is generated by { @link #key ( managedmethodspi ) } based on controller and resource method request paths and is paired with retrieval key - { @link #key ( string ) } generated from request path when method invocation occurs .
handle request for a resource . locate resource method based on request path from request context execute method and serialize back to client returned resource . see class description for general behavior .
generate storage key for resource methods cache . this key is create from controller and resource method request paths and is used on cache initialization . it is paired with { @link #key ( string ) } created from request path on actual method invocation . <p > here is storage key syntax that should be identical with retrieval key . key has optional controller path - missing if use default controller and resource method path . controller path is the declaring class request path { @link managedclassspi#getrequestpath () } and resource path is managed method request path { @link managedmethodspi#getrequestpath () } .
performs an http get request on the { @link endpoint#geturi () } and caches the response if the server sends an etag header .
performs an http put request on the { @link endpoint#geturi () } . sets { @link httpheaders#if_match } if there is a cached etag to detect lost updates .
performs an http delete request on the { @link endpoint#geturi () } . sets { @link httpheaders#if_match } if there is a cached etag to detect lost updates .
compare two <code > fileinformation< / code > objects . see { @link fitfilenamecomparator } for more information .
closes the sql statement .
generates a { @code java . sql . resultset } by using the saved connection . this method queries the table { @code tablename } and appends { @code where } as an optional where clause .
execute post - construct on managed instance . in order to perform instance post - construction managed instance should implement { @link managedpostconstruct } interface .
closes all event streams still opened when event stream manager is destroyed .
subscribes to events stream and returns session id . this method is remote accessible and public . it returns a session id with a short life time for about 10 seconds . <p > this method creates a new { @link sessionid } and stores given configuration object to { @link #sessions } map with created session id as key . session storage is ephemere . it lasts only for { @link #subscribe_ttl } period of time ; after that session id becomes stale . <p > this method should be followed by { @link #createeventstream ( string ) } with returned session id as argument .
enables or disabled buttons based on the allow http header .
called to upload new blob data to the server .
deletes the blob .
parses a string and converts it into a { @code java . sql . timestamp } object .
finds an argument in an given argument list . <p > the search for an argument is case - insensitive and whitespaces at the beginning and the end are ignored . the argument s name and its value are separated by an equal sign . all these inputs will result in &quot ; world&quot ; if you look up &quot ; hello&quot ; : <p > &quot ; hello = world&quot ; &quot ; hello = world &quot ; &quot ; hello = world&quot ; . < / p > <p > note : the case of the value is unchanged .
initializes the fixture arguments call { @code setup } { @code fit . fixture . dotable ( parse ) } and { @code teardown () } .
extracts and removes parameters from a row .
reads the argument list and copies all values in public members with the same name . <p > if these members do not exist the argument is skipped . you can still read the values using { @link #getarg ( string string ) } .
returns all argument names .
replacement of { @code check } which resolves cross - references before calling the original check method of fit .
schedule periodic task execution .
schedule timeout task reseting timeout period if given timeout task is already pending .
purge task helper method . if given <code > task< / code > is not scheduled this method does nothing .
create views meta pool from given managed view configuration object . configuration object is described on class description .
create view instance based on view meta data identified by name and request locale . view instance is created from view implementation class - { @link viewmeta#getimplementation () } .
returns <code > true< / code > if the iteration has more elements . ( in other words returns <code > true< / code > if <code > next< / code > would return an element rather than throwing an exception . )
returns the next matching file .
reads the given parameters and initializes the values of { @link #getencoding () } and { @link #getfile () } .
parses the first table row and generates an { @code int } array which contains the length of each record field .
sets the database username to { @code username } . the username can be received using { @link setuphelper#getuser () } .
sets the database password to { @code password } . the password can be received using { @link setuphelper#getpassword () } .
sets the database connection string to { @code uri } . the connection string can be received using { @link setuphelper#getconnectionstring () } .
configure simple captcha service provider . see class description for configuration object properties . <p > note that images repository should contain only images related to captcha ; sub - directories are not scanned only direct child files .
create a new challenge and store it on http session . if http session does not exist create it . this challenge is used by client to update user interface accordingly . it is called on initial form rendering and every time user choose to load another challenge if current one cannot be solved . <p > client is free to display multiple simple captcha instances but all instances should have distinct index generated in sequence starting from zero .
verify challenge response . if response is not correct returns a new challenge used by client to update user interface . it is highly recommended to refresh challenge on wrong answer to prevent response guessing . <p > instance index should be the same provided to { @link #getchallenge ( int ) } . this is critical and client should consider this constrain . anyway using wrong captcha instance index is not a security breach ; it always consider response as invalid .
get the image identified by given token so that client is able to display it . in order to protect against recording attack a challenge image is identified by a token that is valid only once . <p > if given token does not identify a valid challenge image this method throws { @link nosuchresourceexception } and container responds with 404 not found .
get challenge instances storage bound to current http request . challenges storage is kept on http session . it is legal to have multiple simple captcha instances on a single page but client should use zero based numeric index to identify instances . <p > this method has side effects : it creates http session if is not already created .
configures the application .
prints welcome banner .
prints stopped banner .
creates the chameleon instance . the instance is not started .
parses the -- deploy parameter .
registers a shutdown hook to stop nicely the embedded framework .
parses the -- debug parameter .
traversal ////////////////////////////////
actions //////////////////////////////////
utility //////////////////////////////////
waits until a method returns true . the command takes a method name without parameters and a return value of { @code boolean } as the first parameter and a timeout in ms as the second parameter . <br > the method is called every { @code sleeptime } ms until it returns true or the timeout is exceeded .
transforms the selected row into an &quot ; enter&quot ; command and reinterprets it . <p > example : row content : { @code setencoding | utf - 8 } <br > code in the fixture : { @code public void setencoding () throws exception { transformandenter () ; } } <p > { @code public void setencoding ( string encoding ) { // do stuff with encoding here } }
triggers the action .
handler for triggering the action .
gets the first matching event which matches { @link #matches ( loggingevent ) } and the given parameters .
replaces a row with one or more results .
gets the sum of all results .
sets the locale value to { @code locale } .
sets the format value to { @code format } .
setter for score - sets the score associated with the answer .
getter for variants - gets list of alternative answer summaries .
setter for variants - sets list of alternative answer summaries .
getter for questiontype - gets the class of the question determined by either an automatic question classification process or human judgment .
setter for questiontype - sets the class of the question determined by either an automatic question classification process or human judgment .
}
getter for token - gets the corresponding token for the focus .
getter for deplabel - gets the dependency label of the token with respect to its head .
setter for deplabel - sets the dependency label of the token with respect to its head .
getter for semantictype - gets a semantic type typically the name of an entity annotation type .
setter for semantictype - sets a semantic type typically the name of an entity annotation type .
getter for partofspeech - gets coarse - grained part of speech . --- example : noun verb adj cord
setter for partofspeech - sets coarse - grained part of speech . --- example : noun verb adj cord
getter for lemmaform - gets a canonical / lemmatized form of the covered text .
setter for lemmaform - sets a canonical / lemmatized form of the covered text .
getter for ismainreference - gets if true then this is the main reference to the first argument . modifiers and anaphoric references do not have ismainreference set . --- example : a dark blue [ hat ]
setter for ismainreference - sets if true then this is the main reference to the first argument . modifiers and anaphoric references do not have ismainreference set . --- example : a dark blue [ hat ]
getter for isvariable - gets true iff the token expresses some unknown entity typically the focus of a question : --- example : [ who ] shot jr? what [ city ] was jr born in?
setter for isvariable - sets true iff the token expresses some unknown entity typically the focus of a question : --- example : [ who ] shot jr? what [ city ] was jr born in?
getter for determiner - gets the determiner attached to the node if any --- example : [ the ] book
setter for determiner - sets the determiner attached to the node if any --- example : [ the ] book
getter for sections - gets content of sections in the document .
setter for sections - sets content of sections in the document .
indexed getter for sections - gets an indexed value - content of sections in the document .
indexed setter for sections - sets an indexed value - content of sections in the document .
getter for sectionlabels - gets section labels in the document e . g . sections . 0 sections1 etc .
setter for sectionlabels - sets section labels in the document e . g . sections . 0 sections1 etc .
indexed getter for sectionlabels - gets an indexed value - section labels in the document e . g . sections . 0 sections1 etc .
indexed setter for sectionlabels - sets an indexed value - section labels in the document e . g . sections . 0 sections1 etc .
getter for names - gets all name variants ( preferred / default name synonyms lexicial variants etc ) of the concept .
getter for uris - gets array of uris that identify this named entity . there may be more than one uri if this named entity is ambiguous .
setter for uris - sets array of uris that identify this named entity . there may be more than one uri if this named entity is ambiguous .
getter for ids - gets a list of ids ( e . g . ui in umls ) associated with this concept .
setter for ids - sets a list of ids ( e . g . ui in umls ) associated with this concept .
getter for mentions - gets a list of conceptmentions ( text spans ) that might be surface forms to this concept .
setter for mentions - sets a list of conceptmentions ( text spans ) that might be surface forms to this concept .
getter for types - gets a list of concept types that the concept belongs to .
setter for types - sets a list of concept types that the concept belongs to .
getter for targettype - gets the actual target type annotation .
setter for targettype - sets the actual target type annotation .
getter for rank - gets rank of this result in the original hit - list .
setter for rank - sets rank of this result in the original hit - list .
getter for querystring - gets the query string associated with the hit .
setter for querystring - sets the query string associated with the hit .
getter for candidateanswers - gets candidateanswervariants generated from this searchresult .
setter for candidateanswers - sets candidateanswervariants generated from this searchresult .
indexed getter for candidateanswers - gets an indexed value - candidateanswervariants generated from this searchresult .
indexed setter for candidateanswers - sets an indexed value - candidateanswervariants generated from this searchresult .
getter for query - gets the query in the native syntax of the corresponding search engine .
setter for query - sets the query in the native syntax of the corresponding search engine .
getter for hitlist - gets hit list of search results sorted in descreasing order of relevance score .
setter for hitlist - sets hit list of search results sorted in descreasing order of relevance score .
indexed getter for hitlist - gets an indexed value - hit list of search results sorted in descreasing order of relevance score .
indexed setter for hitlist - sets an indexed value - hit list of search results sorted in descreasing order of relevance score .
getter for abstractquery - gets the abstract query from which this actual query was generated .
setter for abstractquery - sets the abstract query from which this actual query was generated .
getter for searchid - gets an identifier for this search result . used to collect hit - list objects that belong to this search result after they ve been split out for parallel processing then gathered up again .
setter for searchid - sets an identifier for this search result . used to collect hit - list objects that belong to this search result after they ve been split out for parallel processing then gathered up again .
setter for docid - sets a unique identifier for the document that conatins this passage .
getter for offsetinbeginsection - gets character offset of the start of this passage within the section that contains this passage .
setter for offsetinbeginsection - sets character offset of the start of this passage within the section that contains this passage .
getter for offsetinendsection - gets character offset of the end of this passage within the section that contains this passage .
setter for offsetinendsection - sets character offset of the end of this passage within the section that contains this passage .
getter for beginsection - gets the start section of this passage within the document that contains this passage .
setter for beginsection - sets the start section of this passage within the document that contains this passage .
getter for endsection - gets the end section of this passage within the document that contains this passage .
setter for endsection - sets the end section of this passage within the document that contains this passage .
getter for aspects - gets aspects of the gold standard passage .
setter for aspects - sets aspects of the gold standard passage .
getter for triple - gets the relevant triple searched in the rdf store .
setter for triple - sets the relevant triple searched in the rdf store .
getter for sourcerelation - gets the triple from which the search result was generated
setter for sourcerelation - sets the triple from which the search result was generated
getter for subject - gets the subject of the triple - always a uri .
setter for subject - sets the subject of the triple - always a uri .
getter for predicate - gets the predicate of the triple - always a uri .
setter for predicate - sets the predicate of the triple - always a uri .
getter for object - gets the object of the triple - may be a uri or an xml datatype ( string int etc . ) . see isobjeuri to determine if object is a uri .
setter for object - sets the object of the triple - may be a uri or an xml datatype ( string int etc . ) . see isobjeuri to determine if object is a uri .
getter for isobjuri - gets boolean flag - true of object field is a uri false otherwise .
setter for isobjuri - sets boolean flag - true of object field is a uri false otherwise .
getter for operator - gets the operator associated with this concept .
setter for operator - sets the operator associated with this concept .
getter for operatorargs - gets the operator arguments in a complex query concept .
setter for operatorargs - sets the operator arguments in a complex query concept .
activate metrics
deactivate metrics
getter for concept - gets the abstract concept that the text span conveys .
getter for matchedname - gets a synonym of the concept that best matches the concept mention ( similar to conceptmatched in metamap ) .
setter for matchedname - sets a synonym of the concept that best matches the concept mention ( similar to conceptmatched in metamap ) .
getter for score - gets the confidence score that the concept mention matches the concept .
getter for text - gets the candidate answer string .
setter for text - sets the candidate answer string .
getter for mentiontype - gets the manner in which covered text refers to some entity e . g . name nominal pronoun
setter for mentiontype - sets the manner in which covered text refers to some entity e . g . name nominal pronoun
getter for id - gets the id of the concept type .
setter for id - sets the id of the concept type .
getter for name - gets a human readable concept label .
getter for abbreviation - gets the abbreviation of the name label .
setter for abbreviation - sets the abbreviation of the name label .
setter for concept - sets the relevant concept searched in the ontology .
getter for variants - gets list of candidate answer variants that were merged into this final answer .
setter for variants - sets list of candidate answer variants that were merged into this final answer .
getter for namedentitytypes - gets list of named entity types associated with this concept .
setter for namedentitytypes - sets list of named entity types associated with this concept .
getter for concepttype - gets the type of this concept .
setter for concepttype - sets the type of this concept .
todo extend for a vaadin app version
getter for occurrences - gets the occurrences of this variant .
setter for occurrences - sets the occurrences of this variant .
setter for names - sets names for a given candidate answer variant e . g . tandy tandy inc . for candidate answer variant tandy incorporated .
getter for docid - gets the unique id of the document ( if any ) from which this candidate answer was generated .
getter for concepts - gets the list of query concepts that make up this abstract query . the list is ordered .
setter for concepts - sets the list of query concepts that make up this abstract query . the list is ordered .
getter for originaltext - gets the lexical string in the question .
setter for originaltext - sets the lexical string in the question .
getter for args - gets the arguments for the operator .
setter for args - sets the arguments for the operator .
getter for label - gets the semantic role label .
setter for label - sets the semantic role label .
find the next clear bit in the bit set .
thread safe set operation that will set the bit if and only if the bit was not previously set .
tostring
/ * transaction
this code was copied form mmapdirectory in lucene .
creates a new instance of cachevalue the cache capacity should be used for the given file .
javabeanrecordgetset
/ * association
/ * crud
recordrecord . 
 .
hsql
flushes the in - memory bufer to the given output copying at most <code > numbytes< / code > . <p > <b > note : < / b > this method does not refill the buffer however it does advance the buffer position .
list




list
equals
listequals

list
int

n
rebuild the backing array with a different size .
calculates the position of the given element in the given array . the value at the calculated position will be <code > null< / code > if the element doesn t exist in the array otherwise the position will point to the element .
move {
move {
method to generate a valid helm2 of this object
@return polymerelments in helm format @throws helm1converterexception if one single object can not be downgraded to helm1 - format
{ @inheritdoc }
{
{
method to check if all open brackets are closed
method to set the details of the current connection
method to get a valid helm2 of the connection notation
method to add a single element to the group
{
{
main method to run a single helm2parser from the command line
{
method to validate the polymer id in the simple polymer section the id can be peptide rna chem or blob
method to validate the polymer id in the connection section the id can be peptide rna chem or blob the ratio + range was also included the ambiguity is also proven
method to validate the details about the connections ; hydrogen bonds are here included
method to validate the group id
method to validate the details about the group information ; this part can be separated after + to get the id for each single group element : to get the ratio for each single group element
method to validate the repeating section it can be a single number or a range
method to check if the last added polymer element is a peptide or a rna
method to generate a json - object from the notationcontainer
{
{
{
method to get the simple polymer type
method to get the current grouping notation
method to generate for all sections a helm2 string
method to generate a valid helm2 string for the first section
method to generate a valid helm2 string for the second section
method to generate a valid helm2 string for the third section
method to generate a valid helm2 string for the fourth section
method to get the id s from all polymers and groups
method to get the id s from all polymers
method to get the id s from all polymers
method to get a specific polymer by its id
method to generate the right polymerelements in the case of chem and blob only one monomer is allowed
{ @inheritdoc }
{
method to convert the given string into the helm2 format
method to add annotation to this monomer
method to change the default count of one to the user - defined
method to decide which of the monomernotation classes should be initialized
method to decide which of the two constructors of monomernotationgroupelement should be called
method to decide which of the entities classes should be initialized
{
{ @inheritdoc }
method to get the ratio or the interval of this group in the case of an interval it returns a list of two values
method to parse the given helm2 string in the case of an invalid helm2 notation exception is thrown
{ @inheritdoc }
{ @inheritdoc }
method to set for each nucleotide the sugar the base and the phosphat
{
{
{
{
this method is called from within the constructor to initialize the form . warning : do not modify this code . the content of this method is always regenerated by the form editor .
< / editor - fold >
method to add ambiguity to the group
construct a default fraction using the default agent url of http : // localhost : 8500 / .
this method returns an approximation of this thread s execution statistics for the entire period since the thread was started . writes are done without memory barriers to minimize the performance impact of statistics gathering so some or all returned data may be arbitrarily stale and some fields may be far staler than others . for long - running pools however even approximate data may provide useful insights . your mileage may vary however you have been warned ; - )
add a new task to the top of the shared queue incrementing top .
this is a convenience factory method that extracts the list of nodes from the edges . it assumes that every node has at least one edge going from or to it .
this factory method creates a graph with the given nodes and edges . it expressly allows nodes that have no edges attached to them .
this method does the reachability analysis in a way that is useful for many other methods .
a directed graph defines a partial order through reachability and this method sorts the graph s nodes based on that partial order .
unbuffered output is with api . err . format () etc .
subscribes an object method to a service name pattern .
subscribes a static method to a service name pattern .
subscribes an object method to a service name pattern .
determine how may service name pattern subscriptions have occurred .
unsubscribes from a service name pattern .
asynchronous point - to - point communication to a service subscribed that matches the destination service <code > name< / code > .
synchronous point - to - point communication to a service subscribed that matches the destination service <code > name< / code > .
synchronous point - to - point communication to a service subscribed that matches the destination service <code > name< / code > .
asynchronous point - multicast communication to services subscribed that matches the destination service <code > name< / code > .
forward a message to another service subscribed that matches the destination service <code > name< / code > .
asynchronously forward a message to another service subscribed that matches the destination service <code > name< / code > .
returns a response from a service request .
synchronously returns a response from a service request .
asynchronously receive a response .
asynchronously receive a response .
asynchronously receive a response .
asynchronously receive a response .
asynchronously receive a response .
blocks to process incoming cloudi service requests
shutdown the service successfully
todo make specific throwables contributable?
this method checks if a given throwable is fit for local handling returning it if it is and throwing it otherwise .
acquires the runstate lock ; returns current ( locked ) runstate .
spins and / or blocks until runstate lock is available . see above for explanation .
unlocks and sets runstate to newrunstate .
tries to construct and start one worker . assumes that total count has already been incremented as a reservation . invokes deregisterworker on any failure .
tries to add one worker incrementing ctl counts before doing so relying on createworker to back out on failure .
callback from forkjoinworkerthread constructor to establish and record its workqueue .
final callback from terminating worker as well as upon failure to construct or start a worker . removes record of worker from array and adjusts counts . if pool is shutting down tries to complete termination .
tries to create or activate a worker if too few are active .
signals and releases worker v if it is top of idle worker stack . this performs a one - shot version of signalwork only if there is ( apparently ) at least one idle worker .
top - level runloop for workers called by forkjoinworkerthread . run .
scans for and tries to steal a top - level task . scans start at a random location randomly moving on apparent contention otherwise continuing linearly until reaching two consecutive empty passes over all queues with the same checksum ( summing each base index of each queue that moves on each steal ) at which point the worker tries to inactivate and then re - scans attempting to re - activate ( itself or some other worker ) if finding a task ; otherwise returning null to await work . scans otherwise touch as little memory as possible to reduce disruption on other scanning threads .
possibly blocks worker w waiting for a task to steal or returns false if the worker should terminate . if inactivating w has caused the pool to become quiescent checks for pool termination and so long as this is not the only worker waits for up to a given duration . on timeout if ctl has not changed terminates the worker which will in turn wake up another worker to possibly repeat this process .
tries to steal and run tasks within the target s computation . uses a variant of the top - level algorithm restricted to tasks with the given task as ancestor : it prefers taking and running eligible tasks popped from the worker s own queue ( via popcc ) . otherwise it scans others randomly moving on contention or execution deciding to give up based on a checksum ( via return codes frob pollandexeccc ) . the maxtasks argument supports external usages ; internal calls use zero allowing unbounded steps ( external calls trap non - positive values ) .
tries to decrement active count ( sometimes implicitly ) and possibly release or create a compensating worker in preparation for blocking . returns false ( retryable by caller ) on contention detected staleness instability or termination .
returns a cheap heuristic guide for task partitioning when programmers frameworks tools or languages have little or no idea about task granularity . in essence by offering this method we ask users only about tradeoffs in overhead vs expected throughput and its variance rather than how finely to partition tasks .
possibly initiates and / or completes termination .
full version of externalpush handling uncommon cases as well as performing secondary initialization upon the first submission of the first task to the pool . it also detects first submission by an external thread and creates a new shared queue if the one at index if empty or contended .
tries to add the given task to a submission queue at submitter s current queue . only the ( vastly ) most common path is directly handled in this method while screening for need for externalsubmit .
returns common pool queue for an external thread .
performs tryunpush for an external submitter : finds queue locks if apparently non - empty validates upon locking and adjusts top . each check can fail but rarely does .
performs helpcomplete for an external submitter .
performs the given task returning its result upon completion . if the computation encounters an unchecked exception or error it is rethrown as the outcome of this invocation . rethrown exceptions behave in the same way as regular exceptions but when possible contain stack traces ( as displayed for example using { @code ex . printstacktrace () } ) of both the current thread as well as the thread actually encountering the exception ; minimally only the latter .
submits a forkjointask for execution .
returns an estimate of the total number of tasks stolen from one thread s work queue by another . the reported value underestimates the actual total number of steals when the pool is not quiescent . this value may be useful for monitoring and tuning fork / join programs : in general steal counts should be high enough to keep threads busy but low enough to avoid overhead and contention across threads .
creates and returns the common pool respecting user settings specified via system properties .
}
add a new task to the top of the shared queue incrementing top .
waits if necessary for at most the given time for the computation to complete and then retrieves its result if available .
intentionally not volatile : this class is immutable so recalculating per thread works
public iterable<v > values ( k keymin k keymax ) ;
}
this is a convenience method for building simple json strings . it passes an ajsonserhelper to a callback and builds a string based on what the callback does with it .
this method returns an approximation of statistical data for all worker threads since the pool was started . updates of the statistical data is done without synchronization so some or all of the data may be stale and some numbers may be pretty outdated while others are very current even for the same thread . for long - running pools however the data may be useful in analyzing behavior in general and performance anomalies in particular . your mileage may vary you have been warned! ; - )
this method shuts down the thread pool . the method finishes immediately returning a separate afuture for every worker thread . in order to combine them into a single afuture for all worker threads use {
creates an alist based on the contents of an existing <code > java . util . iterable< / code > copying its contents .
creates an alist based on the contents of an existing <code > java . util . list< / code > copying its content .
creates an alist from a given list of elements .
returns a copy of this alist with elements in reversed order .
returns a <code > java . util . iterator< / code > over this alist s elements allowing alists to be used with java s <code > for ( ... : list ) < / code > syntax introduced in version 1 . 5 .
create a {
create a {
create a {
create a {
returns a string representation of a collection separating elements with a <code > separator< / code > and putting <code > prefix< / code > before the first and a <code > suffix< / code > after the last element .
returns an element of a collection that matches a predicate if any or aoption . none () if there is no match .
matches a predicate against collection elements and returns true iff it matches them all .
applies a transformation function to all elements of a collection creating a new collection from the results .
applies a transformation function to all elements of a collection creating a new collection from the results .
same as <code > map () < / code > except that the transformation function returns collections and all the results are flattened into a single collection .
same as <code > map () < / code > except that the transformation function returns collections and all the results are flattened into a single collection .
takes a collection of collections and creates a new collection from the elements leaving out the innermost level of collection .
takes a collection of collections and creates a new collection from the elements leaving out the innermost level of collection .
takes a collection of collections and creates a new collection from the elements leaving out the innermost level of collection .
applies a transformation function to all elements of a collection where the partial function is defined for . creates a new collection of the transformed elements only . so the number of result elements may be less than the number of elements in the source collection .
applies a transformation function to all elements of a collection where the partial function is defined for . creates a new collection of the transformed elements only . so the number of result elements may be less than the number of elements in the source collection .
applies a transformation function to all elements of a collection where the partial function is defined for . creates a new collection of the transformed elements only . so the number of result elements may be less than the number of elements in the source collection .
matches all elements of a collection against a predicate creating a new collection from those that match .
matches all elements of a collection against a predicate creating a new collection from those that match .
matches all elements of a collection against a predicate creating a new collection from those that match .
creates a map from a collection . each element s key is determined by applying a function to the element . all elements with the same key are stored as that key s value in the returned map .
creates a map from a collection . each element s key is determined by applying a function to the element . all elements with the same key are stored as that key s value in the returned map .
applies a binary operator to a start value and all elements of this sequence going left to right .
applies a binary operator to a start value and all elements of this list going left to right .
copies the content of an <code > iterable< / code > into an ( immutable ) <code > acollection< / code > instance . subsequent changes to the underlying collection have no effect on the returned <code > acollection< / code > instance . <p >
wraps the content of a <code > java . util . collection< / code > in an <code > acollection< / code > instance . while the returned instance itself has no mutator methods changes to the underlying collection are reflected in the wrapping <code > acollection< / code > instance . <p >
wraps the content of a <code > java . util . set< / code > in an <code > aset< / code > instance . while the returned instance itself has no mutator methods changes to the underlying collection are reflected in the wrapping <code > aset< / code > instance . <p >
copies the content of an array into an ( immutable ) <code > acollection< / code > instance . subsequent changes to the underlying array have no effect on the returned <code > acollection< / code > instance . <p >
returns a <code > collection< / code > with the exact same elements as an <code > iterable< / code > copying only if the parameter is not a collection .
returns a <code > collection< / code > with the exact same elements as an <code > iterable< / code > copying only if the parameter is not a collection .
copies the elements from an <code > iterator< / code > into a <code > collection< / code > .
returns an ahashmap instance with default ( i . e . equals - based ) equalityforequals initializing it from the contents of a given <code > java . util . map< / code > .
returns an ahashmap instance for a given equalityforequals initializing it from the contents of a given <code > java . util . map< / code > .
returns an ahashmap instance with default ( i . e . equals - based ) equalityforequals initializing it from separate keys and values collections . both collections are iterated exactly once and are expected to have the same size .
returns an ahashmap instance with default ( i . e . equals - based ) equalityforequals initializing it from a collection of keys and a function . for each element of the <code > keys< / code > collection the function is called once to determine the corresponding value and the pair is then stored in the map .
returns an ahashmap instance with a given equalityforequals initializing it from a collection of keys and a function . for each element of the <code > keys< / code > collection the function is called once to determine the corresponding value and the pair is then stored in the map .
very internal method . it assumes hash0 ! = hash1 .
add a new task to the top of the shared queue incrementing top .
add a new task to the top of the localqueue incrementing top . this is only ever called from the owning thread .
fetch ( and remove ) a task from the top of the queue i . e . lifo semantics . this is only ever called from the owning thread removing ( or at least reducing ) contention at the top of the queue : no other thread operates there .
fetch ( and remove ) a task from the bottom of the queue i . e . fifo semantics . this method can be called by any thread .
this is a convenience method that creates an aoption based on java conventions .
returns an alonghashmap initialized from separate keys and values collections . both collections are iterated exactly once and are expected to have the same size .
returns an alonghashmap instance initialized from a collection of keys and a function . for each element of the <code > keys< / code > collection the function is called once to determine the corresponding value and the pair is then stored in the map .
very internal method . it assumes hash0 ! = hash1 .
returns an empty alistmap instance with a given equalityforequals . calling this factory method instead of the constructor allows internal reuse of empty map instances since they are immutable .
returns an alistmap instance with default ( i . e . equals - based ) equalityforequals initializing it from separate keys and values collections . both collections are iterated exactly once and are expected to have the same size .
returns an ahashmap instance with a given equalityforequals initializing it from separate keys and values collections . both collections are iterated exactly once and are expected to have the same size .
returns an alistmap instance with a given equalityforequals initializing it from separate keys and values collections . both collections are iterated exactly once and are expected to have the same size .
this method combines two separate sub - trees into a single ( balanced ) tree . it assumes that both subtrees are balanced and that all elements in tl are smaller than all elements in tr . this situation occurs when a node is deleted and its child nodes must be combined into a resulting tree .
------------------- shutdown handling below this point ---------------------
-------------------------------------- collection transformations
there is usually a performance gain to be had by overriding this default implementation
todo save all included ramls of a raml . when any of them changes reparse!
- > hack to undo this
marshals the specified user - defined value type object to single xml value string representation .
constructs a new { @code xmlrequest } from the current { @code webcontext } .
returns the web endpoint method parameter value from the current http request body sent as xml format . this method supports the following parameter declaration independently . other than them are the same as { @link abstractrequest } . <ol > <li > named collection of user - defined object type< / li > <li > named user - defined object type< / li > < / ol >
converts the specified object to the specified type . the object to be converted must be a { @code node } that has no child or this method return <code > null< / code > .
appends <code > char< / code > array to buffer .
creates <code > char< / code > subarray from buffered content .
returns <code > char< / code > element at given index .
returns sub sequence .
appends string content to buffer .
creates binary search wrapper over a list of comparable elements .
creates binary search wrapper over a list with given comparator .
finds very first index of given element in inclusive index range . returns negative value if element is not found .
serializes the specified user - defined value type object to <code > jsonprimitive< / code > representation .
loads the class of the specified name from the specified { @code inputstream } and returns loaded class representation as { @code javassist . ctclass } .
resolves the classes that is annotated by the specified annotation as { @code javassist . ctclass } .
resolves the classes that implements the specified interface as { @code javassist . ctclass } .
resolves the classes that contains the specified name as { @code javassist . ctclass } .
adds url routing pattern . the routing pattern can be specified as uri template format and the path variables can be passed to web endpoint method like this : <pre > { @code @override } public void routing ( routing routing ) { routing . add ( / user / { id } / * user . class handle ) ; } < / pre > <pre > { @code } public class user {
adds url routing pattern . the routing pattern can be specified as uri template format and the path variables can be passed to web endpoint method like this : <pre > { @code @override } public void routing ( routing routing ) { routing . add ( / user / { id } / * user . class handle ) ; } < / pre > <pre > { @code } public class user {
adds ignore - routing patterns . the requested url that matches to the patterns is not handled by bootleg . <code > * < / code > ( meta character ) can be used in the pattern ( e . g . <code > * . png< / code > ) . <br > <b > note< / b > : ignore - routing patterns are in preference to routing patterns .
send an email
send a javamail message
specify a handler that will be called for all http methods
specify a filter handler that will be used to wrap route executions
if - modified - since header  . <p / >  checkifmodifyfalse 304 not modify status .
 if - none - match header etag . <p / > etag checkifnonematchfalse 304 not modify status .
header .
request parameters copy from spring webutils . <p / > parameter .
parametersquery stringparameter paramter nameprefix .
http basic header .
delimeter that separates role names in tag attribute
appconfig freemarker reader

freemakrer
html
converts packing long int
extract the filename from the given path e . g . mypath / myfile . txt - > myfile . txt .
extract the filename extension from the given path e . g . mypath / myfile . txt - > txt .
apply the given relative path to the given path assuming standard java folder separation ( i . e . / separators ) .
normalize the path by suppressing sequences like path / .. and inner simple dots . <p > the result is convenient for path comparison . for other uses notice that windows separators ( \ ) are replaced by simple slashes .
trim the elements of the given string array calling { @code string . trim () } on each of them .
remove duplicate strings from the given array . also sorts the array as it uses a treeset .
take an array strings and split each element based on the given delimiter . a { @code properties } instance is then generated with the left of the delimiter providing the key and the right of the delimiter providing the value . <p > will trim both the key and value before adding them to the { @code properties } instance .
convenience method to return a collection as a delimited ( e . g . csv ) string . e . g . useful for { @code tostring () } implementations .







str c   str <p / >  : <ul > <li > removefirst ( 12345 1 ) = > 2345 <li > removefirst ( abc b ) = > abc <li > removefirst ( a b ) = > a <li > removefirst ( a a ) = > < / ul >

hmtl <p / > <pre > escapehtml ( &lt ; script&gt ; alert ( hello world ) ; &lt ; / script&gt ; ) = > &amp ; lt ; script&amp ; gt ; alert ( &amp ; quot ; hello world&amp ; quot ; ) ; &amp ; lt ; / script&amp ; gt ; < / pre > <p / >  <ul > <li > & = > &amp ; amp ; <li > < = > &amp ; lt ; <li >> = > &amp ; gt ; <li > = > &amp ; #x27 ; <li > = > &amp ; quot ; < / ul >
 1 . 5m 
stitching like sql percent .
run from the web interface .

check the user s password and execute the login request
logout
get user login information if the session does not exist then try to obtain from the cookie if cookie exists then decrypt obtain user information .
obtain user information from the session
sign settings
check password salt password planpassword .
store user information in a cookie logged in .
generating system user login id string .
cookie
encrypt
obtain user information from the cookie
decrypt
decrypt










10 + key5 + 5 +  md5 


controller
controller
 requiresrolesrequirespermissions requiresauthenticationrequiresuserrequiresguest
actionkeyactionmapping

controller
clearshiro
shiro .
shiro .  .
forwards http request to the specified path .
add file separator


ipproxy

cookie
cookie
url  : www . dlog . cn - > dlog . cn
ip
http


get shaping parameters submitted by the browser
requestajax .
html
log with debug level
examine stack trace to get caller
 <p / > <ul > <li > l :  7% < / li > <li > m : 15% < / li > <li > q :  25% < / li > <li > h :  30% < / li > < / ul >
 css #
 css #

writes { @code jsonresponse } to the current { @code webcontext } .
<p > sets the input validator for this cell editor . < / p > <p > the validator is given the ( integer ) value to be validated and must return a string indicating whether the given value is valid ; <code > null< / code > means valid and non - <code > null< / code > means invalid with the result being the error message to display to the end user . < / p > <p > this is simply a better - typed version of { @link #setvalidator ( function ) } . < / p >
csv
csv

 \ t - > \\ t
converts char array into byte array by stripping the high byte of each character .
converts char sequence into byte array .
converts byte array to char array by simply extending bytes to chars .
converts char array into {
converts char sequence into ascii byte array .
indicates whether the given character is in the <i > sub - delims< / i > set .
indicates whether the given character is in the <i > unreserved< / i > set .
returns the very first index of any char from provided string starting from specified index offset . returns index of founded char or <code > - 1< / code > if nothing found .
returns the very first index of any char from provided string starting from specified index offset . returns index of founded char or <code > - 1< / code > if nothing found .
returns <code > true< / code > if string {
splits a string in several parts ( tokens ) that are separated by delimiter characters . delimiter may contains any number of character and it is always surrounded by two strings .
lookups for locale data and creates new if it doesn t exist .
returns locale from cache .
returns locale from cache where locale may be specified also using language code . converts a locale string like en en_us or en_us_win to <b > new< / b > java locale object .
transforms locale data to locale code . <code > null< / code > values are allowed .
decodes locale code in string array that can be used for <code > locale< / code > constructor .
returns cached <code > numberformat< / code > instance for specified locale .
writes { @code xmlresponse } to the current { @code webcontext } .
called by {

start this job now ( well asap )
start this job in several seconds
customize invocation
hidden
visiblefortesting
resize an image
resize an image
crop an image
encode an image to base64 using a data : uri
 .  .
creates commonly used {
parses string template and replaces macros with resolved values .
run the code in a new thread after a delay
run the code in the same thread than caller .
sets credentials for use when accessing service apis . note that multiple calls to this method override previously set credentials .
returns rest operations object suitable for use with the specified credentials
rendering errors information in json format .
in the form of json rendering forbidden information .
render view as a string
based on the current path structure is going to jump full action of the path
according to the request information of jquery . datatables the results of the query and returns the json data to the client . <p / > the specified query set the data .
according to the request information of jquery . datatables the results of the query and returns the json data to the client . <p / > according to the sql configuration file in accordance with the convention model_name . coloumns \ model_name . where \ model_name . order configured sql to query and returns the results to the client .
according to the request information of jquery . datatables the results of the query and returns the json data to the client . <p / > according to the sql configuration file in accordance with the convention model_name . coloumns \ model_name . where \ model_name . order configured sql to query and specify the parameters and return results to the client .
the source of data for rendering the jquery datatables
rendering the empty datasource .
datagrid
datagrid
datagrid
datagrid
for information on the logged in user . <p / > this access is through the way the cookie and sessionw
the current shiro login user . <p / > if it opens the secruity function can call this method to obtain the logged in user .
jodatime time request
jodatime time request
sets the input items to the underlying comboboxcelleditor .
writes this http response to the specified web context .
sends web endpoint invocation result to the client as http response . this method processes the response as the following steps : <ol > <li > if the web endpoint invocation result is instance of { @code response } sends the http response to the client by invoking { @code response#to ( webcontext ) } method with the current web context . < / li > <li > ( if it does not so ) if the web endpoint method is qualified by { @code @generates } annotation this class determines the { @code response } type from the specified mime media type by invoking { @code configuration#responsetype ( string ) } . < / li > <li > if the web endpoint method is qualified by { @code @negotiated } annotation this class determines the { @code response } type from the mime media type specified on accept http request header by invoking { @code configuration#responsetype ( string ) } . < / li > <li > ( if it does not so ) if the web endpoint method is qualified neither by { @code @generates } nor { @code @negotiated } annotation this class determines the { @code response } type by invoking { @code configuration#responsetype ( string ) } with empty string . < / li > <li > constructs { @code response } instance and sets the mime media type and web endpoint invocation result then sends the http response to the client by invoking { @code response#to ( webcontext ) } method with the current web context . < / li > < / ol >
encapsulates the logic for associating property source with a given servlet .
hex .
base62
url  encodeutf - 8 .
url  encodeutf - 8 .
returns all the extension implementations in the specified injector .
returns current method signature .
compacts memory as much as possible by allocating huge memory block and then forcing garbage collection .
propagates metrics entry to the local metrics collection or ( if unavailable ) logs immediately
propagates metrics entry to the thread local metrics collection does nothing if local metrics collection is missing .
validates that passed request vector is valid . this function is used to prevent the potential attacker to send garbage request vectors into the service . if passed request vector is invalid it should be discarded .
encodes a value so that it won t contain spaces commas and equal signs .
checkedexceptionuncheckedexception .
errorstackstring .
 .
paging retrieve default sorted by id you need to specify the datatables request parameters .
paging retrieve default sorted by id you need to specify the datatables request parameters .
paging retrieve default sorted by id you need to specify the datatables request parameters .
iddatatables
get coding format file .
id


closes an output stream and releases any system resources associated with this stream . no exception will be thrown if an i / o error occurs .
closes a character - output stream and releases any system resources associated with this stream . no exception will be thrown if an i / o error occurs .
copies input stream to output stream using buffer . streams don t have to be wrapped to buffered since copying is already optimized .
copies specified number of bytes from input stream to output stream using buffer .
copies input stream to writer using buffer .
copies reader to writer using buffer . streams don t have to be wrapped to buffered since copying is already optimized .
copies specified number of characters from reader to writer using buffer .
copies reader to output stream using buffer .
copies reader to output stream using buffer and specified encoding .
reads all available bytes from inputstream as a byte array . uses <code > in . available () < / code > to determine the size of input stream . this is the fastest method for reading input stream to byte array but depends on stream implementation of <code > available () < / code > . buffered internally .
compares the content of two byte streams .
compares the content of two character streams .
starts pipeline with the specified stream object that flows through this pipeline .
sets the specified { @code function } to the next processing stage with the class name of the { @code function } as the stage name .
sets the specified { @code function } to the next processing stage with the specified index and the class name of the { @code function } as the stage name .
sets the specified { @code function } to the next processing stage with the specified stage name .
sets the specified { @code function } to the next processing stage with the specified index and stage name .
sets the specified { @code predicate } to the next processing stage with the class name of the { @code predicate } as the stage name .
sets the specified { @code predicate } to the next processing stage with the specified index and the class name of the { @code predicate } as the stage name .
sets the specified { @code predicate } to the next processing stage with the specified stage name .
sets the specified { @code predicate } to the next processing stage with the specified index and stage name .
removes { @code function } or { @code predicate } at the specified index .
to obtain a configuration of sql .
string - > object
validates http request and constructs web endpoint method parameters . this method processes the request as the following steps : <ol > <li > checks the requested http method is allowable . if the web endpoint method is qualified by { @code @allows } this class allows only the http methods qualified in it . < / li > <li > checks the requested mime media type is acceptable . if the web endpoint method is qualified by { @code @accepts } this class accepts only the qualified mime media types . < / li > <li > determines { @code request } type from the content type on http request header by invoking { @code configuration#requesttype ( string ) } method with the content type . < / li > <li > constructs web endpoint method parameters by invoking { @code request#get () } methods and sets them to the current http request processing context . < / li > < / ol >
resolve the given resource location to a { @code java . io . file } i . e . to a file in the file system . <p > does not check whether the file actually exists ; simply returns the file that the given location would correspond to .
determine whether the given url points to a resource in a jar file that is has protocol jar zip wsjar or code - source . <p > zip and wsjar are used by weblogic server and websphere respectively but can be treated like jar files .
returns the default http request processing pipeline . http request processing pipeline consists of [ route ] - &gt ; [ receive ] - &gt ; [ invoke ] - &gt ; [ send ] by default .
zips a file or a folder . if adding a folder all its content will be added .
extracts zip file to the target directory . if patterns are provided only matched paths are extracted .
writes http response representation to output stream . this method determines the response form as the following convention : <ul > <li > if the mime media type ( { @code #mediatype } ) is not empty set it to content - type http response header . < / li > <li > if the status ( { @code #status } ) is greater than 0 set it to http response code . < / li > <li > if { @code #entity } is an instance of { @code string } this method writes it to the http response directly . if mime media type has not been specified text / plain is used . < / li > <li > if { @code #entity } is an instance of { @code externalizable } this method writes it to the http response as { @code objectoutputstream } by invoking { @code externalizable#writeexternal ( java . io . objectoutput ) } . < / li > <li > if { @code #entity } is an instance of { @code serializable } this method writes it to the http response as { @code objectoutputstream } . < / li > <li > the other this method write it to the http response as plain text by invoking { @code #value#tostring () } . if mime media type has not been specified text / plain is used . < / li > < / ul > utf - 8 is used for the character encoding ( mime charset ) at any time .

a static dialog fragment instance creator method .
work around for dialog not to dismiss on back button press .
checks if two strings are equals or if they {
returns <code > true< / code > if the specified <code > type< / code > is a built - in type .
returns <code > true< / code > if the specified <code > type< / code > is an instance of { @code collection } .
returns <code > true< / code > if the specified <code > type< / code > is an instance of supported { @code collection } . <br > <br > supported collections are : <pre > java . util . collection java . util . list java . util . set java . util . sortedset java . util . navigableset java . util . queue java . util . deque
returns <code > true< / code > if the specified <code > type< / code > is an array type .
returns the element type of the specified collection type . the specified type must be collection or array . to make it sure use { @code #iscollection ( type ) } method or { @code #isarray ( type ) } method .
returns the default implementation type of the specified collection interface type . the specified type must be an supported collection . to make it sure use { @code #issupportedcollection ( type ) } . if the specified collection type is <b > not< / b > an interface this method returns the specified implementation type directly . <br > <br > the default implementations are : <pre > java . util . collection - > java . util . arraylist java . util . list - > java . util . arraylist java . util . set - > java . util . hashset java . util . sortedset - > java . util . treeset java . util . navigableset - > java . util . treeset java . util . queue - > java . util . priorityqueue java . util . deque - > java . util . arraydeque < / pre >
returns <code > true< / code > if the specified <code > type< / code > is a supported core value type . <br > <br > supported core value types are : <pre > boolean byte char double float int long short java . math . bigdecimal java . math . biginteger boolean byte character double float integer long short string class java . util . date java . util . calendar java . io . file java . sql . date java . sql . time java . sql . timestamp java . net . url object < / pre >
returns <code > true< / code > if the specified type is an user define value type . user defined value type must satisfy either of the following condition . <ol > <li > ( the class ) has a public constructor that takes one string . class parameter . < / li > <li > has a public static factory method that named valueof and takes one string . class parameter . < / li > < / ol >
adds supported core value type .
returns the raw type of the specified type . this method supports { @code parameterizedtype } or raw { @code class } ( just returns it directly ) . the other types such as array type are not supported . if the specified type is not supported this method returns <code > null< / code > .
matches the regular expression
email validation
phone number verification
phone verification
telephone number including mobile phones and landlines
judge whether it is birthday
identity verification
postal code
currency validation
chinese
matches are linked
tell the time
blank
qrcode  qrcode 
qrcode qrcode 
 qrcode 
 qrcode 
 qrcode 
 qrcode 
 qrcode 
 qrcode 
 qrcode 
constructs a new { @code jsonrequest } from the current { @code webcontext } .
returns the web endpoint method parameter value from the current http request body sent as json format . this method supports the following parameter declaration independently . other than them are the same as { @link abstractrequest } . <ol > <li > named collection of user - defined object type< / li > <li > named user - defined object type< / li > <li > no - named collection of core value type< / li > <li > no - named collection of user - defined value type< / li > <li > no - named collection of user - defined object type< / li > < / ol >
converts the specified object to the specified user - defined value type . the object to be converted must be a { @code jsonprimitive } or this method return <code > null< / code > .
initializes this filter with the specified configuration . constructs the { @code configuration } and sets up the http request processing pipeline . if the custom configuration class has not been specified { @link defaultconfiguration } is used by default .
processes the web request in bootleg .
constructs the { @code configuration } . this method attempts to get custom configuration class from { @code servletcontext } init parameter and instantiate and initialize it . if the custom configuration class has not been specified as the { @code servletcontext } init parameter this method returns <code > null< / code > .
return the full version string of the present goja boot codebase or {

encode a string to base64
decode a base64 value
transform an hexadecimal string to a byte array .
read a properties file with the utf - 8 encoding
read the stream content as a string
read file content to a string
read binary content of a file ( warning does not use on large file ! )
read binary content of a stream ( warning does not use on large file ! )
write binay data to a file
copy an stream to another one .
copy an stream to another one .
if targetlocation does not exist it will be created .
<p > executes this method on permission result . get boolean result as method parameter . granted = true && denied = false . < / p >
<p > executes this method on permission results . get boolean result as method parameter . < / p >
 <p / > <p / >  <code > java . lang . illegalargumentexception< / code >   - 1 0 1
 <p / > <p / >   <code > java . lang . illegalargumentexception< / code > 
 <p / > <p / >   <code > java . lang . illegalargumentexception< / code > 
 <p / > <p / >   <code > roundingmode< / code > 
 <p / > <p / >   <code > roundingmode< / code > 
 <p / > <p / > <code > targets< / code >   
 <p / > <p / >  

creates a handler for jetty server with the given list of users . the list of users can be conveniently loaded by using the other method in this utility class : { @link #loadusers ( propertysource string ) } .
loads user records from a given reader . the text stream produced by reader should contain records in java properties format ( see also { @link properties } ) . each property related to authorization entries should be prefixed . this prefix should be passed as a second parameter to this method { @code authpropertiesprefix } .
serialize to xml string
parse an xml file to dom
parse an xml string content to dom
parse an xml coming from an input stream to dom
check the xmldsig signature of the xml document .
sign the xml document using xmldsig .
return the default classloader to use : typically the thread context classloader if available ; the classloader that loaded the classutils class will be used as fallback . <p > call this method if you intend to use the thread context classloader in a scenario where you clearly prefer a non - null classloader reference : for example for class path resource loading ( but not necessarily for { @code class . forname } which accepts a { @code null } classloader reference as well ) .
replacement for { @code class . forname () } that also returns class instances for primitives ( e . g . int ) and array class names ( e . g . string [] ) . furthermore it is also capable of resolving inner class names in java source style ( e . g . java . lang . thread . state instead of java . lang . thread$state ) .
return the user - defined class for the given instance : usually simply the class of the given instance but the original class in case of a cglib - generated subclass .
check whether the given class is cache - safe in the given context i . e . whether it is loaded by the given classloader or a parent of it .
determine the name of the class file relative to the containing package : e . g . string . class
determine the name of the package of the given class e . g . java . lang for the { @code java . lang . string } class .
determine the name of the package of the given fully - qualified class name e . g . java . lang for the { @code java . lang . string } class name .
return the qualified name of the given class : usually simply the class name but component type class name + [] for arrays .
return the qualified name of the given method consisting of fully qualified interface / class name + . + method name .
determine whether the given class has a public constructor with the given signature and return it if available ( else return { @code null } ) . <p > essentially translates { @code nosuchmethodexception } to { @code null } .
return the number of methods with a given name ( with any argument types ) for the given class and / or its superclasses . includes non - public methods .
determine whether the given method is declared by the user or at least pointing to a user - declared method . <p > checks { @link method#issynthetic () } ( for implementation methods ) as well as the { @code groovyobject } interface ( for interface methods ; on an implementation class implementations of the { @code groovyobject } methods will be marked as synthetic anyway ) . note that despite being synthetic bridge methods ( { @link method#isbridge () } ) are considered as user - level methods since they are eventually pointing to a user - declared generic method .
check if the given class represents a primitive ( i . e . boolean byte char short int long float or double ) or a primitive wrapper ( i . e . boolean byte character short integer long float or double ) .
check if the given class represents an array of primitives i . e . boolean byte char short int long float or double .
check if the given class represents an array of primitive wrappers i . e . boolean byte character short integer long float or double .
resolve the given class if it is a primitive class returning the corresponding primitive wrapper type instead .
check if the right - hand side type may be assigned to the left - hand side type assuming setting by reflection . considers primitive wrapper classes as assignable to the corresponding primitive types .
determine if the given type is assignable from the given value assuming setting by reflection . considers primitive wrapper classes as assignable to the corresponding primitive types .
convert a / - based resource path to a . - based fully qualified class name .
convert a . - based fully qualified class name to a / - based resource path .
return a path suitable for use with { @code classloader . getresource } ( also suitable for use with { @code class . getresource } by prepending a slash ( / ) to the return value ) . built by taking the package of the specified class file converting all dots ( . ) to slashes ( / ) adding a trailing slash if necessary and concatenating the specified resource name to this .
return all interfaces that the given instance implements as array including ones implemented by superclasses .
return all interfaces that the given instance implements as set including ones implemented by superclasses .
return all interfaces that the given class implements as set including ones implemented by superclasses . <p > if the class itself is an interface it gets returned as sole interface .
create a composite interface class for the given interfaces implementing the given interfaces in one single class . <p > this implementation builds a jdk proxy class for the given interfaces .
this method initializes servlet filters . <p > default implementation adds request vector filter by default . < / p > <p > overrides of this method can also do things like enforcing utf - 8 encoding . here is an example of how it can be done : <code > final filterholder encfilterholder = contexthandler . addfilter ( characterencodingfilter . class / * enumset . allof ( dispatchertype . class )) ; encfilterholder . setinitparameter ( encoding utf - 8 ) ; encfilterholder . setinitparameter ( forceencoding true ) ; // this line instructs filter to add encoding < / code > however this is usually not something < / p >
writes properties to the temporary file that will be deleted on process exit and returns file url as a result .

identifies web endpoint method to be invoked from the http request s uri . this method processes the request as the following steps : <ol > <li > gets web endpoint classes from the { @code servletcontext } . if they have not been set on the { @code servletcontext } this method loads them by invoking { @code loader#load () } on the loader that the { @code configuration } returns . < / li > <li > determines if the requested uri is ignored by { @link routing } . if the requested uri is matched to the pattern specified by { @code routing#ignore ( string ... ) } the request is forwarded to the next filter chain . < / li > <li > determines if the requested uri is matched to the uri template specified by { @code routing#add ( string class string ) } . if the requested uri is matched to the uri template the corresponding web endpoint method is set to the current http request processing context . < / li > <li > if the requested uri is not matched to any uri template identifies web endpoint class and method according to the default uri convention ( uri ends with / ... / &lt ; simple - name - of - the - endpoint - class&gt ; / &lt ; endpoint - method&gt ; ) . < / li > <li > if any web endpoint method is not identified the request is forwarded to the next filter chain . < / li > < / ol >
pid  - 1

returns template variable name and value pairs extracted from the specified actual uri .
compares this uri template to the specified one . returns <code > &lt ; 0< / code > if this uri template s segment ( split by / ) count is <b > greater< / b > than the specified one <code > &gt ; 0< / code > if this uri template s segment count is <b > less< / b > than the specified one or this uri template s segment count is equivalent to the specified one . this method is used for sorting uri templates according to the priority { @code uritemplate#matches ( string ) } method is tested by { @link routing } class so a stricter template ( which has more segments ) is prior to a less one .
add permission and message one by one .
determines if first class match the destination and simulates kind of <code > instanceof< / code > . all subclasses and interface of first class are examined against second class . method is not symmetric .
returns <code > true< / code > if provided class is interface implementation .
get a map containing field names and wrapped values for the fields values . <p / > if the wrapped object is a { @link class } then this will return static fields . if the wrapped object is any other { @link object } then this will return instance fields . <p / > these two calls are equivalent <code > <pre > on ( object ) . field ( myfield ) ; on ( object ) . fields () . get ( myfield ) ; < / pre > < / code >
the configuration database specify the name of the database .
allows the subtype to be selective about what to bind .
creates a new instance of {
finds all the supertypes that are annotated with {
determine if the given objects are equal returning { @code true } if both are { @code null } or { @code false } if only one is { @code null } . <p > compares arrays with { @code arrays . equals } performing an equality check based on the array elements rather than the array reference .
constructs web endpoint parameter from the specified source list or type . this method is invoked for every web endpoint method parameter by { @link receive } . this method processes according to the following steps : <ol > <li > if the specified type is an array type returns <code > null< / code > . an array type is not supported in this class . < / li > <li > if the specified type is built - in type ( see { @link types#isbuiltintype ( type ) } ) returns the built - in instance . < / li > <li > constructs the value as the specified type from the specified sources and names . if the web endpoint parameter is declared without any source annotation except built - in type this method always returns <code > null< / code > . < / li > <li > if the construction result is not <code > null< / code > returns the result to the client . < / li > <li > if the result is <code > null< / code > of primitive type returns the default value of each primitive type to the client . < / li > <li > if the result is <code > null< / code > of supported collection type ( see { @link types#issupportedcollection ( type ) } ) returns the empty collection of the specified type to the client . < / li > <li > otherwise returns <code > null< / code > . < / li > < / ol >
returns the value of built - in type .
returns the default value of the specified primitive type .
constructs the value of web endpoint parameter . web endpoint parameter declaration falls into the several patterns and each pattern has the own construction logic as below : <ol > <li > named array type - unsupported . always returns <code > null< / code > . < / li > <li > named collection of core value type - supported . the collection instance is constructed according to the default implementation type ( see { @code types#getdefaultimplementationtype ( type ) } ) . if the collection type is not supported ( see { @code types#issupportedcollection ( type ) } ) this method returns <code > null< / code > . each of the collection elements is constructed from the values that { @code values } has returned as the same way of the following core value type . if the constructed collection has no element this method returns <code > null< / code > . < / li > <li > named collection of user - defined value type - supported . the collection instance is constructed according to the default implementation type ( as the same as collection of core value type ) . each of the collection elements is constructed from the values that { @code values } has returned as the same way of following user - defined value type . < / li > <li > named collection of user - defined object type - unsupported . always returns <code > null< / code > . < / li > <li > named core value type - supported . the value that { @code value } has returned is converted to the core value type . if the conversion failed returns <code > null< / code > < / li > <li > named user - defined value type - supported . if the value that { @code value } has returned is assignable to the user - defined value type returns it . if the value that { @code value } has returned is { @code string . class } this method constructs the user - defined value type with public constructor that takes one string . class parameter or public static <code > valueof ( string . class ) < / code > method . if the conversion failed returns <code > null< / code > . < / li > <li > named user - defined object type - partially supported . if the value that { @code value } method has returned is assignable to the user - defined object type returns it . otherwise returns <code > null< / code > ( does not any type conversion ) . < / li > <li > not named array type - unsupported . always returns <code > null< / code > . < / li > <li > not named collection of core value type - unsupported . always returns <code > null< / code > . < / li > <li > not named collection of user - defined value type - unsupported . always returns <code > null< / code > . < / li > <li > not named collection of user - defined object type - unsupported . always returns <code > null< / code > . < / li > <li > not named core value type - unsupported . always returns <code > null< / code > . < / li > <li > not named user - defined value type - unsupported . always returns <code > null< / code > . < / li > <li > not named user - defined object type - supported . first this method instantiates the user - defined object instance form public default constructor and then constructs each of the instances fields value according to the named type construction described above ( by invoking { @code #newparameter ( webcontext type string ) } with the field type and field name ) . if the instantiation is failed returns <code > null < / code > . < / li > < / ol > this method is overridable . you can provide your own value construction to web endpoint parameter by overriding this method .
converts the specified object to the specified type . this method is overridable . you can provide your own conversion to the parameter construction by overriding this method .
converts the specified object to the specified user - defined value type . this method is overridable . you can provide your own conversion to the parameter construction by overriding this method .
returns the web endpoint method parameter from query string .
returns the web endpoint method parameter from cookie in the http request .
returns the web endpoint method parameter from http session .
 md5sha1 .
init databases .
set freemarker variable .
adding custom query condition and value
adding custom query equal value .
support for a single entity with the integration of datatables plugin
creates generic { @code response } that has the specified entity as message body .
creates { @code jsonresponse } to send the specified entity to the client as json format response .
creates { @code xmlresponse } to send the specified entity to the client as xml format response .
1518

18
15
10

 ( bug ) <p > 258 2a - z10 - 35 0 - 9 a  a 10 < / p > <p > 9 - 111 < / p >


power11





 
<code > params< / code > key
<code > params< / code > key
freemarker
body
invokes web endpoint method . this method processes the request as the following steps : <ol > <li > gets web endpoint class by invoking { @code method#getdeclaringclass () } of the web endpoint method set on the current http request processing context and instantiates it with the { @link instantiator } that the { @link configuration#instantiator () } returns . < / li > <li > invokes web endpoint method on the constructed instance with the parameters set on the current http request processing context and sets the invocation result to the current http request processing context . < / li > <li > if the invocation is failed with { @code webexception } this method sends http response with the status code the exception has . < / li > <li > if the invocation is failed for any reasons this method sends http response with the status code 500 ( internal_server_error ) . < / li > < / ol >
set a permission and message wrapper class { @link permbean } with desired permission / s and respective messages .
<p > execute request for all provided permissions . it checks if permissions are already granted or required to grant . < / p > <p > only if only api is greater than 23 ( i . e . marshmallows or later ) . < / p >
<p > check weather single or multiple permissions requires grant . < / p > use instead { @link requestpermission#request () } directly .
show dialog fragment to show dialogs before asking permission . or you can set to show dialogs only when user denied permission earlier .
get on request permissions results invoke annotated methods and send a local broadcast of results .
invoke annotated methods in provided class .
check if annotated result permissions contains all values from annotated array . then it also check if all permissions in annotated method value array are granted .
check if annotated result permissions contains all values from annotated array . then it also check if any permission in annotated method value array is denied .
/ * creates an instance of an interface which is supposed to handle method calls in the proxy .
sqlsql
according to the default primary key <code > id< / code > is for the new data and entity .
query the database record set .
query a data record .

according to the primary key and entity determine whether for the new entity .
paging retrieve default sorted by id you need to specify the datatables request parameters .

determine whether the given method explicitly declares the given exception or one of its superclasses which means that an exception of that type can be propagated as - is within a reflective invocation .
traverses the referencequeue and removes garbage - collected softvalue objects from the backing map by looking them up using the softvalue . key data member .
creates a new entry but wraps the value in a softvalue instance to enable auto garbage collection .
create a { @code loginexception } with a cause .
 asm 
<p > it prepares database after import . < / p >
checks whether a string matches a given wildcard pattern .
/ * constructor .
/ * main method .
/ * user pressed a button .
-------- register / lookup -----------------------------------------------------------
-------- convert string -----------------------------------------------------------
/ * set the properties to the current control values .
/ * set the properties to the current control values .
this methods uses <code > annotatedinterfacearguments< / code > to return an instance of the specified class with methods returning values from the arguments of this handler .
returns an instance of a if the arguments could be correctly parsed and a was not a subclass of argumentswithhelp or no help was requested null otherwise .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
retrieve the protobufclass based on the pojo value . the returned value may get converted as the protobuf builders / setters use primitives . for example if user has declared <code > integer< / code > this get s converted to <code > int< / code > .
return a protobufentity annotation from any object sent null if there is none .
returns true if there is a protobufentity annotation on this class .
return the protobuf class based on the pojo class i . e . grab the value from the protobufentity annotation .
returns a full mapping of all protobuf fields from the pojo class . essentially the only fields that will be returned if they have the protobufattribute annotation .
return the setter for the protobuf builder . <br > 1 . defaults to just set + upper case the first character of the fieldname . 2 . if it s a collection use the addall type method protobuf has 3 . otherwise use the override value from the user s protobufattribute annotation <br >
retrieve the getter against the protobuf class ; default is to is get plus upper case first character of the field name .
retrieve the setter on the pojo class ; default is to is set plus upper case first character of the field name .
return a singleton fully initialized instance of a { @link passwordvalidator } class to use for jaas authentication . <p > retrieving a singleton by this method will cause the factory to keep state and store a reference to the singleton for later use . you may reset the factory state using the { @code reset () } method to retrieve a new / different singleton the next time this method is called .. <p > note that any properties of the singleton ( e . g . configuration ) cannot necessarily be changed easily . you may call the singleton s { @code init () } method but depending on the implementation provided by the respective class this may or may not have the expected effect . <p > if you need tight control over the singleton including its lifecycle and configuration or you require more than one singleton that are different in their internal state ( e . g . with different configurations ) then you should create such objects with the { @code getinstance () } method and maintain their state as singletons in your application s business logic . <p > classes implementing the { @link passwordvalidator } interface <b > must< / b > be thread safe .
<p > filter that make sql where filter for entities with <b > itsversion< / b > and <b > changed time< / b > algorithm . < / p >
/ * set the properties to the current control values .
/ * set the properties to the current control values .
 (   )  .
return a objectmapper if exist else new objectmapper
initialize mapper
return a jsonfactory if exist else new jsonfactory
json string to java bean <br > <p > list array map < / p > <pre > clazz = new typereference&lt ; list&lt ; mybean&gt ; &gt ; () {} ;
json string to java bean <br > <p > list array map < / p > <pre > clazz = new typereference&lt ; list&lt ; mybean&gt ; &gt ; () {} ;
json string to java bean <br > <p > list array map < / p > <pre > clazz = new typereference&lt ; list&lt ; mybean&gt ; &gt ; () {} ;
json string to java bean <br > <p > list array map < / p > <pre > clazz = new typereference&lt ; list&lt ; mybean&gt ; &gt ; () {} ;
json string to java bean <br > <p > list array map < / p > <pre > clazz = new typereference&lt ; list&lt ; mybean&gt ; &gt ; () {} ;
json string to java bean <br > <p > call { @link myjsonparser#getjsonparser () } return a jsonparser < / p >
json string to java bean <br > <p > e . g : < / p > <pre > { id : idvalue name : namevalue abean : { abeanid : abeanidvalue ... }} < / pre > <p > list array map ... see { @link #tobean ( string typereference ) } < / p >
json string to java bean <br > <p > e . g : < / p > <pre > { id : idvalue name : namevalue abean : { abeanid : abeanidvalue ... }} < / pre > <p > list array map ... see { @link #tobean ( byte [] typereference ) } < / p >
json string to java bean <br > <p > e . g : < / p > <pre > { id : idvalue name : namevalue abean : { abeanid : abeanidvalue ... }} < / pre > <p > list array map ... see { @link #tobean ( reader typereference ) } < / p >
json string to java bean <br > <p > e . g : < / p > <pre > { id : idvalue name : namevalue abean : { abeanid : abeanidvalue ... }} < / pre > <p > list array map ... see { @link #tobean ( url typereference ) } < / p >
json string to java bean <br > <p > e . g : < / p > <pre > { id : idvalue name : namevalue abean : { abeanid : abeanidvalue ... }} < / pre > <p > list array map ... see { @link #tobean ( file typereference ) } < / p >
json string to java bean <br > <p > call { @link myjsonparser#getjsonparser () } return a jsonparser < / p >
json string to java bean <br > <p > e . g : < / p > <pre > { id : idvalue name : namevalue abean : { abeanid : abeanidvalue ... }} < / pre > <p > list array map ... see { @link #tobean ( string typereference ) } < / p >
bean to json string
close a { @code connection } and log any sqlexceptions that occur .
close a { @code preparedstatement } and log any sqlexceptions that occur .
close a { @code resultset } and log any sqlexceptions that occur .

<p > fill given field of given entity according value represented as string . < / p >
sets all the border values .
 constructor  constructorinfo  .
obtain an access token . if previously a token was created and persisted will be returned after validation ( a real call is made to validate ) . <p > if no token previously persisted the method will create a new token using the authentication provider ( authprovider )
send a http request with explicit params
send a http request with explicit params
send a http request with explicit params
send a http request with explicit params
send a http request with explicit params
send a http request with explicit params
send a http request with implicit params
send a http request with implicit params
send a http request with implicit params
send a http request with implicit params
send a http request with implicit params
send a http request with implicit params
send a http request with implicit params
get http method instance by { @link com . rockagen . commons . http . requestmethod }
get http method instance by { @link com . rockagen . commons . http . requestmethod }
handler main
handle response ( resolve response to string httpclient close etc . )
get usernamepasswordcredentials
get usernamepasswordcredentials
get url
<p > resolve string to object array < / p > <p > array length is 2 by default return http : // localhost : 80 / < / p > <li > [ 0 ] -- > httphost< / li > <li > [ 1 ] -- > uri< / li >
assumes targetkinds and e are sensible .
assumes targetkinds and e are sensible .
assumes targetkinds and e are sensible .
{
checkstyle : off
the sql statement is retrieved from the configuration and the admin is trusted
obtain a database connection - either a jndi connection ( directly from the factory ) or a pooled jdbc connection
add
sub
sub
mul
mul
div
div
random
random
to double
to float
 annotation action
 .
 .
for a jmx mbean idenfitied by an objectname copy the values of the given attributes into the target object using the specified setter methods mapped by attribute name .
copy the values of the given attributes into the target object using the specified setter methods mapped by attribute name .
*
visits a type declaration .
<p > fill given field of given entity according value represented as string . < / p >
accept this file?
{ @inheritdoc }
-----------------------------------------------------------------------
assumes targetkinds and e are sensible .
assumes targetkinds and e are sensible .
assumes targetkinds and e are sensible .
/ * copy the input stream to the output stream .
/ * copy the input stream to the output stream .
/ * create a new object using this class name . conform to the standardized classname format : com . tourgeek . terminal . src / dest . name . namesrc / dest
/ * convert this date string to a date object .
/ * convert this date object to a string .
/ * create a filter from these properties .
get property .
set property .
add this applet to a frame and initialize .
returns a copy of the key / values in the map at the point of calling . however setvalue still sets the value in the actual softhashmap .
returns the value . the result has one of the following types : <ul > <li > a wrapper class ( such as { @link integer } ) for a primitive type <li > { @code string } <li > { @code typemirror } <li > { @code enumconstantdeclaration } <li > { @code annotationmirror } <li > { @code collection<annotationvalue > } ( representing the elements in order if the value is an array ) <p / > internal . getvalue returns : * <ul > <li > a wrapper class ( such as { @link integer } ) for a primitive type <li > { @code string } <li > { @code typemirror } <li > { @code variableelement } ( representing an enum constant ) <li > { @code annotationmirror } <li > { @code list<? extends annotationvalue > } ( representing the elements in declared order if the value is an array ) < / ul >
print the help for <code > options< / code > with the specified command line syntax . this method prints help information to system . out .
return a commandline object by specifies { @link parser } { @link options } <code > arguments< / code > <code > stopatnonoption< / code >
/ * get ready to start processing .
/ * set up everything to start processing
returns the next element in the iteration . ( returns a sourcefileobject ) .
save the token using java preferences .
get the persisted token using java preferences .
/ * set up everything to start processing
/ * set up everything to start processing
/ * add this file to the destination . note : only supply the file or the stream not both . supply the object that is easier given the source . this dual option is given to allow destinations that require file objects from ( such as ftp or http ) having to write the instream to a physical file before processing it .
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
/ * set the properties to the current control values .
/ * set the properties to the current control values .
 classloader  classpath urls .
 classloader  package  urls .
return a singleton fully initialized instance of an { @link passwordauthenticator } class to use for jaas authentication . <p > retrieving a singleton by this method will cause the factory to keep state and store a reference to the singleton for later use . you may reset the factory state using the { @code reset () } method to retrieve a new / different singleton the next time this method is called .. <p > note that any properties of the singleton ( e . g . configuration ) cannot necessarily be changed easily . you may call the singleton s { @code init () } method but depending on the implementation provided by the respective class this may or may not have the expected effect . <p > if you need tight control over the singleton including its lifecycle and configuration or you require more than one singleton that are different in their internal state ( e . g . with different configurations ) then you should create such objects with the { @code getinstance () } method and maintain their state as singletons in your application s business logic . <p > classes implementing the { @link passwordauthenticator } interface <b > must< / b > be thread safe .
returns current thread s context class loader
 classloader  .
 classloader  .
 java  {
finds the resource with the given name .
returns an input stream for reading the specified resource .
returns an input stream for reading the specified class .
 class 
initialize all fields of this uri from another uri .
initializes this uri from a base uri and a uri specification string . see rfc 2396 section 4 and appendix b for specifications on parsing the uri and section 5 for specifications on resolving relative uris and relative paths .
initialize the scheme for this uri from a uri string spec .
initialize the authority ( userinfo host and port ) for this uri from a uri string spec .
initialize the path for this uri from a uri string spec .
get the scheme - specific part for this uri ( everything following the scheme and the first colon ) . see rfc 2396 section 5 . 2 for spec .
set the scheme for this uri . the scheme is converted to lowercase before it is set .
set the userinfo for this uri . if a non - null value is passed in and the host value is null then an exception is thrown .
set the host for this uri . if null is passed in the userinfo field is also set to null and the port is set to - 1 .
set the port for this uri . - 1 is used to indicate that the port is not specified otherwise valid port numbers are between 0 and 65535 . if a valid port number is passed in and the host field is null an exception is thrown .
set the path for this uri . if the supplied path is null then the query string and fragment are set to null as well . if the supplied path includes a query string and / or fragment these fields will be parsed and set as well . note that for uris following the generic uri syntax the path specified should start with a slash . for uris that do not follow the generic uri syntax this method sets the scheme - specific part .
append to the end of the path of this uri . if the current path does not end in a slash and the path to be appended does not begin with a slash a slash will be appended to the current path before the new segment is added . also if the current path ends in a slash and the new segment begins with a slash the extra slash will be removed before the new segment is appended .
set the query string for this uri . a non - null value is valid only if this is an uri conforming to the generic uri syntax and the path value is not null .
set the fragment for this uri . a non - null value is valid only if this is a uri conforming to the generic uri syntax and the path value is not null .
get the uri as a string specification . see rfc 2396 section 5 . 2 .
determine whether a string is syntactically capable of representing a valid ipv4 address or the domain name of a network host . a valid ipv4 address consists of four decimal digit groups separated by a . . a hostname consists of domain labels ( each of which must begin and end with an alphanumeric but may contain - ) separated & by a . . see rfc 2396 section 3 . 2 . 2 .
---------------------------------------------------------------- byte
---------------------------------------------------------------- string
<p > write standard field of entity into a stream ( writer - file or pass it through network ) . < / p >
support ? as parameter
support : name as parameter and array or collection type
creates new muffinmanager .
get the current value for this muffin .
set the current value for this muffin .
get data from the system clipboard .
set the global clipboard contents .
replace the clipboard cut / cut / paste command with this command .
open this file .
discovers the registered services of the given class .
sets the operation parametres based on a map of values .
obtains the values of all the parametres of the given operation .
finds a parametrized service based on its id .
finds a service in a collection of services based on its class .
rebuilds the {
parses the results of a query and handles any errors .
converts the {
queries for a list of states over the time span specified . leaving a field { @code null } will default to the api defaults .
prepares next chunk to match new size . the minimal length of new chunk is <code > minchunklen< / code > .
appends single <code > e< / code > to buffer .
appends another fast buffer to this one .
creates <code > e< / code > array from buffered content .
returns an iterator over buffer elements .
format xml { @link outputformat#createprettyprint () }
format xml { @link outputformat#createprettyprint () }
format xml { @link outputformat#createcompactformat () }
format xml { @link outputformat#createcompactformat () }
format xml
obtain xml file encoding attribute
bean to xml . <p > using xstream library from serialize objects to xml . < / p > example : <pre > xalias [] xa = { new xalias ( foo foo . class ) } ; xaliasfield [] xaf = { new xaliasfield ( bar bar . class bar ) } ; xaliasattribute [] xaa = { new xaliasattribute ( name user . class name ) } ; xomitfield [] xf = { new xomitfield ( v . class v ) }
bean to xml . <p > using xstream library from serialize objects to xml . < / p > example : <pre > xalias [] xa = { new xalias ( foo foo . class ) } ; xaliasfield [] xaf = { new xaliasfield ( bar bar . class bar ) } ; xaliasattribute [] xaa = { new xaliasattribute ( name user . class name ) } ; xomitfield [] xf = { new xomitfield ( v . class v ) } ximplicitcollection [] xic = null ; ximmutabletype [] xit = null ; xconverter [] xc = null ; then toxml ( bean xa xaf xaa xf xic xit xc ) ; < / pre > <b > note : xstream mode is { @link xstream#no_references } < / b >
bean to xml . <p > using xstream library from xml to serialize objects . < / p > example : <pre > xalias [] xa = { new xalias ( foo foo . class ) } ; xaliasfield [] xaf = { new xaliasfield ( bar bar . class bar ) } ; xaliasattribute [] xaa = { new xaliasattribute ( name user . class name ) } ; xomitfield [] xf = { new xomitfield ( v . class v ) }
bean to xml . <p > using xstream library from xml to serialize objects . < / p > example : <pre > xalias [] xa = { new xalias ( foo foo . class ) } ; xaliasfield [] xaf = { new xaliasfield ( bar bar . class bar ) } ; xaliasattribute [] xaa = { new xaliasattribute ( name user . class name ) } ; xomitfield [] xf = { new xomitfield ( v . class v ) } ; ximplicitcollection [] xic = null ; ximmutabletype [] xit = null ; xconverter [] xc = null ; then tobean ( xmlstr xa xaf xaa xf xic xit xc ) ; < / pre > <b > note : xstream mode is { @link xstream#id_references } < / b >
parser
xstream alias
url pattern = jdbclog : [ driverclassname ] : connectionurl
jdk 1 . 7
 map
/ * ( non - javadoc )
post a message queue event ( during a login workflow ) . <p > if { @code messageq } is { @code null } then messaging is considered disabled .
retrieve or display the information requested in the provided callbacks . <p > the { @code handle } method implementation checks the instance ( s ) of the { @code callback } object ( s ) passed in to retrieve or display the requested information .
<p > write entity into a stream ( writer - file or pass it through network ) . < / p >
 class  .
class . isassignablefrom ()   null   .
creates a logging version of a connection
prints the authorizationurl the user will open the url and obtain an authorization key . when prompted the user should provide the authorization key .
creates a logging version of a preparedstatement
orderedmap interface
<p > retrieve requested entities from db then write them into a stream by given writer . < / p >
return a singleton fully initialized instance of an { @link audit } class to use for jaas event auditing . <p > retrieving a singleton by this method will cause the factory to keep state and store a reference to the singleton for later use . you may reset the factory state using the { @code reset () } method to retrieve a new / different singleton the next time this method is called .. <p > note that any properties of the singleton ( e . g . configuration ) cannot necessarily be changed easily . you may call the singleton s { @code init () } method but depending on the implementation provided by the respective class this may or may not have the expected effect . <p > if you need tight control over the singleton including its lifecycle and configuration or you require more than one singleton that are different in their internal state ( e . g . with different configurations ) then you should create such objects with the { @code getinstance () } method and maintain their state as singletons in your application s business logic . <p > classes implementing the { @link audit } interface <b > must< / b > be thread safe .
<p > it prepares database after import . < / p >
visits a package declaration .
visits a type declaration .
visits a class declaration .
visits a method or constructor declaration .
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
/ * add listeners to the controls .
/ * set the properties to the current control values .
/ * set the properties to the current control values .
/ * user pressed a button .
suppress warnings about this method being too complex ( can t extract a generic subroutine to reduce exec paths )
return the value of a jaas configuration parameter .
<p > synchronize ihasversion . < / p >
returns a filter that selects declarations containing all of a collection of modifiers .
returns a filter that selects declarations of a particular kind . for example there may be a filter that selects only class declarations or only fields . the filter will select declarations of the specified kind and also any subtypes of that kind ; for example a field filter will also select enum constants .
returns a filter that selects those declarations selected by both this filter and another .
returns a filter that selects those declarations selected by either this filter or another .
returns the declarations matched by this filter . the result is a collection of the same type as the argument ; the { @linkplain #filter ( collection class ) two - parameter version } of <tt > filter< / tt > offers control over the result type .
returns the declarations matched by this filter with the result being restricted to declarations of a given kind . similar to the simpler { @linkplain #filter ( collection ) single - parameter version } of <tt > filter< / tt > but the result type is specified explicitly .
double check for map
direct writing the object attribute values the private / protected modifiers will be ignoring if setter function exist return setter function value . <p > if recursively is true will looking from all class hierarchy< / p >
set constructor is accessible
obtained the parent class generic parameter types <p > for example : < / p > <code > classb&lt ; t&gt ; extends classa&lt ; t&gt ; < / code >
obtained the parent class generic parameter type <p > for example : < / p > <code > classb&lt ; t&gt ; extends classa&lt ; t&gt ; < / code >
obtained the parent class generic parameter classes <p > for example : < / p > <code > classb&lt ; t&gt ; extends classa&lt ; t&gt ; < / code >
obtained the interface generic parameter types <p > for example : < / p > <code > classb&lt ; t&gt ; implements classa&lt ; t&gt ; < / code >
obtained the interface generic parameter type <p > for example : < / p > <code > classb&lt ; t&gt ; implements classa&lt ; t&gt ; < / code >
obtained the interface generic parameter classes <p > for example : < / p > <code > classb&lt ; t&gt ; implements classa&lt ; t&gt ; < / code >
create new instance of specified class and type from a map <p > <b > note : clazz must write setter< / b > < / p >
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
/ * set the properties to the current control values .
/ * set the properties to the current control values .
/ * set up everything to start processing
/ * set up everything to start processing
/ * add this file to the destination . note : only supply the file or the stream not both . supply the object that is easier given the source . this dual option is given to allow destinations that require file objects from ( such as ftp or http ) having to write the instream to a physical file before processing it .
/ * set up everything to start processing
/ * close everything down after processing .
returns <tt > true< / tt > if the iteration has more elements . ( in other words returns <tt > true< / tt > if <tt > next< / tt > would return an element rather than throwing an exception . )
/ * should i skip this file? override this .
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
/ * set the properties to the current control values .
/ * set the properties to the current control values .
 (  )
 (  ) 

initialize a set of connection properties based on key / values in a <code > hashmap< / code > .
copy the value of a specific key in a source map to a specific key in a target map . <p > the method checks if the value assigned to the source key is <code > null< / code > and does not copy it if it is <code > null< / code > .
/ * get everything ready .
/ * set up everything to start processing
/ * close everything down after processing .
/ * add this file to the destination . note : only supply the file or the stream not both . supply the object that is easier given the source . this dual option is given to allow destinations that require file objects from ( such as ftp or http ) having to write the instream to a physical file before processing it .
/ * add the files to the backup file
* adds the provided key and value to this map .
* removed the value and key from this map based on the provided key .
 url  ( pathvariables )
audit an event ( during a login workflow ) . <p > if { @code audit } is { @code null } then auditing is considered disabled
standalone support . usually you specify a property file to use ( ie . property . filename = c : \\ temp \\ updatesite . properties )
move files from the source to the destination .
move files from the source to the destination .
prepare to query the given object .
replaces slashes with hyphens and removes padding =
converts an array of bytes to a string of two digits hex - representations
<p > read entity ( fill fields ) from a stream ( reader - file or through network ) . it is invoked when it s start of &lt ; entity < / p >
<p > read entity attributes from stream . < / p >
returns the indexes for a parameter .
parses a sql with named parameters . the parameter - index mappings are put into the map and the parsed sql is returned .
---- parameters ------------------------------------------------
---- model ------------------------------------------------
==============================================================================
<p > filter for immutable entities of type apersistablebase . < / p >
/ * ( non - javadoc )
authenticate a user by validating the user s password returning a subject with one or more { @code principal } s set ( if validation was successful ) or throw a { @code loginexception } ( if validation fails ) <p / > this method checks whether the provided username matches the provided password . this requires a suitable plain text password validator to work as the actual validation is performed by the provided { @code passwordvalidator } ) . the method also checks that the domain is not { @code null } ( but it does allow an empty string value ) . <p / > if the validation is successful a { @code subject } is populated with three principals is returned : the user s id as a concatenation of the username with the string id : and both the user provided domain and the user provided principal ( i . e . the the identifiers used to authenticate the users ) .
<p > read entities from stream ( by given reader ) and synchronize them into db . < / p >
/ * set up everything to start processing
/ * set up everything to start processing
/ * add this file to the destination . note : only supply the file or the stream not both . supply the object that is easier given the source . this dual option is given to allow destinations that require file objects from ( such as ftp or http ) having to write the instream to a physical file before processing it .
/ * convert the url to the proper format .
 .
 .
 substyletype 
 / sql wrapper
 .

  .
/ * ( non - javadoc )
returns normalized <code > path< / code > ( or simply the <code > path< / code > if it is already in normalized form ) . normalized path does not contain any empty or . segments or .. segments preceded by other segment than .. .
 .
 .
 unix  .
 windows  .
 .
 class  klassinfo  (  ) .
 .
 .
 .
 .
 asm 
 .
returns the field value from the supplied <code > pojo< / code > object . if a <code > pojogetter< / code has been set in the { @link protobufattribute } then use that otherwise try getting the field value directly .
create a new serializer and serializes the supplied object / attribute .
create a new serializer and ( de ) serializes the supplied protobu / attribute to a pojo of type <i > pojoclazz< / i > .
loops through the collection of objects and serializes them iff they have protobufentity annotations .
this method does the actual set on the protobuf builder . if the user specified a converter then use that right before we actually try and set the value .
this method does the actual set on the pojo instance . if the user specified a converter then use that right before we actually try and set the value .
tests whether or not the specified abstract pathname should be included in a pathname list .
{
<p > read entities from stream ( by given reader ) and insert them into db with no changes . db must be emptied before coping . < / p >
creates a logging version of a resultset
produces a mapping of label to index for use in parsing state values to the appropriate slot in the state object .
uses the provided label - index mapping to extract state values and create a new state object .
<p > it will clear current database . < / p >
returns raw class for given <code > type< / code > when implementation class is known and it makes difference .
resolves <code > typevariable< / code > with given implementation class .
returns the component type of the given type . returns <code > null< / code > if given type does not have a single component type . for example the following types all have the component - type myclass : <ul > <li > myclass [] < / li > <li > list&lt ; myclass&gt ; < / li > <li > foo&lt ; ? extends myclass&gt ; < / li > <li > bar&lt ; ? super myclass&gt ; < / li > <li > &lt ; t extends myclass&gt ; t [] < / li > < / ul >
returns generic supertype for given class and 0 - based index .
<p > fill given field of given entity according value represented as string . < / p >
/ * ( non - javadoc )
/ * get everything ready .
/ * set up everything to start processing
/ * cleanup .
/ * add this file to the destination . note : only supply the file or the stream not both . supply the object that is easier given the source . this dual option is given to allow destinations that require file objects from ( such as ftp or http ) having to write the instream to a physical file before processing it .
/ * change to this directory .
poll the configured objects now and store the results in the objects themselves .
poll all of the objects one at a time .
create new instance of specified class and type
create new instance of specified class and type
obtain field if recursively is true obtain fields from all class hierarchy
obtain methods list of specified class if recursively is true obtain methods from all class hierarchy
obtain method list of specified class if recursively is true obtain method from all class hierarchy
obtain constructor list of specified class if recursively is true obtain constructor from all class hierarchy
obtain constructor list of specified class if recursively is true obtain constructor from all class hierarchy
obtain methods list of specified class and which are annotated by incoming annotation class if recursively is true obtain methods from all class hierarchy
obtain constructors list of specified class and which are annotated by incoming annotation class if recursively is true obtain constructors from all class hierarchy



creates a logging version of a preparedstatement
 resultclass
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
/ * set the properties to the current control values .
/ * set the properties to the current control values .
select select count ( * ) 
accept this file?
/ * get ready to start processing .
/ * set up everything to start processing
/ * close everything down after processing .
returns the next element in the interation . ( returns a sourcefileobject ) .
<p > it will clear current database then copy data from another with xml messages trough https connection . < / p >
<p > it copy data from another with xml messages through given http connection . < / p >
<p > connect to secure address with method get to receive authenticate cookies . < / p >
<p > it authenticate by post simulate form . < / p >
dumps single byte to output stream .
longvarbinary
check is broken [ log . info () ] : pmd reports issues although log stmt is guarded .
<p > setter for lastdatereplication . < / p >
inspect the given ( java ) class file in streaming mode .
look up the string value identified by the u2 index value from constant pool ( direct or indirect ) .
<p > removes control characters ( char &lt ; = 32 ) from both ends of this string returning { @code null } if the string is empty ( ) after the trim or if it is { @code null } .
<p > returns either the passed in string or if the string is { @code null } the value of { @code defaultstr } . < / p >
<p > returns either the passed in string or if the string is empty or { @code null } the value of { @code defaultstr } . < / p >
<p > returns either the passed in string or if the string is whitespace empty ( ) or { @code null } the value of { @code defaultstr } . < / p >
<p > compares two charsequences returning { @code true } if they represent equal sequences of characters ignoring case . < / p >
<p > check if a string starts with a specified prefix ( optionally case insensitive ) . < / p >
<p > check if a string ends with a specified suffix ( optionally case insensitive ) . < / p >
finds first occurrence of a substring in the given source but within limited range [ start end ) . it is fastest possible code but still original <code > string . indexof ( string int ) < / code > is much faster ( since it uses char [] value directly ) and should be used when no range is needed .
finds first index of a substring in the given source string with ignored case .
finds first index of a substring in the given source string and range with ignored case .
finds the very first index of a char from the specified array . it returns an int [ 2 ] where int [ 0 ] represents the char index and int [ 1 ] represents position where char was found . returns <code > null< / code > if noting found .
finds last index of a substring in the given source string with ignored case .
finds last index of a substring in the given source string with ignored case .
finds last index of a character in the given source string in specified range [ end start ]
finds the very last index of a substring from the specified array . it returns an int [ 2 ] where int [ 0 ] represents the substring index and int [ 1 ] represents position where substring was found . returns <code > null< / code > if noting found .
finds the very last index of a substring from the specified array . it returns an int [ 2 ] where int [ 0 ] represents the substring index and int [ 1 ] represents position where substring was found . returns <code > null< / code > if noting found .
<p > gets a substring from the specified string avoiding exceptions . < / p >
<p > gets a substring from the specified string avoiding exceptions . < / p >
<p > gets the substring before the first occurrence of a separator . the separator is not returned . < / p >
<p > gets the substring after the first occurrence of a separator . the separator is not returned . < / p >
<p > gets the substring before the last occurrence of a separator . the separator is not returned . < / p >
<p > gets the substring after the last occurrence of a separator . the separator is not returned . < / p >
<p > gets the string that is nested in between two instances of the same string . < / p >
<p > gets the leftmost { @code len } characters of a string . < / p >
<p > gets the rightmost { @code len } characters of a string . < / p >
<p > gets { @code len } characters from the middle of a string . < / p >
<p > repeat a string { @code repeat } times to form a new string . < / p >
<p > repeat a string { @code repeat } times to form a new string with a string separator injected each time . < / p >
<p > deletes all whitespaces from a string as defined by { @link character#iswhitespace ( char ) } . < / p >
<p > removes a substring only if it is at the beginning of a source string otherwise returns the source string . < / p >
<p > case insensitive removal of a substring if it is at the beginning of a source string otherwise returns the source string . < / p >
<p > removes a substring only if it is at the end of a source string otherwise returns the source string . < / p >
<p > case insensitive removal of a substring if it is at the end of a source string otherwise returns the source string . < / p >
<p > removes all occurrences of a substring from within the source string . < / p >
removes all characters contained in provided string .
csv  .
{ @inheritdoc }
{ @inheritdoc }
{
{
{
clean up any state associated with the current login attempt .
initialize the instance - global audit object
initialize the instance - global message queue object
initialize the instance - global password validator object
initialize the instance - global password authenticator object
<p > synchronize entity ( that just read ) with entity in database . it just check if it s new . < / p >
sets the parameter using the appropriate setter method ( if present ) .
obtains the parameter using the appropriate getter method ( if present ) .
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
/ * set the properties to the current control values .
/ * set the properties to the current control values .
returns locale from cache .
returns locale from cache .
returns locale from cache where locale may be specified also using language code . converts a locale string like en en_us or en_us_win to <b > new< / b > java locale object .
transforms locale data to locale code . <code > null< / code > values are allowed .
resolves locale code from locale .
decodes locale code in string array that can be used for <code > locale< / code > constructor .
returns cached <code > dateformatsymbols< / code > instance for specified locale .
returns cached <code > numberformat< / code > instance for specified locale .
lookups for locale info and creates new if it doesn t exist .
creates a logging version of a statement
removes all of the elements from this stack .
pushes an item onto the top of this stack .
removes the object at the top of this stack and returns that object as the value of this function .
if there is no input stream use the file to create one .
returns a cached thread - local {
/ * open and read the properties file .
/ * write out the properties .
parse this url formatted string into properties .
parse the param line and add it to this properties object . ( ie . key = value ) .

-----------------------------------------------------------------
/ * constructor .
/ * create a combobox with all the values in this string array .
/ * add all the items in this array to the combobox and set the default .
/ * utility to create a new panel and add it to this parent panel .
 contextpath  requesturi
http basic header .
flash

<p > sets a parameter for this request . the parameter is actually separate from the request parameters but calling on the getparameter () methods of this class will work as if they weren t . < / p >
<p > returns the values of a parameter in this request . it first looks in the underlying httpservletrequest object for the parameter and if that doesn t exist it looks for the parameter retrieved from the multipart request . < / p >
<p > combines the parameters stored here with those in the underlying request . if paramater values in the underlying request take precedence over those stored here . < / p >
initialize a set of database properties based on key / values in a <code > hashmap< / code > .
matches path against pattern using * ? and ** wildcards . both path and the pattern are tokenized on path separators ( both \ and / ) . ** represents deep tree wildcard as in ant .
matches path to at least one pattern . returns index of matched pattern or <code > - 1< / code > otherwise .
match tokenized string and pattern .
changes the rectangle coordinates by adding the specified x and y offsets
checks if this rectangle entirely contains another rectangle .
checks if this rectangle contains a point .
computes the intersection of this rectangle with another one .
computes the union of this rectangle with another one .
replaces the x coordinates of the rectangle with the x coordinates of another one .
replaces the y coordinates of the rectangle with the y coordinates of another one .
if this rectangle intersets with the other one splits this rectangle horizontally so that it does not intersect with the other one anymore .
if this rectangle intersets with the other one splits this rectangle horizontally so that it does not intersect with the other one anymore .
 .
 .
/ * set the properties to the current control values .
/ * set the properties to the current control values .
finds the offset of the specified column from the grid origin .
finds the offset of the specified row from the grid origin .
computes the coordinates of the specified grid cell relatively to the area top left corner .
computes the absolute coordinates of the specified area in the grid .
computes the absolute coordinates of the specified area in the grid .
finds a grid cell that contains the specified point
finds a grid cell that contains the specified point
goes through the child areas and creates a list of collumns
goes through the child areas and creates a list of rows
given a string potentially containing one or more copies of the replacement pattern $ { name } where name may be any value identifier ( e . g . home_dir1 ) replace each occurrence with the value of the parameter with the enclosed name .
return a new fully initialized instance of a { @link messageq } class to use for jaas event messageing . <p > classes implementing the { @link messageq } interface <b > must< / b > be thread safe .
return a singleton fully initialized instance of a { @link messageq } class to use for jaas event messageing . <p > retrieving a singleton by this method will cause the factory to keep state and store a reference to the singleton for later use . you may reset the factory state using the { @code reset () } method to retrieve a new / different singleton the next time this method is called .. <p > note that any properties of the singleton ( e . g . configuration ) cannot necessarily be changed easily . you may call the singleton s { @code init () } method but depending on the implementation provided by the respective class this may or may not have the expected effect . <p > if you need tight control over the singleton including its lifecycle and configuration or you require more than one singleton that are different in their internal state ( e . g . with different configurations ) then you should create such objects with the { @code getinstance () } method and maintain their state as singletons in your application s business logic . <p > classes implementing the { @link messageq } interface <b > must< / b > be thread safe .
<p > synchronize apersistablebaseversion ( itsversion changed time ) . < / p >
/ * add your property controls to this panel . remember to set your own layout manager . also remember to create a new jpanel and pass it to the super class so controls of the superclass can be included . you have a 3 x 3 grid so add three columns for each control
examines a throwable object and gets it s root cause
appends single <code > byte< / code > to buffer .
appends another fast buffer to this one .
/ * final wrapup - pad to 64 - byte boundary with the bit pattern 1 0 * ( 64 - bit count of bits processed msb - first )
/ * private void debugstatus ( string m ) { system . out . println ( m + : ) ; system . out . println ( in : + dumpbytes ( in )) ; system . out . println ( bits : + bits ) ; system . out . println ( buf : + integer . tohexstring ( buf [ 0 ] ) + + integer . tohexstring ( buf [ 1 ] ) + + integer . tohexstring ( buf [ 2 ] ) + + integer . tohexstring ( buf [ 3 ] )) ; }
multipart / form - data
application / octet - stream






 bean
 bean
----------------------------------------------------------------------------------------------------------------
launches the debugger as a stand - alone swing application .
should be notified every time byte - code is added to the machine .
copies code from the specified code buffer into the internal one resizing the internal code buffer if necessary to make enough room .
renders disassembled instructions into the code table starting at the specified row and instruction address .
{
{
{
gets the actual value of a term which is a numeric type equal in value to the arithmetic operator applied to its arguments . this method checks that both arguments produce values which are fully instantiated and numeric when their { @link term#getvalue () } methods are invoked .
loads a properties file and stores it in the application context . the property resource name and the application scope variable name are passed as initialization parameters in the servlet config in the web . xml .
{
return a queryparameter which contains reference to the original elements except for those from the exception list .
adds a child tree to the children of this point in the tree . if this is already a node then it remains as a node . if this is a leaf then adding a child to it must promote it to become a node . this implementation supports turning leaves into nodes .
clears all the children of this point in the tree . if this point is a leaf it will have no children so this operation does nothing . if this point is a node it will be reduced to a leaf by this operation . this implementation supports turning nodes into leaves .
gets the next element from the sequence if one is available . the difference between this method and { @link #nextinsequence } is that this method consumes any cached solution so subsequent calls advance onto subsequent solutions .
gets the next element from the sequence the cached one if one has already been generated or creating and caching a new one if not . if the cached element from a previous call has not been consumed then subsequent calls to this method will not advance the iterator .
adds a conjunctive body functor or head functor to this clause along with the instructions that implement it .
adds some instructions to the parent predicate and also adds this as a clause on the parent if it has not already been added .
evaluates the arithmetic operator on its two numeric arguments .
called when a property in the workpanelstate is changed . this method calls initpanels to rebuild the user interface to reflect the current application state .
sets the specified work panel to listen to the button press events for all of the ok cancel and apply buttons . regisers this object to listen for changes to the work panels state .
the {
{
{
{
{
keeps the set of flags indicating which window components are present up - to - date .
----------------------------------------------------------------------------------------------------------------
creates a new decimal type with the specified name if it does not already exist .
{
----------------------------------------------------------------------------------------------------------------
determine whether a term is a free variable .
{ @inheritdoc }
performs an optimization pass for specialized instructions .
compares two collections using lexicographic ordering based on a comparator of their elements .
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
todo : fix for selenium
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
processes the http request that is directed to this servlet .
renders the paging control .
renders a button control as a hyperlink for the page control .
{
{
resets the learning method . this should clear all the examples properties to learn from and for and the input machine to train .
this should be called at the start of the learn method to initialize the input and output property sets .
returns the value to which this map maps the specified key .
returns the index to which this map maps the specified key .
associates the specified value with the specified key in this map .
inserts the element at the specified index . this only works if this index already exists .
removes the mapping for the specified key from this map if present .
removes the specified index from the data structure . this only works if the index already exists .
checks if the bean has a named property . note that if the property value is set to null on the bean this method will still return true it tests for the existance of a named property including null ones .
sets the value of a property of the bean by name .
returns a single named property of the bean .
checks if a wrapper type is assignable from a primtive type .
initialized this property introspector on a specified object building the caches of getter and setter methods .
{
{
performs the actual decision based on a property of the state . if the quick lookup table has been initialized then the decision is taken straight from it . if not then the supplied reference to the decision tree at this point is used to find the outcome by scanning over its children .
initializes the lookup table for this decision node . the specified decision tree that corresponds to this node is used to extract all the possible outcomes for this decision and these are stored in a lookup table so that future decisions made with this tree will run faster .
unifies two terms and produces a list of bound variables that form the unification when it it possible .
attempts to unify one term with another against a background of already unified variables in both terms . in the case where two terms are being unified from scratch the variable assignments will be empty .
unifies a variable with a term . if the variable is bound then the bound value is unified with the term . if the term is a bound variable and the variable is free then the vairable is unified with the bound value of the term . otherwise the variable is free and is bound to the value of the term .
{
{ @inheritdoc }
compiles a program clause and adds its instructions to a compiled predicate .
compiles a clause as a query . the clause should have no head only a body .
examines all top - level functors within a clause including any head and body and determines which functor has the highest number of arguments .
compiles the head of a clause into an instruction listing in wam .
allocates stack slots where needed to the variables in a program clause . the algorithm here is fairly complex .
allocates stack slots to all free variables in a query clause .
gather information about variable counts and positions of occurrence of constants and variable within a clause .
pretty prints a compiled predicate .
pretty prints a compiled query .
writes the specified integer value as an ascii string into the specified byte buffer . if the integer value is shorted than the specified length the number will be padded with leading zeros so that it fills the required length . if there is insufficient space in the buffer to write the value into then the buffer size is increased using the supplied byte buffer pool .
returns the contents of a buffer as a string converting ascii characters in the buffer into unicode string characters .
sets the integer id of the attribute . if the attribute class is finalized this will change the value of this attribute to that of the matched id or raise an exception if no matching id exists . if the attribute class is unfinalized this will change the id value of this attribute within the attribute class to the new id provided that the id has not already been assigned to another attribute value . if it has been assigned to another attribute value then an exception is raised .
gets the string value of a string attribute .
sets the specified string as the value of this attribute . the value to set must be a legitimate member of this attributes type when the type has been finalized . if the type has yet to be finalized then the new value is added to the set of possible values for the type .
parses the next sentence from the current token source .
reads a lojix term and invoked appropriate methods on the content handler to describe its structure and contents to it .
----------------------------------------------------------------------------------------------------------------
checks if the named class exists and is loadable .
checks if the named class exists and is loadable and is a sub - type of the specified class .
checks that the named child class is the same type or a sub - type of the named parent class .
checks that the child class is the same type or a sub - type of the parent class .
gets the class object for a named class .
creates an instance of a class instantiated through its no - args constructor .
calls a constuctor with the specified arguments .
calls a named method on an object with a specified set of parameters any java access modifier are overridden .
calls a named method on an object with a specified set of parameters .
calls a named static method on a class with a specified set of parameters .
gets the constructor of a class that takes the specified set of arguments if any matches . if no matching constructor is found then a runtime exception is raised .
finds the argument types of all setter methods on a bean for a given property name . for a method to be a setter method it must have a void return type be public and accept only a single argument . its name must be set followed by the property name .
renders the table .
----------------------------------------------------------------------------------------------------------------
wraps a java . util . concurrent . blockingqueue as a { @link com . thesett . common . util . concurrent . blockingqueue } implementation .
wraps a java . util . concurrent . blockingqueue as a { @link com . thesett . common . util . concurrent . blockingqueue } implementation .
wraps queue as a sizeable atomically counted queue as per the { @link #getsizeablequeue } and { @link #getatomiccountedqueue } methods .
provides a transactional queue that delays all queue manipulation operations until the transaction is committed or erases them if it is rolled back .
provides a transactional requeue that delays all queue manipulation operations until the transaction is committed or erases them if it is rolled back . as this is a requeue the requeue buffer may be examined directly and the queue fully supports browsing with iterators .
wraps queue as a sizeable transactional requeue as per the { @link #getsizeablequeue } and { @link #gettransactionalrequeue } methods .
wraps queue as a sizeable atomically counted queue transactional requeue as per the { @link #getsizeablequeue } { @link #getatomiccountedqueue } and { @link #gettransactionalrequeue } methods .
gets the type of a specified object .
resets the search clearing out the queue and setting it to contain just the start state node .
this logic enqueues all the start states calling the { @link #createsearchnode } method that concrete sub - classes implement to specify the search node type . if there is a repeated state filter set up then this is attached to the search nodes . this is called at the start of the search method to set up the queue into a state which is ready for the search algorithm .
implementation of the general queue search . the basic algorithm is simple : take the next element from the queue and goal test it . if it is a goal then return it and stop the search . if it is not a goal then expand its successor states and enqueue them and then repeat the procedure .
perform the search . this can be called multiple times to get successive results where more than one goal can be found if the algorithm supports this . in this case it should return null once no more goals can be found .
{
creates a new int range type with the specified name if it does not already exist .
{ @inheritdoc }
{
evaluates the arithmetic operator on its two numeric arguments .
{
{
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
{
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
add a new supported tz . add one aliase with the same name
timezone is case sensitive
add a dimension as mandatory . mandatory dimension names are stored in upper case .
build the configuration links ( ie foreigns key ) . checks the validity of the configuration .
{
calculates the set of free variables in a term .
calculates the set of free and non - anonymous variables in a term . this is the set of variables that a user query usually wants to be made aware of .
flattens a sequence of terms as a symbol seperated argument list . terms that have been parsed as a bracketed expressions will not be flattened . all of the terms in the list must sub sub - classes of a specified super class . this is usefull for example when parsing a sequence of functors in a clause body in order to check that all of the body members really are functors and not just terms .
flattens a sequence of terms as a symbol seperated argument list . terms that have been parsed as a bracketed expressions will not be flattened . all of the terms in the list must sub sub - classes of a specified super class . this is usefull for example when parsing a sequence of functors in a clause body in order to check that all of the body members really are functors and not just terms .
converts a term into a clause . the term must be a functor . if it is a functor corresponding to the : - symbol it is a clause with a head and a body . if it is a functor corresponding to the ? - symbol it is a query clause with no head but must have a body . if it is neither but is a functor it is interpreted as a program clause : - with no body that is a fact .
compares two heuristic search nodes by their heuristic values .
reads a text file as a string .
reads a text file as a string .
writes an object using its tostring method to the named file . the object may optionally be appended to the file or may overwrite it .
reads the contents of a reader one line at a time until the end of stream is encountered and returns all together as a string .
appends the specified element to the end of this list ( optional operation ) .
removes the first occurrence in this list of the specified element ( optional operation ) . if this list does not contain the element it is unchanged . more formally removes the element with the lowest index i such that <tt > ( o == null ? get ( i ) == null : o . equals ( get ( i ))) < / tt > ( if such an element exists ) .
inserts the specified element at the specified position in this list ( optional operation ) . shifts the element currently at that position ( if any ) and any subsequent elements to the right ( adds one to their indices ) .
removes the element at the specified position in this list ( optional operation ) . shifts any subsequent elements to the left ( subtracts one from their indices ) . returns the element that was removed from the list .
appends all of the elements in the specified collection to the end of this list in the order that they are returned by the specified collection s iterator ( optional operation ) . the behavior of this operation is unspecified if the specified collection is modified while the operation is in progress . ( note that this will occur if the specified collection is this list and it s nonempty . )
{
{
creates the correct type of search nodes for this search . this search uses heuristic search nodes .
applies a built - in replacement transformation to functors . if the functor matches built - in a { @link builtinfunctor } is created with a mapping to the functors built - in implementation and the functors arguments are copied into this new functor . if the functor does not match a built - in it is returned unmodified .
generates a sequence of spaces to indent debugging output with .
{
{
for a predicate of arity n the first n registers are used to receive its arguments in .
allocates terms within a functor expression to registers . the outermost functor itself is not assigned to a register in wam ( only in l0 ) . functors already directly assigned to argument registers will not be re - assigned by this . variables as arguments will be assigned but not as argument registers .
determines whether a variable is local that is it may only exist on the stack . when variables are introduced into clauses the way in which they are introduced is recorded using the { @link varintroduction } enum . when a variable is being written to the heap for the first time this check may be used to see if a local variant of an instruction is needed in order to globalize the variable on the heap .
checks if a variable is appearing within the last body functor in which it occurs and only does so within argument position .
builds a decision tree by repeatedly selecting the best property of the data examples to split on . the best property is chosen to be the one that reveals the most information about the target property to learn .
this helper method works out how the majority of the specified examples are classified by the named property . the property should always be the goal property that the algorithm is learning and must always take on a finite number of different values .
tests if a property of a set of examples has the same value for all the examples . this algorithm works by iterating through the examples until two different values are found or the end of the collection is reached having found only one value .
for a given set of examples input properties and an output property this method chooses the input property that provides the largest information gain on the value of the output property .
creates a functor .
creates an atom ( functor with no arguments ) .
creates a variable . if the variable name begins with an underscore _ it will be anonymous otherwise it will be named .
handles an http request sent to this action by struts . this simply forwards to the location specified by the redirect request parameter .
extracts the sub - list at the specified page index . the returned list will have size equal to the page size unless it is the last page in which case it may not be a full page .
{
{
{
sets the kind of paint to use . for the image background?
immediately repaints the surface .
renders the surface . this method will create a buffered image to render in if one does not already exist . if rendering is to be done directly to the screen no buffered image will be generated . if the size of the buffered image does not match the graphics context size then a new buffered image will be generated of the correct size before rendering . the { @link #render } method will be called to do the actual drawing .
generates a fresh buffered image of the appropriate type .
creates a graphics2d drawing context from a bufferedimage or graphics context . the graphics context is built using the properties defined for the surface . this method is used to generate the graphics2d context that subclasses will render in . if the buffered image is null then the passed in graphics context will be used to generate the graphics2d context . this is the case when no buffered image is used and the subclass renders straight to the screen .
creates a custom grey - scale binary image format .
creates a custom colour image format .
{
workaround mockwebserver issue #11 .
{
<p > handles requests that accept application / json . < / p >
<p > generic processor of all types of requests . < / p > <p > validates schema availability mandatory fields for the specified schema and creates chains of { @link queryparameteraware } to be processed by the underlying { @link genericschemaservice } . < / p >
<p > handles { @link serviceexception } generated by the underlying layer . < / p >
<p > handles { @link invalidparameterexception } generated by the controller itself when receives an invalid parameter . < / p >
<p > handles { @link invalidschemaexception } generated by the controller itself when receives a request to a non existing schema configuration . < / p >
<p > creates a { @link pair } composed of dimension and information required by the { @link genericschemaservice } . < / p >
todo to be removed
{
checks if the give column exist ( by name )
{
{
allows different queue search algorithms to replace the default one . this overidden method ensures that the peek at head flag is always set on the search algorithm and that it expands it successor nodes in reverse as for depth first searches .
search iteratively on increasing maximum bound limits until the search space is exhausted or a goal state is found .
{ @inheritdoc }
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
search until a goal state is found or the maximum allowed number of steps is reached .
{ @inheritdoc }
parses statements and print the parse tree to the console for quick interactive testing of the parser .
parses many consecutive sentences until an <eof > is reached . this method is intended to aid with consulting files .
parses a single sentence in first order logic . a sentence consists of a term followed by a full stop .
parses multiple sequential terms and if more than one is encountered then the flat list of terms encountered must contain operators in order to be valid prolog syntax . in that case the flat list of terms is passed to the { @link dynamicoperatorparser#parseoperators ( term [] ) } method for deferred decision parsing of dynamic operators .
recursively parses terms which may be functors atoms variables literals or operators into a flat list in the order in which they are encountered .
parses a single atom in first order logic . if the operator has been set up which has the same name as the atom then the atom may actually be a functor expressed as a prefix postfix or infix operator . if this is the case the value returned by this method will be a { @link candidateopsymbol } . otherwise it will be a { @link functor } of arity zero .
parses a single functor in first order logic with its arguments .
parses a list expressed as a sequence of functors in first order logic . the empty list consists of the atom nil and a non - empty list consists of the functor cons with arguments the head of the list and the remainder of the list .
parses a sequence of terms as a comma seperated argument list . the operator in prolog can be used as an operator when it behaves as a functor of arity 2 or it can be used to separate a sequence of terms that are arguments to a functor or list . the sequence of functors must first be parsed as a term using the operator precedence of to form the term . this method takes such a term and flattens it back into a list of terms breaking it only on a sequence of commas . terms that have been parsed as a bracketed expression will not be broken up .
parses a variable in first order logic . variables are scoped within the current sentence being parsed so if the variable has been seen previously in the sentence it is returned rather than a new one being created .
parses an integer literal .
parses a real number literal .
parses a string literal .
peeks at the next token to see if it is an { @link #atom } which is equal to ; and if it is consumes it . if the symbol is consumed then the return value indicates that this has happened . this is intended to be usefull for interactive interpreters when querying the user to see if they want more solutions to be found .
peeks and consumes the next interactive system directive .
interns an operators name as a functor of appropriate arity for the operators fixity and sets the operator in the operator table .
interns and inserts into the operator table all of the built in operators and functors in prolog .
consumes a token of the expected kind from the token sequence . if the next token in the sequence is not of the expected kind an error will be raised .
peeks ahead for the given token type and if one is foudn with that type it is consumed .
binds the session as a transactional context to the current thread if it is not already bound .
forgets pending operations .
extracts all elements from an iterator usually created from a filterator and adds them into the target collection returning that collection as the result .
{ @inheritdoc }
reserves a call point for a block of named callable code . the size of the block of code must be known fully in advance . if the named block already has a call point this will replace it with a new one .
converts a field by field timestamp into millisecond ticks .
converts a field by field timestamp into millisecond ticks .
converts a field by field time of day into millisecond ticks .
extracts the years component of a time in millisecond ticks .
extracts the date ( day in month ) component of a time in millisecond ticks .
sets the component of the timestamp returning the new timestamp with updated component .
sets the minutes component of the timestamp returning the new timestamp with updated component .
sets the seconds component of the timestamp returning the new timestamp with updated component .
sets the year component of the timestamp returning the new timestamp with updated component .
sets the month component of the timestamp returning the new timestamp with updated component .
sets the date component of the timestamp returning the new timestamp with updated component .
calculates the number of milliseconds to the start of the specified year taking 1970 as zero .
writes a time of day with milliseconds in the format hh : mm : ss [ . sss ] into a byte buffer . the specified buffer will be enlarged if necessary using the specified byte buffer pool .
writes only the time component of a time of day timestamp to a byte array in the following format : hh : mm : ss [ . sss ] . the millisecond value is optional and is only written if requested . if there is insufficient space in the buffer to write the value into then the buffer size is increased using the supplied byte buffer pool .
given a millisecond timestamp that lands in a specified year calculate what month the timestamp corresponds to .
reads some number of bytes from the input stream and stores them into the buffer array b . the bytes are also returned wrapped in a byte block so that they can be returnd over rmi .
reads up to len bytes of data from the input stream into an array of bytes .
{
{
{
looks up the specified key in hash table using cuckoo hashing . if the key cannot be found in the table then the next available sequence number is allocated to it and a new entry is added to the hash table for the key again using cuckoo hashing .
checks if the specified key can be found in the set and returns its entry if so .
adds a new entry to a hash table using the cuckoo algorithm .
creates a new hashtable that is twice the size of the old one then re - hashes everything from the old table into the new table .
implements robert jenkins 32 - bit integer hash function . <a href = http : // www . concentric . net / ~ttwang / tech / inthash . htm / > http : // www . concentric . net / ~ttwang / tech / inthash . htm< / a >
thomas wang s 32 - bit shift hash function . <a href = http : // www . concentric . net / ~ttwang / tech / inthash . htm / > http : // www . concentric . net / ~ttwang / tech / inthash . htm< / a >
implements a secondary hash . this uses the 32 - bit shift hash implemented by { @link #hash32shift ( int ) } and then successively applies { @link #hash1 ( int ) } if the generated hash code is not different to the hash code generated by running { @link #hash1 ( int ) } on the key . this ensures that the hash code returned by this will be different to the one generated by { @link #hash1 ( int ) } .
{
listens for the button events ok cancel and apply . if the event is ok or apply the savework method is triggered . if the event is cancel then the discardwork method is triggered .
sets the state of the next available flag and notifies any listeners of this change .
sets the state of the previous available flag and notifies any listeners of this change .
sets the state of the finished and notifies any listeners of this change .
creates an instance of this machine loading and checking for availability of the native implementation library as required .
provides an iterator that generates all solutions on demand as a sequence of variable bindings .
for a given set of probabilities of the occurences of symbols this function calculates the expected information content of a set of symbols given its probability distribution . the answer is expressed as a positive number of bits .
supposing a stream generates pairs of symbols . let the first be a and the second be g . a ranges over a set of symbols { h1 ... hv } and g ranges over a set of symbols { g1 ... gn } .
estimates probabilities given a set of counts of occurrences of symbols .
supposing a stream generates pairs of symbols . let the first be a and the second be g . a ranges over a set of symbols { h1 ... hv } and g ranges over a set of symbols { g1 ... gn } .
{
{
sets this date from a milliseconds timestamp .
recreate internal state before children are cloned .
processes the action .
checks but does not enforce the throttle rate . when this method is called it checks if a length of time greater than that equal to the inverse of the throttling rate has passed since it was last called and returned <tt > true< / tt > . if the length of time still to elapse to the next throttle allow point is zero or less this method will return a negative value if there is still time to pass until the throttle allow point this method will return a positive value indicating the amount of time still to pass . a thread can wait for that period of time before rechecking the throttle condition .
creates a url for the specified string representation .
returns a string with all basic request information in an html table .
returns a string with all header information as an html table .
returns a string with all cookie information as an html table .
returns a string with all request parameter information .
returns a string with all request scope variables .
returns a string with all page scope variables .
returns a string with all session scope variables .
returns a string with all application scope variables .
returns the user principal name .
renders the debugging message .
returns an html table with all the values of the specified property .
returns a string representation of the specified object in a format suitable for debug output . if the object is an array all its elements are extracted and displayed seperated by commas . other objects are converted to strings by their tostring methods .
searches all searchnodes less than the maximum bound for some property of the nodes .
sets the new current screen state and notifies all listeners of the change in screen state .
walks over the supplied term .
compares two heuristic search nodes by their f values .
updates the register file with a new set of registers .
compares the current register file with a new set and creates a list property change notifications for any that have changed value .
fires off a list of property change events to any interested listeners .
{
{
{
{
{ @inheritdoc }
{ @inheritdoc }
upon leaving the clause sets the nonargposition flag on any constants that need it .
checks if the current position is immediately within a top - level functor .
functors are considered top - level when they appear at the top - level within a clause or directly beneath a parent conjunction or disjunction that is considered to be top - level .
adds all of the elements in the specified collection to this heap . attempts to addall of a queue to itself result in <tt > illegalargumentexception< / tt > . further the behavior of this operation is undefined if the specified collection is modified while the operation is in progress .
removes a single instance of the specified element from this heap if it is present . ( optional operation ) . more formally removes an element <tt > e< / tt > such that <tt > ( o == null ? e == null : o . equals ( e )) < / tt > if the collection contains one or more such elements . returns <tt > true< / tt > if the collection contained the specified element ( or equivalently if the collection changed as a result of the call ) .
returns an array containing all of the elements in this heap . if the collection makes any guarantees as to what order its elements are returned by its iterator this method must return the elements in the same order . the returned array will be safe in that no references to it are maintained by the collection . ( in other words this method must allocate a new array even if the collection is backed by an array ) . the caller is thus free to modify the returned array .
returns an array containing all of the elements in this heap ; the runtime type of the returned array is that of the specified array . if the collection fits in the specified array it is returned therein . otherwise a new array is allocated with the runtime type of the specified array and the size of this collection .
provides a look at the last object placed on the stack since it will be the first one out . this method does not change the contents of the stack . because this class is unsynchronized applications using this class are responsible for making sure that a <code > peek () < / code > followed by a <code > pop () < / code > returns the same value .
----------------------------------------------------------------------------------------------------------------
{
applies a built - in replacement transformation to functors . if the functor matches built - in a { @link builtinfunctor } is created with a mapping to the functors built - in implementation and the functors arguments are copied into this new functor . if the functor does not match a built - in it is returned unmodified .
sets the arguments of this operator . it can be convenient to be able to set the outside of the constructor for example when parsing may want to create the operator first and fill in its arguments later .
provides the symbols fixity derived from its associativity .
reports whether this operator is an infix operator .
compares this object with the specified object for order providing a negative integer zero or a positive integer as this symbols priority is less than equal to or greater than the comparator . if this symbol is less than another that means that it has a lower priority value which means that it binds more tightly .
called when a property in the work flow state is changed .
updates the buttons enabled / disabled status to reflect the current screen state .
updates the buttons enabled / disabled status to reflect the current work flow state .
registers the work flow button panel with the specified work flow controller . this will cause the work flow controller to receive button press events from the panel and register the button panel to receive state changes from the underlying work flow model .
{
generates a factory for building enum attributes of the specified enum class .
{ @inheritdoc }
creates an instance of the named component factory .
provides the storage cell for the specified variable . some types of variable may defer their storage onto a storage cell other than themselves other variable types may simply return themselves as their own storage cells .
reports whether or not this variable is bound to a value .
{
sets a column attribute adding padding to the underlying array as necessary to ensure it is large enough to hold the attribute at the requested position .
sets a row attribute adding padding to the underlying array as necessary to ensure it is large enough to hold the attribute at the requested position .
gets a columns attribute if possible without overflowing the underlying array .
gets a rows attribute if possible without overflowing the underlying array .
inserts a set of attributes into the grid at the specified location . this is a private insert method that does not notify model listeners so that the public insert methods can do that as a separate step .
gets the actual value of a term which is a numeric type equal in value to the arithmetic operator applied to its argument . this method checks that the argument produces a value which is fully instantiated and numeric when its { @link term#getvalue () } methods is invoked .
{
{
{
creates a new time range type with the specified name if it does not already exist .
{ @inheritdoc }
{
creates a new string pattern type with the specified name if it does not already exist .
checks a string value against this type to see if it is a valid instance of the type .
{
{
{
{
{
{
{
{
{
{
sets up the initial context once at the start of a traversal .
updates the layout register file with a new set of layout registers .
compares the current register file with a new set and creates a list property change notifications for any that have changed value .
search up the scope tree to locate the variable s value . the parser has already verified that the variable is defined .
implementation of the general bi - dircetional search . the search alternated between taking a forward and a reverse step .
once a match has been found between the forward and reverse fringes of the search a path is known to exist from the start to the goal . the path is not complete at this stage because it remains to reverse all of the steps in the backward half of the path and add them to the forward half of the path to produce the complete forward path from start to the goal .
{ @inheritdoc }
gets the element from the list at the specified index . if the indexes block is not currently cached then a call is made to the { @link #getblock } method to fetch it .
fetches and caches the specified block .
static factory method that locates an existing instance or creates a new property reader for a named resource .
specifies the throttling rate in operations per second .
reads some number of bytes from the input stream and stores them into the buffer array b .
reads up to len bytes of data from the input stream into an array of bytes .
skips over and discards n bytes of data from this input stream .
{
{
gathers the functors to compile as a sequence of choice points . these exist as the arguments to disjunctions recursively below the supplied disjunction . they are flattened into a list by performing a left - to - right depth first traversal over the disjunctions and adding their arguments into a list .
explores one argument of a disjunction as part of the { @link #gatherdisjunctions ( disjunction list ) } function .
{
{
returns the first ( lowest ) key currently in this priority map .
returns the value of the first ( lowest ) key currently in this priority map .
extracts an int from an array of bytes .
outputs an int into a byte array .
outputs an int into a byte array copying only the bottom 24 bits of the integer . the top sign bit is lost by this operation so this only works on positive ints below 2^24 .
extracts an int from an array of bytes . only three bytes are pulled together from the array to make a 24 bit integer albeit returned as a java 32 bit int .
extracts a short from an array of bytes .
outputs a short into a byte array .
{
provides an implementation of the { @link boundproperty } interface to extract the cost as the bound property .
returns the state obtained by applying the specified operation . if the operation is not valid then this should return null .
gets all operators valid from this state . if the current tree to search has any children these are encoded as operators to access those child trees as tree search states . if the current tree is a leaf then an empty iterator is returned .
returns the integer id of the attribute .
gets the object value of a object attribute .
sets the specified object as the value of this attribute . the value to set must be a legitimate member of this attributes type when the type has been finalized . if the type has yet to be finalized then the new value is added to the set of possible values for the type .
converts a string listing sub - strings seperated by a delimeter into an array of strings .
converts an array of strings into a delimeter seperated string .
converts a string to camel case .
converts string between various case forms such as camel case snake case or kebab case .
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
provides a string containing information about the configured logging set up .
lists information about logging handlers .
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
{
{
{
{
{
{
{
looks up the offset of the start of the code for the named functor .
{
{
records the offset of the start of the code for the named functor .
records the id of an internal function for the named functor . the method name uses the word address but this is not really accurate the address field is used to hold an id of the internal function to be invoked . this method differs from { @link #setcodeaddress ( int int int ) } as it does not set the reverse mapping from the address to the functor name since an address is not really being used .
tests if another hierarchy attribute is strict a sub - category of this one . it is a sub - category if it has the same sequence of path labels as this one as a prefix of its whole path label .
returns the long id of the attribute .
sets the integer id of the attribute . if the attribute class is finalized this will change the value of this attribute to that of the matched id or raise an exception if no matching id exists . if the attribute class is unfinalized this will change the id value of this attribute within the attribute class to the new id provided that the id has not already been assigned to another attribute value . if it has been assigned to another attribute value then an exception is raised .
gets the label value at the named level of the hierarchy .
gets the label value at the last level of the hierarchy .
serialized a hierarchy attribute .
deserializes a hierarchy attribute .
returns heuristic evaluation of an eight puzzle board position as the manhattan distance of all tiles from their correct positions .
associates the specified value with the specified key in this map .
returns <tt > true< / tt > if this map contains a mapping for the specified coordinates .
associates the specified value with the specified coordinate in this map ( optional operation ) . if the map previously contained a mapping for this coordinate the old value is replaced .
removes the mapping for this coordinate from this map if present ( optional operation ) .
calculates the modulo of a coordinate with the bucket size . correctly calculates this module for negative coordinates such the the first negative bucket is - 1 with element 0 corresponding to - 100 running to 99 corresponding to - 1 .
adds another user readable error message to this exception .
converts an exception into struts action errors . the exception stack trace is stored under the exception message key . the message resource error . internalerror is stored under the message key generalerror . the stack trace is pretty printed in html .
writes a string of characters to the filtered writer . any newline characters \ n are replaced with an html break tag &lt ; br&gt ; .
/ * perform any handshaking processing . <p > if a selectionkey is passed register for selectable operations . <p > in the blocking case our caller will keep calling us until we finish the handshake . our reads / writes will block as expected . <p > in the non - blocking case we just received the selection notification that this channel is ready for whatever the operation is so give it a try . <p > return : true when handshake is done . false while handshake is in progress
/ * read the channel for more information then unwrap the ( hopefully application ) data we get . <p > if we run out of data we ll return to our caller ( possibly using a selector ) to get notification that more is available . <p > each call to this method will perform at most one underlying read () .
/ * try to flush out any existing outbound data then try to wrap anything new contained in the src buffer . <p > return the number of bytes actually consumed from the buffer but the data may actually be still sitting in the output buffer waiting to be flushed .
/ * flush any remaining data . <p > return true when the filechannelbb and outnetbb are empty .
/ * begin the shutdown process . <p > close out the sslengine if not already done so then wrap our outgoing close_notify message and try to send it on . <p > return true when we re done passing the shutdown messsages .
{
{
{
{ @inheritdoc }
functors are considered top - level when they appear at the top - level within a clause or directly beneath a parent conjunction or disjunction that is considered to be top - level .
{
{
{ @inheritdoc }
classifies a state using the decision tree .
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
translates the partial order into the + 1 0 - 1 convention needed by comparators .
creates a priority queue with an { @link astarcomparator } to control the search ordering of the basic queue search algorithm .
{
{
{ @inheritdoc }
{ @inheritdoc }
{
{
{
{
returns a distriubuted iterator that can provide elements of the list on demand over a remote connection .
calcalates the log base 2 of an integer . this code is tuned to uniformly distributed output values longer numbers are slightly favoured .
calcalates the log base 2 of an integer . this code is tuned to uniformly distributed input values longer numbers are favoured .
calcalates the log base 2 of an integer in o ( log ( n )) steps ; shorter numbers are favoured .
calcalates the log base 10 of an integer . this produces results faster for longer numbers .
calcalates the log base 10 of an integer . this produces results faster for shorter numbers .
calcalates the log base 10 of an integer . this method favours shorter numbers .
calcalates the log base 10 of an integer . this method favours longer numbers or evenly distributed input .
calculates the number of ascii characters that will be needed to represent a specifed signed 32 - bit integer .
calculates the number of ascii characters that will be needed to represent a specifed signed 64 - bit integer .
calculates the number of ascii characters that will be needed to represent a specified signed decimal number .
{
{ @inheritdoc }
{
sets a compiled head functor to this clause .
emmits the binary byte code for the clause into a machine writing into the specified byte array . the state of this clause is changed to linked to indicate that it has been linked into a binary machine .
listens for events from back next finish and cancel inputs . if the event is finish the { @link #savework } method is triggered . if the event is cancel the { @link #discardwork } method is called . if the event is back or next then the { @link #prevpage } or { @link #nextpage } methods are called .
sets the order in which the savework or dicardwork methods of the individual screens encountered in a work flow are called . on of the constants { @link #forward_ordering } or { @link #reverse_ordering } should be passed as the value to this method to specify which ordering to use .
method called when the finish button is pressed . it works through all the screens in the order in which they were accessed ( or reverse order depending on the order set by the {
method called when the cancel button is pressed . it works through all the screens in the order in which they were accessed ( or reverse order depending on the order set by the {
this is a helper method that controller implementations may find useful for moving to a new screen . it places the screen into the panel that this controller was built with replacing any existing screen changes the underlying state to reflect the change to a new current screen and calls the new screens initialize method .
evaluates a logical predicate .
looks up a property value relative to the environment callers class and method . the default environment will be checked for a matching property if defaults are being used . in order to work out the callers class and method this method throws an exception and then searches one level up its stack frames .
looks up a property value relative to the environment base class and modifier . the default environment will be checked for a matching property if defaults are being used .
looks up a property value relative to the environment base class and modifier . the default environment will be checked for a matching property if defaults are being used .
looks up an array property value relative to the environment callers class and method . the default environment will be checked for a matching array property if defaults are being used . in order to work out the callers class and method this method throws an exception and then searches one level up its stack frames .
looks up an array property value relative to the environment base class and modifier . the default environment will be checked for a matching array property if defaults are being used .
looks up an array property value relative to the environment base class and modifier . the default environment will be checked for a matching array property if defaults are being used .
for a given environment base modifier and key and setting of the use of default environments feature this generates an iterator that walks over the order in which to try and access properties .
scans all the properties in the parent properties object and creates arrays for any array property definitions .
{
specifies the throttling rate in operations per second . this must be called with with a value the inverse of which is a measurement in nano seconds such that the number of nano seconds do not overflow a long integer . the value must also be larger than zero .
this method can only be called at the rate set by the { @link #setrate } method if it is called faster than this it will inject short pauses to restrict the call rate to that rate .
checks but does not enforce the throttle rate . when this method is called it checks if a length of time greater than that equal to the inverse of the throttling rate has passed since it was last called and returned <tt > true< / tt > . if the length of time still to elapse to the next throttle allow point is zero or less this method will return a negative value if there is still time to pass until the throttle allow point this method will return a positive value indicating the amount of time still to pass . a thread can wait for that period of time before rechecking the throttle condition .
{
evaluates the arithmetic operator on its numeric argument .
this methods attempts to load the properties from a file or url referenced by the system property with the same name as the properties resource name from a resource on the classpath with the same name as the properties resource name or from a properties file name relative to the current working directory . it tries these methods sequentially one after the other until one succeeds .
tries to load the properties from the file or url named by the system property with name mathching the properties resource name .
tries to load the properties from the classpath using the classloader for this class .
tries to load the properties as a file or url matching the properties resource name . file names will be taken relative to the current working directory .
applies the built - in transform during a post - fix visit of a term .
gets the actual value of a term which is either the term itself or in the case of variables the value that is currently assigned to the variable . when the variable is free the variable term itself is returned .
binds this variable to the specified value .
{
{
compares this term for structural equality with another . two terms are structurally equal if they are the same functor with the same arguments or are the same unbound variable or the bound values of the left or right variable operands are structurally equal . structural equality is a stronger equality than unification and unlike unification it does not produce any variable bindings . two unified terms will always be structurally equal .
{
{ @inheritdoc }
computes and caches in the {
computes and caches in the {
creates the correct type of queue for this search . this search uses a priority queue ordered by heuristic value .
drop the connection to the remote host and release the underlying connector thread if it has been created .
appends a logging event to the remote event reciever .
connects to remote server at <code > address< / code > and <code > port< / code > .
starts a new connector thread to do?
{
{
{
{
sets up the stack of column printers .
assembles the accumulated output in all rows and columns into a table . the table is appended onto {
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
{
{
{
----------------------------------------------------------------------------------------------------------------
{
when operating in transactional mode causes any changes since the last commit to be made visible to the search method .
when operation in transactional mode causes any changes since the last commit to be dropped and never made visible to the search method .
requests an operation that alters the transactional resource . this may be blocked until an appropriate lock can be acquired delayed until commit time or actioned upon a copy of the data structure private to a transaction branch .
adds a transactional operation to the transactional write - behind cache for the specified transaction . if no cache exists for the specified transaction id a new one is created .
waits until the global write lock can be acquired by the specified transaction .
releases the global write lock from being assigned to a transaction .
enlists this transactional resource with the current session . if no session exists this will fail .
locates nested mediaquerynode inside rulesetnode separates rulesetnode and mediaquerynode
inserts the specified element into this queue if possible . when using queues that may impose insertion restrictions ( for example capacity bounds ) method <tt > offer< / tt > is generally preferable to method { @link java . util . collection#add } which can fail to insert an element only by throwing an exception .
inserts the specified element into this queue waiting if necessary up to the specified wait time for space to become available .
retrieves and removes the head of this queue or <tt > null< / tt > if this queue is empty .
retrieves and removes the head of this queue waiting if necessary up to the specified wait time if no elements are present on this queue .
retrieves but does not remove the head of this queue returning <tt > null< / tt > if this queue is empty .
adds the specified element to this queue waiting if necessary for space to become available .
tries a synchronous put into the queue . if a consumer encounters an exception condition whilst processing the data that is put then this is returned to the caller wrapped inside a { @link synchexception } .
retrieves and removes the head of this queue waiting if no elements are present on this queue . any producer that has its data element taken by this call will be immediately unblocked . to keep the producer blocked whilst taking just a single item use the { @link #drainto ( java . util . collection< synchrecord <e >> int boolean ) } method . there is no take method to do that because there is not usually any advantage in a synchronous hand off design that consumes data one item at a time . it is normal to consume data in chunks to ammortize consumption latencies accross many producers where possible .
removes at most the given number of available elements from this queue and adds them into the given collection . a failure encountered while attempting to <tt > add< / tt > elements to collection <tt > c< / tt > may result in elements being in neither either or both collections when the associated exception is thrown . attempts to drain a queue to itself result in <tt > illegalargumentexception< / tt > . further the behavior of this operation is undefined if the specified collection is modified while the operation is in progress .
takes all available data items from the queue or blocks until some become available . the returned items are wrapped in a { @link synchrecord } which provides an interface to requeue them or send errors to their producers where the producers are still blocked .
takes up to maxelements available data items from the queue or blocks until some become available . the returned items are wrapped in a { @link synchrecord } which provides an interface to requeue them or send errors to their producers where the producers are still blocked .
insert element into the queue then possibly signal that the queue is not empty and block the producer on the element until permission to procede is given .
removes an element from the buffer and optionally unblocks the producer of the element if it is waiting and optionally signals that the { @link #notfull } condition may now be true .
fetches the next element from this iterator .
helper method for setting system properties to defaults when they are not already set .
helper method for setting system properties to defaults when they are not already set .
helper method for setting system properties to defaults when they are not already set .
helper method for setting system properties to defaults when they are not already set .
helper method for setting system properties to defaults when they are not already set .
helper method for setting system properties to defaults when they are not already set .
helper method for setting system properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties to defaults when they are not already set .
helper method for setting properties .
helper method for setting properties .
helper method for setting properties .
helper method for setting properties .
helper method for setting properties .
helper method for setting properties .
parses a property as a boolean .
parses a property as an integer .
parses a property as a long .
creates a clone of this scope to be attached to the tree at the site of a mixin reference . if an argumentsnode is passed each of its values override those defined by the mixin s parameters .
some nodes are captured in additional structures to aid later resolution .
recreate internal state before children are cloned .
----------------------------------------------------------------------------------------------------------------
{
back - tracks from the specified node moving succesively upwards through the chain of parent nodes until a node is encountered that has unexamined successors . this method implements the backtracking searches reverse direction . by checking for the presence of unexamined successors this method only backtracks where necessary .
{
{
extracts the raw byte code from the machine for a given call table entry .
{
runs a query and for every non - anonymous variable in the query decodes its binding value from the heap and returns it in a set of variable bindings .
decodes a term from the raw byte representation on the machines heap into an abstract syntax tree .
captures an objects state in this memento .
restores the values currently in this memento to the specified object .
gets the value of the named field of the specified class .
places the specified value into the memento based on the field s declaring class and name .
generates a list of all the fields of the object that this memento maps for a given class .
creates the interpreter and launches its top - level run loop .
implementation of the prod - script goal .
{
{
{
{
inserts the specified element onto the tail of this queue .
retrieves and removes the head of this queue or null if this queue is empty .
creates the correct type of search nodes for this search . this search uses ordinary search nodes .
creates the correct type of queue for this search . this search uses a priority queue ordered by path cost .
{ @inheritdoc }
provides a simple depth first walk over a term .
provides a depth first walk over a term visiting only when a goal predicate matches .
provides a positional depth first walk over a term .
provides a positional depth first walk over a term visiting only when a goal predicate matches .
provides a positional postfix walk over a term .
{
{
{
{ @inheritdoc }
{
{
get properties from an input stream .
get properties from a file .
get properties from a url .
get properties from a path name . the path name may refer to either a file or a url .
trims whitespace from property values . this method returns a new set of properties the same as the properties specified as an argument but with any white space removed by the { @link java . lang . string#trim } method .
helper method . guesses whether a string is a url or not . a string is considered to be a url if it begins with http : ftp : or uucp : .
{ @inheritdoc }
computes the rendered dimensions of the text grid model on screen . used for sizing this component .
sets up metrics relating to the size of the font used to display the text grid . this only needs to be done once but this method can be called many times as it is guarded by an initialization flag to prevent these being calculated many times .
adds a property changed listener to be notified of changes to the application state .
adds a property changed listener to be notified of changes to the named property .
removes the specified property change listener from the list of active listeners .
notifies all property change listeners of the given propertychangeevent .
creates a new double range type with the specified name if it does not already exist .
{
{
requests a color fade against the specified target under a group name .
----------------------------------------------------------------------------------------------------------------
{
{
{
{
{
{
{
creates a horizontal grip - able bar for adjusting the console height .
creates a vertical grip - able bar for adjusting the left panel width .
creates a vertical grip - able bar for adjusting the right panel width .
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
ensures that radio controls are mutually exclusive within control groups .
wait for the predicate to become true on the specified object .
wait for up to a timeout limit for the predicate to become true on the specified object .
implementation of the script goal .
appends the classpath onto the command line .
creates a new date range type with the specified name if it does not already exist .
{
frees all variables held in this stack frame and sets all the stack slots to <tt > null< / tt > . note that as the stack slots are <tt > null< / tt > the {
----------------------------------------------------------------------------------------------------------------
implements the top - level interpreter loop . this will parse and evaluate sentences until it encounters an ctrl - d in query mode at which point the interpreter will terminate .
prints a welcome message .
sets up the jline console reader .
evaluates a query against the resolver or adds a clause to the resolvers domain .
evaluates a query . in the case of queries the interner is used to recover textual names for the resulting variable bindings . the user is queried through the parser to if more than one solution is required .
converts a boolean into a multi type data object .
converts a byte into a multi type data object .
converts a char into a multi type data object .
converts a short into a multi type data object .
converts a int into a multi type data object .
converts a long into a multi type data object .
converts a float into a multi type data object .
converts a double into a multi type data object .
converts a string into a multi type data object .
converts a object into a multi type data object .
given a multi type data object and a class representing a type this method attemps to return an object of that class created from the multi type data . the exception to this rule is if the specified data type is a primtive type such as int . clas then the returned object will be of the equivalent wrapper class type integer . class in this case . this is because a primitive cannot be returned under an object return type .
for a set of types this method selects the best type to convert a given multi type data object into . this method can be usefull when deciding which of several setter methods on a bean is the best one to convert the multi type data obejct into before calling the beans setter method .
inserts an object into the scope .
checks is the specified dimension is equivalent . equivalent means same informations ( including type ) same defaults same links
{
{
{ @inheritdoc }
{ @inheritdoc }
{
clears entries up to and including the specified key from the map . this is a simple garbage collection operation to clear consumed data from the circular buffer .
{
{
{
expands the size of the storage to whichever is the larger of 1 . 5 times the old size or an array large enough to hold the proposed key that caused the expansion copying the old data into a new array .
----------------------------------------------------------------------------------------------------------------
{
{
{
{
notifies all interested listeners of an update to this model .
inserts a single character into the grid at the specified location . this is a private insert method that does not notify model listeners so that the public insert methods can do that as a separate step .
parses the next sentence from the current token source .
{
compares two search nodes by their path cost .
{
parses a flat list of terms which are literals variables functors or operators into a tree in such a way that the operators associativity and precendence is obeyed .
sets the priority and associativity of a named operator in this table . this method may be used to remove operators by some implementations through a special setting of the priority value . a priority value of zero will remove any existing operator matching the fixity of the one specified ( that is pre or post / infix ) . to be accepted the operator must have a priority between 0 and 1200 inclusive and can only be a postfix operator when an infix is not already defined with the same name and similarly for infix operators when a postfix operator is already defined .
checks the operator table for all possible operators matching a given name .
checks if a candidate operator symbol can have one of the specified fixities and resolve it to an oeprator with that fixity if so . if it cannot be resolved an exception is raised .
expands a node into its successors . the successors are added to the specified collection which is returned as the result of this function . the reason that the collection is passed as an argument is that there are many different styles of buffer ( fifo lifo etc ) that search functions can use to implement different kinds of search and it is more efficient to expand directly into the buffer than to have to copy the results into it after this method is called which would be the case if this method returned a collection .
makes a new node of the same type as this one from a successor state .
writes the specified byte <code > b< / code > to this output stream .
writes bytes from the specified byte array <code > b< / code > starting from index specified by <code > off< / code > and continuing for <code > len< / code > bytes to this output stream .
right pads a string with a given string to a given size . this method will repeat the padder string as many times as is necessary until the exact specified size is reached . if the specified size is less than the size of the original string then the original string is returned unchanged .
lists all the parsing errors from the most recent parsing in a string .
lists the properties set from the most recent parsing or an empty string if no parsing has been done yet .
generates a usage string consisting of the name of each option and each options argument description and comment .
parses a set of command line arguments into a set of properties keyed by the argument flag . the free arguments are keyed by integers as strings starting at 1 and then 2 ... and so on .
if a command line has been parsed calling this method sets all of its free arguments that were name = value pairs on the specified properties .
if a command line has been parsed calling this method sets all of its options that were set to the specified properties .
adds the option to list of available command line options .
converts the free arguments into property declarations . after parsing the command line the free arguments are numbered from 1 such that the parsed properties contain values for the keys 1 2 ... this method converts any free arguments declared using the name = value syntax into properties with key name value value .
checks the format of an argument to an option against its specified regular expression format if one has been set . any errors are added to the list of parsing errors .
walks down two iterators comparing them element by element using the equals method .
returns an enumeration describing the available options .
parses the options . <p / >
gets the current settings of the classifier .
sets the stemmer type to use
returns the stemmer to use .
returns the stemmed version of the given word . word is converted to lower case before stemming .
runs the stemmer with the given options .
evaluates a term by invoking its { @link term#getvalue () } method ( which may cause a recursive evaluation for example in the case of arithmetic expressions ) and checks that the result is a fully instantiated numeric value .
creates a new float range type with the specified name if it does not already exist .
sets the state of the work panel . state must be one of the defined constants : not_initialized ready or not_saved .
resets the machine to its initial state . this clears any programs from the machine and clears all of its stacks and heaps .
{
{
{
pretty prints the current environment frame for debugging purposes .
pretty prints the current choice point frame for debugging purposes .
{
invokes an internal function .
implements the call / 1 predicate .
implements the execute variant of the call / 1 predicate .
sets up the registers to make a call for implementing call / 1 . the first register should reference a structure to be turned into a predicate call . the arguments of this structure will be set up in the registers and the entry point of the predicate to call will be returned .
computes the start of the next stack frame . this depends on whether the most recent stack frame is an environment frame or a choice point frame as these have different sizes . the size of the most recent type of frame is computed and added to the current frame pointer to give the start of the next frame .
backtracks to the continuation label stored in the current choice point frame if there is one . otherwise returns a fail to indicate that there are no more choice points so no backtracking can be done .
creates a binding of one variable onto another . one of the supplied addresses must be an unbound variable . if both are unbound variables the higher ( newer ) address is bound to the lower ( older ) one .
records the address of a binding onto the trail . the trail pointer is advanced by one as part of this operation .
undoes variable bindings that have been recorded on the trail . addresses recorded on the trail are reset to ref to self .
tidies trail when a choice point is being discarded and a previous choice point it being made the current one .
attempts to unify structures or references on the heap given two references to them . structures are matched element by element free references become bound .
a simplified unification algorithm for unifying against a constant .
pretty prints a variable allocation slot for tracing purposes .
generates a random starting position .
to check for solvability the empty tile is moved to its goal position and then the number of swaps needed to put the other tiles in position is counted . for an odd number of rows on a square puzzle there must be an even number of swaps for an even number of rows an odd number of swaps .
applies a move to generate a new board position . this creates a new state object and updates its board position . the board position in this object is not changed .
supplies the valid moves for a board position .
pretty prints the board as 3 lines of characters with a space for the empty square .
repeatedly swaps a tile with its neighbours until it reaches the specified location . if the tile is swapped with the empty tile then this is a legal move . if the tile is swapped with another non - empty tile then this is an illegal move and the total number of illegal moves is counted .
applies a move to the board position . this changes the board position stored in this object . this is different from the { @link #getchildstateforoperator } method which updates the board position in a new object .
swaps the two tiles at the specified coordinates . one of the tiles may be the empty tile and the empty tile position will be correctly updated . if neither of the tiles is empty then this is an illegal swap in which case the method returns true .
turns a string representation of the board into a list of characters .
turns a list of characters representation of the board into a proper state .
{
transforms a java . util . logging . logrecord to a message printable on log4j .
converts java . util . logging levels to log4j logging levels .
{
{
{
{
{
{
{
{
{
{
{
{
places an element onto the requeue buffer .
places an element onto the requeue buffer in the acquired state by the specified owner .
atomically adds to the size and count if the queue is running in atomic counting mode or sizeable mode and the element is sizeable .
atomically subtracts from the size and count if the queue is running in atomic counting mode or sizeable mode and the element is sizeable .
signals the signallable resource if the size crosses a threshold boundary in a downward direction .
retrieves the named object . if name is empty returns a new instance of this context ( which represents the same naming context as this context but its environment may be modified independently and it may be accessed concurrently ) .
binds a name to an object . all intermediate contexts and the target context ( that named by all but terminal atomic component of the name ) must already exist .
binds a name to an object . all intermediate contexts and the target context ( that named by all but terminal atomic component of the name ) must already exist .
binds a name to an object overwriting any existing binding . all intermediate contexts and the target context ( that named by all but terminal atomic component of the name ) must already exist .
unbinds the named object . removes the terminal atomic name in name from the target context -- that named by all but the terminal atomic part of name .
binds a new name to the object bound to an old name and unbinds the old name . both names are relative to this context . any attributes associated with the old name become associated with the new name . intermediate contexts of the old name are not changed .
binds a new name to the object bound to an old name and unbinds the old name . both names are relative to this context . any attributes associated with the old name become associated with the new name . intermediate contexts of the old name are not changed .
enumerates the names bound in the named context along with the class names of objects bound to them . the contents of any subcontexts are not included . if a binding is added to or removed from this context its effect on an enumeration previously returned is undefined .
enumerates the names bound in the named context along with the objects bound to them . the contents of any subcontexts are not included .
composes the name of this context with a name relative to this context . given a name ( name ) relative to this context and the name ( prefix ) of this context relative to one of its ancestors this method returns the composition of the two names using the syntax appropriate for the naming system ( s ) involved . that is if name names an object relative to this context the result is the name of the same object but relative to the ancestor context . none of the names may be null .
adds a new environment property to the environment of this context . if the property already exists its value is overwritten . see class description for more details on environment properties .
removes an environment property from the environment of this context . see class description for more details on environment properties .
repeatedly runs the garbage collector and finalization method of the jvm runtime system until the used memory count becomes stable or 500 iterations occur whichever happens soonest . if other threads are active then this method is not likely to work as the used memory count will continually be changing .
this is the high - level rule at some scope ( either the root document or within a rule set / mixin ) . future : imports
media type name optional ( and ( css property ) )
sequence ( whitespace and whitespace ( css property ) )
only whitespace
( selectors { ws0 / class ws0 parameters ws0 { ws0 ) scope ws0 } ws0
( parameter ws0 ( ws0 parameter ) * )
variable ws0 : ws0 expressionphrase
selectorgroup ; ws0 / class arguments ; ws0
selector ws0 ( ws0 selector ) * ws0
simpleselector ( combinator simpleselector ) *
( ident / variable ) ws0 : ws0 expressionphrase ( ws0 ws0 expressionphrase ) * sp0 ( ; / ws0 & } ) / ident ws0 : ws0 ;
expression ( operator expression ) + future : operations / expression ( ws1 expression ) * important?
ident arguments
( ws0 expressionphrase ws0 ( ws0 expressionphrase ws0 ) * ) / ( ws0 )
ex : progid : dximagetransform . microsoft . gradient ( startcolorstr =
( ws0 filterargument ws0 ( ws0 filterargument ws0 ) * ) / ( ws0 )
ex : startcolorstr =
any token used as a value in an expression future : accessors
url ( ( string / [ - _%$ / . & = : ; # + ?alphanumeric ] + ) )
alpha ( ws0 opacity ws0 = ws0 digit1 ws0 )
expression ( ( ! ( ) ws0 [ ; } ] ) . ) * ) ;
ident &delimiter
tokens that don t need to evaluated
alpha [ - alphanumeric ] * &delimiter / string
ex : hello / hello
- ? digit * . digit + / - ? digit +
ex : 0099dd / 09d
\ [ 0 - 9a - fa - f ] { 1 6 } wc?
unicode | \ [ ^ \ x0 - \ x1f ]
locates the referenced mixin in one of the scope nodes on the stack . if found the mixin s scope is cloned and placed onto the stack in place of the mixin reference . additionally any arguments are applied to the mixin s scope .
looks for a variable definition that matches the reference in the scope nodes on the stack . if found a reference node that can repeat this lookup later is placed on the stack not the current value itself . this is done because the value may change if the variable reference is inside a mixin .
 (  )
updates the maximum row height for a row of the data table .
{
{
{
{
{
notifies all interested listeners of an update to this model .
updates the maximum column width for a column of the data table .
updates the current page or index offset of a paged list in the session scope .
{ @inheritdoc }
applies a built - in replacement transformation to functors . if the functor matches built - in a { @link builtinfunctor } is created with a mapping to the functors built - in implementation and the functors arguments are copied into this new functor . if the functor does not match a built - in it is returned unmodified .
returns a new node based on a successor of this node . this new node will also be a heuristicsearchnode .
processes the action providing default error handling . implementation should override this method to provide their own error handling if the default is not to be used .
{
substitutes built - ins within a clause with their built - in definitions .
runs a symbol key traverser over the clause to be compiled to ensure that all of its terms and sub - terms have their symbol keys initialised .
finds and marks all functors within the clause that are considered to be top - level .
{
pretty prints a term relative to the symbol namings provided by the specified interner .
{
{
{
{
{
{
{
{
{
----------------------------------------------------------------------------------------------------------------
{ @inheritdoc }
evaluates the arithmetic comparison on its two numeric arguments .
makes a transaction from the initial state to the running state or no transition if the current state is not initial .
makes a transaction from the running state to the shutdown state or no transition if the current state is not running .
makes a transaction from the running or shutdown state to the terminated state or no transition if the current state is not running or shutdown .
{
{
{
{
inserts the specified element into this heap .
retrieves and removes the ( head ) minimum element of this heap or null if this heap is empty .
calculates the smallest integer value m such that m^2 > = n . the ceiling log2 of n .
compares the specified node with the minimum and updates the minimum if neccessary . if a comparator was used to create this heap then this comparator is used to perform the comparison . if no comparator was set then the natural ordering of the element type is used . the element must implement the comparable interface to support a natural ordering . if it does not there will be a class cast exception thrown .
compares two heap nodes . the comparison performed is dependant on whether a comparator has been set or the natural ordering is to be used .
inserts a single node or a circular doubly linked list of nodes into a list next to the specified node . i does not matter if the specified nodes are singletons or part of a chain as they will be correctly linked in in either case so long as their prev and next references form a loop with themselves .
pauses any calling thread until {
restarts the sweep alogirithm . useful after a kill has stopped it .
returns the value to which this map maps the specified key . returns <tt > null< / tt > if the map contains no mapping for this key . a return value of <tt > null< / tt > does not <i > necessarily< / i > indicate that the map contains no mapping for the key ; it s also possible that the map explicitly maps the key to <tt > null< / tt > . the <tt > containskey< / tt > operation may be used to distinguish these two cases .
associates the specified value with the specified key in this map ( optional operation ) . if the map previously contained a mapping for this key the old value is replaced by the specified value . ( a map <tt > m< / tt > is said to contain a mapping for a key <tt > k< / tt > if and only if { @link #containskey ( object ) m . containskey ( k ) } would return <tt > true< / tt > . ))
removes the mapping for this key from this map if it is present ( optional operation ) . more formally if this map contains a mapping from key <tt > k< / tt > to value <tt > v< / tt > such that <code > ( key == null ? k == null : key . equals ( k )) < / code > that mapping is removed . ( the map can contain at most one such mapping . )
copies all of the mappings from the specified map to this map ( optional operation ) . the effect of this call is equivalent to that of calling { @link #put ( object object ) put ( k v ) } on this map once for each mapping from key <tt > k< / tt > to value <tt > v< / tt > in the specified map . the behavior of this operation is unspecified if the specified map is modified while the operation is in progress .
garbage collects the cache sweeping out any elements that have timed out . this method should really only be invoked in a seperate thread as it does not return ( at least not until the { @link #sweepthreadkillflag } is set ) .
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
provides an iterator over a search method that returns successive search solutions on demand .
finds the set of all goals of a search .
finds a bag of all goals of a search .
provides an iterator over a search method that returns successive search solutions on demand .
finals all solutions to a search and inserts them into the specified collection .
{ @inheritdoc }
generates the next element in the sequence .
{
{
{
restores the properties currently in this memento to the specified object .
gets the value of the named property of the specified class .
sets the value of the named property as a multi type object .
places the specified value into the memento based on the property s declaring class and name .
captures the fields of the associated object .
creates the interpreter and launches its top - level run loop .
{ @inheritdoc }
{ @inheritdoc }
----------------------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------------------
pops the first object placed on the stack off of it and returns it .
{
{
{
renders the table .
{
converts the modifiers to a specification string for keystroke .
{
{
{
notifies all interested listeners of an update to this model .
converts a string to an integer . the string must be a valid integer or the result will be zero .
converts a string to a date . the string must be a date in the correct format or this method will return null .
check that a string is a date in the format specified by dateformat .
checks that a string is a time in the format specified by timeformat .
checks that a string is a datetime in the format specified by datetimeformat .
creates a token source on a string .
creates a token source on a file .
creates a token source on an input stream .
retrieves and removes the head token or <tt > null< / tt > if there are no more tokens .
retrieves but does not remove the head token returning <tt > null< / tt > if there are no more tokens .
{
checks if the term argument to an instruction was a constant .
checks if the term argument to an instruction was a singleton non - argument position variable . the variable must also be non - permanent to ensure that singleton variables in queries are created .
checks if the term argument to an instruction was in a non - argument position .
{
renders the table .
provides an iterator over the child terms if there are any . only functors and clauses are compound and build across a list of child arguments .
makes a clone of the term converting its variables to refer directly to their storage cells .
{
{
works out all the possible successors by applying all the operators returned by the { @link traversable#validoperators } method .
reports whether or not this term is a ground term . constants ( functors of arity zero ) and numbers are ground terms as are functors all of the arguments of which are ground term .
gets the argument within the functor with the specified index .
compares this term for structural equality with another . two terms are structurally equal if they are the same functor with the same arguments or are the same unbound variable or the bound values of the left or right variable operands are structurally equal . structural equality is a stronger equality than unification and unlike unification it does not produce any variable bindings . two unified terms will always be structurally equal .
provides an iterator over the child terms if there are any . only functors are compound and built across a list of child arguments .
makes a clone of the term converting its variables to refer directly to their storage cells .
{
{
creates a string representation of this functors arguments mostly used for debugging purposes .
execute a query to retrieve the summary . this do not have any group by element
execute a query to retrieve the records .
private methode called by the public ones to effectively run the query .
{
{
{
{
disassembles the instructions from the specified byte buffer starting at a given location ( ip ) . an interner for the functor names encountered in the instruction buffer must also be supplied in order to look up the functor names by encoded value .
writes out the instruction plus arguments in the byte code format to the specified location within a code buffer .
{
{
sets the basic type of this type depending on the class .
consults an input stream reading first order logic clauses from it and inserting them into the resolvers knowledge base .
prints all of the logic variables in the results of a query .
prints all of the logic variables in the results of a query .
prints a variable binding in the form var = value .
transforms an iterator over sets of variable bindings resulting from a query to an iterator over a map from the string name of variables to their bindings for the same sequence of query solutions .
{
{
a dedicated thread loop for reading the stream and sending incoming packets to the appropriate router .
read the incoming stream until it ends .
/ * initializer for type 1 uuids . creates random generator and genenerates the node portion of the uuid using the ip address .
/ * creates a type 1 uuid
package - visibility for testing
gets the appropriately modified timestamep for the uuid . must be called from a synchronized block .
stops the playing / indicates that the playing stopped . <p > this method has no effect if runsinplay is enabled in the constructor . <br > < / p >
checks if the trackinfo is an update and fires the appropriate event . this method should not be called without an active playlist or an nullpointerexception will be thrown . this method : <br > - fires nothing if the trackinfo equals the current trackinfo . <br > - fires an trackinfoupdate if the trackinfo contains information not found in the current . <br >
call this method if the trackinfo object in the playlist was updated . only the trackinfo object will be sent via event
fires an update event which notifies that parameters have changed
updates the info about the current song
fires an update event which notifies that parameters have changed
this method is called when an object wants to get a resource . <p > don t use the resources provided as arguments they are just the requests . there is a timeout after 1 second . < / p >
method that uses the data from the outputextensions to generate a final output that will then be rendered .
handles the a request to start playing music via resource
handles the commands encoded as resources / eventids
handles the a request to start playing music via event
this method will be called to create and fire the startmusicrequest
sets every information into its default state ( playlist volume etc ... )
initializes the reader in order to be used . the reader is initialized during the first connection and when reconnecting due to an abruptly disconnection .
starts the packet reader thread and returns once a connection to the server has been established . a connection will be attempted for a maximum of five seconds . an xmppexception will be thrown if the connection fails .
shuts the packet reader down .
resets the parser using the latest connection s reader . reseting the parser is necessary when the plain connection has been secured or when a new opening stream element is going to be sent by the server .
parse top - level packets in order to process them further .
processes a packet after it s been fully parsed by looping through the installed packet collectors and listeners and letting them examine the packet to see if they are a match with the filter .
sets the cli option .
creates a new chat and returns it .
try to get a matching chat for the given user jid based on the { @link matchmode } . <li > none - return null <li > supplied_jid - match the jid in the from field of the message exactly . <li > bare_jid - if not match for from field try the bare jid .
returns a list of hostaddresses under which the specified xmpp server can be reached at for server - to - server communication . a dns lookup for a srv record in the form _xmpp - server . _tcp . example . com is attempted according to section 14 . 4 of rfc 3920 . if that lookup fails a lookup in the older form of _jabber . _tcp . example . com is attempted since servers that implement an older version of the protocol may be listed using that notation . if that lookup fails as well it s assumed that the xmpp server lives at the host resolved by a dns lookup at the specified domain on the default port of 5269 . <p >
convert a new content object to an internal version .
reset the object back to its last saved state .
set a property creating if it does not exist overwriting if it does .
adds a filter to the filter list for the or operation . a packet will pass the filter if any filter in the list accepts it .
process the request in a stream .
clear the current set of properties to add and remove .
calculate an rfc2104 compliant hmac ( hash - based message authentication code )
takes the original request and starts the batching .
todo : unit test
todo : unit test
todo : unit test
todo : unit test
todo : unit test
factory method to create a synchronized map .
-----------------------------------------------------------------------
initializes the writer in order to be used . it is called at the first connection and also is invoked if the connection is disconnected by an error .
sends the specified packet to the server .
returns the next available packet from the queue for writing .
sends to the server a new stream element . this operation may be requested several times so we need to encapsulate the logic in one place . this message will be sent while doing tls sasl and resource binding .
get the goodwill schema associated to a schema name . < / p > typical invocation : <pre > try { goodwillschema type = accessor . getschema ( test ) . get () ; ... } catch ( exception e ) { // connection exception? goodwill server down? } < / pre >
get all schemata . <p / > use schemata instead of schemas which is closer to the original  .
note : if called from base - class constructor couldn t sub - class ; hence just make static
creates a new event object
creates a new event object
returns a list containing all the descriptors and the type .
sets the descriptors ( but not the event - type ) .
returns whether the event contains the specific descriptor . this method also checks whether it matches the type .
adds the consumer to the specified eventlifecycle . in its current implementation the invocation of the callback method is parallel but the notificaton of the listners not .
default implementation waits until a new event has been received and then processes it . <p > this method is made to be overwritten as seen fit by the developer
use this method to start playing sound ( only plays sound if it is not already playing )
shuts down the task engine service .
factory method to create a synchronized map .
-----------------------------------------------------------------------
identical file contents
clean or unmap a direct bytebuffer
rolls back the changes to the map .
checks that this entry is valid for the current thread
returns internal representation for key . use null_key if key is null .
returns a hash value for the specified object . in addition to the object s own hashcode this method applies a supplemental hash function which defends against poor quality hash functions . this is critical because hashmap uses power - of two length hash tables . <p >
check for equality of non - null reference x and possibly - null y .
returns the value to which the specified key is mapped in this identity hash map or <tt > null< / tt > if the map contains no mapping for this key . a return value of <tt > null< / tt > does not <i > necessarily< / i > indicate that the map contains no mapping for the key ; it is also possible that the map explicitly maps the key to <tt > null< / tt > . the <tt > containskey< / tt > method may be used to distinguish these two cases .
returns the entry associated with the specified key in the hashmap . returns null if the hashmap contains no mapping for this key .
associates the specified value with the specified key in this map . if the map previously contained a mapping for this key the old value is replaced .
this method is used instead of put by constructors and pseudoconstructors ( clone readobject ) . it does not resize the table check for comodification etc . it calls createentry rather than addentry .
rehashes the contents of this map into a new array with a larger capacity . this method is called automatically when the number of keys in this map reaches its threshold .
copies all of the mappings from the specified map to this map these mappings will replace any mappings that this map had for any of the keys currently in the specified map .
removes the mapping for this key from this map if present .
removes and returns the entry associated with the specified key in the hashmap . returns null if the hashmap contains no mapping for this key .
special version of remove for entryset .
removes all mappings from this map .
add a new entry with the specified key value and hash code to the specified bucket . it is the responsibility of this method to resize the table if appropriate .
like addentry except that this version is used when creating entries as part of map construction or pseudo - construction ( cloning deserialization ) . this version needn t worry about resizing the table .
creates map delegate .
parses the given date string in either of the three profiles of <a href = http : // xmpp . org / extensions / xep - 0082 . html > xep - 0082 - xmpp date and time profiles< / a > or <a href = http : // xmpp . org / extensions / xep - 0091 . html > xep - 0091 - legacy delayed delivery< / a > format . <p > this method uses internal date formatters and is thus threadsafe .
parses the given date string in different ways and returns the date that lies in the past and / or is nearest to the current date - time .
returns the name portion of a xmpp address . for example for the address matt@jivesoftware . com / smack matt would be returned . if no username is present in the address the empty string will be returned .
returns the server portion of a xmpp address . for example for the address matt@jivesoftware . com / smack jivesoftware . com would be returned . if no server is present in the address the empty string will be returned .
returns the resource portion of a xmpp address . for example for the address matt@jivesoftware . com / smack smack would be returned . if no resource is present in the address the empty string will be returned .
returns the xmpp address with any resource information removed . for example for the address matt@jivesoftware . com / smack matt@jivesoftware . com would be returned .
returns true if jid is a full jid ( i . e . a jid with resource part ) .
escapes the node portion of a jid according to jid escaping ( jep - 0106 ) . escaping replaces characters prohibited by node - prep with escape sequences as follows : <p >
un - escapes the node portion of a jid according to jid escaping ( jep - 0106 ) . <p > escaping replaces characters prohibited by node - prep with escape sequences as follows : <p >
encodes a string for use in an xml attribute by escaping characters with a special meaning . in particular white spaces are encoded as character references such that they are not replaced by on parsing .
hashes a string using the sha - 1 algorithm and returns the result as a string of hexadecimal numbers . this method is synchronized to avoid excessive messagedigest object creation . if calling this method becomes a bottleneck in your code you may wish to maintain a pool of messagedigest objects instead of using this method . <p > a hash is a one - way function -- that is given an input an output is easily computed . however given the output the input is almost impossible to compute . this is useful for passwords since we can store the hash and a hacker will then have a very hard time determining the original password .
encodes an array of bytes as string representation of hexadecimal .
encodes a string as a base64 string .
encodes a byte array into a bse64 string .
decodes a base64 string . unlike base64 . decode () this method does not try to detect and decompress a gzip - compressed input .
returns a random string of numbers and letters ( lower and upper case ) of the specified length . the method uses the random class that is built - in to java which is suitable for low to medium grade security uses . this means that the output is only pseudo random i . e . each number is mathematically generated so is not truly random . <p >
overridden to just get the count and nothing else .
adds the ability for the play / pause requests
adds the ability to select tracks
adds the ability to select the next / previous track
adds the ability to jump to a specified position of the current track
adds the ability to change the playback
adds the ability to change the volume from outside the player
adds the ability to return the available playlists on request .
this method gets called when a new command was found . it automatically fires the update event or an error
handles the volume - command
handles the jump - command
handles the select track command
{ @inheritdoc }
generate a cache bound to the thread .
generate a cache bound to the request
{
{
get the name of an alternative field for an alternative stream .
todo : unit test
converts to an immutable map with keys that are in the filter not transfered . nested maps are also transfered .
converts a map into map or byte [] values with string keys . no control over depth of nesting . keys in the filter set are not transfered resulting map is mutable .
for instance the sparseprincipal uses it .
todo : unit test
todo : unit test
adapt an object to a session . i haven t used typing here becuase i don t want to bind to the jars in question and create dependencies .
make the method on the target object accessible and then invoke it .
delete an entire tree starting from the deepest part of the tree and working back up . will stop the moment a permission denied is encountered either for read or for delete .
method to get existing [ key1 key2 key3 key4 ] value or create new one if it s absent . needs implementation of create ( key1 key2 key3 key4 ) in order to work
only update specified properties of the object
retrieves a { @link keepalivemanager } for the specified { @link connection } creating one if it doesn t already exist .
/ * start the executor service if it hasn t been started yet .
/ * stop the executor service if all monitored connections are disconnected .
/ * call after every connection to add the packet listener .
sets the ping interval .
cancels any existing periodic ping task if there is one and schedules a new ping task if pinginterval is greater then zero .
/ * ( non - javadoc )
/ * ( non - javadoc )
/ * ( non - javadoc )
{
{
{
adds a cli option to the parser .
adds all given option ignoring null elements .
adds a cli option to the parser .
tests if an option is already added to the parser .
parses command line arguments and fills set options .
prints a usage screen based on set options .
parses command line arguments for a given cli parser .
closes the connection by setting presence to unavailable then closing the stream to the xmpp server . the shutdown logic will be used during a planned disconnection or when dealing with an unexpected disconnection . unlike { @link #disconnect () } the connection s packet reader packet writer and { @link userroster } will not be removed ; thus connection s state is kept .
initializes the connection by creating a packet reader and writer and opening a xmpp stream to the server .
notification message saying that the server supports tls so confirm the server that we want to secure the connection .
the server has indicated that tls negotiation can start . we now need to secure the existing plain connection and perform a handshake . this method won t return until the connection has finished the handshake or an error occured while securing the connection .
returns the compression handler that can be used for one compression methods offered by the server .
starts using stream compression that will compress network traffic . traffic can be reduced up to 90% . therefore stream compression is ideal when using a slow speed network connection . however the server and the client will need to use more cpu time in order to un / compress network data so under high load the server performance might be affected . <p > <p / > stream compression has to have been previously offered by the server . currently only the zlib method is supported by the client . stream compression negotiation has to be done before authentication took place . <p > <p / > note : to use stream compression the smackx . jar file has to be present in the classpath .
request the server that we want to start using stream compression . when using tls then negotiation of stream compression can only happen after tls was negotiated . if tls compression is being used the stream compression should not be used .
start using stream compression since the server has acknowledged stream compression .
establishes a connection to the xmpp server and performs an automatic login only if the previous connection state was logged ( authenticated ) . it basically creates and maintains a socket connection to the server . <p > <p / > listeners will be preserved from a previous connection if the reconnection occurs after an abrupt termination .
sends out a notification that there was an error with the connection and closes the connection . also prints the stack trace of the given exception
sends a notification indicating that the connection was reconnected successfully .
registers a new sasl mechanism
returns the registerd saslmechanism classes sorted by the level of preference .
performs sasl authentication of the specified user . if sasl authentication was successful then resource binding and session establishment will be performed . this method will return the full jid provided by the server while binding a resource to the connection . <p >
performs sasl authentication of the specified user . if sasl authentication was successful then resource binding and session establishment will be performed . this method will return the full jid provided by the server while binding a resource to the connection . <p >
performs anonymous sasl authentication . if sasl authentication was successful then resource binding and session establishment will be performed . this method will return the full jid provided by the server while binding a resource to the connection . <p >
========= propfind proppatch support ===============================
========= lock support ===============================
this method sets the controls for the output - plugin behaviour . <p > supply a function which controls the outputplugin - behaviour . you can set priorities . the output - plugin with the highest positive priority ( in int ) will be processed first . negative priorities are processed last ( so outputplugins with no priorities will be processed in between positive and negative priorities )
generates the data to control the event
define the sling . home parameter implementing the algorithme defined on the wiki page to find the setting according to this algorithm : <ol > <li > command line option <code > - c< / code > < / li > <li > system property <code > sling . home< / code > < / li > <li > environment variable <code > sling_home< / code > < / li > <li > default value <code > sling< / code > < / li > < / ol >
parses the command line arguments into a map of strings indexed by strings . this method suppports single character option names only at the moment . each pair of an option name and its value is stored into the map . if a single dash - character is encountered the rest of the command line are interpreted as option names and are stored in the map unmodified as entries with the same key and value . <table > <tr > <th > command line< / th > <th > mapping< / th > < / tr > <tr > <td > x< / td > <td > x - > x< / td > < / tr > <tr > <td > - y z< / td > <td > y - > z< / td > < / tr > <tr > <td > - yz< / td > <td > y - > z< / td > < / tr > <tr > <td > - y - z< / td > <td > y - > y z - > z< / td > < / tr > <tr > <td > - y x - - z a< / td > <td > y - > x - z - > - z a - > a< / td > < / tr > < / table >
emit an informational message to standard out
emit an error message to standard err
the throwable if not - null is also prefixed line by line with the prefix
creates a new startevent . assumes the output is using the java - sound output .
creates a new startevent
notify that a new string has been written .
checks whether it can provide the resource
checks whether there are any resources registered from the source
checks whether the resourcecontainer can provide at least one resource
returns all existing resources for the id . if there are no resources for the id the id will get skipped
returns the resource ( if existing ) from the source
factory method to create a synchronized map .
try to retrieve an object from the cache . has the side - effect of loading an uncached object into cache the first time .
combine the parameters into a key suitable for storage and lookup in the cache .
remove this object from the cache . note storageclient uses the word remove to mean delete . this method should do the same .
put an object in the cache
sets a jar filter .
runs the locator and collects all locations using the filters if set . the method can be called multiple times and will only result in a new map if any of the filters have been changed . if no filter has been changed the current map will be returned .
include a name and file
include from a jar file
add a sasl mechanism to the list to be used .
add a collection of sasl mechanisms to the list to be used .
creates the listeners that will print in the console when new activity is detected .
create resources used by this component .
executes a http call using a path in the jcr to point to a template and a map of properties to populate that template with . an example might be a soap call .
registers the standard - events
registers or adds an event to the local_events . properties file with the informations found in the eventlistener
registers or adds an event to the local_events . properties file
executes with a lock
unregisters or deletes an event from the local_events . properties file
checks if the outputextension can execute with the current event
creates a new event object
creates a new event object
creates a new event object
creates a new event object
helper method to get an instance of { @link clusteridentifier } .
helper method to get an instance of { @link clusteridentifier } .
build a new dse cluster instance .
build a new dse cluster instance .
create a new session for a dse cluster initializes it and sets the keyspace to the provided one .
creates a new musicplayererror
starts the playing command
stops the playing of the music
commands the player to fulfill the command
creates the playlist - request
creates the playlist - answer
creates a new stopevent
{ @inheritdoc }
appends one or more postfixes and separates them by slashes .
create a query parameter with a boolean value .
create a query parameter with a number value .
create a query parameter with a string value . the value will be urlencoded .
create a query parameter with a string value .
gets the first playlist if found in the eventmodel
this method is called from within the constructor to initialize the form . <p > note : this code was generated by netbeans .
this is the launch button action method . this method launches the apache sling bootloader and informs the user to wait before accessing it in a browser .
pings the apache sling server url every 5 seconds to see if it has finished booting . once it receives an ok status it enables the button to launch the browser and disables the launch nakamura button .
pings the apache sling server url looking for an ok status . returns true once that ok status is received .
performs the action when the browser button is pressed which is launch a web browser and browse to the server url .
returns an imageicon or null if the path was invalid .
returns the full contents of a ( assumed ) text file for use in a label .
the main method which executes the program .
replace contents with given values
exports the presence to a hashmap
imports ( if no errors occurred ) the presence from the resourcemodel
advance current json value to specified element in json array . set current json value to null otherwise .
advance current json value to specified value of current json object . set current json value to null otherwise .
return an integer for current json value parsing string values as required .
return a double number for current json value parsing string values as required .
return string value for current json value
creates a new resource .
verifies that an command is not malformed
verifies that the player is capable of handling the command
verifies tha the command is legal and able to be executed
create a { @link cluster } instance .
create a { @link session } instance .
obtain a cassandra cluster instance .
obtain a cassandra cluster instance .
obtain a cassandra session instance .
obtain a cassandra session instance .
obtain a cassandra session instance .
bind values to a { @link preparedstatement } .
bind values to a { @link preparedstatement } .
execute a select query and returns the { @link resultset } .
execute a select query and returns the { @link resultset } .
execute a select query and returns the { @link resultset } .
execute a select query and returns just one row .
execute a select query and returns just one row .
execute a select query and returns just one row .
/ * ----------------------------------------------------------------------
async - execute a query .
async - execute a query .
/ * ----------------------------------------------------------------------
async - execute a query .
execute a batch statement .
execute a batch statement .
async - execute a batch statement .
sets a jar filter .
returns all subclasses found for the given class .
returns all subclasses found for the given fully qualified class name .
returns all known subclasses for a given class location and package name
returns all known subclasses found in a given directory .
returns all known subclasses found in a given location
sets the resource data . <p > note! this object is immutable! < / p >
sets who should or has provided the resource object . <p > note! this object is immutable! < / p >
sets who should or has consumed the resource object . <p > note! this object is immutable! < / p >
creates a list with this element in it .
returns the accumulated size of all the bottom level maps .
this method is called to register for what events it wants to provide resources . <p > the event has to be in the following format : it should contain only one descriptor and and one resource with the id description which contains an description of the event . < / p >
this method is called when an object wants to get a resource . <p > don t use the resources provided as arguments they are just the requests . there is a timeout after 1 second . < / p >
returns the next available packet . the method call will block ( not return ) until a packet is available or the <tt > timeout< / tt > has elapased . if the timeout elapses without a result <tt > null< / tt > will be returned .
processes a packet to see if it meets the criteria for this packet collector . if so the packet is added to the result queue .
factory method to create a synchronized map .
gets the first volume if found in the eventmodel
logs the error and returns an iq error response
logs the error and returns an iq error response
logs the rsm page not found error and returns an iq error response
creates an error response for a given iq request .
returns true if the identifiable is the target of the eventmodel
factory method to create a synchronized map .
-----------------------------------------------------------------------
todo : unit test
sets the login enabled time
/ * ( non - javadoc )
factory method to create a synchronized set .
sets the name associated with this entry .
updates the state of the entry with the new values .
returns an unmodifiable collection of the roster groups that this entry belongs to .
indicates whether some other object is equal to this by comparing all members . <p > the { @link #equals ( object ) } method returns <code > true< / code > if the user jids are equal .
{ @inheritdoc }
{ @inherit - doc }
{ @inheritdoc }
{ @inheritdoc }
appends rsm info to query response .
parses an rsm from a query xml element
filters response objects based on the rsm parameters . updates the rsm object with item count first and last jid
handles an event from osgi and indexes it . the indexing operation should only index metadata and not bodies . indexing of bodies is performed by a seperate thread .
creates a new leavingevent
reloads the entire roster from the server . this is an asynchronous operation which means the method will return immediately and the roster will be reloaded at a later point when the server responds to the reload request .
creates a new group . <p > <p / > note : you must add at least one entry to the group for the group to be kept after a logout / login . this is due to the way that xmpp stores group information .
creates a new roster entry and presence subscription . the server will asynchronously update the roster with the subscription status .
removes a roster entry from the roster . the roster entry will also be removed from the unfiled entries or from any roster group where it could belong and will no longer be part of the roster . note that this is an asynchronous call -- smack must wait for the server to send an updated subscription status .
returns an unmodifiable collection of all entries in the roster including entries that don t belong to any groups .
returns the roster entry associated with the given xmpp address or <tt > null< / tt > if the user is not an entry in the roster .
returns the presence info for a particular user . if the user is offline or if no presence data is available ( such as when you are not subscribed to the user s presence updates ) unavailable presence will be returned . <p > <p / > if the user has several presences ( one for each resource ) then the presence with highest priority will be returned . if multiple presences have the same priority the one with the most available presence mode will be returned . in order that s { @link org . jivesoftware . smack . packet . presence . mode#chat free to chat } { @link org . jivesoftware . smack . packet . presence . mode#available available } { @link org . jivesoftware . smack . packet . presence . mode#away away } { @link org . jivesoftware . smack . packet . presence . mode#xa extended away } and { @link org . jivesoftware . smack . packet . presence . mode#dnd do not disturb } . <p > <p / > note that presence information is received asynchronously . so just after logging in to the server presence values for users in the roster may be unavailable even if they are actually online . in other words the value returned by this method should only be treated as a snapshot in time and may not accurately reflect other user s presence instant by instant . if you need to track presence over time such as when showing a visual representation of the roster consider using a { @link rosterlistener } .
returns the presence info for a particular user s resource or unavailable presence if the user is offline or if no presence information is available such as when you are not subscribed to the user s presence updates .
returns an iterator ( of presence objects ) for all of a user s current presences or an unavailable presence if the user is unavailable ( offline ) or if no presence information is available such as when you are not subscribed to the user s presence updates .
returns the key to use in the presencemap for a fully qualified xmpp id . the roster can contain any valid address format such us domain / resource user@domain or user@domain / resource . if the roster contains an entry associated with the fully qualified xmpp id then use the fully qualified xmpp id as the key in presencemap otherwise use the bare address . note : when the key in presencemap is a fully qualified xmpp id the userpresences is useless since it will always contain one entry for the user .
changes the presence of available contacts offline by simulating an unavailable presence sent from the server . after a disconnection every presence is set to offline .
fires roster changed event to roster listeners indicating that the specified collections of contacts have been added updated or deleted from the roster .
sets the digest value using a connection id and password . password digests offer a more secure alternative for authentication compared to plain text . the digest is the hex - encoded sha - 1 hash of the connection id plus the user s password . if the digest and password are set digest authentication will be used . if only one value is set the respective authentication mode will be used .
generates the resources
sets the value stored in this map entry . <p / > this map entry is not connected to a map so only the local data is changed .
/ * ( non - javadoc )
/ * ( non - javadoc )
creates a new presenceevent
creates a new presenceevent
factory method to create a synchronized map .
-----------------------------------------------------------------------
tries to set the volume of the playerrequest . <p > if the player supports the change of the volume it will create a new playerrequest and return it if not it returns this . < / p >
returns a list of resources that can be added to an already existing event . <p > this causes the addon to block the event in the outputplugin lifecycle of the event .
helper method for playlistselector
creates a new playerrequest . <p > the resulting playerrequest is not permanent which means that it will mute all other sound but is limited to 10 minutes . <br > for this method to return a non - empty optional the following criteria must be met : <br > <ul > <li > the player must exist and be support the standard defined through the sdk< / li > <li > the players - capabilities must allow requests from outside< / li > <li > the players - capabilities must allow a requests with specified a specified playlist / trackinfo< / li > < / ul >
creates a new playerrequest . <p > the resulting playerrequest is not permanent which means that it will mute all other sound but is limited to 10 minutes . <br > for this method to return a non - empty optional the following criteria must be met : <br > <ul > <li > the player must exist and be support the standard defined through the sdk< / li > <li > the players - capabilities must allow requests from outside< / li > <li > the players - capabilities must allow a requests with specified a specified playlist / trackinfo< / li > < / ul >
creates a new playerrequest . <p > for this method to return a non - empty optional the following criteria must be met : <br > <ul > <li > the player must exist and be support the standard defined through the sdk< / li > <li > the players - capabilities must allow requests from outside< / li > <li > the players - capabilities must allow a requests with specified a specified playlist / trackinfo< / li > < / ul >
returns the time passed if available
the listener will always be called when the properties - file changes .
initializes properties in the addon . creates new properties file using default properties .
reloads the propertiesfile into the properties object
parses stream error packets .
parse the available sasl mechanisms reported from the server .
parse the available compression methods reported from the server .
parses a packet extension sub - packet .
decodes a string into an object of the specified type . if the object type is not supported null will be returned .
creates a new startrequest
creates a new startrequest
creates a new startrequest
creates a new startrequest
creates a new startrequest
verifies that the startmusicrequest is correct and checks whether the you are meant to react to it
creates a filter where valid when an object in a collection is the <strong > same as< / strong > the base object .
creates a filter where valid when an object in a collection is the <strong > equal to< / strong > the base object .
creates a filter where valid when an comparable in a collection is considered <strong > less than< / strong > the base object .
creates a filter where valid when an object in a collection is considered <strong > less than< / strong > the base object based on the given comparator .
returns the playbackstate from the resource
returns the secret key for a sub - domain . if no key was found then the default secret key will be returned .
returns if we want components to be able to connect multiple times to the same jid . this is a custom openfire extension and will not work with any other xmpp server . other xmpp servers should ignore this extra setting .
gets the value mapped to the key specified .
puts a key - value mapping into this map . neither the key nor the value may be null .
removes the specified mapping from this map .
returns a set view of this map s entries . an iterator returned entry is valid until <code > next () < / code > is called again . the <code > setvalue () < / code > method on the <code > toarray< / code > entries has no effect .
returns a set view of this map s keys .
returns a collection view of this map s values .
purges stale mappings from this map . <p / > note that this method is not synchronized! special care must be taken if for instance you want stale mappings to be removed on a periodic basis by some background thread .
purges the specified reference .
gets the entry mapped to the key specified .
gets the hash code for a mapentry . subclasses can override this for example to use the identityhashcode .
creates a referenceentry instead of a hashentry .
replaces the superclass method to store the state of this class . <p / > serialization is not one of the jdk s nicest topics . normal serialization will initialise the superclass before the subclass . sometimes however this isn t what you want as in this case the <code > put () < / code > method on read can be affected by subclass state . <p / > the solution adopted here is to serialize the state data of this class in this protected method . this method must be called by the <code > writeobject () < / code > of the first serializable subclass . <p / > subclasses may override if they have a specific field that must be present on read before this implementation will work . generally the read determines what must be serialized here if anything .
replaces the superclassm method to read the state of this class . <p / > serialization is not one of the jdk s nicest topics . normal serialization will initialise the superclass before the subclass . sometimes however this isn t what you want as in this case the <code > put () < / code > method on read can be affected by subclass state . <p / > the solution adopted here is to deserialize the state data of this class in this protected method . this method must be called by the <code > readobject () < / code > of the first serializable subclass . <p / > subclasses may override if the subclass has a specific field that must be present before <code > put () < / code > or <code > calculatethreshold () < / code > will work correctly .
controls whether the fired event should be dispatched to all the listeners . this method should execute quickly
sets the presence
updates the boolean whether it is the mode vague
sends the specified text as a message to the other chat participant . this is a convenience method for :
delivers a message directly to this chat which will add the message to the collector and deliver it to all listeners registered with the chat . this is used by the connection class to deliver messages without a thread id .
generates a script .
loads and tests the configuration from configuration properties file . the default configuration file name is de / vandermeer / execs / configuration . properties . the file name can be overwritten using the -- property - file cli option . the method will also test for some configuration keys to exist and fail if they are not defined .
sets target for generation and initializes an stg object from an stg template file . the default template file name is de / vandermeer / execs / executable - script . stg . this default can be overwritten using the property stg . file in the configuration properties file . the default and the property file name can be overwritten using the -- stg - file cli option . the set target ( cli option -- target ) must be supported by the template file otherwise this method will fail .
initializes the application directory for the generator . there is no default set and no configuration property can be used . the application directory has to be set using the cli option -- application - directory . otherwise this method will fail .
loads a classmap from a property file . a classmap maps class names to script names . a class name must be an implementation of the executable application interface {
tests and if necessary creates an output directory . the root path is the current directory as given by the system property user . dir . the created output directory has the name of the specified target for the generator . the method fails if the output directory cannot be created or if it exists and is write protected .
loads properties from a file .
writes an st object to a file .
gets the first progress if found in the eventmodel
factory method to create a synchronized collection .
-----------------------------------------------------------------------
discover firerest services located in a range of ipv4 inetaddresses . e . g . the range of 256 addresses that starts with 10 . 0 . 1 . 128 ends with 10 . 0 . 2 . 127 .
( re - ) discover the service configuration
return the cached service configuration resolving the service if required .
-----------------------------------------------------------------------------------
returns the map of string key / value pairs of account attributes .
sets the account attributes . the map must only contain string key / value pairs .
returns the api used to manage the threadpool
creates a new stoprequest
verifies that the stopmusicrequest is correct and checks whether the you are meant to react to it
{
{
{
obtain a dse cluster instance .
{
{
obtain a dse session instance .
obtain a dse session instance .
{
adds a connection listener to this connection that will be notified when the connection closes or fails .
creates a new packet collector for this connection . a packet filter determines which packets will be accumulated by the collector . a packetcollector is more suitable to use than a { @link packetlistener } when you need to wait for a specific result .
registers a packet listener with this connection . a packet listener will be invoked only when an incoming packet is received . a packet filter determines which packets will be delivered to the listener . if the same packet listener is added again with a different filter only the new filter will be used .
registers a packet listener with this connection . the listener will be notified of every packet that this connection sends . a packet filter determines which packets will be delivered to the listener . note that the thread that writes packets will be used to invoke the listeners . therefore each packet listener should complete all operations quickly or use a different thread for processing .
process all packet listeners for sending packets .
registers a packet interceptor with this connection . the interceptor will be invoked every time a packet is about to be sent by this connection . interceptors may modify the packet to be sent . a packet filter determines which packets will be delivered to the interceptor .
process interceptors . interceptors may modify the packet that is about to be sent . since the thread that requested to send the packet will invoke all interceptors it is important that interceptors perform their work as soon as possible so that the thread does not remain blocked for a long period .
initialize the { @link #debugger } . you can specify a customized { @link smackdebugger } by setup the system property <code > smack . debuggerclass< / code > to the implementation .
creates the most suitable type .
generates a connection with the server and tries to authenticate . if an error occurs in any of the steps then a componentexception is thrown .
notification message that the connection with the server was lost unexpectedly . we will try to reestablish the connection for ever until the connection has been reestablished or this thread has been stopped .
adds an { @link iqresultlistener } that will be invoked when an iq result is sent to the server itself and is of type result or error . this is a nice way for the server to send iq packets to other xmpp entities and be waked up when a response is received back . <p >
rolls back the changes to the map .
retrieve the current thread id for use by the transaction code .
checks that this node is valid for the current thread
returns the key to which this map maps the specified value . returns null if the map contains no mapping for this value .
returns a set view of the mappings contained in this map . each element in the returned set is a map . entry . the set is backed by the map so changes to the map are reflected in the set and vice - versa . if the map is modified while an iteration over the set is in progress the results of the iteration are undefined . the set supports element removal which removes the corresponding mapping from the map via the iterator . remove set . remove removeall retainall and clear operations . it does not support the add or addall operations . <p >
returns a set view of the keys contained in this map . the set is backed by the map so changes to the map are reflected in the set and vice - versa . if the map is modified while an iteration over the set is in progress the results of the iteration are undefined . the set supports element removal which removes the corresponding mapping from the map via the iterator . remove set . remove removeall retainall and clear operations . it does not support the add or addall operations . <p >
returns a collection view of the values contained in this map . the collection is backed by the map so changes to the map are reflected in the collection and vice - versa . if the map is modified while an iteration over the collection is in progress the results of the iteration are undefined . the collection supports element removal which removes the corresponding mapping from the map via the iterator . remove collection . remove removeall retainall and clear operations . it does not support the add or addall operations . <p >
common remove logic ( remove by key or remove by value )
common get logic used to get by key or get by value
do the actual lookup of a piece of valid data
do the actual lookup of a piece of data
compare two objects
find the least node from a given node . very useful for starting a sorting iterator ...
find the most node from a given node .
get the next larger node from the specified node
get the next smaller ( previous ) node from the specified node
get the most valid node from the specified node
find the least valid node from a given node . very useful for starting a sorting iterator ...
copy the color from one node to another dealing with the fact that one or both nodes may in fact be null
is the specified node red? if the node does not exist no it s black thank you
is the specified black red? if the node does not exist sure it s black thank you
force a node ( if it exists ) red
force a node ( if it exists ) black
get a node s grandparent . mind you the node its parent or its grandparent may not exist . no problem
get a node s parent . mind you the node or its parent may not exist . no problem
get a node s right child . mind you the node may not exist . no problem
get a node s left child . mind you the node may not exist . no problem
is this node its parent s left child? mind you the node or its parent may not exist . no problem . if the node doesn t exist ... it s its non - existent parent s left child . if the node does exist but has no parent ... no we re not the non - existent parent s left child . otherwise ( both the specified node and its parent exist ) check .
is this node its parent s right child? mind you the node or its parent may not exist . no problem . if the node doesn t exist ... it s its non - existent parent s right child . if the node does exist but has no parent ... no we re not the non - existent parent s right child . otherwise ( both the specified node and its parent exist ) check .
do a rotate left . standard fare in the world of balanced trees
do a rotate right . standard fare in the world of balanced trees
complicated red - black insert stuff . based on sun s treemap implementation though it s barely recognizable any more
complicated red - black delete stuff . based on sun s treemap implementation though it s barely recognizable any more
complicated red - black delete stuff . based on sun s treemap implementation though it s barely recognizable any more . this rebalances the tree ( somewhat as red - black trees are not perfectly balanced -- perfect balancing takes longer )
swap two nodes ( except for their content ) taking care of special cases where one is the other s parent ... hey it happens .
check if an object is fit to be proper input ... has to be comparable if the comparator has not been set and non - null
insert a node by its value
returns true if this map contains a mapping for the specified key .
returns true if this map maps one or more keys to the specified value .
returns the value to which this map maps the specified key . returns null if the map contains no mapping for this key .
associates the specified value with the specified key in this map .
removes the mapping for this key from this map if present
removes all mappings from this map
returns a set view of the keys contained in this map . the set is backed by the map so changes to the map are reflected in the set and vice - versa . if the map is modified while an iteration over the set is in progress the results of the iteration are undefined . the set supports element removal which removes the corresponding mapping from the map via the iterator . remove set . remove removeall retainall and clear operations . it does not support the add or addall operations .
returns a collection view of the values contained in this map . the collection is backed by the map so changes to the map are reflected in the collection and vice - versa . if the map is modified while an iteration over the collection is in progress the results of the iteration are undefined . the collection supports element removal which removes the corresponding mapping from the map via the iterator . remove collection . remove removeall retainall and clear operations . it does not support the add or addall operations .
it is very rare that this method would be required . you probably want to use entryset instead . this method returns all entry s in this map no matter what its transactional status .
copy all entries including transaction statuses from this map into the supplied map . do not use this method unless you know exactly what you are doing . the auto commit flag of the supplied map may be changed as a result of calling this method check that this is valid first .
gets the entry corresponding to the specified key ; if no such entry exists returns the entry for the least key greater than the specified key ; if no such entry exists ( i . e . the greatest key in the tree is less than the specified key ) returns <tt > null< / tt > .
/ * remove operation with a flag so we can tell coherence if the remove was caused by cache internal processing such as eviction or loading
clears all entries out of cache where the entries are older than the maximum defined age .
removes the least recently used elements if the cache size is greater than or equal to the maximum allowed size until the cache is at least 10% empty .
when the bundle gets activated we retrieve the osgi properties .
{
{
{
asks the player for more information about the playlist . <p > this method may block for 1 second .
asks the player for more information about the specified playlist and creates a playerrequest with the answer .
creates a new playlistselector . <p > for this method to return a non - empty optional the following criteria must be met : <br > <ul > <li > the player must exist< / li > <li > the players - capabilities must allow requests from outside< / li > <li > the players - capabilities must allow a requests with specified a specified playlist< / li > <li > the players - capabilities signal its broadcasting playlists< / li > < / ul >
creates a new roster store on disk
opens a roster store
method to get existing [ key1 key2 ] value or create new one if it s absent . needs implementation of create ( key1 key2 ) in order to work
return list of inetaddress for localhost that are not loopback addresses ( e . g . 127 . 0 . 0 . 1 )
scan a range of inetaddresses starting with the given address
return first address on subnet containing given address
factory method to create a synchronized map .
-----------------------------------------------------------------------
{
<p > reads a document from the given <code > file< / code > < / p >
<p > reads a document from the given <code > url< / code > < / p >
<p > reads a document from the given url or filename . < / p > <p / > <p / > if the systemid contains a <code > : < / code > character then it is assumed to be a url otherwise its assumed to be a file name . if you want finer grained control over this mechansim then please explicitly pass in either a { @link url } or a { @link file } instance instead of a { @link string } to denote the source of the document . < / p >
<p > reads a document from the given <code > reader< / code > < / p >
<p > reads a document from the given array of characters < / p >
<p > reads a document from the given stream < / p >
<p > reads a document from the given <code > reader< / code > < / p >
-------------------------------------------------------------------------
factory method to create a synchronized map .
-----------------------------------------------------------------------
retruns true if any of these arguments is already existing and would be overwritten otherwise retruns false . the method also returns true if everything is null except the albumcover - format ( maybe known in advance ) .
retruns true if any of these arguments is already existing and would be overwritten otherwise retruns false . the method also returns true if everything is null except the albumcover - format ( maybe known in advance ) .
returns a trackinfo if some information was added and not overwritten ( see isnew ) and a change occurred .
exports the trackinfo to a hashmap
returns the optional trackinfo if the hashmap contains no malformed data
creates a trackinfo from the resourcemodel
a new map with just [ key -- &gt ; value ] maplet
sets the jar filter for the executor . this filter can contain any name of a jar file that should be considered during search . if not set no filter is applied . if the argument is null no filter is used . otherwise all strings in the argument are used as jar files and only those jar files will be used in a search . using filters can speed up the search process . filters can be set any time a new filter will overwrite an existing one ( using null will disable filtering ) .
adds a new application at runtime with name ( shortcut to start ) and related class .
adds a set of application at runtime as in all found applications that can be executed
main method
executes an application .
prints a list of pre - registered and found applications .
prints usage information to standard out .
public main to start the application executor .
creates a new muteevent
creates a new muteevent will mute everything
invalidate and refresh the cache <p / > this is blocking and returns when the cache has been updated
given a schema name get the associated goodwillschema . this method tries hard to find it i . e . it will refresh the cache if the schema is not in the cache .
writes the given lines to the given file if possible .
tests if the class is run from an executable jar .
adds a new option to cli parser and option list .
get the schema as a collection of fields . we guarantee the ordering by field id .
given a name return the field matching the name .
returns the package name for a jar entry .
{ @inheritdoc }
{ @inheritdoc }
{ @inheritdoc }
maps the content of the base map to its values .
/ * ( non - javadoc )
/ * ( non - javadoc )
create the eventlistener .
sets the supplied state for this iterativecallback .
public wrapper for the iteration
do the actual iteration
gets the first trackinfo if found in the eventmodel
exports the progress
creates a progress - object from the resourcemodel
return an red image with the given text auto - sized to fit the current imagewidthximageheight
return image from given url .
load json from given file resource . this is a convenient equivalent to getjson () with a file url .
http get json from given url resource .
property principals are stored with keys of the form _pp_<principal >
content tokens activate aces for a user that holds the content token . the token is signed by the secret key associated with the target object / acl and the token is token content item is then returned for the caller to save .
take key and value pairs from source and create map from value to key in target .
new empty collection with similar type to source . the known concrete types replicated exactly are {
creates cartesian product of two lists .
sets the thread running
execute
/ * ( non - javadoc )
returns the thread to the pool .
factory method to create a synchronized map .
creates a new endedevent
returns the current played track or null
gets the name ( optional ) <p > playlist doesn t need to have a name < / p >
returns the associated data ( not really specified specified by implementation )
updates the trackinfo - object
shuffles the playlist and returns the shuffled playlist so the original stays intact . only the part of the playlist after the current position is shuffled .
returns true if all the active playbackmodes are supported
exports the playlist to a hashmap
constructs ( if no errors were found ) the playlist from the resource
decodes four bytes from array <var > source< / var > and writes the resulting bytes ( up to three of them ) to <var > destination< / var > . the source and destination arrays can be manipulated anywhere along their length by specifying <var > srcoffset< / var > and <var > destoffset< / var > . this method does not check to make sure your arrays are large enough to accomodate <var > srcoffset< / var > + 4 for the <var > source< / var > array or <var > destoffset< / var > + 3 for the <var > destination< / var > array . this method returns the actual number of bytes that were converted from the base64 encoding . <p > this is the lowest level of the decoding methods with all possible parameters . < / p >
takes the original request and starts the batching .
creates a trackinfo from the resourcemodel
creates a new stopevent
creates a new stopevent
returns the name portion of a xmpp address . for example for the address matt@jivesoftware . com / smack matt would be returned . if no username is present in the address the empty string will be returned .
escapes all necessary characters in the string so that it can be used in an xml doc .
hashes a string using the sha - 1 algorithm and returns the result as a string of hexadecimal numbers . this method is synchronized to avoid excessive messagedigest object creation . if calling this method becomes a bottleneck in your code you may wish to maintain a pool of messagedigest objects instead of using this method . <p > a hash is a one - way function -- that is given an input an output is easily computed . however given the output the input is almost impossible to compute . this is useful for passwords since we can store the hash and a hacker will then have a very hard time determining the original password .
turns an array of bytes into a string representing each byte as an unsigned hex number . <p > method by santeri paavolainen helsinki finland 1996<br > ( c ) santeri paavolainen helsinki finland 1996<br > distributed under lgpl .
builds and sends the <tt > auth< / tt > stanza to the server . note that this method of authentication is not recommended since it is very inflexable . use { @link #authenticate ( string string callbackhandler ) } whenever possible .
same as { @link #authenticate ( string string string string ) } but with the hostname used as the servicename . <p > kept for backward compatibility only .
builds and sends the <tt > auth< / tt > stanza to the server . the callback handler will handle any additional information such as the authentication id or realm if it is needed .
the server is challenging the sasl mechanism for the stanza he just sent . send a response to the server s challenge .
create a json representation of the goodwillschemafield . it will always contain the name type and position . description and sql attributes are however optional .
pretty print the sql type . todo : add layer of abstraction too netezza specific
main method for outputplugin runs the data - conversion and output - renderer
handles an event from osgi and places it in the appropriate queue .
used only for testing
set a property . the property will only be set if writable . if the property or this athorizable is read only nothing will happen .
remove the property .
add a principal to this authorizable .
remove a principal from this authorizable .
@throws componentexception
creates a new event object
notification that the root window is closing . stop listening for received and transmitted packets .
factory method to create a synchronized map .
{ @inheritdoc }
todo : unit test
helper method to get an instance of { @link sessionidentifier } .
call this method when you have encountered the user
invoked when an activator - event occurs .
{ @inheritdoc }
todo : unit test
todo : unit test
todo : unit test
todo : unit test
/ * ( non - javadoc )
/ * ( non - javadoc )
gets whether the request is permanent ( = permanent resource is available and true )
returns true if the resource is true otherwise returns false
sets the name of the group . changing the group s name is like moving all the group entries of the group to a new group specified by the new name . since this group won t have entries it will be removed from the roster . this means that all the references to this object will be invalid and will need to be updated to the new group specified by the new name .
returns the roster entry associated with the given xmpp address or <tt > null< / tt > if the user is not an entry in the group .
adds a roster entry to this group . if the entry was unfiled then it will be removed from the unfiled list and will be added to this group . note that this is an asynchronous call -- smack must wait for the server to receive the updated roster .
gets the value mapped to the key specified .
checks whether the map contains the specified key .
checks whether the map contains the specified value .
puts a key - value mapping into this map .
puts all the values from the specified map into this map . <p / > this implementation iterates around the specified map and uses { @link #put ( object object ) } .
removes the specified mapping from this map .
clears the map resetting the size to zero and nullifying references to avoid garbage collection issues .
gets the hash code for the key specified . this implementation uses the additional hashing routine from jdk1 . 4 . subclasses can override this to return alternate hash codes .
compares two keys in internal converted form to see if they are equal . this implementation uses the equals method . subclasses can override this to match differently .
compares two values in external form to see if they are equal . this implementation uses the equals method and assumes neither value is null . subclasses can override this to match differently .
gets the entry mapped to the key specified . <p / > this method exists for subclasses that may need to perform a multi - step process accessing the entry . the public methods in this class don t use this method to gain a small performance boost .
updates an existing key - value mapping to change the value . <p / > this implementation calls <code > setvalue () < / code > on the entry . subclasses could override to handle changes to the map .
reuses an existing key - value mapping storing completely new data . <p / > this implementation sets all the data fields on the entry . subclasses could populate additional entry fields .
adds a new key - value mapping into this map . <p / > this implementation calls <code > createentry () < / code > <code > addentry () < / code > and <code > checkcapacity () < / code > . it also handles changes to <code > modcount< / code > and <code > size< / code > . subclasses could override to fully control adds to the map .
removes a mapping from the map . <p / > this implementation calls <code > removeentry () < / code > and <code > destroyentry () < / code > . it also handles changes to <code > modcount< / code > and <code > size< / code > . subclasses could override to fully control removals from the map .
removes an entry from the chain stored in a particular index . <p / > this implementation removes the entry from the data storage table . the size is not updated . subclasses could override to handle changes to the map .
kills an entry ready for the garbage collector . <p / > this implementation prepares the hashentry for garbage collection . subclasses can override this to implement caching ( override clear as well ) .
checks the capacity of the map and enlarges it if necessary . <p / > this implementation uses the threshold to check if the map needs enlarging
changes the size of the data structure to the capacity proposed .
calculates the new capacity of the map . this implementation normalizes the capacity to a power of two .
gets the <code > next< / code > field from a <code > hashentry< / code > . used in subclasses that have no visibility of the field .
gets an iterator over the map . changes made to the iterator affect this map . <p / > a mapiterator returns the keys in the map . it also provides convenient methods to get the key and value and set the value . it avoids the need to create an entryset / keyset / values object . it also avoids creating the map . entry object .
creates an entry set iterator . subclasses can override this to return iterators with different properties .
gets the keyset view of the map . changes made to the view affect this map . to simply iterate through the keys use { @link #mapiterator () } .
writes the map data to the stream . this method must be overridden if a subclass must be setup before <code > put () < / code > is used . <p / > serialization is not one of the jdk s nicest topics . normal serialization will initialise the superclass before the subclass . sometimes however this isn t what you want as in this case the <code > put () < / code > method on read can be affected by subclass state . <p / > the solution adopted here is to serialize the state data of this class in this protected method . this method must be called by the <code > writeobject () < / code > of the first serializable subclass . <p / > subclasses may override if they have a specific field that must be present on read before this implementation will work . generally the read determines what must be serialized here if anything .
reads the map data from the stream . this method must be overridden if a subclass must be setup before <code > put () < / code > is used . <p / > serialization is not one of the jdk s nicest topics . normal serialization will initialise the superclass before the subclass . sometimes however this isn t what you want as in this case the <code > put () < / code > method on read can be affected by subclass state . <p / > the solution adopted here is to deserialize the state data of this class in this protected method . this method must be called by the <code > readobject () < / code > of the first serializable subclass . <p / > subclasses may override if the subclass has a specific field that must be present before <code > put () < / code > or <code > calculatethreshold () < / code > will work correctly .
load a map from binary stream
the data isnt there . see the last writeutf for an example .
the data isnt there . see the last writeutf for an example .
this method is used to register the modules
internal initiation of addon - fake constructor comes before prepare
starts a reconnection mechanism if it was configured to do that . the algorithm is been executed when the first connection error is detected . <p / > the reconnection mechanism will try to reconnect periodically in this way : <ol > <li > first it will try 6 times every 10 seconds . <li > then it will try 10 times every 1 minute . <li > finally it will try indefinitely every 5 minutes . < / ol >
fires listeners when a reconnection attempt has failed .
fires listeners when the connection will retry a reconnection . expressed in seconds .
